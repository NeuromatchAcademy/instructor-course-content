
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 3: “Why” models — Neuromatch Academy: Computational Neuroscience (instructor's version)</title>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-logo-square-4xp.jpg" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W1D1_Tutorial4.html" rel="next" title="Tutorial 4: Model Discussions"/>
<link href="W1D1_Tutorial2.html" rel="prev" title="Tutorial 2: “How” models"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
<div class="bd-sidebar__content">
<div class="bd-sidebar__top"><div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
<img alt="logo" class="logo" src="../../../_static/nma-logo-square-4xp.jpg"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Computational Neuroscience (instructor's version)</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../instructor/intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox">
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox">
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</input></li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using discord
    </a>
</li>
</ul>
</input></li>
</ul>
<p class="caption">
<span class="caption-text">
  Intro to Modeling
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Model Types (W1D1)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2">
<a class="reference internal" href="W1D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D1_Tutorial1.html">
     Tutorial 1: “What” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D1_Tutorial2.html">
     Tutorial 2: “How” models
    </a>
</li>
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 3: “Why” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D1_Tutorial4.html">
     Tutorial 4: Model Discussions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_ModelingPractice/chapter_title.html">
   Modeling Practice (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelingPractice/instructor/W1D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelingPractice/instructor/W1D2_Tutorial1.html">
     Tutorial 1: Framing the Question
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelingPractice/instructor/W1D2_Outro.html">
     Outro
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_ModelFitting/chapter_title.html">
   Model Fitting (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial1.html">
     Tutorial 1: Linear regression with MSE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial2.html">
     Tutorial 2: Linear regression with MLE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial3.html">
     Tutorial 3: Confidence intervals and bootstrapping
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial4.html">
     Tutorial 4: Multiple linear regression and polynomial regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial5.html">
     Tutorial 5: Model Selection: Bias-variance trade-off
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial6.html">
     Tutorial 6: Model Selection: Cross-validation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/chapter_title.html">
   Generalized Linear Models (W1D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/instructor/W1D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/instructor/W1D4_Tutorial1.html">
     Tutorial 1: GLMs for Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/instructor/W1D4_Tutorial2.html">
     Tutorial 2: Classifiers and regularizers
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/instructor/W1D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/chapter_title.html">
   Dimensionality Reduction (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Tutorial1.html">
     Tutorial 1: Geometric view of data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Tutorial2.html">
     Tutorial 2: Principal Component Analysis
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Tutorial3.html">
     Tutorial 3: Dimensionality Reduction &amp; Reconstruction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Tutorial4.html">
     Tutorial 4:  Nonlinear Dimensionality Reduction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_DeepLearning/chapter_title.html">
   Deep Learning (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Tutorial3.html">
     Tutorial 3: Building and Evaluating Normative Encoding Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Tutorial4.html">
     Bonus Tutorial: Diving Deeper into Decoding &amp; Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Bonus_Autoencoders/chapter_title.html">
   Autoencoders (Bonus)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial1.html">
     Tutorial 1: Intro to Autoencoders
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial2.html">
     Tutorial 2: Autoencoder extensions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial3.html">
     Tutorial 3: Autoencoders applications
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Outro.html">
     Outro
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/MachineLearning.html">
   Machine Learning Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_LinearSystems/chapter_title.html">
   Linear Systems (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial1.html">
     Tutorial 1: Linear dynamical systems
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial2.html">
     Tutorial 2: Markov Processes
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial3.html">
     Tutorial 3: Combining determinism and stochasticity
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial4.html">
     Tutorial 4: Autoregressive models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/chapter_title.html">
   Biological Neuron Models (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial1.html">
     Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial2.html">
     Tutorial 2: Effects of Input Correlation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial3.html">
     Tutorial 3: Synaptic transmission - Models of static and dynamic synapses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial4.html">
     Bonus Tutorial: Spike-timing dependent plasticity (STDP)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_DynamicNetworks/chapter_title.html">
   Dynamic Networks (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial1.html">
     Tutorial 1: Neural Rate Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial2.html">
     Tutorial 2: Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial3.html">
     Bonus Tutorial: Extending the Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/DynamicalSystems.html">
   Dynamical Systems Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Stochastic Processes
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_BayesianDecisions/chapter_title.html">
   Bayesian Decisions (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial1.html">
     Tutorial 1: Bayes with a binary hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial2.html">
     Tutorial 2: Bayesian inference and decisions with continuous hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial3.html">
     Bonus Tutorial : Fitting to data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_HiddenDynamics/chapter_title.html">
   Hidden Dynamics (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial1.html">
     Tutorial 1: Sequential Probability Ratio Test
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial2.html">
     Tutorial 2: Hidden Markov Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial3.html">
     Tutorial 3: The Kalman Filter
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial4.html">
     Bonus Tutorial 4: The Kalman Filter, part 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial5.html">
     Bonus Tutorial 5: Expectation Maximization for spiking neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_OptimalControl/chapter_title.html">
   Optimal Control (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial1.html">
     Tutorial 1: Optimal Control for Discrete States
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial2.html">
     Tutorial 2: Optimal Control for Continuous State
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/chapter_title.html">
   Reinforcement Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial4.html">
     Tutorial 4: From Reinforcement Learning to Planning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D5_NetworkCausality/chapter_title.html">
   Network Causality (W3D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial1.html">
     Tutorial 1: Interventions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial2.html">
     Tutorial 2: Correlations
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial3.html">
     Tutorial 3: Simultaneous fitting/regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial4.html">
     Tutorial 4: Instrumental Variables
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/StochasticProcesses.html">
   Stochastic Processes Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction to projects
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through4.html">
     Modeling Steps 1 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through10.html">
     Modeling Steps 5 - 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModel.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProject.html">
     Example Data Project: the Train Illusion
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/datasets_overview.html">
   Datasets
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/neurons.html">
     Neurons
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/neurons_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/fMRI.html">
     fMRI
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/fMRI_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/ECoG.html">
     ECoG
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/ECoG_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/behavior.html">
     Behavior
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
<label for="toctree-checkbox-24">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/behavior_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/theory.html">
     Theory
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
<label for="toctree-checkbox-25">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/theory/README.html">
       Guide
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_templates.html">
   Project Templates
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/project_2020_highlights.html">
   Projects 2020
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
<label for="toctree-checkbox-26">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/neurons.html">
     Neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/theory.html">
     Theory
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/behavior.html">
     Behavior
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/fMRI.html">
     fMRI
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/eeg.html">
     EEG
    </a>
</li>
</ul>
</li>
</ul>
</div>
</nav></div>
<div class="bd-sidebar__bottom">
<!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="headerbtn" data-placement="right" data-toggle="tooltip" for="__navigation" title="Toggle navigation">
<span class="headerbtn__icon-container">
<i class="fas fa-bars"></i>
</span>
</label>
</div>
<div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
<button aria-label="Launch interactive content" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-rocket"></i>
</button>
<div class="menu-dropdown__content">
<ul>
</ul>
</div>
</div>
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="menu-dropdown menu-dropdown-repository-buttons">
<button aria-label="Source repositories" class="headerbtn menu-dropdown__trigger">
<i class="fab fa-github"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="headerbtn__text-container">repository</span>
</a>
</li>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content/issues/new?title=Issue%20on%20page%20%2Ftutorials/W1D1_ModelTypes/instructor/W1D1_Tutorial3.html&amp;body=Your%20issue%20content%20here." title="Open an issue">
<span class="headerbtn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="headerbtn__text-container">open issue</span>
</a>
</li>
</ul>
</div>
</div>
<div class="menu-dropdown menu-dropdown-download-buttons">
<button aria-label="Download this page" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-download"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W1D1_ModelTypes/instructor/W1D1_Tutorial3.ipynb" title="Download source file">
<span class="headerbtn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="headerbtn__text-container">.ipynb</span>
</a>
</li>
<li>
<button class="headerbtn" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="headerbtn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="headerbtn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
</div>
<label class="headerbtn headerbtn-page-toc" for="__page-toc">
<span class="headerbtn__icon-container">
<i class="fas fa-list"></i>
</span>
</label>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
    </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 3: “Why” models
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-why-models">
     Video 1: “Why” models
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#download-data">
     Download Data
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-optimization-and-information">
   Section 1: Optimization and Information
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-computing-entropy">
     Coding Exercise 1: Computing Entropy
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-information-neurons-and-spikes">
   Section 2: Information, neurons, and spikes
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-entropy-of-different-distributions">
     Video 2: Entropy of different distributions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
</a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-calculate-entropy-of-isi-distributions-from-data">
   Section 3: Calculate entropy of ISI distributions from data
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-1-computing-probabilities-from-histogram">
     Section 3.1: Computing probabilities from histogram
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-probabilities-from-histogram">
       Video 3: Probabilities from histogram
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-1-probability-mass-function">
       Coding Exercise 3.1: Probability Mass Function
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-2-calculating-entropy-from-pmf">
     Section 3.2: Calculating entropy from pmf
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-calculating-entropy-from-pmf">
       Video 4: Calculating entropy from pmf
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-3-2-entropy-of-neurons">
       Interactive Demo 3.2: Entropy of neurons
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-reflecting-on-why-models">
   Section 4: Reflecting on why models
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-3-reflecting-on-how-models">
     Think! 3: Reflecting on how models
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-summary-of-model-types">
     Video 5: Summary of model types
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#notation">
   Notation
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus">
   Bonus
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-section-1-the-foundations-for-entropy">
     Bonus Section 1: The foundations for Entropy
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 3: “Why” models</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 3: “Why” models
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-why-models">
     Video 1: “Why” models
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#download-data">
     Download Data
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-optimization-and-information">
   Section 1: Optimization and Information
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-computing-entropy">
     Coding Exercise 1: Computing Entropy
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-information-neurons-and-spikes">
   Section 2: Information, neurons, and spikes
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-entropy-of-different-distributions">
     Video 2: Entropy of different distributions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
</a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-calculate-entropy-of-isi-distributions-from-data">
   Section 3: Calculate entropy of ISI distributions from data
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-1-computing-probabilities-from-histogram">
     Section 3.1: Computing probabilities from histogram
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-probabilities-from-histogram">
       Video 3: Probabilities from histogram
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-1-probability-mass-function">
       Coding Exercise 3.1: Probability Mass Function
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-2-calculating-entropy-from-pmf">
     Section 3.2: Calculating entropy from pmf
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-calculating-entropy-from-pmf">
       Video 4: Calculating entropy from pmf
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-3-2-entropy-of-neurons">
       Interactive Demo 3.2: Entropy of neurons
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-reflecting-on-why-models">
   Section 4: Reflecting on why models
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-3-reflecting-on-how-models">
     Think! 3: Reflecting on how models
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-summary-of-model-types">
     Video 5: Summary of model types
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#notation">
   Notation
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus">
   Bonus
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-section-1-the-foundations-for-entropy">
     Bonus Section 1: The foundations for Entropy
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/main/tutorials/W1D1_ModelTypes/instructor/W1D1_Tutorial3.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/W1D1_ModelTypes/instructor/W1D1_Tutorial3.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<div class="section" id="tutorial-3-why-models">
<h1>Tutorial 3: “Why” models<a class="headerlink" href="#tutorial-3-why-models" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 1, Day 1: Model Types</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Matt Laporte, Byron Galbraith, Konrad Kording</p>
<p><strong>Content reviewers:</strong> Dalin Guo, Aishwarya Balwani, Madineh Sarvestani, Maryam Vaziri-Pashkam, Michael Waskom, Ella Batty</p>
<p><strong>Post-production team:</strong> Gagana B, Spiros Chavlis</p>
<p>We would like to acknowledge <a class="reference external" href="https://www.nature.com/articles/s41586-019-1787-x">Steinmetz <em>et al.</em> (2019)</a> for sharing their data, a subset of which is used here.</p>
<p><strong>Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs</strong></p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p></div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing of tutorial: 45 minutes</em></p>
<p>This is tutorial 3 of a 3-part series on different flavors of models used to understand neural data. In parts 1 and 2 we explored mechanisms that would produce the data. In this tutorial we will explore models and techniques that can potentially explain <em>why</em> the spiking data we have observed is produced the way it is.</p>
<p>To understand why different spiking behaviors may be beneficial, we will learn about the concept of entropy. Specifically, we will:</p>
<ul class="simple">
<li><p>Write code to compute formula for entropy, a measure of information</p></li>
<li><p>Compute the entropy of a number of toy distributions</p></li>
<li><p>Compute the entropy of spiking activity from the Steinmetz dataset</p></li>
</ul>
<div class="section" id="tutorial-slides">
<h2>Tutorial slides<a class="headerlink" href="#tutorial-slides" title="Permalink to this headline">¶</a></h2>
<p>These are the slides for the videos in all tutorials today</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<iframe allowfullscreen="" frameborder="0" height="480" src="https://mfr.ca-1.osf.io/render?url=https://osf.io/6dxwe/?direct%26mode=render%26action=download%26mode=render" width="854"></iframe>
</div></div>
</div>
</div>
<div class="section" id="video-1-why-models">
<h2>Video 1: “Why” models<a class="headerlink" href="#video-1-why-models" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "93af4f292bc74f858ecc99707e7e91f4"}
</script></div>
</div>
</div>
</div>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure Settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Figure Settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span> <span class="c1">#interactive display</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plotting-functions">
<h2>Plotting Functions<a class="headerlink" href="#plotting-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Plotting Functions</span>

<span class="k">def</span> <span class="nf">plot_pmf</span><span class="p">(</span><span class="n">pmf</span><span class="p">,</span><span class="n">isi_range</span><span class="p">):</span>
  <span class="sd">"""Plot the probability mass function."""</span>
  <span class="n">ymax</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.05</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pmf</span><span class="p">))</span>
  <span class="n">pmf_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pmf</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pmf</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">pmf_</span><span class="p">,</span> <span class="n">drawstyle</span><span class="o">=</span><span class="s2">"steps"</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">pmf_</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="s2">"pre"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Neuron </span><span class="si">{</span><span class="n">neuron_idx</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Inter-spike interval (s)"</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"Probability mass"</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">isi_range</span><span class="p">);</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">ymax</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="download-data">
<h2>Download Data<a class="headerlink" href="#download-data" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Download Data</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'https://osf.io/sy5xt/download'</span><span class="p">)</span>
<span class="k">if</span> <span class="n">r</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="mi">200</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'Could not download data'</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">steinmetz_spikes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">),</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="s1">'spike_times'</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_12292</span><span class="o">/</span><span class="mf">2315815098.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">io</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">import</span> <span class="nn">requests</span>
<span class="ne">----&gt; </span><span class="mi">4</span> <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'https://osf.io/sy5xt/download'</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="k">if</span> <span class="n">r</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="mi">200</span><span class="p">:</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span>   <span class="nb">print</span><span class="p">(</span><span class="s1">'Could not download data'</span><span class="p">)</span>

<span class="nn">~/anaconda3/lib/python3.8/site-packages/requests/api.py</span> in <span class="ni">get</span><span class="nt">(url, params, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">73</span>     <span class="s2">"""</span>
<span class="g g-Whitespace">     </span><span class="mi">74</span><span class="s2"> </span>
<span class="ne">---&gt; </span><span class="mi">75</span><span class="s2">     return request('get', url, params=params, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">76</span><span class="s2"> </span>
<span class="g g-Whitespace">     </span><span class="mi">77</span><span class="s2"> </span>

<span class="nn">~/anaconda3/lib/python3.8/site-packages/requests/api.py</span> in <span class="ni">request</span><span class="nt">(method, url, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">59</span><span class="s2">     # cases, and look like a memory leak in others.</span>
<span class="g g-Whitespace">     </span><span class="mi">60</span><span class="s2">     with sessions.Session() as session:</span>
<span class="ne">---&gt; </span><span class="mi">61</span><span class="s2">         return session.request(method=method, url=url, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">62</span><span class="s2"> </span>
<span class="g g-Whitespace">     </span><span class="mi">63</span><span class="s2"> </span>

<span class="nn">~/anaconda3/lib/python3.8/site-packages/requests/sessions.py</span> in <span class="ni">request</span><span class="nt">(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)</span>
<span class="g g-Whitespace">    </span><span class="mi">527</span><span class="s2">         }</span>
<span class="g g-Whitespace">    </span><span class="mi">528</span><span class="s2">         send_kwargs.update(settings)</span>
<span class="ne">--&gt; </span><span class="mi">529</span><span class="s2">         resp = self.send(prep, **send_kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">530</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">531</span><span class="s2">         return resp</span>

<span class="nn">~/anaconda3/lib/python3.8/site-packages/requests/sessions.py</span> in <span class="ni">send</span><span class="nt">(self, request, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">665</span><span class="s2">             # Redirect resolving generator.</span>
<span class="g g-Whitespace">    </span><span class="mi">666</span><span class="s2">             gen = self.resolve_redirects(r, request, **kwargs)</span>
<span class="ne">--&gt; </span><span class="mi">667</span><span class="s2">             history = [resp for resp in gen]</span>
<span class="g g-Whitespace">    </span><span class="mi">668</span><span class="s2">         else:</span>
<span class="g g-Whitespace">    </span><span class="mi">669</span><span class="s2">             history = []</span>

<span class="nn">~/anaconda3/lib/python3.8/site-packages/requests/sessions.py</span> in <span class="ni">&lt;listcomp&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">    </span><span class="mi">665</span><span class="s2">             # Redirect resolving generator.</span>
<span class="g g-Whitespace">    </span><span class="mi">666</span><span class="s2">             gen = self.resolve_redirects(r, request, **kwargs)</span>
<span class="ne">--&gt; </span><span class="mi">667</span><span class="s2">             history = [resp for resp in gen]</span>
<span class="g g-Whitespace">    </span><span class="mi">668</span><span class="s2">         else:</span>
<span class="g g-Whitespace">    </span><span class="mi">669</span><span class="s2">             history = []</span>

<span class="nn">~/anaconda3/lib/python3.8/site-packages/requests/sessions.py</span> in <span class="ni">resolve_redirects</span><span class="nt">(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">235</span><span class="s2">             else:</span>
<span class="g g-Whitespace">    </span><span class="mi">236</span><span class="s2"> </span>
<span class="ne">--&gt; </span><span class="mi">237</span><span class="s2">                 resp = self.send(</span>
<span class="g g-Whitespace">    </span><span class="mi">238</span><span class="s2">                     req,</span>
<span class="g g-Whitespace">    </span><span class="mi">239</span><span class="s2">                     stream=stream,</span>

<span class="nn">~/anaconda3/lib/python3.8/site-packages/requests/sessions.py</span> in <span class="ni">send</span><span class="nt">(self, request, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">685</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">686</span><span class="s2">         if not stream:</span>
<span class="ne">--&gt; </span><span class="mi">687</span><span class="s2">             r.content</span>
<span class="g g-Whitespace">    </span><span class="mi">688</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">689</span><span class="s2">         return r</span>

<span class="nn">~/anaconda3/lib/python3.8/site-packages/requests/models.py</span> in <span class="ni">content</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">836</span><span class="s2">                 self._content = None</span>
<span class="g g-Whitespace">    </span><span class="mi">837</span><span class="s2">             else:</span>
<span class="ne">--&gt; </span><span class="mi">838</span><span class="s2">                 self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''</span>
<span class="g g-Whitespace">    </span><span class="mi">839</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">840</span><span class="s2">         self._content_consumed = True</span>

<span class="nn">~/anaconda3/lib/python3.8/site-packages/requests/models.py</span> in <span class="ni">generate</span><span class="nt">()</span>
<span class="g g-Whitespace">    </span><span class="mi">758</span><span class="s2">             if hasattr(self.raw, 'stream'):</span>
<span class="g g-Whitespace">    </span><span class="mi">759</span><span class="s2">                 try:</span>
<span class="ne">--&gt; </span><span class="mi">760</span><span class="s2">                     for chunk in self.raw.stream(chunk_size, decode_content=True):</span>
<span class="g g-Whitespace">    </span><span class="mi">761</span><span class="s2">                         yield chunk</span>
<span class="g g-Whitespace">    </span><span class="mi">762</span><span class="s2">                 except ProtocolError as e:</span>

<span class="nn">~/anaconda3/lib/python3.8/site-packages/urllib3/response.py</span> in <span class="ni">stream</span><span class="nt">(self, amt, decode_content)</span>
<span class="g g-Whitespace">    </span><span class="mi">574</span><span class="s2">         else:</span>
<span class="g g-Whitespace">    </span><span class="mi">575</span><span class="s2">             while not is_fp_closed(self._fp):</span>
<span class="ne">--&gt; </span><span class="mi">576</span><span class="s2">                 data = self.read(amt=amt, decode_content=decode_content)</span>
<span class="g g-Whitespace">    </span><span class="mi">577</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">578</span><span class="s2">                 if data:</span>

<span class="nn">~/anaconda3/lib/python3.8/site-packages/urllib3/response.py</span> in <span class="ni">read</span><span class="nt">(self, amt, decode_content, cache_content)</span>
<span class="g g-Whitespace">    </span><span class="mi">517</span><span class="s2">             else:</span>
<span class="g g-Whitespace">    </span><span class="mi">518</span><span class="s2">                 cache_content = False</span>
<span class="ne">--&gt; </span><span class="mi">519</span><span class="s2">                 data = self._fp.read(amt) if not fp_closed else b""</span>
<span class="g g-Whitespace">    </span><span class="mi">520</span><span class="s2">                 if (</span>
<span class="g g-Whitespace">    </span><span class="mi">521</span><span class="s2">                     amt != 0 and not data</span>

<span class="nn">~/anaconda3/lib/python3.8/http/client.py</span> in <span class="ni">read</span><span class="nt">(self, amt)</span>
<span class="g g-Whitespace">    </span><span class="mi">456</span><span class="s2">             # Amount is given, implement using readinto</span>
<span class="g g-Whitespace">    </span><span class="mi">457</span><span class="s2">             b = bytearray(amt)</span>
<span class="ne">--&gt; </span><span class="mi">458</span><span class="s2">             n = self.readinto(b)</span>
<span class="g g-Whitespace">    </span><span class="mi">459</span><span class="s2">             return memoryview(b)[:n].tobytes()</span>
<span class="g g-Whitespace">    </span><span class="mi">460</span><span class="s2">         else:</span>

<span class="nn">~/anaconda3/lib/python3.8/http/client.py</span> in <span class="ni">readinto</span><span class="nt">(self, b)</span>
<span class="g g-Whitespace">    </span><span class="mi">500</span><span class="s2">         # connection, and the user is reading more bytes than will be provided</span>
<span class="g g-Whitespace">    </span><span class="mi">501</span><span class="s2">         # (for example, reading in 1k chunks)</span>
<span class="ne">--&gt; </span><span class="mi">502</span><span class="s2">         n = self.fp.readinto(b)</span>
<span class="g g-Whitespace">    </span><span class="mi">503</span><span class="s2">         if not n and b:</span>
<span class="g g-Whitespace">    </span><span class="mi">504</span><span class="s2">             # Ideally, we would raise IncompleteRead if the content-length</span>

<span class="nn">~/anaconda3/lib/python3.8/socket.py</span> in <span class="ni">readinto</span><span class="nt">(self, b)</span>
<span class="g g-Whitespace">    </span><span class="mi">667</span><span class="s2">         while True:</span>
<span class="g g-Whitespace">    </span><span class="mi">668</span><span class="s2">             try:</span>
<span class="ne">--&gt; </span><span class="mi">669</span><span class="s2">                 return self._sock.recv_into(b)</span>
<span class="g g-Whitespace">    </span><span class="mi">670</span><span class="s2">             except timeout:</span>
<span class="g g-Whitespace">    </span><span class="mi">671</span><span class="s2">                 self._timeout_occurred = True</span>

<span class="nn">~/anaconda3/lib/python3.8/ssl.py</span> in <span class="ni">recv_into</span><span class="nt">(self, buffer, nbytes, flags)</span>
<span class="g g-Whitespace">   </span><span class="mi">1239</span><span class="s2">                   "non-zero flags not allowed in calls to recv_into() on </span><span class="si">%s</span><span class="s2">" %</span>
<span class="g g-Whitespace">   </span><span class="mi">1240</span><span class="s2">                   self.__class__)</span>
<span class="ne">-&gt; </span><span class="mi">1241</span><span class="s2">             return self.read(nbytes, buffer)</span>
<span class="g g-Whitespace">   </span><span class="mi">1242</span><span class="s2">         else:</span>
<span class="g g-Whitespace">   </span><span class="mi">1243</span><span class="s2">             return super().recv_into(buffer, nbytes, flags)</span>

<span class="nn">~/anaconda3/lib/python3.8/ssl.py</span> in <span class="ni">read</span><span class="nt">(self, len, buffer)</span>
<span class="g g-Whitespace">   </span><span class="mi">1097</span><span class="s2">         try:</span>
<span class="g g-Whitespace">   </span><span class="mi">1098</span><span class="s2">             if buffer is not None:</span>
<span class="ne">-&gt; </span><span class="mi">1099</span><span class="s2">                 return self._sslobj.read(len, buffer)</span>
<span class="g g-Whitespace">   </span><span class="mi">1100</span><span class="s2">             else:</span>
<span class="g g-Whitespace">   </span><span class="mi">1101</span><span class="s2">                 return self._sslobj.read(len)</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-optimization-and-information">
<h1>Section 1: Optimization and Information<a class="headerlink" href="#section-1-optimization-and-information" title="Permalink to this headline">¶</a></h1>
<p><em>Remember that the notation section is located after the Summary for quick reference!</em></p>
<p>Neurons can only fire so often in a fixed period of time, as the act of emitting a spike consumes energy that is depleted and must eventually be replenished. To communicate effectively for downstream computation, the neuron would need to make good use of its limited spiking capability. This becomes an optimization problem:</p>
<p>What is the optimal way for a neuron to fire in order to maximize its ability to communicate information?</p>
<p>In order to explore this question, we first need to have a quantifiable measure for information. Shannon introduced the concept of entropy to do just that, and defined it as</p>
<div class="amsmath math notranslate nohighlight" id="equation-10d55fed-9528-4b1e-b2f3-e8e01a2ee448">
<span class="eqno">(7)<a class="headerlink" href="#equation-10d55fed-9528-4b1e-b2f3-e8e01a2ee448" title="Permalink to this equation">¶</a></span>\[\begin{equation}
H_b(X) = -\sum_{x\in X} p(x) \log_b p(x)
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(H\)</span> is entropy measured in units of base <span class="math notranslate nohighlight">\(b\)</span> and <span class="math notranslate nohighlight">\(p(x)\)</span> is the probability of observing the event <span class="math notranslate nohighlight">\(x\)</span> from the set of all possible events in <span class="math notranslate nohighlight">\(X\)</span>. See the Bonus Section 1 for a more detailed look at how this equation was derived.</p>
<p>The most common base of measuring entropy is <span class="math notranslate nohighlight">\(b=2\)</span>, so we often talk about <em>bits</em> of information, though other bases are used as well (e.g. when <span class="math notranslate nohighlight">\(b=e\)</span> we call the units <em>nats</em>).</p>
<p>First, let’s explore how entropy changes between some simple discrete probability distributions. In the rest of this tutorial we will refer to these as probability mass functions (PMF), where <span class="math notranslate nohighlight">\(p(x_i)\)</span> equals the <span class="math notranslate nohighlight">\(i^{th}\)</span> value in an array, and mass refers to how much of the distribution is contained at that value.</p>
<p>For our first PMF, we will choose one where all of the probability mass is located in the middle of the distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_bins</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># number of points supporting the distribution</span>
<span class="n">x_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># will be subdivided evenly into bins corresponding to points</span>

<span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">*</span><span class="n">x_range</span><span class="p">,</span> <span class="n">n_bins</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># bin edges</span>

<span class="n">pmf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_bins</span><span class="p">)</span>
<span class="n">pmf</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">pmf</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># middle point has all the mass</span>

<span class="c1"># Since we already have a PMF, rather than un-binned samples, `plt.hist` is not</span>
<span class="c1"># suitable. Instead, we directly plot the PMF as a step function to visualize</span>
<span class="c1"># the histogram:</span>
<span class="n">pmf_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pmf</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pmf</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># this is necessary to align plot steps with bin edges</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">pmf_</span><span class="p">,</span> <span class="n">drawstyle</span><span class="o">=</span><span class="s2">"steps"</span><span class="p">)</span>
<span class="c1"># `fill_between` provides area shading</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">pmf_</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="s2">"pre"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"x"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"p(x)"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">x_range</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>If we were to draw a sample from this distribution, we know exactly what we would get every time. Distributions where all the mass is concentrated on a single event are known as <em>deterministic</em>.</p>
<p>How much entropy is contained in a deterministic distribution? We will compute this in the next exercise.</p>
<div class="section" id="coding-exercise-1-computing-entropy">
<h2>Coding Exercise 1: Computing Entropy<a class="headerlink" href="#coding-exercise-1-computing-entropy" title="Permalink to this headline">¶</a></h2>
<p>Your first exercise is to implement a method that computes the entropy of a discrete probability distribution, given its mass function. Remember that we are interested in entropy in units of <em>bits</em>, so be sure to use the correct log function.</p>
<p>Recall that <span class="math notranslate nohighlight">\(\log(0)\)</span> is undefined. When evaluated at <span class="math notranslate nohighlight">\(0\)</span>, NumPy log functions (such as <code class="docutils literal notranslate"><span class="pre">np.log2</span></code>) return <code class="docutils literal notranslate"><span class="pre">np.nan</span></code> (“Not a Number”). By convention, these undefined terms— which correspond to points in the distribution with zero mass—are excluded from the sum that computes the entropy.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">entropy</span><span class="p">(</span><span class="n">pmf</span><span class="p">):</span>
  <span class="sd">"""Given a discrete distribution, return the Shannon entropy in bits.</span>

<span class="sd">  This is a measure of information in the distribution. For a totally</span>
<span class="sd">  deterministic distribution, where samples are always found in the same bin,</span>
<span class="sd">  then samples from the distribution give no more information and the entropy</span>
<span class="sd">  is 0.</span>

<span class="sd">  For now this assumes `pmf` arrives as a well-formed distribution (that is,</span>
<span class="sd">  `np.sum(pmf)==1` and `not np.any(pmf &lt; 0)`)</span>

<span class="sd">  Args:</span>
<span class="sd">    pmf (np.ndarray): The probability mass function for a discrete distribution</span>
<span class="sd">      represented as an array of probabilities.</span>
<span class="sd">  Returns:</span>
<span class="sd">    h (number): The entropy of the distribution in `pmf`.</span>

<span class="sd">  """</span>
  <span class="c1">############################################################################</span>
  <span class="c1"># Exercise for students: compute the entropy of the provided PMF</span>
  <span class="c1">#   1. Exclude the points in the distribution with no mass (where `pmf==0`).</span>
  <span class="c1">#      Hint: this is equivalent to including only the points with `pmf&gt;0`.</span>
  <span class="c1">#   2. Implement the equation for Shannon entropy (in bits).</span>
  <span class="c1">#  When ready to test, comment or remove the next line</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Exercise: implement the equation for entropy"</span><span class="p">)</span>
  <span class="c1">############################################################################</span>

  <span class="c1"># reduce to non-zero entries to avoid an error from log2(0)</span>
  <span class="n">pmf</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># implement the equation for Shannon entropy (in bits)</span>
  <span class="n">h</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># return the absolute value (avoids getting a -0 result)</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

<span class="c1"># Call entropy function and print result</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">entropy</span><span class="p">(</span><span class="n">pmf</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> bits"</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">entropy</span><span class="p">(</span><span class="n">pmf</span><span class="p">):</span>
  <span class="sd">"""Given a discrete distribution, return the Shannon entropy in bits.</span>

<span class="sd">  This is a measure of information in the distribution. For a totally</span>
<span class="sd">  deterministic distribution, where samples are always found in the same bin,</span>
<span class="sd">  then samples from the distribution give no more information and the entropy</span>
<span class="sd">  is 0.</span>

<span class="sd">  For now this assumes `pmf` arrives as a well-formed distribution (that is,</span>
<span class="sd">  `np.sum(pmf)==1` and `not np.any(pmf &lt; 0)`)</span>

<span class="sd">  Args:</span>
<span class="sd">    pmf (np.ndarray): The probability mass function for a discrete distribution</span>
<span class="sd">      represented as an array of probabilities.</span>
<span class="sd">  Returns:</span>
<span class="sd">    h (number): The entropy of the distribution in `pmf`.</span>
<span class="sd">  """</span>
  <span class="c1"># reduce to non-zero entries to avoid an error from log2(0)</span>
  <span class="n">pmf</span> <span class="o">=</span> <span class="n">pmf</span><span class="p">[</span><span class="n">pmf</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>

  <span class="c1"># implement the equation for Shannon entropy (in bits)</span>
  <span class="n">h</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pmf</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">pmf</span><span class="p">))</span>

  <span class="c1"># return the absolute value (avoids getting a -0 result)</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

<span class="c1"># Call entropy function and print result</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">entropy</span><span class="p">(</span><span class="n">pmf</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> bits"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We expect zero surprise from a deterministic distribution. If we had done this calculation by hand, it would simply be <span class="math notranslate nohighlight">\(-1\log_2 1 = -0=0\)</span>.</p>
<p>Note that changing the location of the peak (i.e. the point and bin on which all the mass rests) doesn’t alter the entropy. The entropy is about how predictable a sample is with respect to a distribution. A single peak is deterministic regardless of which point it sits on - the following plot shows a PMF that would also have zero entropy.</p>
<p>Execute this cell to visualize another PMF with zero entropy</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to visualize another PMF with zero entropy</span>
<span class="n">pmf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_bins</span><span class="p">)</span>
<span class="n">pmf</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># arbitrary point has all the mass</span>

<span class="n">pmf_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pmf</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pmf</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">pmf_</span><span class="p">,</span> <span class="n">drawstyle</span><span class="o">=</span><span class="s2">"steps"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">pmf_</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="s2">"pre"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"x"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"p(x)"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">x_range</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>What about a distribution with mass split equally between two points?</p>
<p>Execute this cell to visualize a PMF with split mass</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to visualize a PMF with split mass</span>

<span class="n">pmf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_bins</span><span class="p">)</span>
<span class="n">pmf</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">pmf</span><span class="p">)</span> <span class="o">//</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">pmf</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">pmf</span><span class="p">)</span> <span class="o">//</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="n">pmf_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pmf</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pmf</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">pmf_</span><span class="p">,</span> <span class="n">drawstyle</span><span class="o">=</span><span class="s2">"steps"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">pmf_</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="s2">"pre"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"x"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"p(x)"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">x_range</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Here, the entropy calculation is: <span class="math notranslate nohighlight">\(-(0.5 \log_2 0.5 + 0.5\log_2 0.5)=1\)</span></p>
<p>There is 1 bit of entropy. This means that before we take a random sample, there is 1 bit of uncertainty about which point in the distribution the sample will fall on: it will either be the first peak or the second one.</p>
<p>Likewise, if we make one of the peaks taller (i.e. its point holds more of the probability mass) and the other one shorter, the entropy will decrease because of the increased certainty that the sample will fall on one point and not the other: : <span class="math notranslate nohighlight">\(-(0.2 \log_2 0.2 + 0.8\log_2 0.8)\approx 0.72\)</span></p>
<p>Try changing the definition of the number and weighting of peaks, and see how the entropy varies.</p>
<p>If we split the probability mass among even more points, the entropy continues to increase. Let’s derive the general form for <span class="math notranslate nohighlight">\(N\)</span> points of equal mass, where <span class="math notranslate nohighlight">\(p_i=p=1/N\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-245d62d7-c247-44b2-98a8-72f75f38bd90">
<span class="eqno">(8)<a class="headerlink" href="#equation-245d62d7-c247-44b2-98a8-72f75f38bd90" title="Permalink to this equation">¶</a></span>\[\begin{align}
-\sum_i p_i \log_b p_i &amp;= -\sum_i^N \frac{1}{N} \log_b \frac{1}{N} \\
&amp;= -\log_b \frac{1}{N} \\
&amp;= \log_b N
\end{align}\]</div>
<p>If we have <span class="math notranslate nohighlight">\(N\)</span> discrete points, the <em>uniform distribution</em> (where all points have equal mass) is the distribution with the highest entropy: <span class="math notranslate nohighlight">\(\log_b N\)</span>. This upper bound on entropy is useful when considering binning strategies, as any estimate of entropy over <span class="math notranslate nohighlight">\(N\)</span> discrete points (or bins) must be in the interval <span class="math notranslate nohighlight">\([0, \log_b N]\)</span>.</p>
<p>Execute this cell to visualize a PMF of uniform distribution</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to visualize a PMF of uniform distribution</span>

<span class="n">pmf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_bins</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_bins</span>  <span class="c1"># [1/N] * N</span>

<span class="n">pmf_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pmf</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pmf</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">pmf_</span><span class="p">,</span> <span class="n">drawstyle</span><span class="o">=</span><span class="s2">"steps"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">pmf_</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="s2">"pre"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"x"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"p(x)"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">x_range</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Here, there are 50 points and the entropy of the uniform distribution is <span class="math notranslate nohighlight">\(\log_2 50\approx 5.64\)</span>. If we construct <em>any</em> discrete distribution <span class="math notranslate nohighlight">\(X\)</span> over 50 points (or bins) and calculate an entropy of <span class="math notranslate nohighlight">\(H_2(X)&gt;\log_2 50\)</span>, something must be wrong with our implementation of the discrete entropy computation.</p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-information-neurons-and-spikes">
<h1>Section 2: Information, neurons, and spikes<a class="headerlink" href="#section-2-information-neurons-and-spikes" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing to here from start of tutorial: 20 min</em></p>
<div class="section" id="video-2-entropy-of-different-distributions">
<h2>Video 2: Entropy of different distributions<a class="headerlink" href="#video-2-entropy-of-different-distributions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>Recall the discussion of spike times and inter-spike intervals (ISIs) from Tutorial 1. What does the information content (or distributional entropy) of these measures say about our theory of nervous systems?</p>
<p>We’ll consider three hypothetical neurons that all have the same mean ISI, but with different distributions:</p>
<ol class="simple">
<li><p>Deterministic</p></li>
<li><p>Uniform</p></li>
<li><p>Exponential</p></li>
</ol>
<p>Fixing the mean of the ISI distribution is equivalent to fixing its inverse: the neuron’s mean firing rate. If a neuron has a fixed energy budget and each of its spikes has the same energy cost, then by fixing the mean firing rate, we are normalizing for energy expenditure. This provides a basis for comparing the entropy of different ISI distributions. In other words: if our neuron has a fixed budget, what ISI distribution should it express (all else being equal) to maximize the information content of its outputs?</p>
<p>Let’s construct our three distributions and see how their entropies differ.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_bins</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">mean_isi</span> <span class="o">=</span> <span class="mf">0.025</span>
<span class="n">isi_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">)</span>

<span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">*</span><span class="n">isi_range</span><span class="p">,</span> <span class="n">n_bins</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">mean_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">mean_isi</span><span class="p">)</span>

<span class="c1"># 1. all mass concentrated on the ISI mean</span>
<span class="n">pmf_single</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_bins</span><span class="p">)</span>
<span class="n">pmf_single</span><span class="p">[</span><span class="n">mean_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>

<span class="c1"># 2. mass uniformly distributed about the ISI mean</span>
<span class="n">pmf_uniform</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_bins</span><span class="p">)</span>
<span class="n">pmf_uniform</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="o">*</span><span class="n">mean_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">mean_idx</span><span class="p">)</span>

<span class="c1"># 3. mass exponentially distributed about the ISI mean</span>
<span class="n">pmf_exp</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">expon</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">bins</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">scale</span><span class="o">=</span><span class="n">mean_isi</span><span class="p">)</span>
<span class="n">pmf_exp</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pmf_exp</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id1">
<h2><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>Run this cell to plot the three PMFs</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title</span>
<span class="c1">#@markdown Run this cell to plot the three PMFs</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">dists</span> <span class="o">=</span>  <span class="p">[</span><span class="c1"># (subplot title, pmf, ylim)</span>
          <span class="p">(</span><span class="s2">"(1) Deterministic"</span><span class="p">,</span> <span class="n">pmf_single</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">)),</span>
          <span class="p">(</span><span class="s2">"(1) Uniform"</span><span class="p">,</span> <span class="n">pmf_uniform</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">)),</span>
          <span class="p">(</span><span class="s2">"(1) Exponential"</span><span class="p">,</span> <span class="n">pmf_exp</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">))]</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">pmf_</span><span class="p">,</span> <span class="n">ylim</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">dists</span><span class="p">):</span>
  <span class="n">pmf_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">pmf_</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pmf_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">pmf_</span><span class="p">,</span> <span class="n">drawstyle</span><span class="o">=</span><span class="s2">"steps"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">pmf_</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="s2">"pre"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"Inter-spike interval (s)"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"Probability mass"</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">isi_range</span><span class="p">);</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">ylim</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
  <span class="sa">f</span><span class="s2">"Deterministic: </span><span class="si">{</span><span class="n">entropy</span><span class="p">(</span><span class="n">pmf_single</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> bits"</span><span class="p">,</span>
  <span class="sa">f</span><span class="s2">"Uniform: </span><span class="si">{</span><span class="n">entropy</span><span class="p">(</span><span class="n">pmf_uniform</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> bits"</span><span class="p">,</span>
  <span class="sa">f</span><span class="s2">"Exponential: </span><span class="si">{</span><span class="n">entropy</span><span class="p">(</span><span class="n">pmf_exp</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> bits"</span><span class="p">,</span>
  <span class="n">sep</span><span class="o">=</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-3-calculate-entropy-of-isi-distributions-from-data">
<h1>Section 3: Calculate entropy of ISI distributions from data<a class="headerlink" href="#section-3-calculate-entropy-of-isi-distributions-from-data" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing to here from start of tutorial: 25 min</em></p>
<div class="section" id="section-3-1-computing-probabilities-from-histogram">
<h2>Section 3.1: Computing probabilities from histogram<a class="headerlink" href="#section-3-1-computing-probabilities-from-histogram" title="Permalink to this headline">¶</a></h2>
<div class="section" id="video-3-probabilities-from-histogram">
<h3>Video 3: Probabilities from histogram<a class="headerlink" href="#video-3-probabilities-from-histogram" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
<p>In the previous example we created the PMFs by hand to illustrate idealized scenarios. How would we compute them from data recorded from actual neurons?</p>
<p>One way is to convert the ISI histograms we’ve previously computed into discrete probability distributions using the following equation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-0a1187fe-bfbe-4e4e-ac08-de3be907806e">
<span class="eqno">(9)<a class="headerlink" href="#equation-0a1187fe-bfbe-4e4e-ac08-de3be907806e" title="Permalink to this equation">¶</a></span>\[\begin{equation}
p_i = \frac{n_i}{\sum\nolimits_{i}n_i}
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(p_i\)</span> is the probability of an ISI falling within a particular interval <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(n_i\)</span> is the count of how many ISIs were observed in that interval.</p>
</div>
<div class="section" id="coding-exercise-3-1-probability-mass-function">
<h3>Coding Exercise 3.1: Probability Mass Function<a class="headerlink" href="#coding-exercise-3-1-probability-mass-function" title="Permalink to this headline">¶</a></h3>
<p>Your second exercise is to implement a method that will produce a probability mass function from an array of ISI bin counts.</p>
<p>To verify your solution, we will compute the probability distribution of ISIs from real neural data taken from the Steinmetz dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">pmf_from_counts</span><span class="p">(</span><span class="n">counts</span><span class="p">):</span>
  <span class="sd">"""Given counts, normalize by the total to estimate probabilities."""</span>
  <span class="c1">###########################################################################</span>
  <span class="c1"># Exercise: Compute the PMF. Remove the next line to test your function</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: compute the PMF from ISI counts"</span><span class="p">)</span>
  <span class="c1">###########################################################################</span>

  <span class="n">pmf</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">pmf</span>


<span class="c1"># Get neuron index</span>
<span class="n">neuron_idx</span> <span class="o">=</span> <span class="mi">283</span>

<span class="c1"># Get counts of ISIs from Steinmetz data</span>
<span class="n">isi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">steinmetz_spikes</span><span class="p">[</span><span class="n">neuron_idx</span><span class="p">])</span>
<span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">*</span><span class="n">isi_range</span><span class="p">,</span> <span class="n">n_bins</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">counts</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">isi</span><span class="p">,</span> <span class="n">bins</span><span class="p">)</span>

<span class="c1"># Compute pmf</span>
<span class="n">pmf</span> <span class="o">=</span> <span class="n">pmf_from_counts</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>

<span class="c1"># Visualize</span>
<span class="n">plot_pmf</span><span class="p">(</span><span class="n">pmf</span><span class="p">,</span><span class="n">isi_range</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">pmf_from_counts</span><span class="p">(</span><span class="n">counts</span><span class="p">):</span>
  <span class="sd">"""Given counts, normalize by the total to estimate probabilities."""</span>
  <span class="n">pmf</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">pmf</span>


<span class="c1"># Get neuron index</span>
<span class="n">neuron_idx</span> <span class="o">=</span> <span class="mi">283</span>

<span class="c1"># Get counts of ISIs from Steinmetz data</span>
<span class="n">isi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">steinmetz_spikes</span><span class="p">[</span><span class="n">neuron_idx</span><span class="p">])</span>
<span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">*</span><span class="n">isi_range</span><span class="p">,</span> <span class="n">n_bins</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">counts</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">isi</span><span class="p">,</span> <span class="n">bins</span><span class="p">)</span>

<span class="c1"># Compute pmf</span>
<span class="n">pmf</span> <span class="o">=</span> <span class="n">pmf_from_counts</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>

<span class="c1"># Visualize</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_pmf</span><span class="p">(</span><span class="n">pmf</span><span class="p">,</span><span class="n">isi_range</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="section-3-2-calculating-entropy-from-pmf">
<h2>Section 3.2: Calculating entropy from pmf<a class="headerlink" href="#section-3-2-calculating-entropy-from-pmf" title="Permalink to this headline">¶</a></h2>
<div class="section" id="video-4-calculating-entropy-from-pmf">
<h3>Video 4: Calculating entropy from pmf<a class="headerlink" href="#video-4-calculating-entropy-from-pmf" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
<p>Now that we have the probability distribution for the actual neuron spiking activity, we can calculate its entropy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Entropy for Neuron </span><span class="si">{</span><span class="n">neuron_idx</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">entropy</span><span class="p">(</span><span class="n">pmf</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> bits"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="interactive-demo-3-2-entropy-of-neurons">
<h3>Interactive Demo 3.2: Entropy of neurons<a class="headerlink" href="#interactive-demo-3-2-entropy-of-neurons" title="Permalink to this headline">¶</a></h3>
<p>We can combine the above distribution plot and entropy calculation with an interactive widget to explore how the different neurons in the dataset vary in spiking activity and relative information. Note that the mean firing rate across neurons is not fixed, so some neurons with a uniform ISI distribution may have higher entropy than neurons with a more exponential distribution.</p>
<div class="section" id="id2">
<h4><a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h4>
<p><strong>Run the cell</strong> to enable the sliders.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title</span>
<span class="c1">#@markdown **Run the cell** to enable the sliders.</span>

<span class="k">def</span> <span class="nf">_pmf_from_counts</span><span class="p">(</span><span class="n">counts</span><span class="p">):</span>
  <span class="sd">"""Given counts, normalize by the total to estimate probabilities."""</span>
  <span class="n">pmf</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">pmf</span>

<span class="k">def</span> <span class="nf">_entropy</span><span class="p">(</span><span class="n">pmf</span><span class="p">):</span>
  <span class="sd">"""Given a discrete distribution, return the Shannon entropy in bits."""</span>
  <span class="c1"># remove non-zero entries to avoid an error from log2(0)</span>
  <span class="n">pmf</span> <span class="o">=</span> <span class="n">pmf</span><span class="p">[</span><span class="n">pmf</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
  <span class="n">h</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pmf</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">pmf</span><span class="p">))</span>
  <span class="c1"># absolute value applied to avoid getting a -0 result</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">neuron</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">steinmetz_spikes</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
<span class="k">def</span> <span class="nf">steinmetz_pmf</span><span class="p">(</span><span class="n">neuron</span><span class="p">):</span>
  <span class="sd">""" Given a neuron from the Steinmetz data, compute its PMF and entropy """</span>
  <span class="n">isi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">steinmetz_spikes</span><span class="p">[</span><span class="n">neuron</span><span class="p">])</span>
  <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">*</span><span class="n">isi_range</span><span class="p">,</span> <span class="n">n_bins</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">counts</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">isi</span><span class="p">,</span> <span class="n">bins</span><span class="p">)</span>
  <span class="n">pmf</span> <span class="o">=</span> <span class="n">_pmf_from_counts</span><span class="p">(</span><span class="n">counts</span><span class="p">)</span>

  <span class="n">plot_pmf</span><span class="p">(</span><span class="n">pmf</span><span class="p">,</span><span class="n">isi_range</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Neuron </span><span class="si">{</span><span class="n">neuron</span><span class="si">}</span><span class="s2">: H = </span><span class="si">{</span><span class="n">_entropy</span><span class="p">(</span><span class="n">pmf</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> bits"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-4-reflecting-on-why-models">
<h1>Section 4: Reflecting on why models<a class="headerlink" href="#section-4-reflecting-on-why-models" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing to here from start of tutorial: 35 min</em></p>
<div class="section" id="think-3-reflecting-on-how-models">
<h2>Think! 3: Reflecting on how models<a class="headerlink" href="#think-3-reflecting-on-how-models" title="Permalink to this headline">¶</a></h2>
<p>Please discuss the following questions for around 10 minutes with your group:</p>
<ul class="simple">
<li><p>Have you seen why models before?</p></li>
<li><p>Have you ever done one?</p></li>
<li><p>Why are why models useful?</p></li>
<li><p>When are they possible? Does your field have why models?</p></li>
<li><p>What do we learn from constructing them?</p></li>
</ul>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing of tutorial: 45 minutes</em></p>
<div class="section" id="video-5-summary-of-model-types">
<h2>Video 5: Summary of model types<a class="headerlink" href="#video-5-summary-of-model-types" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>Congratulations! You’ve finished your first NMA tutorial. In this 3 part tutorial series, we used different types of models to understand the spiking behavior of neurons recorded in the Steinmetz data set.</p>
<ul class="simple">
<li><p>We used “what” models to discover that the ISI distribution of real neurons is closest to an exponential distribution</p></li>
<li><p>We used “how” models to discover that balanced excitatory and inhibitory inputs, coupled with a leaky membrane, can give rise to neuronal spiking with exhibiting such an exponential ISI distribution</p></li>
<li><p>We used “why” models to discover that exponential ISI distributions contain the most information when the mean spiking is constrained</p></li>
</ul>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="notation">
<h1>Notation<a class="headerlink" href="#notation" title="Permalink to this headline">¶</a></h1>
<div class="amsmath math notranslate nohighlight" id="equation-0c924670-ea3a-4e0a-8cbe-d248c8de22c8">
<span class="eqno">(10)<a class="headerlink" href="#equation-0c924670-ea3a-4e0a-8cbe-d248c8de22c8" title="Permalink to this equation">¶</a></span>\[\begin{align}
H(X) &amp;\quad \text{entropy of random variable X}\\
b &amp;\quad \text{base, e.g. b=2 or b=e}\\
x &amp;\quad \text{event x}\\
p(x) &amp;\quad \text{probability of observing event x}\\
\text{ISI} &amp;\quad \text{interspike interval}\\
n_i &amp;\quad \text{count of observed ISIs in interval i}\\
p_i  &amp;\quad \text{probability of of an ISI falling within a particular interval i}
\end{align}\]</div>
</div>
<hr class="docutils"/>
<div class="section" id="bonus">
<h1>Bonus<a class="headerlink" href="#bonus" title="Permalink to this headline">¶</a></h1>
<hr class="docutils"/>
<div class="section" id="bonus-section-1-the-foundations-for-entropy">
<h2>Bonus Section 1: The foundations for Entropy<a class="headerlink" href="#bonus-section-1-the-foundations-for-entropy" title="Permalink to this headline">¶</a></h2>
<p>In his foundational <a class="reference external" href="https://en.wikipedia.org/wiki/A_Mathematical_Theory_of_Communication">1948 paper</a> on information theory, Claude Shannon began with three criteria for a function <span class="math notranslate nohighlight">\(H\)</span> defining the entropy of a discrete distribution of probability masses <span class="math notranslate nohighlight">\(p_i\in p(X)\)</span> over the points <span class="math notranslate nohighlight">\(x_i\in X\)</span>:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(H\)</span> should be continuous in the <span class="math notranslate nohighlight">\(p_i\)</span>.</p></li>
</ol>
<ul class="simple">
<li><p>That is, <span class="math notranslate nohighlight">\(H\)</span> should change smoothly in response to smooth changes to the mass <span class="math notranslate nohighlight">\(p_i\)</span> on each point <span class="math notranslate nohighlight">\(x_i\)</span>.</p></li>
</ul>
<ol class="simple">
<li><p>If all the points have equal shares of the probability mass, <span class="math notranslate nohighlight">\(p_i=1/N\)</span>, <span class="math notranslate nohighlight">\(H\)</span> should be a non-decreasing function of <span class="math notranslate nohighlight">\(N\)</span>.</p></li>
</ol>
<ul class="simple">
<li><p>That is, if <span class="math notranslate nohighlight">\(X_N\)</span> is the support with <span class="math notranslate nohighlight">\(N\)</span> discrete points and <span class="math notranslate nohighlight">\(p(x\in X_N)\)</span> assigns constant mass to each point, then <span class="math notranslate nohighlight">\(H(X_1) &lt; H(X_2) &lt; H(X_3) &lt; \dots\)</span></p></li>
</ul>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(H\)</span> should be preserved by (invariant to) the equivalent (de)composition of distributions.</p></li>
</ol>
<ul>
<li><p>For example (from Shannon’s paper) if we have a discrete distribution over three points with masses <span class="math notranslate nohighlight">\((\frac{1}{2},\frac{1}{3},\frac{1}{6})\)</span>, then their entropy can be represented in terms of a direct choice between the three and calculated <span class="math notranslate nohighlight">\(H(\frac{1}{2},\frac{1}{3},\frac{1}{6})\)</span>. However, it could also be represented in terms of a series of two choices:</p>
<ol class="simple">
<li><p>either we sample the point with mass <span class="math notranslate nohighlight">\(1/2\)</span> or not (<em>not</em> is the other <span class="math notranslate nohighlight">\(1/2\)</span>, whose subdivisions are not given in the first choice),</p></li>
<li><p>if (with probability <span class="math notranslate nohighlight">\(1/2\)</span>) we <em>don’t</em> sample the first point, we sample one of the two remaining points, masses <span class="math notranslate nohighlight">\(1/3\)</span> and <span class="math notranslate nohighlight">\(1/6\)</span>.</p></li>
</ol>
<p>Thus in this case we require that <span class="math notranslate nohighlight">\(H(\frac{1}{2},\frac{1}{3},\frac{1}{6})=H(\frac{1}{2},\frac{1}{2}) + \frac{1}{2}H(\frac{1}{3}, \frac{1}{6})\)</span></p>
</li>
</ul>
<p>There is a unique function (up to a linear scaling factor) which satisfies these 3 requirements:</p>
<div class="amsmath math notranslate nohighlight" id="equation-0889c510-55be-4bd1-bc9c-7c3540fa0428">
<span class="eqno">(11)<a class="headerlink" href="#equation-0889c510-55be-4bd1-bc9c-7c3540fa0428" title="Permalink to this equation">¶</a></span>\[\begin{equation}
H_b(X) = -\sum_{x\in X} p(x) \log_b p(x)
\end{equation}\]</div>
<p>Where the base of the logarithm <span class="math notranslate nohighlight">\(b&gt;1\)</span> controls the units of entropy. The two most common cases are <span class="math notranslate nohighlight">\(b=2\)</span> for units of <em>bits</em>, and <span class="math notranslate nohighlight">\(b=e\)</span> for <em>nats</em>.</p>
<p>We can view this function as the expectation of the self-information over a distribution:</p>
<div class="amsmath math notranslate nohighlight" id="equation-47fe019c-f737-4105-9e29-d52b13d57fb0">
<span class="eqno">(12)<a class="headerlink" href="#equation-47fe019c-f737-4105-9e29-d52b13d57fb0" title="Permalink to this equation">¶</a></span>\[\begin{align}
H_b(X) &amp;= \mathbb{E}_{x\in X} \left[I_b(x)\right]\\
I_b(x) &amp;= -\log_b p(x)
\end{align}\]</div>
<p>Self-information is just the negative logarithm of probability, and is a measure of how surprising an event sampled from the distribution would be. Events with <span class="math notranslate nohighlight">\(p(x)=1\)</span> are certain to occur, and their self-information is zero (as is the entropy of the distribution they compose) meaning they are totally unsurprising. The smaller the probability of an event, the higher its self-information, and the more surprising the event would be to observe.</p>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W1D1_ModelTypes/instructor"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="W1D1_Tutorial2.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Tutorial 2: “How” models</p>
</div>
</a>
<a class="right-next" href="W1D1_Tutorial4.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Tutorial 4: Model Discussions</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
    By Neuromatch<br/>
  
      © Copyright 2021.<br/>
</p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>