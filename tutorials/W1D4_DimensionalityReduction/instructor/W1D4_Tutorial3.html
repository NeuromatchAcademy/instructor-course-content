
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 3: Dimensionality Reduction &amp; Reconstruction — Neuromatch Academy: Computational Neuroscience (instructor's version)</title>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/custom.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-logo-square-4xp.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W1D4_Tutorial4.html" rel="next" title="Tutorial 4: Nonlinear Dimensionality Reduction"/>
<link href="W1D4_Tutorial2.html" rel="prev" title="Tutorial 2: Principal Component Analysis"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
<div class="bd-sidebar__content">
<div class="bd-sidebar__top"><div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
<img alt="logo" class="logo" src="../../../_static/nma-logo-square-4xp.png"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Computational Neuroscience (instructor's version)</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../tatraining/TA_Training_CN.html">
   TA Training: Computational Neuroscience (CN)
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox">
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox">
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</input></li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using discord
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">
   Quick links and policies
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../prereqs/ComputationalNeuroscience.html">
   Prerequisites and preparatory materials for NMA Computational Neuroscience
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Pre-reqs Refresher
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/chapter_title.html">
   Neuro Video Series (W0D0)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial1.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial2.html">
     Human Psychophysics
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial3.html">
     Behavioral Readout
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial4.html">
     Live in Lab
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial5.html">
     Brain Signals: Spiking Activity
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial6.html">
     Brain Signals: LFP
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial7.html">
     Brain Signals: EEG &amp; MEG
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial8.html">
     Brain Signals: fMRI
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial9.html">
     Brain Signals: Calcium Imaging
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial10.html">
     Stimulus Representation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial11.html">
     Neurotransmitters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial12.html">
     Neurons to Consciousness
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">
   Python Workshop 1 (W0D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D1_PythonWorkshop1/instructor/W0D1_Tutorial1.html">
     Tutorial: LIF Neuron Part I
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">
   Python Workshop 2 (W0D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D2_PythonWorkshop2/instructor/W0D2_Tutorial1.html">
     Tutorial 1: LIF Neuron Part II
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D3_LinearAlgebra/chapter_title.html">
   Linear Algebra (W0D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Tutorial1.html">
     Tutorial 1: Vectors
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Tutorial2.html">
     Tutorial 2: Matrices
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Tutorial3.html">
     Bonus Tutorial: Discrete Dynamical Systems
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D4_Calculus/chapter_title.html">
   Calculus (W0D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_Tutorial1.html">
     Tutorial 1: Differentiation and Integration
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_Tutorial2.html">
     Tutorial 2: Differential Equations
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_Tutorial3.html">
     Tutorial 3: Numerical Methods
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D5_Statistics/chapter_title.html">
   Statistics (W0D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_Tutorial1.html">
     Tutorial 1: Probability Distributions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_Tutorial2.html">
     Tutorial 2: Statistical Inference
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Intro to Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_ModelTypes/chapter_title.html">
   Model Types (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial1.html">
     Tutorial 1: “What” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial2.html">
     Tutorial 2: “How” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial3.html">
     Tutorial 3: “Why” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial4.html">
     Tutorial 4: Model Discussions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_ModelingPractice/chapter_title.html">
   Modeling Practice (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_Tutorial1.html">
     Tutorial 1: Framing the Question
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_ModelFitting/chapter_title.html">
   Model Fitting (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial1.html">
     Tutorial 1: Linear regression with MSE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial2.html">
     Tutorial 2: Linear regression with MLE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial3.html">
     Tutorial 3: Confidence intervals and bootstrapping
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial4.html">
     Tutorial 4: Multiple linear regression and polynomial regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial5.html">
     Tutorial 5: Model Selection: Bias-variance trade-off
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial6.html">
     Tutorial 6: Model Selection: Cross-validation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/chapter_title.html">
   Generalized Linear Models (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Tutorial1.html">
     Tutorial 1: GLMs for Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Tutorial2.html">
     Tutorial 2: Classifiers and regularizers
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Dimensionality Reduction (W1D4)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2">
<a class="reference internal" href="W1D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D4_Tutorial1.html">
     Tutorial 1: Geometric view of data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D4_Tutorial2.html">
     Tutorial 2: Principal Component Analysis
    </a>
</li>
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 3: Dimensionality Reduction &amp; Reconstruction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D4_Tutorial4.html">
     Tutorial 4:  Nonlinear Dimensionality Reduction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_DeepLearning/chapter_title.html">
   Deep Learning (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial3.html">
     Tutorial 3: Building and Evaluating Normative Encoding Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial4.html">
     Bonus Tutorial: Diving Deeper into Decoding &amp; Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Bonus_Autoencoders/chapter_title.html">
   Autoencoders (Bonus)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial1.html">
     Tutorial 1: Intro to Autoencoders
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial2.html">
     Tutorial 2: Autoencoder extensions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial3.html">
     Tutorial 3: Autoencoders applications
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Outro.html">
     Outro
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/MachineLearning.html">
   Machine Learning Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_LinearSystems/chapter_title.html">
   Linear Systems (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial1.html">
     Tutorial 1: Linear dynamical systems
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial2.html">
     Tutorial 2: Markov Processes
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial3.html">
     Tutorial 3: Combining determinism and stochasticity
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial4.html">
     Tutorial 4: Autoregressive models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/chapter_title.html">
   Biological Neuron Models (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial1.html">
     Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial2.html">
     Tutorial 2: Effects of Input Correlation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial3.html">
     Tutorial 3: Synaptic transmission - Models of static and dynamic synapses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial4.html">
     Bonus Tutorial: Spike-timing dependent plasticity (STDP)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_DynamicNetworks/chapter_title.html">
   Dynamic Networks (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial1.html">
     Tutorial 1: Neural Rate Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial2.html">
     Tutorial 2: Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial3.html">
     Bonus Tutorial: Extending the Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/DynamicalSystems.html">
   Dynamical Systems Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Stochastic Processes
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_BayesianDecisions/chapter_title.html">
   Bayesian Decisions (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial1.html">
     Tutorial 1: Bayes with a binary hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial2.html">
     Tutorial 2: Bayesian inference and decisions with continuous hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial3.html">
     Bonus Tutorial : Fitting to data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_HiddenDynamics/chapter_title.html">
   Hidden Dynamics (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial1.html">
     Tutorial 1: Sequential Probability Ratio Test
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial2.html">
     Tutorial 2: Hidden Markov Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial3.html">
     Tutorial 3: The Kalman Filter
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial4.html">
     Bonus Tutorial 4: The Kalman Filter, part 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial5.html">
     Bonus Tutorial 5: Expectation Maximization for spiking neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_OptimalControl/chapter_title.html">
   Optimal Control (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial1.html">
     Tutorial 1: Optimal Control for Discrete States
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial2.html">
     Tutorial 2: Optimal Control for Continuous State
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/chapter_title.html">
   Reinforcement Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial4.html">
     Tutorial 4: Model-Based Reinforcement Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D5_NetworkCausality/chapter_title.html">
   Network Causality (W3D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
<label for="toctree-checkbox-24">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial1.html">
     Tutorial 1: Interventions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial2.html">
     Tutorial 2: Correlations
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial3.html">
     Tutorial 3: Simultaneous fitting/regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial4.html">
     Tutorial 4: Instrumental Variables
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/StochasticProcesses.html">
   Stochastic Processes Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
<label for="toctree-checkbox-25">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through4.html">
     Modeling Steps 1 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through10.html">
     Modeling Steps 5 - 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModel.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProject.html">
     Example Data Project: the Train Illusion
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/datasets_overview.html">
   Datasets
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
<label for="toctree-checkbox-26">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/neurons.html">
     Neurons
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
<label for="toctree-checkbox-27">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/neurons_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/fMRI.html">
     fMRI
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
<label for="toctree-checkbox-28">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/fMRI_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/ECoG.html">
     ECoG
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
<label for="toctree-checkbox-29">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/ECoG_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/behavior.html">
     Behavior
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
<label for="toctree-checkbox-30">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/behavior_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/theory.html">
     Theory
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
<label for="toctree-checkbox-31">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/theory/README.html">
       Guide
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_templates.html">
   Project Templates
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/project_2020_highlights.html">
   Projects 2020
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/>
<label for="toctree-checkbox-32">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/neurons.html">
     Neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/theory.html">
     Theory
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/behavior.html">
     Behavior
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/fMRI.html">
     fMRI
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/eeg.html">
     EEG
    </a>
</li>
</ul>
</li>
</ul>
</div>
</nav></div>
<div class="bd-sidebar__bottom">
<!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="headerbtn" data-placement="right" data-toggle="tooltip" for="__navigation" title="Toggle navigation">
<span class="headerbtn__icon-container">
<i class="fas fa-bars"></i>
</span>
</label>
</div>
<div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
<button aria-label="Launch interactive content" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-rocket"></i>
</button>
<div class="menu-dropdown__content">
<ul>
</ul>
</div>
</div>
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="menu-dropdown menu-dropdown-repository-buttons">
<button aria-label="Source repositories" class="headerbtn menu-dropdown__trigger">
<i class="fab fa-github"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="headerbtn__text-container">repository</span>
</a>
</li>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content/issues/new?title=Issue%20on%20page%20%2Ftutorials/W1D4_DimensionalityReduction/instructor/W1D4_Tutorial3.html&amp;body=Your%20issue%20content%20here." title="Open an issue">
<span class="headerbtn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="headerbtn__text-container">open issue</span>
</a>
</li>
</ul>
</div>
</div>
<div class="menu-dropdown menu-dropdown-download-buttons">
<button aria-label="Download this page" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-download"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W1D4_DimensionalityReduction/instructor/W1D4_Tutorial3.ipynb" title="Download source file">
<span class="headerbtn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="headerbtn__text-container">.ipynb</span>
</a>
</li>
<li>
<button class="headerbtn" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="headerbtn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="headerbtn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
</div>
<label class="headerbtn headerbtn-page-toc" for="__page-toc">
<span class="headerbtn__icon-container">
<i class="fas fa-list"></i>
</span>
</label>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
    </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 3: Dimensionality Reduction &amp; Reconstruction
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-pca-for-dimensionality-reduction">
     Video 1: PCA for dimensionality reduction
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper Functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-perform-pca-on-mnist">
   Section 1: Perform PCA on MNIST
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-scree-plot-of-mnist">
     Coding Exercise 1: Scree plot of MNIST
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-calculate-the-variance-explained">
   Section 2: Calculate the variance explained
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-plot-the-explained-variance">
     Coding Exercise 2: Plot the explained variance
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-reconstruct-data-with-different-numbers-of-pcs">
   Section 3: Reconstruct data with different numbers of PCs
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-data-reconstruction">
     Video 2: Data Reconstruction
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-data-reconstruction">
     Coding Exercise 3: Data reconstruction
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-3-reconstruct-the-data-matrix-using-different-numbers-of-pcs">
     Interactive Demo 3: Reconstruct the data matrix using different numbers of PCs
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
</a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-visualize-pca-components">
   Section 4: Visualize PCA components
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-4-visualization-of-the-weights">
     Coding Exercise 4: Visualization of the weights
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#notation">
   Notation
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus">
   Bonus
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-section-1-examine-denoising-using-pca">
     Bonus Section 1: Examine denoising using PCA
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-coding-exercise-1-add-noise-to-the-data">
       Bonus Coding Exercise 1: Add noise to the data
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-coding-exercise-2-denoising">
       Bonus Coding Exercise 2: Denoising
      </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 3: Dimensionality Reduction &amp; Reconstruction</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 3: Dimensionality Reduction &amp; Reconstruction
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-pca-for-dimensionality-reduction">
     Video 1: PCA for dimensionality reduction
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper Functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-perform-pca-on-mnist">
   Section 1: Perform PCA on MNIST
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-scree-plot-of-mnist">
     Coding Exercise 1: Scree plot of MNIST
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-calculate-the-variance-explained">
   Section 2: Calculate the variance explained
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-plot-the-explained-variance">
     Coding Exercise 2: Plot the explained variance
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-reconstruct-data-with-different-numbers-of-pcs">
   Section 3: Reconstruct data with different numbers of PCs
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-data-reconstruction">
     Video 2: Data Reconstruction
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-data-reconstruction">
     Coding Exercise 3: Data reconstruction
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-3-reconstruct-the-data-matrix-using-different-numbers-of-pcs">
     Interactive Demo 3: Reconstruct the data matrix using different numbers of PCs
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
</a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-visualize-pca-components">
   Section 4: Visualize PCA components
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-4-visualization-of-the-weights">
     Coding Exercise 4: Visualization of the weights
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#notation">
   Notation
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus">
   Bonus
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-section-1-examine-denoising-using-pca">
     Bonus Section 1: Examine denoising using PCA
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-coding-exercise-1-add-noise-to-the-data">
       Bonus Coding Exercise 1: Add noise to the data
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-coding-exercise-2-denoising">
       Bonus Coding Exercise 2: Denoising
      </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/main/tutorials/W1D4_DimensionalityReduction/instructor/W1D4_Tutorial3.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/W1D4_DimensionalityReduction/instructor/W1D4_Tutorial3.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<div class="section" id="tutorial-3-dimensionality-reduction-reconstruction">
<h1>Tutorial 3: Dimensionality Reduction &amp; Reconstruction<a class="headerlink" href="#tutorial-3-dimensionality-reduction-reconstruction" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 1, Day 4: Dimensionality Reduction</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Alex Cayco Gajic, John Murray</p>
<p><strong>Content reviewers:</strong> Roozbeh Farhoudi, Matt Krause, Spiros Chavlis, Richard Gao, Michael Waskom,  Siddharth Suresh, Natalie Schaworonkow, Ella Batty</p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p></div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing of tutorial: 50 minutes</em></p>
<p>In this notebook we’ll learn to apply PCA for dimensionality reduction, using a classic dataset that is often used to benchmark machine learning algorithms: MNIST. We’ll also learn how to use PCA for reconstruction and denoising.</p>
<p>Overview:</p>
<ul class="simple">
<li><p>Perform PCA on MNIST</p></li>
<li><p>Calculate the variance explained</p></li>
<li><p>Reconstruct data with different numbers of PCs</p></li>
<li><p>(Bonus) Examine denoising using PCA</p></li>
</ul>
<p>You can learn more about the MNIST dataset <a class="reference external" href="https://en.wikipedia.org/wiki/MNIST_database">here</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Tutorial slides</span>
<span class="c1"># @markdown These are the slides for the videos in all tutorials today</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">IFrame</span>
<span class="n">link_id</span> <span class="o">=</span> <span class="s2">"kaq2x"</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"If you want to download the slides: https://osf.io/download/</span><span class="si">{</span><span class="n">link_id</span><span class="si">}</span><span class="s2">/"</span><span class="p">)</span>
<span class="n">IFrame</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="sa">f</span><span class="s2">"https://mfr.ca-1.osf.io/render?url=https://osf.io/</span><span class="si">{</span><span class="n">link_id</span><span class="si">}</span><span class="s2">/?direct%26mode=render%26action=download%26mode=render"</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="video-1-pca-for-dimensionality-reduction">
<h2>Video 1: PCA for dimensionality reduction<a class="headerlink" href="#video-1-pca-for-dimensionality-reduction" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure Settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure Settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>   <span class="c1"># interactive display</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plotting-functions">
<h2>Plotting Functions<a class="headerlink" href="#plotting-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting Functions</span>

<span class="k">def</span> <span class="nf">plot_variance_explained</span><span class="p">(</span><span class="n">variance_explained</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Plots eigenvalues.</span>

<span class="sd">  Args:</span>
<span class="sd">    variance_explained (numpy array of floats) : Vector of variance explained</span>
<span class="sd">                                                 for each PC</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>

<span class="sd">  """</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">variance_explained</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">variance_explained</span><span class="p">,</span>
           <span class="s1">'--k'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of components'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Variance explained'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_MNIST_reconstruction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X_reconstructed</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Plots 9 images in the MNIST dataset side-by-side with the reconstructed</span>
<span class="sd">  images.</span>

<span class="sd">  Args:</span>
<span class="sd">    X (numpy array of floats)               : Data matrix each column</span>
<span class="sd">                                              corresponds to a different</span>
<span class="sd">                                              random variable</span>
<span class="sd">    X_reconstructed (numpy array of floats) : Data matrix each column</span>
<span class="sd">                                              corresponds to a different</span>
<span class="sd">                                              random variable</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
  <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">k1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">k2</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
      <span class="n">k</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:],</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
                 <span class="n">extent</span><span class="o">=</span><span class="p">[(</span><span class="n">k1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="n">k1</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="p">(</span><span class="n">k2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="n">k2</span> <span class="o">*</span> <span class="mi">28</span><span class="p">],</span>
                 <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">255</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">((</span><span class="mi">3</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">((</span><span class="mi">3</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">'both'</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'both'</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                  <span class="n">labelbottom</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Data'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">clim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">250</span><span class="p">])</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
  <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">k1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">k2</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
      <span class="n">k</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">X_reconstructed</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:]),</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
                 <span class="n">extent</span><span class="o">=</span><span class="p">[(</span><span class="n">k1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="n">k1</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="p">(</span><span class="n">k2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="n">k2</span> <span class="o">*</span> <span class="mi">28</span><span class="p">],</span>
                 <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">255</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">((</span><span class="mi">3</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">((</span><span class="mi">3</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">'both'</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'both'</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                  <span class="n">labelbottom</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">clim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">250</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Reconstructed'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_MNIST_sample</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Plots 9 images in the MNIST dataset.</span>

<span class="sd">  Args:</span>
<span class="sd">     X (numpy array of floats) : Data matrix each column corresponds to a</span>
<span class="sd">                                 different random variable</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>

<span class="sd">  """</span>

  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">k1</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">k2</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
      <span class="n">k</span> <span class="o">=</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:],</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
                 <span class="n">extent</span><span class="o">=</span><span class="p">[(</span><span class="n">k1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="n">k1</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="p">(</span><span class="n">k2</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="n">k2</span> <span class="o">*</span> <span class="mi">28</span><span class="p">],</span>
                 <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">255</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">((</span><span class="mi">3</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">((</span><span class="mi">3</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">'both'</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'both'</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                  <span class="n">labelbottom</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">clim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">250</span><span class="p">])</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_MNIST_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Visualize PCA basis vector weights for MNIST. Red = positive weights,</span>
<span class="sd">  blue = negative weights, white = zero weight.</span>

<span class="sd">  Args:</span>
<span class="sd">     weights (numpy array of floats) : PCA basis vector</span>

<span class="sd">  Returns:</span>
<span class="sd">     Nothing.</span>
<span class="sd">  """</span>

  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'seismic'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">'both'</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">'both'</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                  <span class="n">labelbottom</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">clim</span><span class="p">(</span><span class="o">-</span><span class="mf">.15</span><span class="p">,</span> <span class="mf">.15</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">ticks</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mf">.15</span><span class="p">,</span> <span class="o">-</span><span class="mf">.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">.05</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">.05</span><span class="p">,</span> <span class="mf">.1</span><span class="p">,</span> <span class="mf">.15</span><span class="p">])</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_eigenvalues</span><span class="p">(</span><span class="n">evals</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Plots eigenvalues.</span>

<span class="sd">  Args:</span>
<span class="sd">     (numpy array of floats) : Vector of eigenvalues</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>

<span class="sd">  """</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">evals</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">evals</span><span class="p">,</span> <span class="s1">'o-k'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Component'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Eigenvalue'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Scree plot'</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">limit</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="helper-functions">
<h2>Helper Functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper Functions</span>

<span class="k">def</span> <span class="nf">add_noise</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">frac_noisy_pixels</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Randomly corrupts a fraction of the pixels by setting them to random values.</span>

<span class="sd">  Args:</span>
<span class="sd">     X (numpy array of floats)  : Data matrix</span>
<span class="sd">     frac_noisy_pixels (scalar) : Fraction of noisy pixels</span>

<span class="sd">  Returns:</span>
<span class="sd">     (numpy array of floats)    : Data matrix + noise</span>

<span class="sd">  """</span>

  <span class="n">X_noisy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
  <span class="n">N_noise_ixs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">X_noisy</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">frac_noisy_pixels</span><span class="p">)</span>
  <span class="n">noise_ixs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">X_noisy</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">N_noise_ixs</span><span class="p">,</span>
                               <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">X_noisy</span><span class="p">[</span><span class="n">noise_ixs</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">noise_ixs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">X_noisy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_noisy</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

  <span class="k">return</span> <span class="n">X_noisy</span>


<span class="k">def</span> <span class="nf">change_of_basis</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Projects data onto a new basis.</span>

<span class="sd">  Args:</span>
<span class="sd">    X (numpy array of floats) : Data matrix each column corresponding to a</span>
<span class="sd">                                different random variable</span>
<span class="sd">    W (numpy array of floats) : new orthonormal basis columns correspond to</span>
<span class="sd">                                basis vectors</span>

<span class="sd">  Returns:</span>
<span class="sd">    (numpy array of floats)   : Data matrix expressed in new basis</span>
<span class="sd">  """</span>

  <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">Y</span>


<span class="k">def</span> <span class="nf">get_sample_cov_matrix</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Returns the sample covariance matrix of data X.</span>

<span class="sd">  Args:</span>
<span class="sd">    X (numpy array of floats) : Data matrix each column corresponds to a</span>
<span class="sd">                                different random variable</span>

<span class="sd">  Returns:</span>
<span class="sd">    (numpy array of floats)   : Covariance matrix</span>
<span class="sd">"""</span>

  <span class="n">X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
  <span class="n">cov_matrix</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">cov_matrix</span>


<span class="k">def</span> <span class="nf">sort_evals_descending</span><span class="p">(</span><span class="n">evals</span><span class="p">,</span> <span class="n">evectors</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Sorts eigenvalues and eigenvectors in decreasing order. Also aligns first two</span>
<span class="sd">  eigenvectors to be in first two quadrants (if 2D).</span>

<span class="sd">  Args:</span>
<span class="sd">    evals (numpy array of floats)    :   Vector of eigenvalues</span>
<span class="sd">    evectors (numpy array of floats) :   Corresponding matrix of eigenvectors</span>
<span class="sd">                                         each column corresponds to a different</span>
<span class="sd">                                         eigenvalue</span>

<span class="sd">  Returns:</span>
<span class="sd">    (numpy array of floats)          : Vector of eigenvalues after sorting</span>
<span class="sd">    (numpy array of floats)          : Matrix of eigenvectors after sorting</span>
<span class="sd">  """</span>

  <span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">evals</span><span class="p">))</span>
  <span class="n">evals</span> <span class="o">=</span> <span class="n">evals</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
  <span class="n">evectors</span> <span class="o">=</span> <span class="n">evectors</span><span class="p">[:,</span> <span class="n">index</span><span class="p">]</span>
  <span class="k">if</span> <span class="n">evals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">arccos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">evectors</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
                           <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])))</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span><span class="p">:</span>
      <span class="n">evectors</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">evectors</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">arccos</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">evectors</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                           <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])))</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span><span class="p">:</span>
      <span class="n">evectors</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">evectors</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

  <span class="k">return</span> <span class="n">evals</span><span class="p">,</span> <span class="n">evectors</span>


<span class="k">def</span> <span class="nf">pca</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Performs PCA on multivariate data. Eigenvalues are sorted in decreasing order</span>

<span class="sd">  Args:</span>
<span class="sd">     X (numpy array of floats) :   Data matrix each column corresponds to a</span>
<span class="sd">                                   different random variable</span>

<span class="sd">  Returns:</span>
<span class="sd">    (numpy array of floats)    : Data projected onto the new basis</span>
<span class="sd">    (numpy array of floats)    : Corresponding matrix of eigenvectors</span>
<span class="sd">    (numpy array of floats)    : Vector of eigenvalues</span>

<span class="sd">  """</span>

  <span class="n">X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
  <span class="n">cov_matrix</span> <span class="o">=</span> <span class="n">get_sample_cov_matrix</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
  <span class="n">evals</span><span class="p">,</span> <span class="n">evectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">cov_matrix</span><span class="p">)</span>
  <span class="n">evals</span><span class="p">,</span> <span class="n">evectors</span> <span class="o">=</span> <span class="n">sort_evals_descending</span><span class="p">(</span><span class="n">evals</span><span class="p">,</span> <span class="n">evectors</span><span class="p">)</span>
  <span class="n">score</span> <span class="o">=</span> <span class="n">change_of_basis</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">evectors</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">score</span><span class="p">,</span> <span class="n">evectors</span><span class="p">,</span> <span class="n">evals</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-perform-pca-on-mnist">
<h1>Section 1: Perform PCA on MNIST<a class="headerlink" href="#section-1-perform-pca-on-mnist" title="Permalink to this headline">¶</a></h1>
<p>The MNIST dataset consists of 70,000 images of individual handwritten digits. Each image is a 28x28 pixel grayscale image. For convenience, each 28x28 pixel image is often unravelled into a single 784 (=28x28) element vector, so that the whole dataset is represented as a 70,000 x 784 matrix. Each row represents a different image, and each column represents a different pixel.</p>
<p>Enter the following cell to load the MNIST dataset and plot the first nine images. It may take a few minutes to load.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>

<span class="c1"># GET mnist data</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'mnist_784'</span><span class="p">,</span> <span class="n">as_frame</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">data</span>

<span class="c1"># Visualize</span>
<span class="n">plot_MNIST_sample</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The MNIST dataset has an extrinsic dimensionality of 784, much higher than the 2-dimensional examples used in the previous tutorials! To make sense of this data, we’ll use dimensionality reduction. But first, we need to determine the intrinsic dimensionality <span class="math notranslate nohighlight">\(K\)</span> of the data. One way to do this is to look for an “elbow” in the scree plot, to determine which eigenvalues are significant.</p>
<div class="section" id="coding-exercise-1-scree-plot-of-mnist">
<h2>Coding Exercise 1: Scree plot of MNIST<a class="headerlink" href="#coding-exercise-1-scree-plot-of-mnist" title="Permalink to this headline">¶</a></h2>
<p>In this exercise you will examine the scree plot in the MNIST dataset.</p>
<p><strong>Steps:</strong></p>
<ul class="simple">
<li><p>Perform PCA on the dataset using our function <code class="docutils literal notranslate"><span class="pre">pca</span></code> from tutorial 2 (already loaded in) and examine the scree plot.</p></li>
<li><p>When do the eigenvalues appear (by eye) to reach zero? (<strong>Hint:</strong> use <code class="docutils literal notranslate"><span class="pre">plt.xlim</span></code> to zoom into a section of the plot).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">pca</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#################################################</span>
<span class="c1">## TODO for students</span>
<span class="c1"># Fill out function and remove</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: perform PCA and visualize scree plot"</span><span class="p">)</span>
<span class="c1">#################################################</span>

<span class="c1"># Perform PCA</span>
<span class="n">score</span><span class="p">,</span> <span class="n">evectors</span><span class="p">,</span> <span class="n">evals</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># Plot the eigenvalues</span>
<span class="n">plot_eigenvalues</span><span class="p">(</span><span class="n">evals</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>  <span class="c1"># limit x-axis up to 100 for zooming</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>

<span class="c1"># Perform PCA</span>
<span class="n">score</span><span class="p">,</span> <span class="n">evectors</span><span class="p">,</span> <span class="n">evals</span> <span class="o">=</span> <span class="n">pca</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Plot the eigenvalues</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_eigenvalues</span><span class="p">(</span><span class="n">evals</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>  <span class="c1"># limit x-axis up to 100 for zooming</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-calculate-the-variance-explained">
<h1>Section 2: Calculate the variance explained<a class="headerlink" href="#section-2-calculate-the-variance-explained" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing to here from start of tutorial: 15 min</em></p>
<p>The scree plot suggests that most of the eigenvalues are near zero, with fewer than 100 having large values. Another common way to determine the intrinsic dimensionality is by considering the variance explained. This can be examined with a cumulative plot of the fraction of the total variance explained by the top <span class="math notranslate nohighlight">\(K\)</span> components, i.e.,</p>
<div class="amsmath math notranslate nohighlight" id="equation-71b60e14-88cb-4ac2-9888-dad331738423">
<span class="eqno">(219)<a class="headerlink" href="#equation-71b60e14-88cb-4ac2-9888-dad331738423" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\text{var explained} = \frac{\sum_{i=1}^K \lambda_i}{\sum_{i=1}^N \lambda_i}
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\lambda_i\)</span> is the <span class="math notranslate nohighlight">\(i^{th}\)</span> eigenvalue and <span class="math notranslate nohighlight">\(N\)</span> is the total number of components (the original number of dimensions in the data).</p>
<p>The intrinsic dimensionality is often quantified by the <span class="math notranslate nohighlight">\(K\)</span> necessary to explain a large proportion of the total variance of the data (often a defined threshold, e.g., 90%).</p>
<div class="section" id="coding-exercise-2-plot-the-explained-variance">
<h2>Coding Exercise 2: Plot the explained variance<a class="headerlink" href="#coding-exercise-2-plot-the-explained-variance" title="Permalink to this headline">¶</a></h2>
<p>In this exercise you will plot the explained variance.</p>
<p><strong>Steps:</strong></p>
<ul class="simple">
<li><p>Fill in the function below to calculate the fraction variance explained as a function of the number of principal components. <strong>Hint:</strong> use <code class="docutils literal notranslate"><span class="pre">np.cumsum</span></code>.</p></li>
<li><p>Plot the variance explained using <code class="docutils literal notranslate"><span class="pre">plot_variance_explained</span></code>.</p></li>
</ul>
<p><strong>Questions:</strong></p>
<ul class="simple">
<li><p>How many principal components are required to explain 90% of the variance?</p></li>
<li><p>How does the intrinsic dimensionality of this dataset compare to its extrinsic dimensionality?</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_variance_explained</span><span class="p">(</span><span class="n">evals</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Calculates variance explained from the eigenvalues.</span>

<span class="sd">  Args:</span>
<span class="sd">    evals (numpy array of floats) : Vector of eigenvalues</span>

<span class="sd">  Returns:</span>
<span class="sd">    (numpy array of floats)       : Vector of variance explained</span>

<span class="sd">  """</span>

  <span class="c1">#################################################</span>
  <span class="c1">## TO DO for students: calculate the explained variance using the equation</span>
  <span class="c1">## from Section 2.</span>
  <span class="c1"># Comment once you've filled in the function</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: calculate explain variance!"</span><span class="p">)</span>
  <span class="c1">#################################################</span>

  <span class="c1"># Cumulatively sum the eigenvalues</span>
  <span class="n">csum</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># Normalize by the sum of eigenvalues</span>
  <span class="n">variance_explained</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">variance_explained</span>


<span class="c1"># Calculate the variance explained</span>
<span class="n">variance_explained</span> <span class="o">=</span> <span class="n">get_variance_explained</span><span class="p">(</span><span class="n">evals</span><span class="p">)</span>

<span class="c1"># Visualize</span>
<span class="n">plot_variance_explained</span><span class="p">(</span><span class="n">variance_explained</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>

<span class="k">def</span> <span class="nf">get_variance_explained</span><span class="p">(</span><span class="n">evals</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Plots eigenvalues.</span>

<span class="sd">  Args:</span>
<span class="sd">    (numpy array of floats) : Vector of eigenvalues</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>

<span class="sd">  """</span>

  <span class="c1"># Cumulatively sum the eigenvalues</span>
  <span class="n">csum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">evals</span><span class="p">)</span>

  <span class="c1"># Normalize by the sum of eigenvalues</span>
  <span class="n">variance_explained</span> <span class="o">=</span> <span class="n">csum</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">evals</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">variance_explained</span>


<span class="c1"># Calculate the variance explained</span>
<span class="n">variance_explained</span> <span class="o">=</span> <span class="n">get_variance_explained</span><span class="p">(</span><span class="n">evals</span><span class="p">)</span>

<span class="c1"># Visualize</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_variance_explained</span><span class="p">(</span><span class="n">variance_explained</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-3-reconstruct-data-with-different-numbers-of-pcs">
<h1>Section 3: Reconstruct data with different numbers of PCs<a class="headerlink" href="#section-3-reconstruct-data-with-different-numbers-of-pcs" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing to here from start of tutorial: 25 min</em></p>
<div class="section" id="video-2-data-reconstruction">
<h2>Video 2: Data Reconstruction<a class="headerlink" href="#video-2-data-reconstruction" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>Now we have seen that the top 100 or so principal components of the data can explain most of the variance. We can use this fact to perform <em>dimensionality reduction</em>, i.e., by storing the data using only 100 components rather than the samples of all 784 pixels. Remarkably, we will be able to reconstruct much of the structure of the data using only the top 100 components. To see this, recall that to perform PCA we projected the data <span class="math notranslate nohighlight">\(\bf X\)</span> onto the eigenvectors of the covariance matrix:</p>
<div class="amsmath math notranslate nohighlight" id="equation-037ad365-5a33-41da-9166-c7532c87b3c3">
<span class="eqno">(220)<a class="headerlink" href="#equation-037ad365-5a33-41da-9166-c7532c87b3c3" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\bf S = X W
\end{equation}\]</div>
<p>Since <span class="math notranslate nohighlight">\(\bf W\)</span> is an orthogonal matrix, <span class="math notranslate nohighlight">\({\bf W}^{-1} = {\bf W}^\top\)</span>. So by multiplying by <span class="math notranslate nohighlight">\({\bf W}^\top\)</span> on each side we can rewrite this equation as</p>
<div class="amsmath math notranslate nohighlight" id="equation-0032e829-cc6f-414f-93ca-8f2a260e3904">
<span class="eqno">(221)<a class="headerlink" href="#equation-0032e829-cc6f-414f-93ca-8f2a260e3904" title="Permalink to this equation">¶</a></span>\[\begin{equation}
{\bf X = S W}^\top.
\end{equation}\]</div>
<p>This now gives us a way to reconstruct the data matrix from the scores and loadings. To reconstruct the data from a low-dimensional approximation, we just have to truncate these matrices.  Let’s denote <span class="math notranslate nohighlight">\({\bf S}_{1:K}\)</span> and <span class="math notranslate nohighlight">\({\bf W}_{1:K}\)</span> the matrices with only the first <span class="math notranslate nohighlight">\(K\)</span> columns of <span class="math notranslate nohighlight">\(\bf S\)</span> and <span class="math notranslate nohighlight">\(\bf W\)</span>, respectively. Then our reconstruction is:</p>
<div class="amsmath math notranslate nohighlight" id="equation-ecce70bd-219c-4b30-b48e-4592414df2b2">
<span class="eqno">(222)<a class="headerlink" href="#equation-ecce70bd-219c-4b30-b48e-4592414df2b2" title="Permalink to this equation">¶</a></span>\[\begin{equation}
{\bf \hat X = S}_{1:K} ({\bf W}_{1:K})^\top.
\end{equation}\]</div>
</div>
<div class="section" id="coding-exercise-3-data-reconstruction">
<h2>Coding Exercise 3: Data reconstruction<a class="headerlink" href="#coding-exercise-3-data-reconstruction" title="Permalink to this headline">¶</a></h2>
<p>Fill in the function below to reconstruct the data using different numbers of principal components.</p>
<p><strong>Steps:</strong></p>
<ul class="simple">
<li><p>Fill in the following function to reconstruct the data based on the weights and scores. Don’t forget to add the mean!</p></li>
<li><p>Make sure your function works by reconstructing the data with all <span class="math notranslate nohighlight">\(K=784\)</span> components. The two images should look identical.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">reconstruct_data</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">evectors</span><span class="p">,</span> <span class="n">X_mean</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Reconstruct the data based on the top K components.</span>

<span class="sd">  Args:</span>
<span class="sd">    score (numpy array of floats)    : Score matrix</span>
<span class="sd">    evectors (numpy array of floats) : Matrix of eigenvectors</span>
<span class="sd">    X_mean (numpy array of floats)   : Vector corresponding to data mean</span>
<span class="sd">    K (scalar)                       : Number of components to include</span>

<span class="sd">  Returns:</span>
<span class="sd">    (numpy array of floats)          : Matrix of reconstructed data</span>

<span class="sd">  """</span>

  <span class="c1">#################################################</span>
  <span class="c1">## TO DO for students: Reconstruct the original data in X_reconstructed</span>
  <span class="c1"># Comment once you've filled in the function</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: reconstructing data function!"</span><span class="p">)</span>
  <span class="c1">#################################################</span>

  <span class="c1"># Reconstruct the data from the score and eigenvectors</span>
  <span class="c1"># Don't forget to add the mean!!</span>
  <span class="n">X_reconstructed</span> <span class="o">=</span>  <span class="o">...</span>

  <span class="k">return</span> <span class="n">X_reconstructed</span>


<span class="n">K</span> <span class="o">=</span> <span class="mi">784</span>

<span class="c1"># Reconstruct the data based on all components</span>
<span class="n">X_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">X_reconstructed</span> <span class="o">=</span> <span class="n">reconstruct_data</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">evectors</span><span class="p">,</span> <span class="n">X_mean</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>

<span class="c1"># Plot the data and reconstruction</span>
<span class="n">plot_MNIST_reconstruction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X_reconstructed</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">reconstruct_data</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">evectors</span><span class="p">,</span> <span class="n">X_mean</span><span class="p">,</span> <span class="n">K</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Reconstruct the data based on the top K components.</span>

<span class="sd">  Args:</span>
<span class="sd">    score (numpy array of floats)    : Score matrix</span>
<span class="sd">    evectors (numpy array of floats) : Matrix of eigenvectors</span>
<span class="sd">    X_mean (numpy array of floats)   : Vector corresponding to data mean</span>
<span class="sd">    K (scalar)                       : Number of components to include</span>

<span class="sd">  Returns:</span>
<span class="sd">    (numpy array of floats)          : Matrix of reconstructed data</span>

<span class="sd">  """</span>

  <span class="c1"># Reconstruct the data from the score and eigenvectors</span>
  <span class="c1"># Don't forget to add the mean!!</span>
  <span class="n">X_reconstructed</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">score</span><span class="p">[:,</span> <span class="p">:</span><span class="n">K</span><span class="p">],</span> <span class="n">evectors</span><span class="p">[:,</span> <span class="p">:</span><span class="n">K</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">X_mean</span>

  <span class="k">return</span> <span class="n">X_reconstructed</span>


<span class="n">K</span> <span class="o">=</span> <span class="mi">784</span>

<span class="c1"># Reconstruct the data based on all components</span>
<span class="n">X_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">X_reconstructed</span> <span class="o">=</span> <span class="n">reconstruct_data</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">evectors</span><span class="p">,</span> <span class="n">X_mean</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>

<span class="c1"># Plot the data and reconstruction</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_MNIST_reconstruction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X_reconstructed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="interactive-demo-3-reconstruct-the-data-matrix-using-different-numbers-of-pcs">
<h2>Interactive Demo 3: Reconstruct the data matrix using different numbers of PCs<a class="headerlink" href="#interactive-demo-3-reconstruct-the-data-matrix-using-different-numbers-of-pcs" title="Permalink to this headline">¶</a></h2>
<p>Now run the code below and experiment with the slider to reconstruct the data matrix using different numbers of principal components.</p>
<ol class="simple">
<li><p>How many principal components are necessary to reconstruct the numbers (by eye)? How does this relate to the intrinsic dimensionality of the data?</p></li>
<li><p>Do you see any information in the data with only a single principal component?</p></li>
</ol>
<div class="section" id="id1">
<h3><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>Make sure you execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title</span>

<span class="c1"># @markdown Make sure you execute this cell to enable the widget!</span>


<span class="k">def</span> <span class="nf">refresh</span><span class="p">(</span><span class="n">K</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
  <span class="n">X_reconstructed</span> <span class="o">=</span> <span class="n">reconstruct_data</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">evectors</span><span class="p">,</span> <span class="n">X_mean</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>
  <span class="n">plot_MNIST_reconstruction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X_reconstructed</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Reconstructed, K=</span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">K</span><span class="p">))</span>


<span class="n">_</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">refresh</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove explanation</span>
<span class="sd">"""</span>
<span class="sd">1)  By around 91 components, they're pretty clear and similar to the original data.</span>
<span class="sd">This means that the intrinsic dimensionality of the data is less than 100.</span>

<span class="sd">2) You can't see too much but you seem to be able to partially distinguish ones or other numbers with</span>
<span class="sd">a vertical straight line (like the 9) from the rest, which resembles 0 in the reconstruction. You could</span>
<span class="sd">probably usually distinguish 0s from 1s.</span>
<span class="sd">"""</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-4-visualize-pca-components">
<h1>Section 4: Visualize PCA components<a class="headerlink" href="#section-4-visualize-pca-components" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing to here from start of tutorial: 40 min</em></p>
<div class="section" id="coding-exercise-4-visualization-of-the-weights">
<h2>Coding Exercise 4: Visualization of the weights<a class="headerlink" href="#coding-exercise-4-visualization-of-the-weights" title="Permalink to this headline">¶</a></h2>
<p>Next, let’s take a closer look at the first principal component by visualizing its corresponding weights.</p>
<p><strong>Steps:</strong></p>
<ul class="simple">
<li><p>Enter <code class="docutils literal notranslate"><span class="pre">plot_MNIST_weights</span></code> to visualize the weights of the first basis vector.</p></li>
<li><p>What structure do you see? Which pixels have a strong positive weighting? Which have a strong negative weighting? What kinds of images would this basis vector differentiate (hint: think about the last demo with 1 component)?</p></li>
<li><p>Try visualizing the second and third basis vectors. Do you see any structure? What about the 100th basis vector? 500th? 700th?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">plot_MNIST_weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">################################################################</span>
<span class="c1"># Comment once you've filled in the function</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: visualize PCA components"</span><span class="p">)</span>
<span class="c1">################################################################</span>

<span class="c1"># Plot the weights of the first principal component</span>
<span class="n">plot_MNIST_weights</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>

<span class="c1"># Plot the weights of the first principal component</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_MNIST_weights</span><span class="p">(</span><span class="n">evectors</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing of tutorial: 50 minutes</em></p>
<ul class="simple">
<li><p>In this tutorial, we learned how to use PCA for dimensionality reduction by selecting the top principal components. This can be useful as the intrinsic dimensionality (<span class="math notranslate nohighlight">\(K\)</span>) is often less than the extrinsic dimensionality (<span class="math notranslate nohighlight">\(N\)</span>) in neural data. <span class="math notranslate nohighlight">\(K\)</span> can be inferred by choosing the number of eigenvalues necessary to capture some fraction of the variance.</p></li>
<li><p>We also learned how to reconstruct an approximation of the original data using the top <span class="math notranslate nohighlight">\(K\)</span> principal components. In fact, an alternate formulation of PCA is to find the <span class="math notranslate nohighlight">\(K\)</span> dimensional space that minimizes the reconstruction error.</p></li>
<li><p>Noise tends to inflate the apparent intrinsic dimensionality, however the higher components reflect noise rather than new structure in the data. PCA can be used for denoising data by removing noisy higher components.</p></li>
<li><p>In MNIST, the weights corresponding to the first principal component appear to discriminate between a 0 and 1. We will discuss the implications of this for data visualization in the following tutorial.</p></li>
</ul>
</div>
<hr class="docutils"/>
<div class="section" id="notation">
<h1>Notation<a class="headerlink" href="#notation" title="Permalink to this headline">¶</a></h1>
<div class="amsmath math notranslate nohighlight" id="equation-4181b966-abd3-4529-a9cc-3c74376d3e61">
<span class="eqno">(223)<a class="headerlink" href="#equation-4181b966-abd3-4529-a9cc-3c74376d3e61" title="Permalink to this equation">¶</a></span>\[\begin{align}
K &amp;\quad \text{selected number of principal components}\\
N &amp;\quad \text{total number of principal components}\\
\bf W &amp;\quad \text{weights, loadings matrix}\\
{\bf X} &amp;\quad \text{original data matrix}\\
\bf S &amp;\quad \text{projected matrix, scores}\\
{\bf S}_{1:K} &amp;\quad \text{first K columns of score matrix } \bf S\\
{\bf W}_{1:K} &amp;\quad \text{first K columns of weight matrix } \bf W\\
\end{align}\]</div>
</div>
<hr class="docutils"/>
<div class="section" id="bonus">
<h1>Bonus<a class="headerlink" href="#bonus" title="Permalink to this headline">¶</a></h1>
<hr class="docutils"/>
<div class="section" id="bonus-section-1-examine-denoising-using-pca">
<h2>Bonus Section 1: Examine denoising using PCA<a class="headerlink" href="#bonus-section-1-examine-denoising-using-pca" title="Permalink to this headline">¶</a></h2>
<p>In this lecture, we saw that PCA finds an optimal low-dimensional basis to minimize the reconstruction error. Because of this property, PCA can be useful for denoising corrupted samples of the data.</p>
<div class="section" id="bonus-coding-exercise-1-add-noise-to-the-data">
<h3>Bonus Coding Exercise 1: Add noise to the data<a class="headerlink" href="#bonus-coding-exercise-1-add-noise-to-the-data" title="Permalink to this headline">¶</a></h3>
<p>In this exercise you will add salt-and-pepper noise to the original data and see how that affects the eigenvalues.</p>
<p><strong>Steps:</strong></p>
<ul class="simple">
<li><p>Use the function <code class="docutils literal notranslate"><span class="pre">add_noise</span></code> to add noise to 20% of the pixels.</p></li>
<li><p>Then, perform PCA and plot the variance explained. How many principal components are required to explain 90% of the variance? How does this compare to the original data?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">add_noise</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#################################################</span>
<span class="c1">## TO DO for students</span>
<span class="c1"># Comment once you've filled in the function</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: make MNIST noisy and compute PCA!"</span><span class="p">)</span>
<span class="c1">#################################################</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2020</span><span class="p">)</span>  <span class="c1"># set random seed</span>

<span class="c1"># Add noise to data</span>
<span class="n">X_noisy</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># Perform PCA on noisy data</span>
<span class="n">score_noisy</span><span class="p">,</span> <span class="n">evectors_noisy</span><span class="p">,</span> <span class="n">evals_noisy</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># Compute variance explained</span>
<span class="n">variance_explained_noisy</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># Visualize</span>
<span class="n">plot_MNIST_sample</span><span class="p">(</span><span class="n">X_noisy</span><span class="p">)</span>
<span class="n">plot_variance_explained</span><span class="p">(</span><span class="n">variance_explained_noisy</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2020</span><span class="p">)</span>  <span class="c1"># set random seed</span>

<span class="c1"># Add noise to data</span>
<span class="n">X_noisy</span> <span class="o">=</span> <span class="n">add_noise</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">.2</span><span class="p">)</span>

<span class="c1"># Perform PCA on noisy data</span>
<span class="n">score_noisy</span><span class="p">,</span> <span class="n">evectors_noisy</span><span class="p">,</span> <span class="n">evals_noisy</span> <span class="o">=</span> <span class="n">pca</span><span class="p">(</span><span class="n">X_noisy</span><span class="p">)</span>

<span class="c1"># Compute variance explained</span>
<span class="n">variance_explained_noisy</span> <span class="o">=</span> <span class="n">get_variance_explained</span><span class="p">(</span><span class="n">evals_noisy</span><span class="p">)</span>

<span class="c1"># Visualize</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_MNIST_sample</span><span class="p">(</span><span class="n">X_noisy</span><span class="p">)</span>
  <span class="n">plot_variance_explained</span><span class="p">(</span><span class="n">variance_explained_noisy</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="bonus-coding-exercise-2-denoising">
<h3>Bonus Coding Exercise 2: Denoising<a class="headerlink" href="#bonus-coding-exercise-2-denoising" title="Permalink to this headline">¶</a></h3>
<p>Next, use PCA to perform denoising by projecting the noise-corrupted data onto the basis vectors found from the original dataset. By taking the top K components of this projection, we can reduce noise in dimensions orthogonal to the K-dimensional latent space.</p>
<p><strong>Steps:</strong></p>
<ul class="simple">
<li><p>Subtract the mean of the noise-corrupted data.</p></li>
<li><p>Project the data onto the basis found with the original dataset (<code class="docutils literal notranslate"><span class="pre">evectors</span></code>, not <code class="docutils literal notranslate"><span class="pre">evectors_noisy</span></code>) and take the top <span class="math notranslate nohighlight">\(K\)</span> components.</p></li>
<li><p>Reconstruct the data as normal, using the top 50 components.</p></li>
<li><p>Play around with the amount of noise and K to build intuition.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#################################################</span>
<span class="c1">## TO DO for students</span>
<span class="c1"># Comment once you've filled in the function</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: reconstruct noisy data from PCA"</span><span class="p">)</span>
<span class="c1">#################################################</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2020</span><span class="p">)</span>  <span class="c1"># set random seed</span>

<span class="c1"># Add noise to data</span>
<span class="n">X_noisy</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># Compute mean of noise-corrupted data</span>
<span class="n">X_noisy_mean</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># Project onto the original basis vectors</span>
<span class="n">projX_noisy</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># Reconstruct the data using the top 50 components</span>
<span class="n">X_reconstructed</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># Visualize</span>
<span class="n">plot_MNIST_reconstruction</span><span class="p">(</span><span class="n">X_noisy</span><span class="p">,</span> <span class="n">X_reconstructed</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2020</span><span class="p">)</span>  <span class="c1"># set random seed</span>

<span class="c1"># Add noise to data</span>
<span class="n">X_noisy</span> <span class="o">=</span> <span class="n">add_noise</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mf">.2</span><span class="p">)</span>

<span class="c1"># Compute mean of noise-corrupted data</span>
<span class="n">X_noisy_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X_noisy</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Project onto the original basis vectors</span>
<span class="n">projX_noisy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X_noisy</span> <span class="o">-</span> <span class="n">X_noisy_mean</span><span class="p">,</span> <span class="n">evectors</span><span class="p">)</span>

<span class="c1"># Reconstruct the data using the top 50 components</span>
<span class="n">X_reconstructed</span> <span class="o">=</span> <span class="n">reconstruct_data</span><span class="p">(</span><span class="n">projX_noisy</span><span class="p">,</span> <span class="n">evectors</span><span class="p">,</span> <span class="n">X_noisy_mean</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>

<span class="c1"># Visualize</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_MNIST_reconstruction</span><span class="p">(</span><span class="n">X_noisy</span><span class="p">,</span> <span class="n">X_reconstructed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W1D4_DimensionalityReduction/instructor"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="W1D4_Tutorial2.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Tutorial 2: Principal Component Analysis</p>
</div>
</a>
<a class="right-next" href="W1D4_Tutorial4.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Tutorial 4:  Nonlinear Dimensionality Reduction</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
    By Neuromatch<br/>
<div class="extra_footer">
<div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"/></a>
The contents of this repository are shared under the <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>
</div>
</p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>