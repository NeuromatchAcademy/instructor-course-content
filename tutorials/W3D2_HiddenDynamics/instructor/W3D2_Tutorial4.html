
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Bonus Tutorial 4: The Kalman Filter, part 2 — Neuromatch Academy: Computational Neuroscience (instructor's version)</title>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/custom.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-logo-square-4xp.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W3D2_Tutorial5.html" rel="next" title="Bonus Tutorial 5: Expectation Maximization for spiking neurons"/>
<link href="W3D2_Tutorial3.html" rel="prev" title="Tutorial 3: The Kalman Filter"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
<div class="bd-sidebar__content">
<div class="bd-sidebar__top"><div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
<img alt="logo" class="logo" src="../../../_static/nma-logo-square-4xp.png"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Computational Neuroscience (instructor's version)</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../tatraining/TA_Training_CN.html">
   TA Training: Computational Neuroscience (CN)
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox">
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox">
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</input></li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using discord
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">
   Quick links and policies
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../prereqs/ComputationalNeuroscience.html">
   Prerequisites and preparatory materials for NMA Computational Neuroscience
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Pre-reqs Refresher
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/chapter_title.html">
   Neuro Video Series (W0D0)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial1.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial2.html">
     Human Psychophysics
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial3.html">
     Behavioral Readout
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial4.html">
     Live in Lab
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial5.html">
     Brain Signals: Spiking Activity
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial6.html">
     Brain Signals: LFP
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial7.html">
     Brain Signals: EEG &amp; MEG
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial8.html">
     Brain Signals: fMRI
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial9.html">
     Brain Signals: Calcium Imaging
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial10.html">
     Stimulus Representation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial11.html">
     Neurotransmitters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial12.html">
     Neurons to Consciousness
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">
   Python Workshop 1 (W0D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D1_PythonWorkshop1/instructor/W0D1_Tutorial1.html">
     Tutorial: LIF Neuron Part I
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">
   Python Workshop 2 (W0D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D2_PythonWorkshop2/instructor/W0D2_Tutorial1.html">
     Tutorial 1: LIF Neuron Part II
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D3_LinearAlgebra/chapter_title.html">
   Linear Algebra (W0D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Tutorial1.html">
     Tutorial 1: Vectors
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Tutorial2.html">
     Tutorial 2: Matrices
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Tutorial3.html">
     Bonus Tutorial: Discrete Dynamical Systems
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D4_Calculus/chapter_title.html">
   Calculus (W0D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_Tutorial1.html">
     Tutorial 1: Differentiation and Integration
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_Tutorial2.html">
     Tutorial 2: Differential Equations
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_Tutorial3.html">
     Tutorial 3: Numerical Methods
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D5_Statistics/chapter_title.html">
   Statistics (W0D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_Tutorial1.html">
     Tutorial 1: Probability Distributions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_Tutorial2.html">
     Tutorial 2: Statistical Inference
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Intro to Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_ModelTypes/chapter_title.html">
   Model Types (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial1.html">
     Tutorial 1: “What” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial2.html">
     Tutorial 2: “How” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial3.html">
     Tutorial 3: “Why” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial4.html">
     Tutorial 4: Model Discussions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_ModelingPractice/chapter_title.html">
   Modeling Practice (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_Tutorial1.html">
     Tutorial 1: Framing the Question
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_ModelFitting/chapter_title.html">
   Model Fitting (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial1.html">
     Tutorial 1: Linear regression with MSE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial2.html">
     Tutorial 2: Linear regression with MLE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial3.html">
     Tutorial 3: Confidence intervals and bootstrapping
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial4.html">
     Tutorial 4: Multiple linear regression and polynomial regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial5.html">
     Tutorial 5: Model Selection: Bias-variance trade-off
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial6.html">
     Tutorial 6: Model Selection: Cross-validation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/chapter_title.html">
   Generalized Linear Models (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Tutorial1.html">
     Tutorial 1: GLMs for Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Tutorial2.html">
     Tutorial 2: Classifiers and regularizers
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/chapter_title.html">
   Dimensionality Reduction (W1D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial1.html">
     Tutorial 1: Geometric view of data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial2.html">
     Tutorial 2: Principal Component Analysis
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial3.html">
     Tutorial 3: Dimensionality Reduction &amp; Reconstruction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial4.html">
     Tutorial 4:  Nonlinear Dimensionality Reduction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_DeepLearning/chapter_title.html">
   Deep Learning (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial3.html">
     Tutorial 3: Building and Evaluating Normative Encoding Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial4.html">
     Bonus Tutorial: Diving Deeper into Decoding &amp; Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Bonus_Autoencoders/chapter_title.html">
   Autoencoders (Bonus)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial1.html">
     Tutorial 1: Intro to Autoencoders
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial2.html">
     Tutorial 2: Autoencoder extensions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial3.html">
     Tutorial 3: Autoencoders applications
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Outro.html">
     Outro
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/MachineLearning.html">
   Machine Learning Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_LinearSystems/chapter_title.html">
   Linear Systems (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial1.html">
     Tutorial 1: Linear dynamical systems
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial2.html">
     Tutorial 2: Markov Processes
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial3.html">
     Tutorial 3: Combining determinism and stochasticity
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial4.html">
     Tutorial 4: Autoregressive models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/chapter_title.html">
   Biological Neuron Models (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial1.html">
     Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial2.html">
     Tutorial 2: Effects of Input Correlation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial3.html">
     Tutorial 3: Synaptic transmission - Models of static and dynamic synapses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial4.html">
     Bonus Tutorial: Spike-timing dependent plasticity (STDP)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_DynamicNetworks/chapter_title.html">
   Dynamic Networks (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial1.html">
     Tutorial 1: Neural Rate Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial2.html">
     Tutorial 2: Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial3.html">
     Bonus Tutorial: Extending the Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/DynamicalSystems.html">
   Dynamical Systems Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Stochastic Processes
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_BayesianDecisions/chapter_title.html">
   Bayesian Decisions (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial1.html">
     Tutorial 1: Bayes with a binary hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial2.html">
     Tutorial 2: Bayesian inference and decisions with continuous hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial3.html">
     Bonus Tutorial : Fitting to data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Hidden Dynamics (W3D2)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2">
<a class="reference internal" href="W3D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D2_Tutorial1.html">
     Tutorial 1: Sequential Probability Ratio Test
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D2_Tutorial2.html">
     Tutorial 2: Hidden Markov Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D2_Tutorial3.html">
     Tutorial 3: The Kalman Filter
    </a>
</li>
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Bonus Tutorial 4: The Kalman Filter, part 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D2_Tutorial5.html">
     Bonus Tutorial 5: Expectation Maximization for spiking neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D2_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_OptimalControl/chapter_title.html">
   Optimal Control (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial1.html">
     Tutorial 1: Optimal Control for Discrete States
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial2.html">
     Tutorial 2: Optimal Control for Continuous State
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/chapter_title.html">
   Reinforcement Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial4.html">
     Tutorial 4: Model-Based Reinforcement Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D5_NetworkCausality/chapter_title.html">
   Network Causality (W3D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
<label for="toctree-checkbox-24">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial1.html">
     Tutorial 1: Interventions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial2.html">
     Tutorial 2: Correlations
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial3.html">
     Tutorial 3: Simultaneous fitting/regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial4.html">
     Tutorial 4: Instrumental Variables
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/StochasticProcesses.html">
   Stochastic Processes Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
<label for="toctree-checkbox-25">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through4.html">
     Modeling Steps 1 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through10.html">
     Modeling Steps 5 - 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModel.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProject.html">
     Example Data Project: the Train Illusion
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/datasets_overview.html">
   Datasets
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
<label for="toctree-checkbox-26">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/neurons.html">
     Neurons
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
<label for="toctree-checkbox-27">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/neurons_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/fMRI.html">
     fMRI
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
<label for="toctree-checkbox-28">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/fMRI_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/ECoG.html">
     ECoG
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
<label for="toctree-checkbox-29">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/ECoG_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/behavior.html">
     Behavior
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
<label for="toctree-checkbox-30">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/behavior_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/theory.html">
     Theory
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
<label for="toctree-checkbox-31">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/theory/README.html">
       Guide
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_templates.html">
   Project Templates
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/project_2020_highlights.html">
   Projects 2020
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/>
<label for="toctree-checkbox-32">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/neurons.html">
     Neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/theory.html">
     Theory
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/behavior.html">
     Behavior
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/fMRI.html">
     fMRI
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/eeg.html">
     EEG
    </a>
</li>
</ul>
</li>
</ul>
</div>
</nav></div>
<div class="bd-sidebar__bottom">
<!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="headerbtn" data-placement="right" data-toggle="tooltip" for="__navigation" title="Toggle navigation">
<span class="headerbtn__icon-container">
<i class="fas fa-bars"></i>
</span>
</label>
</div>
<div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
<button aria-label="Launch interactive content" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-rocket"></i>
</button>
<div class="menu-dropdown__content">
<ul>
</ul>
</div>
</div>
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="menu-dropdown menu-dropdown-repository-buttons">
<button aria-label="Source repositories" class="headerbtn menu-dropdown__trigger">
<i class="fab fa-github"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="headerbtn__text-container">repository</span>
</a>
</li>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content/issues/new?title=Issue%20on%20page%20%2Ftutorials/W3D2_HiddenDynamics/instructor/W3D2_Tutorial4.html&amp;body=Your%20issue%20content%20here." title="Open an issue">
<span class="headerbtn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="headerbtn__text-container">open issue</span>
</a>
</li>
</ul>
</div>
</div>
<div class="menu-dropdown menu-dropdown-download-buttons">
<button aria-label="Download this page" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-download"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W3D2_HiddenDynamics/instructor/W3D2_Tutorial4.ipynb" title="Download source file">
<span class="headerbtn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="headerbtn__text-container">.ipynb</span>
</a>
</li>
<li>
<button class="headerbtn" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="headerbtn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="headerbtn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
</div>
<label class="headerbtn headerbtn-page-toc" for="__page-toc">
<span class="headerbtn__icon-container">
<i class="fas fa-list"></i>
</span>
</label>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
    </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Bonus Tutorial 4: The Kalman Filter, part 2
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-introduction">
     Video 1: Introduction
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#data-retrieval-and-loading">
     Data retrieval and loading
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-linear-dynamical-system-lds">
   Section 1: Linear Dynamical System (LDS)
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-linear-dynamical-systems">
     Video 2: Linear Dynamical Systems
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#kalman-filter-definitions">
     Kalman filter definitions:
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-1-sampling-from-a-latent-linear-dynamical-system">
     Section 1.1: Sampling from a latent linear dynamical system
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-1-sampling-from-a-linear-dynamical-system">
       Exercise 1: Sampling from a linear dynamical system
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-adjusting-system-dynamics">
       Interactive Demo: Adjusting System Dynamics
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-kalman-filtering">
   Section 2: Kalman Filtering
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-kalman-filtering">
     Video 3: Kalman Filtering
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-2-implement-kalman-filtering">
     Exercise 2: Implement Kalman filtering
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-fitting-eye-gaze-data">
   Section 3: Fitting Eye Gaze Data
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-fitting-eye-gaze-data">
     Video 4: Fitting Eye Gaze Data
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-tracking-eye-gaze">
     Interactive Demo: Tracking Eye Gaze
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
</a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-1-fitting-data-with-pykalman">
     Section 3.1: Fitting data with
     <code class="docutils literal notranslate">
<span class="pre">
       pykalman
      </span>
</code>
</a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id3">
</a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#discussion-questions">
     Discussion questions:
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#handling-eye-blinks">
     Handling Eye Blinks
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus">
   Bonus
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#review-on-gaussian-joint-marginal-and-conditional-distributions">
     Review on Gaussian joint, marginal and conditional distributions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#kalman-smoothing">
     Kalman Smoothing
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-kalman-smoothing-and-the-em-algorithm">
       Video 5: Kalman Smoothing and the EM Algorithm
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-3-implement-kalman-smoothing">
       Exercise 3: Implement Kalman smoothing
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#the-expectation-maximization-em-algorithm">
     The Expectation-Maximization (EM) Algorithm
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#expectation-step">
       Expectation step
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#maximization-step">
       Maximization step
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#the-m-step-for-a-lds">
       The M-step for a LDS
      </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>Bonus Tutorial 4: The Kalman Filter, part 2</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Bonus Tutorial 4: The Kalman Filter, part 2
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-introduction">
     Video 1: Introduction
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#data-retrieval-and-loading">
     Data retrieval and loading
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-linear-dynamical-system-lds">
   Section 1: Linear Dynamical System (LDS)
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-linear-dynamical-systems">
     Video 2: Linear Dynamical Systems
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#kalman-filter-definitions">
     Kalman filter definitions:
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-1-sampling-from-a-latent-linear-dynamical-system">
     Section 1.1: Sampling from a latent linear dynamical system
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-1-sampling-from-a-linear-dynamical-system">
       Exercise 1: Sampling from a linear dynamical system
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-adjusting-system-dynamics">
       Interactive Demo: Adjusting System Dynamics
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-kalman-filtering">
   Section 2: Kalman Filtering
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-kalman-filtering">
     Video 3: Kalman Filtering
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-2-implement-kalman-filtering">
     Exercise 2: Implement Kalman filtering
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-fitting-eye-gaze-data">
   Section 3: Fitting Eye Gaze Data
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-fitting-eye-gaze-data">
     Video 4: Fitting Eye Gaze Data
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-tracking-eye-gaze">
     Interactive Demo: Tracking Eye Gaze
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
</a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-1-fitting-data-with-pykalman">
     Section 3.1: Fitting data with
     <code class="docutils literal notranslate">
<span class="pre">
       pykalman
      </span>
</code>
</a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id3">
</a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#discussion-questions">
     Discussion questions:
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#handling-eye-blinks">
     Handling Eye Blinks
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus">
   Bonus
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#review-on-gaussian-joint-marginal-and-conditional-distributions">
     Review on Gaussian joint, marginal and conditional distributions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#kalman-smoothing">
     Kalman Smoothing
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-kalman-smoothing-and-the-em-algorithm">
       Video 5: Kalman Smoothing and the EM Algorithm
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-3-implement-kalman-smoothing">
       Exercise 3: Implement Kalman smoothing
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#the-expectation-maximization-em-algorithm">
     The Expectation-Maximization (EM) Algorithm
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#expectation-step">
       Expectation step
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#maximization-step">
       Maximization step
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#the-m-step-for-a-lds">
       The M-step for a LDS
      </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/main/tutorials/W3D2_HiddenDynamics/instructor/W3D2_Tutorial4.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/W3D2_HiddenDynamics/instructor/W3D2_Tutorial4.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<div class="section" id="bonus-tutorial-4-the-kalman-filter-part-2">
<h1>Bonus Tutorial 4: The Kalman Filter, part 2<a class="headerlink" href="#bonus-tutorial-4-the-kalman-filter-part-2" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 3, Day 2: Hidden Dynamics</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Caroline Haimerl and Byron Galbraith</p>
<p><strong>Content reviewers:</strong> Jesse Livezey, Matt Krause, Michael Waskom, and Xaq Pitkow</p>
<p><strong>Post-production team:</strong> Gagana B, Spiros Chavlis</p>
<br/>
<p><strong>Important note:</strong> This is bonus material, included from NMA 2020. It has not been substantially revised for 2021. This means that the notation and standards are slightly different. We include it here because it provides additional information about how the Kalman filter works in two dimensions.</p>
<br/>
<p><strong>Useful references:</strong></p>
<ul class="simple">
<li><p>Roweis, Ghahramani (1998): A unifying review of linear Gaussian Models</p></li>
<li><p>Bishop (2006): Pattern Recognition and Machine Learning</p></li>
</ul>
<br/>
<p><strong>Acknowledgements:</strong></p>
<p>This tutorial is in part based on code originally created by Caroline Haimerl for Dr. Cristina Savin’s <em>Probabilistic Time Series</em> class at the Center for Data Science, New York University</p>
<div class="section" id="video-1-introduction">
<h2>Video 1: Introduction<a class="headerlink" href="#video-1-introduction" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p>In the previous tutorial we gained intuition for the Kalman filter in one dimension. In this tutorial, we will examine the <strong>two-dimensional</strong> Kalman filter and more of its mathematical foundations.</p>
<p>In this tutorial, you will:</p>
<ul class="simple">
<li><p>Review linear dynamical systems</p></li>
<li><p>Implement the Kalman filter</p></li>
<li><p>Explore how the Kalman filter can be used to smooth data from an eye-tracking experiment</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>conda<span class="w"> </span>install<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>ipywidgets<span class="w"> </span>--yes
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>conda<span class="w"> </span>install<span class="w"> </span>numpy<span class="w"> </span>matplotlib<span class="w"> </span>scipy<span class="w"> </span>requests<span class="w"> </span>--yes
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install PyKalman (https://pykalman.github.io/)</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>pykalman<span class="w"> </span>--quiet

<span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pykalman</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Figure settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>       <span class="c1"># interactive display</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="data-retrieval-and-loading">
<h2>Data retrieval and loading<a class="headerlink" href="#data-retrieval-and-loading" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Data retrieval and loading</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">hashlib</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">fname</span> <span class="o">=</span> <span class="s2">"W2D3_mit_eyetracking_2009.npz"</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://osf.io/jfk8w/download"</span>
<span class="n">expected_md5</span> <span class="o">=</span> <span class="s2">"20c7bc4a6f61f49450997e381cf5e0dd"</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">fname</span><span class="p">):</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
  <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">ConnectionError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"!!! Failed to download data !!!"</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">r</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="n">requests</span><span class="o">.</span><span class="n">codes</span><span class="o">.</span><span class="n">ok</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"!!! Failed to download data !!!"</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span> <span class="o">!=</span> <span class="n">expected_md5</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"!!! Data download appears corrupted !!!"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">fid</span><span class="p">:</span>
        <span class="n">fid</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_eyetracking_data</span><span class="p">(</span><span class="n">data_fname</span><span class="o">=</span><span class="n">fname</span><span class="p">):</span>

  <span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">data_fname</span><span class="p">,</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">dobj</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="o">**</span><span class="n">dobj</span><span class="p">)</span>

  <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">stim</span><span class="p">),</span> <span class="nb">format</span><span class="o">=</span><span class="s1">'JPG'</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">stim</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">'stimuli'</span><span class="p">]]</span>
  <span class="n">subjects</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">'subjects'</span><span class="p">]</span>

  <span class="k">return</span> <span class="n">subjects</span><span class="p">,</span> <span class="n">images</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Helper functions</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_kalman</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">observation</span><span class="p">,</span> <span class="n">estimate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'filter'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'r-'</span><span class="p">,</span>
                <span class="n">title</span><span class="o">=</span><span class="s1">'LDS'</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">axes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
      <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">state</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">state</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">'g-'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'true latent'</span><span class="p">)</span>
      <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">observation</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">observation</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">'k.'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span> <span class="o">=</span> <span class="n">axes</span>

    <span class="k">if</span> <span class="n">estimate</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">estimate</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">estimate</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">'X position'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'Y position'</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">estimate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">state</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">observation</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="s1">'.k'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'dim 1'</span><span class="p">)</span>
      <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">state</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">observation</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">'.'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'grey'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'dim 2'</span><span class="p">)</span>
      <span class="n">ax2</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">'correlation'</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">'latent'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'measured'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">state</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">estimate</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="s1">'.'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
               <span class="n">label</span><span class="o">=</span><span class="s1">'latent dim 1'</span><span class="p">)</span>
      <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">state</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">estimate</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">'x'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
               <span class="n">label</span><span class="o">=</span><span class="s1">'latent dim 2'</span><span class="p">)</span>
      <span class="n">ax2</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">'correlation'</span><span class="p">,</span>
              <span class="n">xlabel</span><span class="o">=</span><span class="s1">'real latent'</span><span class="p">,</span>
              <span class="n">ylabel</span><span class="o">=</span><span class="s1">'estimated latent'</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span>


<span class="k">def</span> <span class="nf">plot_gaze_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">img</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># overlay gaze on stimulus</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

    <span class="n">xlim</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">ylim</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">img</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">'auto'</span><span class="p">)</span>
        <span class="n">ylim</span> <span class="o">=</span> <span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">xlim</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">'m'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="n">xlim</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="n">ylim</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ax</span>


<span class="k">def</span> <span class="nf">plot_kf_state</span><span class="p">(</span><span class="n">kf</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="n">mu_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">kf</span><span class="o">.</span><span class="n">n_dim_state</span><span class="p">)</span>
    <span class="n">mu_0</span><span class="p">[:</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">kf</span><span class="o">.</span><span class="n">initial_state_mean</span> <span class="o">=</span> <span class="n">mu_0</span>

    <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">kf</span><span class="o">.</span><span class="n">smooth</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mu</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">mu</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">'limegreen'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">mu</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">mu</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">'orange'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'&gt;'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">mu</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">mu</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">'orange'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'s'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-linear-dynamical-system-lds">
<h1>Section 1: Linear Dynamical System (LDS)<a class="headerlink" href="#section-1-linear-dynamical-system-lds" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-2-linear-dynamical-systems">
<h2>Video 2: Linear Dynamical Systems<a class="headerlink" href="#video-2-linear-dynamical-systems" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</div>
<div class="section" id="kalman-filter-definitions">
<h2>Kalman filter definitions:<a class="headerlink" href="#kalman-filter-definitions" title="Permalink to this headline">¶</a></h2>
<p>The latent state <span class="math notranslate nohighlight">\(s_t\)</span> evolves as a stochastic linear dynamical system in discrete time, with a dynamics matrix <span class="math notranslate nohighlight">\(D\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-bfce3625-f6df-4570-ae0e-c8f620a526d9">
<span class="eqno">(384)<a class="headerlink" href="#equation-bfce3625-f6df-4570-ae0e-c8f620a526d9" title="Permalink to this equation">¶</a></span>\[\begin{equation}
s_t = Ds_{t-1}+w_t
\end{equation}\]</div>
<p>Just as in the HMM, the structure is a Markov chain where the state at time point <span class="math notranslate nohighlight">\(t\)</span> is conditionally independent of previous states given the state at time point <span class="math notranslate nohighlight">\(t-1\)</span>.</p>
<p>Sensory measurements <span class="math notranslate nohighlight">\(m_t\)</span> (observations) are noisy linear projections of the latent state:</p>
<div class="amsmath math notranslate nohighlight" id="equation-d2561b54-e4b5-4ed5-9b7e-df432f4b9908">
<span class="eqno">(385)<a class="headerlink" href="#equation-d2561b54-e4b5-4ed5-9b7e-df432f4b9908" title="Permalink to this equation">¶</a></span>\[\begin{equation}
m_t = Hs_{t}+\eta_t
\end{equation}\]</div>
<p>Both states and measurements have Gaussian variability, often called noise: ‘process noise’ <span class="math notranslate nohighlight">\(w_t\)</span> for the states, and ‘measurement’ or ‘observation noise’ <span class="math notranslate nohighlight">\(\eta_t\)</span> for the measurements. The initial state is also Gaussian distributed. These quantites have means and covariances:</p>
<div class="amsmath math notranslate nohighlight" id="equation-dd3d82b8-a018-4790-b874-17888345b20f">
<span class="eqno">(386)<a class="headerlink" href="#equation-dd3d82b8-a018-4790-b874-17888345b20f" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
w_t &amp; \sim &amp; \mathcal{N}(0, Q) \\
\eta_t &amp; \sim &amp; \mathcal{N}(0, R) \\
s_0 &amp; \sim &amp; \mathcal{N}(\mu_0, \Sigma_0)
\end{eqnarray}\]</div>
<p>As a consequence, <span class="math notranslate nohighlight">\(s_t\)</span>, <span class="math notranslate nohighlight">\(m_t\)</span> and their joint distributions are Gaussian. This makes all of the math analytically tractable using linear algebra, so we can easily compute the marginal and conditional distributions we will use for inferring the current state given the entire history of measurements.</p>
<p><em><strong>Please note</strong>: we are trying to create uniform notation across tutorials. In some videos created in 2020, measurements <span class="math notranslate nohighlight">\(m_t\)</span> were denoted <span class="math notranslate nohighlight">\(y_t\)</span>, and the Dynamics matrix <span class="math notranslate nohighlight">\(D\)</span> was denoted <span class="math notranslate nohighlight">\(F\)</span>. We apologize for any confusion!</em></p>
</div>
<div class="section" id="section-1-1-sampling-from-a-latent-linear-dynamical-system">
<h2>Section 1.1: Sampling from a latent linear dynamical system<a class="headerlink" href="#section-1-1-sampling-from-a-latent-linear-dynamical-system" title="Permalink to this headline">¶</a></h2>
<p>The first thing we will investigate is how to generate timecourse samples from a linear dynamical system given its parameters. We will start by defining the following system:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># task dimensions</span>
<span class="n">n_dim_state</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_dim_obs</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># initialize model parameters</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">'D'</span><span class="p">:</span> <span class="mf">0.9</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_state</span><span class="p">),</span>  <span class="c1"># state transition matrix</span>
  <span class="s1">'Q'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_obs</span><span class="p">),</span>  <span class="c1"># state noise covariance</span>
  <span class="s1">'H'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_state</span><span class="p">),</span>  <span class="c1"># observation matrix</span>
  <span class="s1">'R'</span><span class="p">:</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_obs</span><span class="p">),</span>  <span class="c1"># observation noise covariance</span>
  <span class="s1">'mu_0'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_dim_state</span><span class="p">),</span>  <span class="c1"># initial state mean</span>
  <span class="s1">'sigma_0'</span><span class="p">:</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_state</span><span class="p">),</span>  <span class="c1"># initial state noise covariance</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Coding note</strong>: We used a parameter dictionary <code class="docutils literal notranslate"><span class="pre">params</span></code> above. As the number of parameters we need to provide to our functions increases, it can be beneficial to condense them into a data structure like this to clean up the number of inputs we pass in. The trade-off is that we have to know what is in our data structure to use those values, rather than looking at the function signature directly.</p>
<div class="section" id="exercise-1-sampling-from-a-linear-dynamical-system">
<h3>Exercise 1: Sampling from a linear dynamical system<a class="headerlink" href="#exercise-1-sampling-from-a-linear-dynamical-system" title="Permalink to this headline">¶</a></h3>
<p>In this exercise you will implement the dynamics functions of a linear dynamical system to sample both a latent space trajectory (given parameters set above) and noisy measurements.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">sample_lds</span><span class="p">(</span><span class="n">n_timesteps</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">  </span><span class="sd">""" Generate samples from a Linear Dynamical System specified by the provided</span>
<span class="sd">  parameters.</span>

<span class="sd">  Args:</span>
<span class="sd">  n_timesteps (int): the number of time steps to simulate</span>
<span class="sd">  params (dict): a dictionary of model parameters: (D, Q, H, R, mu_0, sigma_0)</span>
<span class="sd">  seed (int): a random seed to use for reproducibility checks</span>

<span class="sd">  Returns:</span>
<span class="sd">  ndarray, ndarray: the generated state and observation data</span>
<span class="sd">  """</span>
  <span class="n">n_dim_state</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'D'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">n_dim_obs</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'H'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="c1"># set seed</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

  <span class="c1"># precompute random samples from the provided covariance matrices</span>
  <span class="c1"># mean defaults to 0</span>
  <span class="n">mi</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">cov</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">'Q'</span><span class="p">])</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n_timesteps</span><span class="p">)</span>
  <span class="n">eta</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">cov</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">'R'</span><span class="p">])</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n_timesteps</span><span class="p">)</span>

  <span class="c1"># initialize state and observation arrays</span>
  <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_timesteps</span><span class="p">,</span> <span class="n">n_dim_state</span><span class="p">))</span>
  <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_timesteps</span><span class="p">,</span> <span class="n">n_dim_obs</span><span class="p">))</span>

  <span class="c1">###################################################################</span>
  <span class="c1">## TODO for students: compute the next state and observation values</span>
  <span class="c1"># Fill out function and remove</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: compute the next state and observation values"</span><span class="p">)</span>
  <span class="c1">###################################################################</span>

  <span class="c1"># simulate the system</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_timesteps</span><span class="p">):</span>
    <span class="c1"># write the expressions for computing state values given the time step</span>
    <span class="k">if</span> <span class="n">t</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">state</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">state</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># write the expression for computing the observation</span>
    <span class="n">obs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">state</span><span class="p">,</span> <span class="n">obs</span>


<span class="c1"># Uncomment below to test your function</span>
<span class="c1"># state, obs = sample_lds(100, params)</span>
<span class="c1"># print('sample at t=3 ', state[3])</span>
<span class="c1"># plot_kalman(state, obs, title='sample')</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">sample_lds</span><span class="p">(</span><span class="n">n_timesteps</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">  </span><span class="sd">""" Generate samples from a Linear Dynamical System specified by the provided</span>
<span class="sd">  parameters.</span>

<span class="sd">  Args:</span>
<span class="sd">  n_timesteps (int): the number of time steps to simulate</span>
<span class="sd">  params (dict): a dictionary of model parameters: (D, Q, H, R, mu_0, sigma_0)</span>
<span class="sd">  seed (int): a random seed to use for reproducibility checks</span>

<span class="sd">  Returns:</span>
<span class="sd">  ndarray, ndarray: the generated state and observation data</span>
<span class="sd">  """</span>
  <span class="n">n_dim_state</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'D'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">n_dim_obs</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'H'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="c1"># set seed</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

  <span class="c1"># precompute random samples from the provided covariance matrices</span>
  <span class="c1"># mean defaults to 0</span>
  <span class="n">mi</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">cov</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">'Q'</span><span class="p">])</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n_timesteps</span><span class="p">)</span>
  <span class="n">eta</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">cov</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">'R'</span><span class="p">])</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n_timesteps</span><span class="p">)</span>

  <span class="c1"># initialize state and observation arrays</span>
  <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_timesteps</span><span class="p">,</span> <span class="n">n_dim_state</span><span class="p">))</span>
  <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_timesteps</span><span class="p">,</span> <span class="n">n_dim_obs</span><span class="p">))</span>

  <span class="c1"># simulate the system</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_timesteps</span><span class="p">):</span>
    <span class="c1"># write the expressions for computing state values given the time step</span>
    <span class="k">if</span> <span class="n">t</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">state</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">'mu_0'</span><span class="p">],</span>
                                           <span class="n">cov</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">'sigma_0'</span><span class="p">])</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">state</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'D'</span><span class="p">]</span> <span class="o">@</span> <span class="n">state</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">mi</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>

    <span class="c1"># write the expression for computing the observation</span>
    <span class="n">obs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'H'</span><span class="p">]</span> <span class="o">@</span> <span class="n">state</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">eta</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>

  <span class="k">return</span> <span class="n">state</span><span class="p">,</span> <span class="n">obs</span>


<span class="n">state</span><span class="p">,</span> <span class="n">obs</span> <span class="o">=</span> <span class="n">sample_lds</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'sample at t=3 '</span><span class="p">,</span> <span class="n">state</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_kalman</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">'sample'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="interactive-demo-adjusting-system-dynamics">
<h3>Interactive Demo: Adjusting System Dynamics<a class="headerlink" href="#interactive-demo-adjusting-system-dynamics" title="Permalink to this headline">¶</a></h3>
<p>To test your understanding of the parameters of a linear dynamical system, think about what you would expect if you made the following changes:</p>
<ol class="simple">
<li><p>Reduce observation noise <span class="math notranslate nohighlight">\(R\)</span></p></li>
<li><p>Increase respective temporal dynamics <span class="math notranslate nohighlight">\(D\)</span></p></li>
</ol>
<p>Use the interactive widget below to vary the values of <span class="math notranslate nohighlight">\(R\)</span> and <span class="math notranslate nohighlight">\(D\)</span>.</p>
<div class="section" id="id1">
<h4><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<p>Make sure you execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title</span>

<span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">R</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatLogSlider</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
                  <span class="n">D</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">.01</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">explore_dynamics</span><span class="p">(</span><span class="n">R</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">D</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'D'</span><span class="p">:</span> <span class="n">D</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_state</span><span class="p">),</span>  <span class="c1"># state transition matrix</span>
    <span class="s1">'Q'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_obs</span><span class="p">),</span>  <span class="c1"># state noise covariance</span>
    <span class="s1">'H'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_state</span><span class="p">),</span>  <span class="c1"># observation matrix</span>
    <span class="s1">'R'</span><span class="p">:</span> <span class="n">R</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_obs</span><span class="p">),</span>  <span class="c1"># observation noise covariance</span>
    <span class="s1">'mu_0'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_dim_state</span><span class="p">),</span>  <span class="c1"># initial state mean,</span>
    <span class="s1">'sigma_0'</span><span class="p">:</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_state</span><span class="p">),</span>  <span class="c1"># initial state noise covariance</span>
    <span class="p">}</span>

    <span class="n">state</span><span class="p">,</span> <span class="n">obs</span> <span class="o">=</span> <span class="n">sample_lds</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="n">plot_kalman</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">'sample'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-kalman-filtering">
<h1>Section 2: Kalman Filtering<a class="headerlink" href="#section-2-kalman-filtering" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-3-kalman-filtering">
<h2>Video 3: Kalman Filtering<a class="headerlink" href="#video-3-kalman-filtering" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>We want to infer the latent state variable <span class="math notranslate nohighlight">\(s_t\)</span> given the measured (observed) variable <span class="math notranslate nohighlight">\(m_t\)</span>.</p>
<div class="amsmath math notranslate nohighlight" id="equation-1066814c-4af3-45df-bfff-5deb6a8ac49b">
<span class="eqno">(387)<a class="headerlink" href="#equation-1066814c-4af3-45df-bfff-5deb6a8ac49b" title="Permalink to this equation">¶</a></span>\[\begin{equation}
P(s_t|m_1, ..., m_t, m_{t+1}, ..., m_T)\sim \mathcal{N}(\hat{\mu}_t, \hat{\Sigma_t})
\end{equation}\]</div>
<p>First we obtain estimates of the latent state by running the filtering from <span class="math notranslate nohighlight">\(t=0,....T\)</span>.</p>
<div class="amsmath math notranslate nohighlight" id="equation-c2112478-8c6d-4035-95c7-464a77bf692f">
<span class="eqno">(388)<a class="headerlink" href="#equation-c2112478-8c6d-4035-95c7-464a77bf692f" title="Permalink to this equation">¶</a></span>\[\begin{equation}
s_t^{\rm pred}\sim \mathcal{N}(\hat{\mu}_t^{\rm pred},\hat{\Sigma}_t^{\rm pred})\end{equation}\]</div>
<p>Where <span class="math notranslate nohighlight">\(\hat{\mu}_t^{\rm pred}\)</span> and <span class="math notranslate nohighlight">\(\hat{\Sigma}_t^{\rm pred}\)</span> are derived as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-51c542d6-ccee-4a25-8d62-3537d3fd0d73">
<span class="eqno">(389)<a class="headerlink" href="#equation-51c542d6-ccee-4a25-8d62-3537d3fd0d73" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
\hat{\mu}_1^{\rm pred} &amp; = &amp; D\hat{\mu}_{0} \\
\hat{\mu}_t^{\rm pred} &amp; = &amp; D\hat{\mu}_{t-1}
\end{eqnarray}\]</div>
<p>This is the prediction for <span class="math notranslate nohighlight">\(s_t\)</span> obtained simply by taking the expected value of <span class="math notranslate nohighlight">\(s_{t-1}\)</span> and projecting it forward one step using the transition matrix <span class="math notranslate nohighlight">\(D\)</span>.
We do the same for the covariance, taking into account the noise covariance <span class="math notranslate nohighlight">\(Q\)</span> and the fact that scaling a variable by <span class="math notranslate nohighlight">\(D\)</span> scales its covariance <span class="math notranslate nohighlight">\(\Sigma\)</span> as <span class="math notranslate nohighlight">\(D\Sigma D^T\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-6d8e58d1-a0a1-4f76-9d81-b252d14973a3">
<span class="eqno">(390)<a class="headerlink" href="#equation-6d8e58d1-a0a1-4f76-9d81-b252d14973a3" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
\hat{\Sigma}_0^{\rm pred} &amp; = &amp; D\hat{\Sigma}_{0}D^T+Q \\
\hat{\Sigma}_t^{\rm pred} &amp; = &amp; D\hat{\Sigma}_{t-1}D^T+Q
\end{eqnarray}\]</div>
<p>We then use a Bayesian update from the newest measurements to obtain <span class="math notranslate nohighlight">\(\hat{\mu}_t^{\rm filter}\)</span> and <span class="math notranslate nohighlight">\(\hat{\Sigma}_t^{\rm filter}\)</span></p>
<p>Project our prediction to observational space:</p>
<div class="amsmath math notranslate nohighlight" id="equation-0f68e18e-c0ac-407a-8eca-83598c07f8ca">
<span class="eqno">(391)<a class="headerlink" href="#equation-0f68e18e-c0ac-407a-8eca-83598c07f8ca" title="Permalink to this equation">¶</a></span>\[\begin{equation}
m_t^{\rm pred}\sim \mathcal{N}(H\hat{\mu}_t^{\rm pred}, H\hat{\Sigma}_t^{\rm pred}H^T+R)
\end{equation}\]</div>
<p>update prediction by actual data:</p>
<div class="amsmath math notranslate nohighlight" id="equation-75f991e9-b476-4604-bde4-1e213a4489f0">
<span class="eqno">(392)<a class="headerlink" href="#equation-75f991e9-b476-4604-bde4-1e213a4489f0" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
s_t^{\rm filter} &amp; \sim &amp; \mathcal{N}(\hat{\mu}_t^{\rm filter}, \hat{\Sigma}_t^{\rm filter}) \\
\hat{\mu}_t^{\rm filter} &amp; = &amp; \hat{\mu}_t^{\rm pred}+K_t(m_t-H\hat{\mu}_t^{\rm pred}) \\
\hat{\Sigma}_t^{\rm filter} &amp; = &amp; (I-K_tH)\hat{\Sigma}_t^{\rm pred}
\end{eqnarray}\]</div>
<p>Kalman gain matrix:</p>
<div class="amsmath math notranslate nohighlight" id="equation-cfdb42c0-9517-4150-9480-366d29ffde60">
<span class="eqno">(393)<a class="headerlink" href="#equation-cfdb42c0-9517-4150-9480-366d29ffde60" title="Permalink to this equation">¶</a></span>\[\begin{equation}
K_t=\hat{\Sigma}_t^{\rm pred}H^T(H\hat{\Sigma}_t^{\rm pred}H^T+R)^{-1}
\end{equation}\]</div>
<p>We use the latent-only prediction to project it to the observational space and compute a correction proportional to the error <span class="math notranslate nohighlight">\(m_t-HDz_{t-1}\)</span> between prediction and data. The coefficient of this correction is the Kalman gain matrix.</p>
<p><strong>Interpretations</strong></p>
<p>If measurement noise is small and dynamics are fast, then estimation will depend mostly on currently observed data.
If the measurement noise is large, then the Kalman filter uses past observations as well, combining them as long as the underlying state is at least somewhat predictable.</p>
<p>In order to explore the impact of filtering, we will use the following noisy oscillatory system:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># task dimensions</span>
<span class="n">n_dim_state</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_dim_obs</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">T</span><span class="o">=</span><span class="mi">100</span>

<span class="c1"># initialize model parameters</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">'D'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mf">20.</span><span class="p">)</span><span class="o">**</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">.9</span><span class="p">]]),</span>  <span class="c1"># state transition matrix</span>
  <span class="s1">'Q'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_obs</span><span class="p">),</span>                               <span class="c1"># state noise covariance</span>
  <span class="s1">'H'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_state</span><span class="p">),</span>                             <span class="c1"># observation matrix</span>
  <span class="s1">'R'</span><span class="p">:</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_obs</span><span class="p">),</span>                       <span class="c1"># observation noise covariance</span>
  <span class="s1">'mu_0'</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_dim_state</span><span class="p">),</span>                        <span class="c1"># initial state mean</span>
  <span class="s1">'sigma_0'</span><span class="p">:</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_state</span><span class="p">),</span>                 <span class="c1"># initial state noise covariance</span>
<span class="p">}</span>

<span class="n">state</span><span class="p">,</span> <span class="n">obs</span> <span class="o">=</span> <span class="n">sample_lds</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="n">plot_kalman</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">'sample'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="exercise-2-implement-kalman-filtering">
<h2>Exercise 2: Implement Kalman filtering<a class="headerlink" href="#exercise-2-implement-kalman-filtering" title="Permalink to this headline">¶</a></h2>
<p>In this exercise you will implement the Kalman filter (forward) process. Your focus will be on writing the expressions for the Kalman gain, filter mean, and filter covariance at each time step (refer to the equations above).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">kalman_filter</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="w">  </span><span class="sd">""" Perform Kalman filtering (forward pass) on the data given the provided</span>
<span class="sd">  system parameters.</span>

<span class="sd">  Args:</span>
<span class="sd">    data (ndarray): a sequence of observations of shape(n_timesteps, n_dim_obs)</span>
<span class="sd">    params (dict): a dictionary of model parameters: (D, Q, H, R, mu_0, sigma_0)</span>

<span class="sd">  Returns:</span>
<span class="sd">    ndarray, ndarray: the filtered system means and noise covariance values</span>
<span class="sd">  """</span>
  <span class="c1"># pulled out of the params dict for convenience</span>
  <span class="n">D</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'D'</span><span class="p">]</span>
  <span class="n">Q</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'Q'</span><span class="p">]</span>
  <span class="n">H</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'H'</span><span class="p">]</span>
  <span class="n">R</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'R'</span><span class="p">]</span>

  <span class="n">n_dim_state</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">n_dim_obs</span> <span class="o">=</span> <span class="n">H</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">I</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_state</span><span class="p">)</span>  <span class="c1"># identity matrix</span>

  <span class="c1"># state tracking arrays</span>
  <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">n_dim_state</span><span class="p">))</span>
  <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">n_dim_state</span><span class="p">,</span> <span class="n">n_dim_state</span><span class="p">))</span>

  <span class="c1"># filter the data</span>
  <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">t</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">mu_pred</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'mu_0'</span><span class="p">]</span>
      <span class="n">sigma_pred</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'sigma_0'</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">mu_pred</span> <span class="o">=</span> <span class="n">D</span> <span class="o">@</span> <span class="n">mu</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
      <span class="n">sigma_pred</span> <span class="o">=</span> <span class="n">D</span> <span class="o">@</span> <span class="n">sigma</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">@</span> <span class="n">D</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">Q</span>

    <span class="c1">###########################################################################</span>
    <span class="c1">## TODO for students: compute the filtered state mean and covariance values</span>
    <span class="c1"># Fill out function and remove</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: compute the filtered state mean and covariance values"</span><span class="p">)</span>
    <span class="c1">###########################################################################</span>
    <span class="c1"># write the expression for computing the Kalman gain</span>
    <span class="n">K</span> <span class="o">=</span> <span class="o">...</span>
    <span class="c1"># write the expression for computing the filtered state mean</span>
    <span class="n">mu</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span>
    <span class="c1"># write the expression for computing the filtered state noise covariance</span>
    <span class="n">sigma</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span>


<span class="c1"># Uncomment below to test your function</span>
<span class="c1"># filtered_state_means, filtered_state_covariances = kalman_filter(obs, params)</span>
<span class="c1"># plot_kalman(state, obs, filtered_state_means, title="my kf-filter",</span>
<span class="c1">#             color='r', label='my kf-filter')</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">kalman_filter</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="w">  </span><span class="sd">""" Perform Kalman filtering (forward pass) on the data given the provided</span>
<span class="sd">  system parameters.</span>

<span class="sd">  Args:</span>
<span class="sd">    data (ndarray): a sequence of observations of shape(n_timesteps, n_dim_obs)</span>
<span class="sd">    params (dict): a dictionary of model parameters: (D, Q, H, R, mu_0, sigma_0)</span>

<span class="sd">  Returns:</span>
<span class="sd">    ndarray, ndarray: the filtered system means and noise covariance values</span>
<span class="sd">  """</span>
  <span class="c1"># pulled out of the params dict for convenience</span>
  <span class="n">D</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'D'</span><span class="p">]</span>
  <span class="n">Q</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'Q'</span><span class="p">]</span>
  <span class="n">H</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'H'</span><span class="p">]</span>
  <span class="n">R</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'R'</span><span class="p">]</span>

  <span class="n">n_dim_state</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">n_dim_obs</span> <span class="o">=</span> <span class="n">H</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">I</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_state</span><span class="p">)</span>  <span class="c1"># identity matrix</span>

  <span class="c1"># state tracking arrays</span>
  <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">n_dim_state</span><span class="p">))</span>
  <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">n_dim_state</span><span class="p">,</span> <span class="n">n_dim_state</span><span class="p">))</span>

  <span class="c1"># filter the data</span>
  <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">t</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">mu_pred</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'mu_0'</span><span class="p">]</span>
      <span class="n">sigma_pred</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'sigma_0'</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">mu_pred</span> <span class="o">=</span> <span class="n">D</span> <span class="o">@</span> <span class="n">mu</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
      <span class="n">sigma_pred</span> <span class="o">=</span> <span class="n">D</span> <span class="o">@</span> <span class="n">sigma</span><span class="p">[</span><span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">@</span> <span class="n">D</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">Q</span>

    <span class="c1"># write the expression for computing the Kalman gain</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">sigma_pred</span> <span class="o">@</span> <span class="n">H</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">H</span> <span class="o">@</span> <span class="n">sigma_pred</span> <span class="o">@</span> <span class="n">H</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">R</span><span class="p">)</span>
    <span class="c1"># write the expression for computing the filtered state mean</span>
    <span class="n">mu</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">mu_pred</span> <span class="o">+</span> <span class="n">K</span> <span class="o">@</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">H</span> <span class="o">@</span> <span class="n">mu_pred</span><span class="p">)</span>
    <span class="c1"># write the expression for computing the filtered state noise covariance</span>
    <span class="n">sigma</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">I</span> <span class="o">-</span> <span class="n">K</span> <span class="o">@</span> <span class="n">H</span><span class="p">)</span> <span class="o">@</span> <span class="n">sigma_pred</span>

  <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span>


<span class="n">filtered_state_means</span><span class="p">,</span> <span class="n">filtered_state_covariances</span> <span class="o">=</span> <span class="n">kalman_filter</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_kalman</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">filtered_state_means</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">"my kf-filter"</span><span class="p">,</span>
              <span class="n">color</span><span class="o">=</span><span class="s1">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'my kf-filter'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-3-fitting-eye-gaze-data">
<h1>Section 3: Fitting Eye Gaze Data<a class="headerlink" href="#section-3-fitting-eye-gaze-data" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-4-fitting-eye-gaze-data">
<h2>Video 4: Fitting Eye Gaze Data<a class="headerlink" href="#video-4-fitting-eye-gaze-data" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>Tracking eye gaze is used in both experimental and user interface applications. Getting an accurate estimation of where someone is looking on a screen in pixel coordinates can be challenging, however, due to the various sources of noise inherent in obtaining these measurements. A main source of noise is the general accuracy of the eye tracker device itself and how well it maintains calibration over time. Changes in ambient light or subject position can further reduce accuracy of the sensor. Eye blinks introduce a different form of noise as interruptions in the data stream which also need to be addressed.</p>
<p>Fortunately we have a candidate solution for handling noisy eye gaze data in the Kalman filter we just learned about. Let’s look at how we can apply these methods to a small subset of data taken from the <a class="reference external" href="http://people.csail.mit.edu/tjudd/WherePeopleLook/index.html">MIT Eyetracking Database</a> [<a class="reference external" href="http://people.csail.mit.edu/tjudd/WherePeopleLook/Docs/wherepeoplelook.pdf">Judd et al. 2009</a>]. This data was collected as part of an effort to model <a class="reference external" href="http://www.scholarpedia.org/article/Visual_salience">visual saliency</a> – given an image, can we predict where a person is most likely going to look.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load eyetracking data</span>
<span class="n">subjects</span><span class="p">,</span> <span class="n">images</span> <span class="o">=</span> <span class="n">load_eyetracking_data</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="interactive-demo-tracking-eye-gaze">
<h2>Interactive Demo: Tracking Eye Gaze<a class="headerlink" href="#interactive-demo-tracking-eye-gaze" title="Permalink to this headline">¶</a></h2>
<p>We have three stimulus images and five different subjects’ gaze data. Each subject fixated in the center of the screen before the image appeared, then had a few seconds to freely look around. You can use the widget below to see how different subjects visually scanned the presented image. A subject ID of -1 will show the stimulus images without any overlayed gaze trace.</p>
<p>Note that the images are rescaled below for display purposes, they were in their original aspect ratio during the task itself.</p>
<div class="section" id="id2">
<h3><a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>Make sure you execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title</span>

<span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">subject_id</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
                  <span class="n">image_id</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">plot_subject_trace</span><span class="p">(</span><span class="n">subject_id</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">image_id</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">subject_id</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
    <span class="n">subject</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">subject</span> <span class="o">=</span> <span class="n">subjects</span><span class="p">[</span><span class="n">subject_id</span><span class="p">]</span>
  <span class="n">data</span> <span class="o">=</span> <span class="n">subject</span><span class="p">[</span><span class="n">image_id</span><span class="p">]</span>
  <span class="n">img</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="n">image_id</span><span class="p">]</span>

  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">'auto'</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">'m'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="section-3-1-fitting-data-with-pykalman">
<h2>Section 3.1: Fitting data with <code class="docutils literal notranslate"><span class="pre">pykalman</span></code><a class="headerlink" href="#section-3-1-fitting-data-with-pykalman" title="Permalink to this headline">¶</a></h2>
<p>Now that we have data, we’d like to use Kalman filtering to give us a better estimate of the true gaze. Up until this point we’ve known the parameters of our LDS, but here we need to estimate them from data directly. We will use the <code class="docutils literal notranslate"><span class="pre">pykalman</span></code> package to handle this estimation using the EM algorithm, a useful and influential learning algorithm described briefly in the bonus material.</p>
<p>Before exploring fitting models with <code class="docutils literal notranslate"><span class="pre">pykalman</span></code> it’s worth pointing out some naming conventions used by the library:</p>
<div class="amsmath math notranslate nohighlight" id="equation-05be920e-c506-4ed7-960f-c84fa89767f6">
<span class="eqno">(394)<a class="headerlink" href="#equation-05be920e-c506-4ed7-960f-c84fa89767f6" title="Permalink to this equation">¶</a></span>\[\begin{align}
D &amp;: \texttt{transition_matrices} &amp; 
Q &amp;: \texttt{transition_covariance} \\
H &amp;: \texttt{observation_matrices} &amp;
R &amp;: \texttt{observation_covariance} \\
\mu_0 &amp;: \texttt{initial_state_mean} &amp; \Sigma_0 &amp;: \texttt{initial_state_covariance}
\end{align}\]</div>
<p>The first thing we need to do is provide a guess at the dimensionality of the latent state. Let’s start by assuming the dynamics line-up directly with the observation data (pixel x,y-coordinates), and so we have a state dimension of 2.</p>
<p>We also need to decide which parameters we want the EM algorithm to fit. In this case, we will let the EM algorithm discover the dynamics parameters i.e. the <span class="math notranslate nohighlight">\(D\)</span>, <span class="math notranslate nohighlight">\(Q\)</span>, <span class="math notranslate nohighlight">\(H\)</span>, and <span class="math notranslate nohighlight">\(R\)</span> matrices.</p>
<p>We set up our <code class="docutils literal notranslate"><span class="pre">pykalman</span></code> <code class="docutils literal notranslate"><span class="pre">KalmanFilter</span></code> object with these settings using the code below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set up our KalmanFilter object and tell it which parameters we want to</span>
<span class="c1"># estimate</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">n_dim_obs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_dim_state</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">kf</span> <span class="o">=</span> <span class="n">pykalman</span><span class="o">.</span><span class="n">KalmanFilter</span><span class="p">(</span>
  <span class="n">n_dim_state</span><span class="o">=</span><span class="n">n_dim_state</span><span class="p">,</span>
  <span class="n">n_dim_obs</span><span class="o">=</span><span class="n">n_dim_obs</span><span class="p">,</span>
  <span class="n">em_vars</span><span class="o">=</span><span class="p">[</span><span class="s1">'transition_matrices'</span><span class="p">,</span> <span class="s1">'transition_covariance'</span><span class="p">,</span>
           <span class="s1">'observation_matrices'</span><span class="p">,</span> <span class="s1">'observation_covariance'</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Because we know from the reported experimental design that subjects fixated in the center of the screen right before the image appears, we can set the initial starting state estimate <span class="math notranslate nohighlight">\(\mu_0\)</span> as being the center pixel of the stimulus image (the first data point in this sample dataset) with a correspondingly low initial noise covariance <span class="math notranslate nohighlight">\(\Sigma_0\)</span>. Once we have everything set, it’s time to fit some data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Choose a subject and stimulus image</span>
<span class="n">subject_id</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">image_id</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">subjects</span><span class="p">[</span><span class="n">subject_id</span><span class="p">][</span><span class="n">image_id</span><span class="p">]</span>

<span class="c1"># Provide the initial states</span>
<span class="n">kf</span><span class="o">.</span><span class="n">initial_state_mean</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">kf</span><span class="o">.</span><span class="n">initial_state_covariance</span> <span class="o">=</span> <span class="mf">0.1</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_dim_state</span><span class="p">)</span>

<span class="c1"># Estimate the parameters from data using the EM algorithm</span>
<span class="n">kf</span><span class="o">.</span><span class="n">em</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'D=</span><span class="se">\n</span><span class="si">{</span><span class="n">kf</span><span class="o">.</span><span class="n">transition_matrices</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Q =</span><span class="se">\n</span><span class="si">{</span><span class="n">kf</span><span class="o">.</span><span class="n">transition_covariance</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'H =</span><span class="se">\n</span><span class="si">{</span><span class="n">kf</span><span class="o">.</span><span class="n">observation_matrices</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'R =</span><span class="se">\n</span><span class="si">{</span><span class="n">kf</span><span class="o">.</span><span class="n">observation_covariance</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We see that the EM algorithm has found fits for the various dynamics parameters. One thing you will note is that both the state and observation matrices are close to the identity matrix, which means the x- and y-coordinate dynamics are independent of each other and primarily impacted by the noise covariances.</p>
<p>We can now use this model to smooth the observed data from the subject. In addition to the source image, we can also see how this model will work with the gaze recorded by the same subject on the other images as well, or even with different subjects.</p>
<p>Below are the three stimulus images overlayed with recorded gaze in magenta and smoothed state from the filter in green, with gaze begin (orange triangle) and gaze end (orange square) markers.</p>
<div class="section" id="id3">
<h3><a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>Make sure you execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title</span>

<span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">subject_id</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">plot_smoothed_traces</span><span class="p">(</span><span class="n">subject_id</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
  <span class="n">subject</span> <span class="o">=</span> <span class="n">subjects</span><span class="p">[</span><span class="n">subject_id</span><span class="p">]</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">subject</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_gaze_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">img</span><span class="o">=</span><span class="n">img</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">plot_kf_state</span><span class="p">(</span><span class="n">kf</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="discussion-questions">
<h2>Discussion questions:<a class="headerlink" href="#discussion-questions" title="Permalink to this headline">¶</a></h2>
<p>Why do you think one trace from one subject was sufficient to provide a decent fit across all subjects? If you were to go back and change the subject_id and/or image_id for when we fit the data using EM, do you think the fits would be different?</p>
<p>We don’t think the eye is exactly following a linear dynamical system. Nonetheless that is what we assumed for this exercise when we applied a Kalman filter. Despite the mismatch, these algorithms do perform well. Discuss what differences we might find between the true and assumed processes. What mistakes might be likely consequences of these differences?</p>
<p>Finally, recall that the original task was to use this data to help develop models of visual salience. While our Kalman filter is able to provide smooth estimates of observed gaze data, it’s not telling us anything about <em>why</em> the gaze is going in a certain direction. In fact, if we sample data from our parameters and plot them, we get what amounts to a random walk.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kf_state</span><span class="p">,</span> <span class="n">kf_data</span> <span class="o">=</span> <span class="n">kf</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_gaze_data</span><span class="p">(</span><span class="n">kf_data</span><span class="p">,</span> <span class="n">img</span><span class="o">=</span><span class="n">images</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">plot_kf_state</span><span class="p">(</span><span class="n">kf</span><span class="p">,</span> <span class="n">kf_data</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This should not be surprising, as we have given the model no other observed data beyond the pixels at which gaze was detected. We expect there is some other aspect driving the latent state of where to look next other than just the previous fixation location.</p>
<p>In summary, while the Kalman filter is a good option for smoothing the gaze trajectory itself, especially if using a lower-quality eye tracker or in noisy environmental conditions, a linear dynamical system may not be the right way to approach the much more challenging task of modeling visual saliency.</p>
</div>
<div class="section" id="handling-eye-blinks">
<h2>Handling Eye Blinks<a class="headerlink" href="#handling-eye-blinks" title="Permalink to this headline">¶</a></h2>
<p>In the MIT Eyetracking Database, raw tracking data includes times when the subject blinked. The way this is represented in the data stream is via negative pixel coordinate values.</p>
<p>We could try to mitigate these samples by simply deleting them from the stream, though this introduces other issues. For instance, if each sample corresponds to a fixed time step, and you arbitrarily remove some samples, the integrity of that consistent timestep between samples is lost. It’s sometimes better to flag data as missing rather than to pretend it was never there at all, especially with time series data.</p>
<p>Another solution is to use masked arrays. In <code class="docutils literal notranslate"><span class="pre">numpy</span></code>, a <a class="reference external" href="https://numpy.org/doc/stable/reference/maskedarray.generic.html#what-is-a-masked-array">masked array</a> is an <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> with an additional embedded boolean masking array that indicates which elements should be masked. When computation is performed on the array, the masked elements are ignored. Both <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> and <code class="docutils literal notranslate"><span class="pre">pykalman</span></code> work with masked arrays, and, in fact, this is the approach taken with the data we explore in this notebook.</p>
<p>In preparing the dataset for this notebook, the original dataset was preprocessed to set all gaze data as masked arrays, with the mask enabled for any pixel with a negative x or y coordinate.</p>
</div>
</div>
<div class="section" id="bonus">
<h1>Bonus<a class="headerlink" href="#bonus" title="Permalink to this headline">¶</a></h1>
<div class="section" id="review-on-gaussian-joint-marginal-and-conditional-distributions">
<h2>Review on Gaussian joint, marginal and conditional distributions<a class="headerlink" href="#review-on-gaussian-joint-marginal-and-conditional-distributions" title="Permalink to this headline">¶</a></h2>
<p>Assume</p>
<div class="amsmath math notranslate nohighlight" id="equation-3d26c849-8dec-481c-9d2b-24b1fa46e5e2">
<span class="eqno">(395)<a class="headerlink" href="#equation-3d26c849-8dec-481c-9d2b-24b1fa46e5e2" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
z &amp; = &amp; \begin{bmatrix}x \\y\end{bmatrix}\sim N\left(\begin{bmatrix}a \\b\end{bmatrix}, \begin{bmatrix}A &amp; C \\C^T &amp; B\end{bmatrix}\right)
\end{eqnarray}\]</div>
<p>then the marginal distributions are</p>
<div class="amsmath math notranslate nohighlight" id="equation-4c54d006-4f72-4e23-a022-eae35475bb06">
<span class="eqno">(396)<a class="headerlink" href="#equation-4c54d006-4f72-4e23-a022-eae35475bb06" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
x &amp; \sim &amp; \mathcal{N}(a, A) \\
y &amp; \sim &amp; \mathcal{N}(b,B)
\end{eqnarray}\]</div>
<p>and the conditional distributions are</p>
<div class="amsmath math notranslate nohighlight" id="equation-f3ac5878-c45e-4bbc-b7af-b7a9c46e584c">
<span class="eqno">(397)<a class="headerlink" href="#equation-f3ac5878-c45e-4bbc-b7af-b7a9c46e584c" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
x|y &amp; \sim &amp; \mathcal{N}(a+CB^{-1}(y-b), A-CB^{-1}C^T) \\
y|x &amp; \sim &amp; \mathcal{N}(b+C^TA^{-1}(x-a), B-C^TA^{-1}C)
\end{eqnarray}\]</div>
<p><em>important take away: given the joint Gaussian distribution we can derive the conditionals</em></p>
</div>
<div class="section" id="kalman-smoothing">
<h2>Kalman Smoothing<a class="headerlink" href="#kalman-smoothing" title="Permalink to this headline">¶</a></h2>
<div class="section" id="video-5-kalman-smoothing-and-the-em-algorithm">
<h3>Video 5: Kalman Smoothing and the EM Algorithm<a class="headerlink" href="#video-5-kalman-smoothing-and-the-em-algorithm" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
<p>Obtain estimates by propagating from <span class="math notranslate nohighlight">\(y_T\)</span> back to <span class="math notranslate nohighlight">\(y_0\)</span> using results of forward pass (<span class="math notranslate nohighlight">\(\hat{\mu}_t^{\rm filter}, \hat{\Sigma}_t^{\rm filter}, P_t=\hat{\Sigma}_{t+1}^{\rm pred}\)</span>)</p>
<div class="amsmath math notranslate nohighlight" id="equation-a0efe5c0-7712-4759-82e8-4464cab423b8">
<span class="eqno">(398)<a class="headerlink" href="#equation-a0efe5c0-7712-4759-82e8-4464cab423b8" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
s_t &amp; \sim &amp; \mathcal{N}(\hat{\mu}_t^{\rm smooth}, \hat{\Sigma}_t^{\rm smooth}) \\
\hat{\mu}_t^{\rm smooth} &amp; = &amp; \hat{\mu}_t^{\rm filter}+J_t(\hat{\mu}_{t+1}^{\rm smooth}-D\hat{\mu}_t^{\rm filter}) \\
\hat{\Sigma}_t^{\rm smooth} &amp; = &amp; \hat{\Sigma}_t^{\rm filter}+J_t(\hat{\Sigma}_{t+1}^{\rm smooth}-P_t)J_t^T \\
J_t &amp; = &amp; \hat{\Sigma}_t^{\rm filter}D^T P_t^{-1}
\end{eqnarray}\]</div>
<p>This gives us the final estimate for <span class="math notranslate nohighlight">\(z_t\)</span>.</p>
<div class="amsmath math notranslate nohighlight" id="equation-1016e012-9b16-4df0-9e64-8458a2d4247c">
<span class="eqno">(399)<a class="headerlink" href="#equation-1016e012-9b16-4df0-9e64-8458a2d4247c" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
\hat{\mu}_t &amp; = &amp; \hat{\mu}_t^{\rm smooth} \\
\hat{\Sigma}_t &amp; = &amp; \hat{\Sigma}_t^{\rm smooth}
\end{eqnarray}\]</div>
</div>
<div class="section" id="exercise-3-implement-kalman-smoothing">
<h3>Exercise 3: Implement Kalman smoothing<a class="headerlink" href="#exercise-3-implement-kalman-smoothing" title="Permalink to this headline">¶</a></h3>
<p>In this exercise you will implement the Kalman smoothing (backward) process. Again you will focus on writing the expressions for computing the smoothed mean, smoothed covariance, and <span class="math notranslate nohighlight">\(J_t\)</span> values.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">kalman_smooth</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="w">  </span><span class="sd">""" Perform Kalman smoothing (backward pass) on the data given the provided</span>
<span class="sd">  system parameters.</span>

<span class="sd">  Args:</span>
<span class="sd">    data (ndarray): a sequence of observations of shape(n_timesteps, n_dim_obs)</span>
<span class="sd">    params (dict): a dictionary of model parameters: (D, Q, H, R, mu_0, sigma_0)</span>

<span class="sd">  Returns:</span>
<span class="sd">    ndarray, ndarray: the smoothed system means and noise covariance values</span>
<span class="sd">  """</span>
  <span class="c1"># pulled out of the params dict for convenience</span>
  <span class="n">D</span><span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'D'</span><span class="p">]</span>
  <span class="n">Q</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'Q'</span><span class="p">]</span>
  <span class="n">H</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'H'</span><span class="p">]</span>
  <span class="n">R</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'R'</span><span class="p">]</span>

  <span class="n">n_dim_state</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">n_dim_obs</span> <span class="o">=</span> <span class="n">H</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="c1"># first run the forward pass to get the filtered means and covariances</span>
  <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">kalman_filter</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

  <span class="c1"># initialize state mean and covariance estimates</span>
  <span class="n">mu_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
  <span class="n">sigma_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span>
  <span class="n">mu_hat</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">sigma_hat</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

  <span class="c1"># smooth the data</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)):</span>
    <span class="n">sigma_pred</span> <span class="o">=</span> <span class="n">D</span><span class="o">@</span> <span class="n">sigma</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">@</span> <span class="n">D</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">Q</span>  <span class="c1"># sigma_pred at t+1</span>
    <span class="c1">###########################################################################</span>
    <span class="c1">## TODO for students: compute the smoothed state mean and covariance values</span>
    <span class="c1"># Fill out function and remove</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: compute the smoothed state mean and covariance values"</span><span class="p">)</span>
    <span class="c1">###########################################################################</span>

    <span class="c1"># write the expression to compute the Kalman gain for the backward process</span>
    <span class="n">J</span> <span class="o">=</span> <span class="o">...</span>
    <span class="c1"># write the expression to compute the smoothed state mean estimate</span>
    <span class="n">mu_hat</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span>
    <span class="c1"># write the expression to compute the smoothed state noise covariance estimate</span>
    <span class="n">sigma_hat</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">mu_hat</span><span class="p">,</span> <span class="n">sigma_hat</span>


<span class="c1"># Uncomment once the kalman_smooth function is complete</span>
<span class="c1"># smoothed_state_means, smoothed_state_covariances = kalman_smooth(obs, params)</span>
<span class="c1"># axes = plot_kalman(state, obs, filtered_state_means, color="r",</span>
<span class="c1">#                    label="my kf-filter")</span>
<span class="c1"># plot_kalman(state, obs, smoothed_state_means, color="b",</span>
<span class="c1">#             label="my kf-smoothed", axes=axes)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">kalman_smooth</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="w">  </span><span class="sd">""" Perform Kalman smoothing (backward pass) on the data given the provided</span>
<span class="sd">  system parameters.</span>

<span class="sd">  Args:</span>
<span class="sd">    data (ndarray): a sequence of observations of shape(n_timesteps, n_dim_obs)</span>
<span class="sd">    params (dict): a dictionary of model parameters: (D, Q, H, R, mu_0, sigma_0)</span>

<span class="sd">  Returns:</span>
<span class="sd">    ndarray, ndarray: the smoothed system means and noise covariance values</span>
<span class="sd">  """</span>
  <span class="c1"># pulled out of the params dict for convenience</span>
  <span class="n">D</span><span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'D'</span><span class="p">]</span>
  <span class="n">Q</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'Q'</span><span class="p">]</span>
  <span class="n">H</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'H'</span><span class="p">]</span>
  <span class="n">R</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">'R'</span><span class="p">]</span>

  <span class="n">n_dim_state</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">n_dim_obs</span> <span class="o">=</span> <span class="n">H</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="c1"># first run the forward pass to get the filtered means and covariances</span>
  <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">kalman_filter</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

  <span class="c1"># initialize state mean and covariance estimates</span>
  <span class="n">mu_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
  <span class="n">sigma_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span>
  <span class="n">mu_hat</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">sigma_hat</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

  <span class="c1"># smooth the data</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)):</span>
    <span class="n">sigma_pred</span> <span class="o">=</span> <span class="n">D</span><span class="o">@</span> <span class="n">sigma</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">@</span> <span class="n">D</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">Q</span>  <span class="c1"># sigma_pred at t+1</span>

    <span class="c1"># write the expression to compute the Kalman gain for the backward process</span>
    <span class="n">J</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">@</span> <span class="n">D</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">sigma_pred</span><span class="p">)</span>
    <span class="c1"># write the expression to compute the smoothed state mean estimate</span>
    <span class="n">mu_hat</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">mu</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">J</span> <span class="o">@</span> <span class="p">(</span><span class="n">mu_hat</span><span class="p">[</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">D</span><span class="o">@</span> <span class="n">mu</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>
    <span class="c1"># write the expression to compute the smoothed state noise covariance estimate</span>
    <span class="n">sigma_hat</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">+</span> <span class="n">J</span> <span class="o">@</span> <span class="p">(</span><span class="n">sigma_hat</span><span class="p">[</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">sigma_pred</span><span class="p">)</span> <span class="o">@</span> <span class="n">J</span><span class="o">.</span><span class="n">T</span>

  <span class="k">return</span> <span class="n">mu_hat</span><span class="p">,</span> <span class="n">sigma_hat</span>


<span class="n">smoothed_state_means</span><span class="p">,</span> <span class="n">smoothed_state_covariances</span> <span class="o">=</span> <span class="n">kalman_smooth</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">axes</span> <span class="o">=</span> <span class="n">plot_kalman</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">filtered_state_means</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"r"</span><span class="p">,</span>
                     <span class="n">label</span><span class="o">=</span><span class="s2">"my kf-filter"</span><span class="p">)</span>
  <span class="n">plot_kalman</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">smoothed_state_means</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"b"</span><span class="p">,</span>
              <span class="n">label</span><span class="o">=</span><span class="s2">"my kf-smoothed"</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">axes</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Forward vs Backward</strong></p>
<p>Now that we have implementations for both, let’s compare their performance by computing the MSE between the filtered (forward) and smoothed (backward) estimated states and the true latent state.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Filtered MSE: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">state</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">filtered_state_means</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Smoothed MSE: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">state</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">smoothed_state_means</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In this example, the smoothed estimate is clearly superior to the filtered one. This makes sense as the forward pass uses only the past measurements, whereas the backward pass can use future measurement too, correcting the forward pass estimates given all the data we’ve collected.</p>
<p>So why would you ever use Kalman filtering alone, without smoothing? As Kalman filtering only depends on already observed data (i.e. the past) it can be run in a streaming, or on-line, setting. Kalman smoothing relies on future data as it were, and as such can only be applied in a batch, or off-line, setting. So use Kalman filtering if you need real-time corrections and Kalman smoothing if you are considering already-collected data.</p>
<p>This online case is typically what the brain faces.</p>
</div>
</div>
<div class="section" id="the-expectation-maximization-em-algorithm">
<h2>The Expectation-Maximization (EM) Algorithm<a class="headerlink" href="#the-expectation-maximization-em-algorithm" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>want to maximize <span class="math notranslate nohighlight">\(\log p(m|\theta)\)</span></p></li>
<li><p>need to marginalize out latent state <em>(which is not tractable)</em></p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-e74012aa-92c4-4df8-a0a8-7b358b6d5cff">
<span class="eqno">(400)<a class="headerlink" href="#equation-e74012aa-92c4-4df8-a0a8-7b358b6d5cff" title="Permalink to this equation">¶</a></span>\[\begin{equation}
p(m|\theta)=\int p(m,s|\theta)dz
\end{equation}\]</div>
<ul class="simple">
<li><p>add a probability distribution <span class="math notranslate nohighlight">\(q(s)\)</span> which will approximate the latent state distribution</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\log p(m|\theta)\int_s q(s)dz\]</div>
<ul class="simple">
<li><p>can be rewritten as</p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-eff347a7-0d38-4cf4-bd23-fcc4f0d2487b">
<span class="eqno">(401)<a class="headerlink" href="#equation-eff347a7-0d38-4cf4-bd23-fcc4f0d2487b" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathcal{L}(q,\theta)+KL\left(q(s)||p(s|m),\theta\right)
\end{equation}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathcal{L}(q,\theta)\)</span> contains the joint distribution of <span class="math notranslate nohighlight">\(m\)</span> and <span class="math notranslate nohighlight">\(s\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(KL(q||p)\)</span> contains the conditional distribution of <span class="math notranslate nohighlight">\(s|m\)</span></p></li>
</ul>
<div class="section" id="expectation-step">
<h3>Expectation step<a class="headerlink" href="#expectation-step" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>parameters are kept fixed</p></li>
<li><p>find a good approximation <span class="math notranslate nohighlight">\(q(s)\)</span>: maximize lower bound <span class="math notranslate nohighlight">\(\mathcal{L}(q,\theta)\)</span> with respect to <span class="math notranslate nohighlight">\(q(s)\)</span></p></li>
<li><p>(already implemented Kalman filter+smoother)</p></li>
</ul>
</div>
<div class="section" id="maximization-step">
<h3>Maximization step<a class="headerlink" href="#maximization-step" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>keep distribution <span class="math notranslate nohighlight">\(q(s)\)</span> fixed</p></li>
<li><p>change parameters to maximize the lower bound <span class="math notranslate nohighlight">\(\mathcal{L}(q,\theta)\)</span></p></li>
</ul>
<p>As mentioned, we have already effectively solved for the E-Step with our Kalman filter and smoother. The M-step requires further derivation, which is covered in the Appendix. Rather than having you implement the M-Step yourselves, let’s instead turn to using a library that has already implemented EM for exploring some experimental data from cognitive neuroscience.</p>
</div>
<div class="section" id="the-m-step-for-a-lds">
<h3>The M-step for a LDS<a class="headerlink" href="#the-m-step-for-a-lds" title="Permalink to this headline">¶</a></h3>
<p><em>(see Bishop, chapter 13.3.2 Learning in LDS)</em>
Update parameters of the probability distribution</p>
<p>For the updates in the M-step we will need the following posterior marginals obtained from the Kalman smoothing results* <span class="math notranslate nohighlight">\(\hat{\mu}_t^{\rm smooth}, \hat{\Sigma}_t^{\rm smooth}\)</span></p>
<div class="amsmath math notranslate nohighlight" id="equation-6fbc5fde-125b-40be-83b0-9bf438429605">
<span class="eqno">(402)<a class="headerlink" href="#equation-6fbc5fde-125b-40be-83b0-9bf438429605" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
E(s_t) &amp;=&amp; \hat{\mu}_t \\
E(s_ts_{t-1}^T) &amp;=&amp; J_{t-1}\hat{\Sigma}_t+\hat{\mu}_t\hat{\mu}_{t-1}^T\\
E(s_ts_{t}^T) &amp;=&amp; \hat{\Sigma}_t+\hat{\mu}_t\hat{\mu}_{t}^T
\end{eqnarray}\]</div>
<br/>
<p><strong>Update parameters</strong></p>
<p>Initial parameters</p>
<div class="amsmath math notranslate nohighlight" id="equation-1201cf3c-9fe4-47be-9458-29dc26120deb">
<span class="eqno">(403)<a class="headerlink" href="#equation-1201cf3c-9fe4-47be-9458-29dc26120deb" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
\mu_0^{\rm new}&amp;=&amp; E(s_0)\\
Q_0^{\rm new} &amp;=&amp; E(s_0s_0^T)-E(s_0)E(s_0^T) \\
\end{eqnarray}\]</div>
<br/>
<p>Hidden (latent) state parameters</p>
<div class="amsmath math notranslate nohighlight" id="equation-e7206270-22e3-4d58-8028-55114f0d01b9">
<span class="eqno">(404)<a class="headerlink" href="#equation-e7206270-22e3-4d58-8028-55114f0d01b9" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
D^{\rm new} &amp;=&amp; \left(\sum_{t=2}^N E(s_ts_{t-1}^T)\right)\left(\sum_{t=2}^N E(s_{t-1}s_{t-1}^T)\right)^{-1} \\
Q^{\rm new} &amp;=&amp; \frac{1}{T-1} \sum_{t=2}^N E\big(s_ts_t^T\big) - D^{\rm new}E\big(s_{t-1}s_{t}^T\big) - E\big(s_ts_{t-1}^T\big)D^{\rm new}+D^{\rm new}E\big(s_{t-1}s_{t-1}^T\big)\big(D^{\rm new}\big)^{T}\\
\end{eqnarray}\]</div>
<br/>
<p>Observable (measured) space parameters</p>
<div class="amsmath math notranslate nohighlight" id="equation-299a1b3d-e4f6-402c-9274-a5692be7f870">
<span class="eqno">(405)<a class="headerlink" href="#equation-299a1b3d-e4f6-402c-9274-a5692be7f870" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
H^{\rm new} &amp;=&amp; \left(\sum_{t=1}^N y_t E(s_t^T)\right)\left(\sum_{t=1}^N E(s_t s_t^T)\right)^{-1}\\
R^{\rm new} &amp;=&amp; \frac{1}{T}\sum_{t=1}^Ny_ty_t^T-H^{\rm new}E(s_t)y_t^T-y_tE(s_t^T)H^{\rm new}+H^{\rm new}E(s_ts_t^T)H_{\rm new}
\end{eqnarray}\]</div>
</div>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W3D2_HiddenDynamics/instructor"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="W3D2_Tutorial3.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Tutorial 3: The Kalman Filter</p>
</div>
</a>
<a class="right-next" href="W3D2_Tutorial5.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Bonus Tutorial 5: Expectation Maximization for spiking neurons</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
    By Neuromatch<br>
<div class="extra_footer">
<div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"/></a>
The contents of this repository are shared under the <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>
</div>
</br></p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>