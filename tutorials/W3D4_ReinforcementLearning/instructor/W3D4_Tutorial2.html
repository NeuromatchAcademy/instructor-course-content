
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 2: Learning to Act: Multi-Armed Bandits — Neuromatch Academy: Computational Neuroscience (instructor's version)</title>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-logo-square-4xp.jpg" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W3D4_Tutorial3.html" rel="next" title="Tutorial 3: Learning to Act: Q-Learning"/>
<link href="W3D4_Tutorial1.html" rel="prev" title="Tutorial 1: Learning to Predict"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
<div class="bd-sidebar__content">
<div class="bd-sidebar__top"><div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
<img alt="logo" class="logo" src="../../../_static/nma-logo-square-4xp.jpg"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Computational Neuroscience (instructor's version)</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox">
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox">
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</input></li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using discord
    </a>
</li>
</ul>
</input></li>
</ul>
<p class="caption">
<span class="caption-text">
  Intro to Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_ModelTypes/chapter_title.html">
   Model Types (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial1.html">
     Tutorial 1: “What” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial2.html">
     Tutorial 2: “How” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial3.html">
     Tutorial 3: “Why” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial4.html">
     Tutorial 4: Model Discussions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_ModelingPractice/chapter_title.html">
   Modeling Practice (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelingPractice/instructor/W1D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelingPractice/instructor/W1D2_Tutorial1.html">
     Tutorial 1: Framing the Question
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelingPractice/instructor/W1D2_Outro.html">
     Outro
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_ModelFitting/chapter_title.html">
   Model Fitting (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial1.html">
     Tutorial 1: Linear regression with MSE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial2.html">
     Tutorial 2: Linear regression with MLE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial3.html">
     Tutorial 3: Confidence intervals and bootstrapping
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial4.html">
     Tutorial 4: Multiple linear regression and polynomial regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial5.html">
     Tutorial 5: Model Selection: Bias-variance trade-off
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial6.html">
     Tutorial 6: Model Selection: Cross-validation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/chapter_title.html">
   Generalized Linear Models (W1D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/instructor/W1D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/instructor/W1D4_Tutorial1.html">
     Tutorial 1: GLMs for Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/instructor/W1D4_Tutorial2.html">
     Tutorial 2: Classifiers and regularizers
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/instructor/W1D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/chapter_title.html">
   Dimensionality Reduction (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Tutorial1.html">
     Tutorial 1: Geometric view of data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Tutorial2.html">
     Tutorial 2: Principal Component Analysis
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Tutorial3.html">
     Tutorial 3: Dimensionality Reduction &amp; Reconstruction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Tutorial4.html">
     Tutorial 4:  Nonlinear Dimensionality Reduction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_DeepLearning/chapter_title.html">
   Deep Learning (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Tutorial3.html">
     Tutorial 3: Building and Evaluating Normative Encoding Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Tutorial4.html">
     Bonus Tutorial: Diving Deeper into Decoding &amp; Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Bonus_Autoencoders/chapter_title.html">
   Autoencoders (Bonus)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial1.html">
     Tutorial 1: Intro to Autoencoders
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial2.html">
     Tutorial 2: Autoencoder extensions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial3.html">
     Tutorial 3: Autoencoders applications
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Outro.html">
     Outro
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/MachineLearning.html">
   Machine Learning Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_LinearSystems/chapter_title.html">
   Linear Systems (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial1.html">
     Tutorial 1: Linear dynamical systems
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial2.html">
     Tutorial 2: Markov Processes
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial3.html">
     Tutorial 3: Combining determinism and stochasticity
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial4.html">
     Tutorial 4: Autoregressive models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/chapter_title.html">
   Biological Neuron Models (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial1.html">
     Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial2.html">
     Tutorial 2: Effects of Input Correlation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial3.html">
     Tutorial 3: Synaptic transmission - Models of static and dynamic synapses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial4.html">
     Bonus Tutorial: Spike-timing dependent plasticity (STDP)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_DynamicNetworks/chapter_title.html">
   Dynamic Networks (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial1.html">
     Tutorial 1: Neural Rate Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial2.html">
     Tutorial 2: Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial3.html">
     Bonus Tutorial: Extending the Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/DynamicalSystems.html">
   Dynamical Systems Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Stochastic Processes
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_BayesianDecisions/chapter_title.html">
   Bayesian Decisions (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial1.html">
     Tutorial 1: Bayes with a binary hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial2.html">
     Tutorial 2: Bayesian inference and decisions with continuous hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial3.html">
     Bonus Tutorial : Fitting to data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_HiddenDynamics/chapter_title.html">
   Hidden Dynamics (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial1.html">
     Tutorial 1: Sequential Probability Ratio Test
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial2.html">
     Tutorial 2: Hidden Markov Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial3.html">
     Tutorial 3: The Kalman Filter
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial4.html">
     Bonus Tutorial 4: The Kalman Filter, part 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial5.html">
     Bonus Tutorial 5: Expectation Maximization for spiking neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_OptimalControl/chapter_title.html">
   Optimal Control (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial1.html">
     Tutorial 1: Optimal Control for Discrete States
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial2.html">
     Tutorial 2: Optimal Control for Continuous State
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Reinforcement Learning (W3D4)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2">
<a class="reference internal" href="W3D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
</li>
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D4_Tutorial4.html">
     Tutorial 4: From Reinforcement Learning to Planning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D5_NetworkCausality/chapter_title.html">
   Network Causality (W3D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial1.html">
     Tutorial 1: Interventions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial2.html">
     Tutorial 2: Correlations
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial3.html">
     Tutorial 3: Simultaneous fitting/regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial4.html">
     Tutorial 4: Instrumental Variables
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/StochasticProcesses.html">
   Stochastic Processes Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through4.html">
     Modeling Steps 1 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through10.html">
     Modeling Steps 5 - 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModel.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProject.html">
     Example Data Project: the Train Illusion
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/datasets_overview.html">
   Datasets
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/neurons.html">
     Neurons
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/neurons_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/fMRI.html">
     fMRI
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/fMRI_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/ECoG.html">
     ECoG
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/ECoG_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/behavior.html">
     Behavior
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
<label for="toctree-checkbox-24">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/behavior_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/theory.html">
     Theory
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
<label for="toctree-checkbox-25">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/theory/README.html">
       Guide
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_templates.html">
   Project Templates
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/project_2020_highlights.html">
   Projects 2020
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
<label for="toctree-checkbox-26">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/neurons.html">
     Neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/theory.html">
     Theory
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/behavior.html">
     Behavior
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/fMRI.html">
     fMRI
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/eeg.html">
     EEG
    </a>
</li>
</ul>
</li>
</ul>
</div>
</nav></div>
<div class="bd-sidebar__bottom">
<!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="headerbtn" data-placement="right" data-toggle="tooltip" for="__navigation" title="Toggle navigation">
<span class="headerbtn__icon-container">
<i class="fas fa-bars"></i>
</span>
</label>
</div>
<div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
<button aria-label="Launch interactive content" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-rocket"></i>
</button>
<div class="menu-dropdown__content">
<ul>
</ul>
</div>
</div>
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="menu-dropdown menu-dropdown-repository-buttons">
<button aria-label="Source repositories" class="headerbtn menu-dropdown__trigger">
<i class="fab fa-github"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="headerbtn__text-container">repository</span>
</a>
</li>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content/issues/new?title=Issue%20on%20page%20%2Ftutorials/W3D4_ReinforcementLearning/instructor/W3D4_Tutorial2.html&amp;body=Your%20issue%20content%20here." title="Open an issue">
<span class="headerbtn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="headerbtn__text-container">open issue</span>
</a>
</li>
</ul>
</div>
</div>
<div class="menu-dropdown menu-dropdown-download-buttons">
<button aria-label="Download this page" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-download"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W3D4_ReinforcementLearning/instructor/W3D4_Tutorial2.ipynb" title="Download source file">
<span class="headerbtn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="headerbtn__text-container">.ipynb</span>
</a>
</li>
<li>
<button class="headerbtn" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="headerbtn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="headerbtn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
</div>
<label class="headerbtn headerbtn-page-toc" for="__page-toc">
<span class="headerbtn__icon-container">
<i class="fas fa-list"></i>
</span>
</label>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
    </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 2: Learning to Act: Multi-Armed Bandits
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-multi-armed-bandits">
   Section 1: Multi-Armed Bandits
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-multi-armed-bandits">
     Video 1: Multi-Armed Bandits
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-choosing-an-action">
   Section 2: Choosing an Action
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-implement-epsilon-greedy">
     Coding Exercise 2: Implement Epsilon-Greedy
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-2-changing-epsilon">
     Interactive Demo 2: Changing Epsilon
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
</a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-learning-from-rewards">
   Section 3: Learning from Rewards
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-updating-action-values">
     Coding Exercise 3: Updating Action Values
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-solving-multi-armed-bandits">
   Section 4: Solving Multi-Armed Bandits
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-4-changing-epsilon-and-alpha">
     Interactive Demo 4: Changing Epsilon and Alpha
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
</a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
</li>
</ul>
</nav>
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 2: Learning to Act: Multi-Armed Bandits</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 2: Learning to Act: Multi-Armed Bandits
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-multi-armed-bandits">
   Section 1: Multi-Armed Bandits
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-multi-armed-bandits">
     Video 1: Multi-Armed Bandits
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-choosing-an-action">
   Section 2: Choosing an Action
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-implement-epsilon-greedy">
     Coding Exercise 2: Implement Epsilon-Greedy
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-2-changing-epsilon">
     Interactive Demo 2: Changing Epsilon
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
</a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-learning-from-rewards">
   Section 3: Learning from Rewards
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-updating-action-values">
     Coding Exercise 3: Updating Action Values
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-solving-multi-armed-bandits">
   Section 4: Solving Multi-Armed Bandits
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-4-changing-epsilon-and-alpha">
     Interactive Demo 4: Changing Epsilon and Alpha
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
</a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/main/tutorials/W3D4_ReinforcementLearning/instructor/W3D4_Tutorial2.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/W3D4_ReinforcementLearning/instructor/W3D4_Tutorial2.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<div class="section" id="tutorial-2-learning-to-act-multi-armed-bandits">
<h1>Tutorial 2: Learning to Act: Multi-Armed Bandits<a class="headerlink" href="#tutorial-2-learning-to-act-multi-armed-bandits" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 3, Day 4: Reinforcement Learning</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Marcelo Mattar and Eric DeWitt with help from Byron Galbraith</p>
<p><strong>Content reviewers:</strong> Ella Batty, Matt Krause and Michael Waskom</p>
<p><strong>Post-production team:</strong> Gagana B, Spiros Chavlis</p>
<p><strong>Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs</strong></p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p></div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing of tutorial: 45 min</em></p>
<p>In this tutorial you will use ‘bandits’ to understand the fundamentals of how a policy interacts with the learning algorithm in reinforcement learning.</p>
<ul class="simple">
<li><p>You will understand the fundamental tradeoff between exploration and exploitation in a policy.</p></li>
<li><p>You will understand how the learning rate interacts with exploration to find the best available action.</p></li>
</ul>
<div class="section" id="tutorial-slides">
<h2>Tutorial slides<a class="headerlink" href="#tutorial-slides" title="Permalink to this headline">¶</a></h2>
<p>These are the slides for all videos in this tutorial.</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<iframe allowfullscreen="" frameborder="0" height="480" src="https://mfr.ca-1.osf.io/render?url=https://osf.io/2jzdu/?direct%26mode=render%26action=download%26mode=render" width="854"></iframe>
</div></div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure Settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Figure Settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>       <span class="c1"># interactive display</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plotting-functions">
<h2>Plotting Functions<a class="headerlink" href="#plotting-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Plotting Functions</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_choices</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">choice_fn</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">rng_seed</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">rng_seed</span><span class="p">)</span>
  <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">choice_fn</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">)</span>
    <span class="n">counts</span><span class="p">[</span><span class="n">action</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="p">)),</span> <span class="n">counts</span><span class="o">/</span><span class="n">n_steps</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="s1">'</span><span class="si">% c</span><span class="s1">hosen'</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">'action'</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">xticks</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">plot_multi_armed_bandit_results</span><span class="p">(</span><span class="n">results</span><span class="p">):</span>
  <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">'rewards'</span><span class="p">])</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">"Total Reward: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">'rewards'</span><span class="p">])</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
          <span class="n">xlabel</span><span class="o">=</span><span class="s1">'step'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'reward'</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">'qs'</span><span class="p">])</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">'step'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'value'</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">'mu'</span><span class="p">])))</span>
  <span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">'mu'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'latent'</span><span class="p">)</span>
  <span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">'qs'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'learned'</span><span class="p">)</span>
  <span class="n">ax3</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">'action'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'value'</span><span class="p">)</span>
  <span class="n">ax3</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_parameter_performance</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">trial_rewards</span><span class="p">,</span> <span class="n">trial_optimal</span><span class="p">):</span>
  <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

  <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">trial_rewards</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Average Reward (</span><span class="si">{</span><span class="n">fixed</span><span class="si">}</span><span class="s1">)'</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">'step'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'reward'</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

  <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">trial_optimal</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Performance (</span><span class="si">{</span><span class="n">fixed</span><span class="si">}</span><span class="s1">)'</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">'step'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'</span><span class="si">% o</span><span class="s1">ptimal'</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-multi-armed-bandits">
<h1>Section 1: Multi-Armed Bandits<a class="headerlink" href="#section-1-multi-armed-bandits" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-1-multi-armed-bandits">
<h2>Video 1: Multi-Armed Bandits<a class="headerlink" href="#video-1-multi-armed-bandits" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "af681dff858044639e04c1dd7f88f6d6"}
</script></div>
</div>
<p>Consider the following learning problem. You are faced repeatedly with a choice among <span class="math notranslate nohighlight">\(k\)</span> different options, or actions. After each choice you receive a reward signal in the form of a numerical value, where the larger value is the better. Your objective is to maximize the expected total reward over some time period, for example, over 1000 action selections, or time steps.</p>
<p>This is the original form of the k-armed bandit problem. This name derives from the colloquial name for a slot machine, the “one-armed bandit”, because it has the one lever to pull, and it is often rigged to take more money than it pays out over time. The multi-armed bandit extension is to imagine, for instance, that you are faced with multiple slot machines that you can play, but only one at a time. Which machine should you play, i.e., which arm should you pull, which action should you take, at any given time to maximize your total payout.</p>
<a class="reference internal image-reference" href="https://github.com/NeuromatchAcademy/course-content/blob/main/tutorials/static/W3D4_Tutorial2_MultiarmedBandit.png?raw=true"><img alt="MultiArmedBandit" src="https://github.com/NeuromatchAcademy/course-content/blob/main/tutorials/static/W3D4_Tutorial2_MultiarmedBandit.png?raw=true" style="width: 625px; height: 269px;"/></a>
<p>While there are many different levels of sophistication and assumptions in how the rewards are determined, for simplicity’s sake we will assume that each action results in a reward drawn from a fixed Gaussian distribution with unknown mean and unit variance. This problem setting is referred to as the <em>environment</em>, and the goal is to find the arm with the highest mean value.</p>
<p>We will solve this <em>optimization problem</em> with an <em>agent</em>, in this case an algorithm that takes in rewards and returns actions.</p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-choosing-an-action">
<h1>Section 2: Choosing an Action<a class="headerlink" href="#section-2-choosing-an-action" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing to here from start of tutorial: 10 min</em></p>
<p>The first thing our agent needs to be able to do is choose which arm to pull. The strategy for choosing actions based on our expectations is called a <em>policy</em> (often denoted <span class="math notranslate nohighlight">\(\pi\)</span>). We could have a random policy – just pick an arm at random each time – though this doesn’t seem likely to be capable of optimizing our reward. We want some intentionality, and to do that we need a way of describing our beliefs about the arms’ reward potential. We do this with an action-value function</p>
<div class="amsmath math notranslate nohighlight" id="equation-ede3ed49-2592-4b02-abc3-884b0553700d">
<span class="eqno">(309)<a class="headerlink" href="#equation-ede3ed49-2592-4b02-abc3-884b0553700d" title="Permalink to this equation">¶</a></span>\[\begin{equation}
q(a) = \mathbb{E} [r_{t} | a_{t} = a]
\end{equation}\]</div>
<p>where the value <span class="math notranslate nohighlight">\(q\)</span> for taking action <span class="math notranslate nohighlight">\(a \in A\)</span> at time <span class="math notranslate nohighlight">\(t\)</span> is equal to the expected value of the reward <span class="math notranslate nohighlight">\(r_t\)</span> given that we took action <span class="math notranslate nohighlight">\(a\)</span> at that time. In practice, this is often represented as an array of values, where each action’s value is a different element in the array.</p>
<p>Great, now that we have a way to describe our beliefs about the values each action should return, let’s come up with a policy.</p>
<p>An obvious choice would be to take the action with the highest expected value. This is referred to as the <em>greedy</em> policy</p>
<div class="amsmath math notranslate nohighlight" id="equation-68e1820d-5dc5-40f8-86ef-59eb16b014aa">
<span class="eqno">(310)<a class="headerlink" href="#equation-68e1820d-5dc5-40f8-86ef-59eb16b014aa" title="Permalink to this equation">¶</a></span>\[\begin{equation}
a_{t} = \text{argmax}_{a} \; q_{t} (a)
\end{equation}\]</div>
<p>where our choice action is the one that maximizes the current value function.</p>
<p>So far so good, but it can’t be this easy. And, in fact, the greedy policy does have a fatal flaw: it easily gets trapped in local maxima. It never explores to see what it hasn’t seen before if one option is already better than the others. This leads us to a fundamental challenge in coming up with effective policies.</p>
<p><strong>The Exploitation-Exploration Dilemma</strong></p>
<p>If we never try anything new, if we always stick to the safe bet, we don’t know what we are missing. Sometimes we aren’t missing much of anything, and regret not sticking with our preferred choice, yet other times we stumble upon something new that was way better than we thought.</p>
<p>This is the exploitation-exploration dilemma: do you go with your best choice now, or risk the less certain option with the hope of finding something better. Too much exploration, however, means you may end up with a sub-optimal reward once it’s time to stop.</p>
<p>In order to avoid getting stuck in local minima while also maximizing reward, effective policies need some way to balance between these two aims.</p>
<p>A simple extension to our greedy policy is to add some randomness. For instance, a coin flip – heads we take the best choice now, tails we pick one at random. This is referred to as the <span class="math notranslate nohighlight">\(\epsilon\)</span>-greedy policy:</p>
<div class="amsmath math notranslate nohighlight" id="equation-1bdf5a39-067b-4695-b52f-ac19a7592b3b">
<span class="eqno">(311)<a class="headerlink" href="#equation-1bdf5a39-067b-4695-b52f-ac19a7592b3b" title="Permalink to this equation">¶</a></span>\[\begin{equation}
P (a_{t} = a) = 
        \begin{cases}
        1 - \epsilon + \epsilon/N    &amp; \quad \text{if } a_{t} = \text{argmax}_{a} \; q_{t} (a) \\
        \epsilon/N        &amp; \quad \text{else} 
        \end{cases} 
\end{equation}\]</div>
<p>which is to say that with probability 1 - <span class="math notranslate nohighlight">\(\epsilon\)</span> for <span class="math notranslate nohighlight">\(\epsilon \in [0,1]\)</span> we select the greedy choice, and otherwise we select an action at random (including the greedy option).</p>
<p>Despite its relative simplicity, the epsilon-greedy policy is quite effective, which leads to its general popularity.</p>
<div class="section" id="coding-exercise-2-implement-epsilon-greedy">
<h2>Coding Exercise 2: Implement Epsilon-Greedy<a class="headerlink" href="#coding-exercise-2-implement-epsilon-greedy" title="Permalink to this headline">¶</a></h2>
<p><em>Referred to in video as Exercise 1</em></p>
<p>In this exercise you will implement the epsilon-greedy algorithm for deciding which action to take from a set of possible actions given their value function and a probability <span class="math notranslate nohighlight">\(\epsilon\)</span> of simply choosing one at random.</p>
<p>TIP: You may find <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.random.html"><code class="docutils literal notranslate"><span class="pre">np.random.random</span></code></a>, <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html"><code class="docutils literal notranslate"><span class="pre">np.random.choice</span></code></a>, and <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.argmax.html"><code class="docutils literal notranslate"><span class="pre">np.argmax</span></code></a> useful here.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">epsilon_greedy</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">):</span>
  <span class="sd">"""Epsilon-greedy policy: selects the maximum value action with probability</span>
<span class="sd">  (1-epsilon) and selects randomly with epsilon probability.</span>

<span class="sd">  Args:</span>
<span class="sd">    q (ndarray): an array of action values</span>
<span class="sd">    epsilon (float): probability of selecting an action randomly</span>

<span class="sd">  Returns:</span>
<span class="sd">    int: the chosen action</span>
<span class="sd">  """</span>
  <span class="c1">#####################################################################</span>
  <span class="c1">## TODO for students: implement the epsilon greedy decision algorithm</span>
  <span class="c1"># Fill out function and remove</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: implement the epsilon greedy decision algorithm"</span><span class="p">)</span>
  <span class="c1">#####################################################################</span>
  <span class="c1"># write a boolean expression that determines if we should take the best action</span>
  <span class="n">be_greedy</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">if</span> <span class="n">be_greedy</span><span class="p">:</span>

    <span class="c1"># write an expression for selecting the best action from the action values</span>
    <span class="n">action</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">else</span><span class="p">:</span>

    <span class="c1"># write an expression for selecting a random action</span>
    <span class="n">action</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">action</span>


<span class="c1"># Set parameters</span>
<span class="n">q</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="c1"># Visualize</span>
<span class="n">plot_choices</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">epsilon_greedy</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">epsilon_greedy</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">):</span>
  <span class="sd">"""Epsilon-greedy policy: selects the maximum value action with probability</span>
<span class="sd">  (1-epsilon) and selects randomly with epsilon probability.</span>

<span class="sd">  Args:</span>
<span class="sd">    q (ndarray): an array of action values</span>
<span class="sd">    epsilon (float): probability of selecting an action randomly</span>

<span class="sd">  Returns:</span>
<span class="sd">    int: the chosen action</span>
<span class="sd">  """</span>
  <span class="c1"># write a boolean expression that determines if we should take the best action</span>
  <span class="n">be_greedy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">epsilon</span>

  <span class="k">if</span> <span class="n">be_greedy</span><span class="p">:</span>

    <span class="c1"># write an expression for selecting the best action from the action values</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>

  <span class="k">else</span><span class="p">:</span>

    <span class="c1"># write an expression for selecting a random action</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">q</span><span class="p">))</span>

  <span class="k">return</span> <span class="n">action</span>


<span class="c1"># Set parameters</span>
<span class="n">q</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="c1"># Visualize</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_choices</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">epsilon_greedy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W3D4_Tutorial2_21_2.png" src="../../../_images/W3D4_Tutorial2_21_2.png"/>
</div>
</div>
<p>This is what we should expect, that the action with the largest value (action 1) is selected about (1-<span class="math notranslate nohighlight">\(\epsilon\)</span>) of the time, or 90% for <span class="math notranslate nohighlight">\(\epsilon = 0.1\)</span>, and the remaining 10% is split evenly amongst the other options. Use the demo below to explore how changing <span class="math notranslate nohighlight">\(\epsilon\)</span> affects the distribution of selected actions.</p>
</div>
<div class="section" id="interactive-demo-2-changing-epsilon">
<h2>Interactive Demo 2: Changing Epsilon<a class="headerlink" href="#interactive-demo-2-changing-epsilon" title="Permalink to this headline">¶</a></h2>
<p>Epsilon is our one parameter for balancing exploitation and exploration.  Given a set of values <span class="math notranslate nohighlight">\(q = [-2, 5, 0, 1]\)</span>, use the widget below to see how changing <span class="math notranslate nohighlight">\(\epsilon\)</span> influences our selection of the max value 5 (action = 1) vs the others.</p>
<p>At the extremes of its range (0 and 1), the <span class="math notranslate nohighlight">\(\epsilon\)</span>-greedy policy reproduces two other policies. What are they?</p>
<div class="section" id="id1">
<h3><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>Make sure you execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title</span>

<span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">explore_epilson_values</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
  <span class="n">q</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
  <span class="n">plot_choices</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">epsilon_greedy</span><span class="p">,</span> <span class="n">rng_seed</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "d3f15c693c584810a02c68139893e1b0"}
</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove explanation</span>
<span class="sd">"""</span>
<span class="sd">When epsilon is zero, the agent always chooses the currently best option; it</span>
<span class="sd">becomes greedy. When epsilon is 1, the agent chooses randomly.</span>
<span class="sd">"""</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-3-learning-from-rewards">
<h1>Section 3: Learning from Rewards<a class="headerlink" href="#section-3-learning-from-rewards" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing to here from start of tutorial: 25 min</em></p>
<p>Now that we have a policy for deciding what to do, how do we learn from our actions?</p>
<p>One way to do this is just keep a record of every result we ever got and use the averages for each action. If we have a potentially very long running episode, the computational cost of keeping all these values and recomputing the mean over and over again isn’t ideal. Instead we can use a streaming mean calculation, which looks like this:</p>
<div class="amsmath math notranslate nohighlight" id="equation-a2e0ff9e-28dc-4bfc-b53e-a2f18c1e4e22">
<span class="eqno">(312)<a class="headerlink" href="#equation-a2e0ff9e-28dc-4bfc-b53e-a2f18c1e4e22" title="Permalink to this equation">¶</a></span>\[\begin{equation}
q_{t+1}(a) \leftarrow q_{t}(a) + \frac{1}{n_t} (r_{t} - q_{t}(a))
\end{equation}\]</div>
<p>where our action-value function <span class="math notranslate nohighlight">\(q_t(a)\)</span> is the mean of the rewards seen so far, <span class="math notranslate nohighlight">\(n_t\)</span> is the number of actions taken by time <span class="math notranslate nohighlight">\(t\)</span>, and <span class="math notranslate nohighlight">\(r_t\)</span> is the reward just received for taking action <span class="math notranslate nohighlight">\(a\)</span>.</p>
<p>This still requires us to remember how many actions we’ve taken, so let’s generalize this a bit further and replace the action total with a general parameter <span class="math notranslate nohighlight">\(\alpha\)</span>, which we will call the learning rate</p>
<div class="amsmath math notranslate nohighlight" id="equation-da440928-92ac-480e-a2e6-61747b828cb9">
<span class="eqno">(313)<a class="headerlink" href="#equation-da440928-92ac-480e-a2e6-61747b828cb9" title="Permalink to this equation">¶</a></span>\[\begin{equation}
q_{t+1}(a) \leftarrow q_{t}(a) + \alpha (r_{t} - q_{t}(a)).
\end{equation}\]</div>
<div class="section" id="coding-exercise-3-updating-action-values">
<h2>Coding Exercise 3: Updating Action Values<a class="headerlink" href="#coding-exercise-3-updating-action-values" title="Permalink to this headline">¶</a></h2>
<p><em>Referred to in video as Exercise 2</em></p>
<p>In this exercise you will implement the action-value update rule above. The function will take in the action-value function represented as an array <code class="docutils literal notranslate"><span class="pre">q</span></code>, the action taken, the reward received, and the learning rate, <code class="docutils literal notranslate"><span class="pre">alpha</span></code>. The function will return the updated value for the selection action.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">update_action_value</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
  <span class="sd">""" Compute the updated action value given the learning rate and observed</span>
<span class="sd">  reward.</span>

<span class="sd">  Args:</span>
<span class="sd">    q (ndarray): an array of action values</span>
<span class="sd">    action (int): the action taken</span>
<span class="sd">    reward (float): the reward received for taking the action</span>
<span class="sd">    alpha (float): the learning rate</span>

<span class="sd">  Returns:</span>
<span class="sd">    float: the updated value for the selected action</span>
<span class="sd">  """</span>
  <span class="c1">#####################################################</span>
  <span class="c1">## TODO for students: compute the action value update</span>
  <span class="c1"># Fill out function and remove</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: compute the action value update"</span><span class="p">)</span>
  <span class="c1">#####################################################</span>

  <span class="c1"># Write an expression for the updated action value</span>
  <span class="n">value</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">value</span>


<span class="c1"># Set parameters</span>
<span class="n">q</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">action</span> <span class="o">=</span> <span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Original q(</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s2">) value = </span><span class="si">{</span><span class="n">q</span><span class="p">[</span><span class="n">action</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Update action</span>
<span class="n">q</span><span class="p">[</span><span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">update_action_value</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Updated q(</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s2">) value = </span><span class="si">{</span><span class="n">q</span><span class="p">[</span><span class="n">action</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">update_action_value</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
  <span class="sd">""" Compute the updated action value given the learning rate and observed</span>
<span class="sd">  reward.</span>

<span class="sd">  Args:</span>
<span class="sd">    q (ndarray): an array of action values</span>
<span class="sd">    action (int): the action taken</span>
<span class="sd">    reward (float): the reward received for taking the action</span>
<span class="sd">    alpha (float): the learning rate</span>

<span class="sd">  Returns:</span>
<span class="sd">    float: the updated value for the selected action</span>
<span class="sd">  """</span>

  <span class="c1"># Write an expression for the updated action value</span>
  <span class="n">value</span> <span class="o">=</span> <span class="n">q</span><span class="p">[</span><span class="n">action</span><span class="p">]</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">reward</span> <span class="o">-</span> <span class="n">q</span><span class="p">[</span><span class="n">action</span><span class="p">])</span>

  <span class="k">return</span> <span class="n">value</span>


<span class="c1"># Set parameters</span>
<span class="n">q</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">action</span> <span class="o">=</span> <span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Original q(</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s2">) value = </span><span class="si">{</span><span class="n">q</span><span class="p">[</span><span class="n">action</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Update action</span>
<span class="n">q</span><span class="p">[</span><span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">update_action_value</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Updated q(</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s2">) value = </span><span class="si">{</span><span class="n">q</span><span class="p">[</span><span class="n">action</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original q(2) value = 0
Updated q(2) value = 0.1
</pre></div>
</div>
</div>
</div>
<p>You should see</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Original</span> <span class="n">q</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="n">value</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">Updated</span> <span class="n">q</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="n">value</span> <span class="o">=</span> <span class="mf">0.1</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-4-solving-multi-armed-bandits">
<h1>Section 4: Solving Multi-Armed Bandits<a class="headerlink" href="#section-4-solving-multi-armed-bandits" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing to here from start of tutorial: 31 min</em></p>
<p>Now that we have both a policy and a learning rule, we can combine these to solve our original multi-armed bandit task. Recall that we have some number of arms that give rewards drawn from Gaussian distributions with unknown mean and unit variance, and our goal is to find the arm with the highest mean.</p>
<p>First, let’s see how we will simulate this environment by reading through the annotated code below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">multi_armed_bandit</span><span class="p">(</span><span class="n">n_arms</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
  <span class="sd">""" A Gaussian multi-armed bandit using an epsilon-greedy policy. For each</span>
<span class="sd">  action, rewards are randomly sampled from normal distribution, with a mean</span>
<span class="sd">  associated with that arm and unit variance.</span>

<span class="sd">  Args:</span>
<span class="sd">    n_arms (int): number of arms or actions</span>
<span class="sd">    epsilon (float): probability of selecting an action randomly</span>
<span class="sd">    alpha (float): the learning rate</span>
<span class="sd">    n_steps (int): number of steps to evaluate</span>

<span class="sd">  Returns:</span>
<span class="sd">    dict: a dictionary containing the action values, actions, and rewards from</span>
<span class="sd">    the evaluation along with the true arm parameters mu and the optimality of</span>
<span class="sd">    the chosen actions.</span>
<span class="sd">  """</span>
  <span class="c1"># Gaussian bandit parameters</span>
  <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n_arms</span><span class="p">)</span>

  <span class="c1"># Evaluation and reporting state</span>
  <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_arms</span><span class="p">)</span>
  <span class="n">qs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_steps</span><span class="p">,</span> <span class="n">n_arms</span><span class="p">))</span>
  <span class="n">rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)</span>
  <span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)</span>
  <span class="n">optimal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)</span>

  <span class="c1"># Run the bandit</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>

    <span class="c1"># Choose an action</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">epsilon_greedy</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">)</span>
    <span class="n">actions</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">action</span>

    <span class="c1"># Compute rewards for all actions</span>
    <span class="n">all_rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>

    <span class="c1"># Observe the reward for the chosen action</span>
    <span class="n">reward</span> <span class="o">=</span> <span class="n">all_rewards</span><span class="p">[</span><span class="n">action</span><span class="p">]</span>
    <span class="n">rewards</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">reward</span>

    <span class="c1"># Was it the best possible choice?</span>
    <span class="n">optimal_action</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">all_rewards</span><span class="p">)</span>
    <span class="n">optimal</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">action</span> <span class="o">==</span> <span class="n">optimal_action</span>

    <span class="c1"># Update the action value</span>
    <span class="n">q</span><span class="p">[</span><span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">update_action_value</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
    <span class="n">qs</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">q</span>

  <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s1">'qs'</span><span class="p">:</span> <span class="n">qs</span><span class="p">,</span>
      <span class="s1">'actions'</span><span class="p">:</span> <span class="n">actions</span><span class="p">,</span>
      <span class="s1">'rewards'</span><span class="p">:</span> <span class="n">rewards</span><span class="p">,</span>
      <span class="s1">'mu'</span><span class="p">:</span> <span class="n">mu</span><span class="p">,</span>
      <span class="s1">'optimal'</span><span class="p">:</span> <span class="n">optimal</span>
  <span class="p">}</span>

  <span class="k">return</span> <span class="n">results</span>
</pre></div>
</div>
</div>
</div>
<p>We can use our multi-armed bandit method to evaluate how our epsilon-greedy policy and learning rule perform at solving the task. First we will set our environment to have 10 arms and our agent parameters to <span class="math notranslate nohighlight">\(\epsilon=0.1\)</span> and <span class="math notranslate nohighlight">\(\alpha=0.01\)</span>. In order to get a good sense of the agent’s performance, we will run the episode for 1000 steps.</p>
<p>Execute to see visualization</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute to see visualization</span>

<span class="c1"># set for reproducibility, comment out / change seed value for different results</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">n_arms</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">n_steps</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">multi_armed_bandit</span><span class="p">(</span><span class="n">n_arms</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">'rewards'</span><span class="p">])</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Observed Reward ($\epsilon$=</span><span class="si">{</span><span class="n">epsilon</span><span class="si">}</span><span class="s1">, $</span><span class="se">\\</span><span class="s1">alpha$=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s1">)'</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="s1">'step'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'reward'</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">'qs'</span><span class="p">])</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">'Action Values ($\epsilon$=</span><span class="si">{</span><span class="n">epsilon</span><span class="si">}</span><span class="s1">, $</span><span class="se">\\</span><span class="s1">alpha$=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s1">)'</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="s1">'step'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'value'</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_arms</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W3D4_Tutorial2_37_0.png" src="../../../_images/W3D4_Tutorial2_37_0.png"/>
</div>
</div>
<p>Alright, we got some rewards that are kind of all over the place, but the agent seemed to settle in on the first arm as the preferred choice of action relatively quickly. Let’s see how well we did at recovering the true means of the Gaussian random variables behind the arms.</p>
<p>Execute to see visualization</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute to see visualization</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">'mu'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'latent'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">'qs'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'learned'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">'$\epsilon$=</span><span class="si">{</span><span class="n">epsilon</span><span class="si">}</span><span class="s1">, $</span><span class="se">\\</span><span class="s1">alpha$=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span>
       <span class="n">xlabel</span><span class="o">=</span><span class="s1">'action'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'value'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W3D4_Tutorial2_40_0.png" src="../../../_images/W3D4_Tutorial2_40_0.png"/>
</div>
</div>
<p>Well, we seem to have found a very good estimate for action 0, but most of the others are not great. In fact, we can see the effect of the local maxima trap at work – the greedy part of our algorithm locked onto action 0, which is actually the 2nd best choice to action 6. Since these are the means of Gaussian random variables, we can see that the overlap between the two would be quite high, so even if we did explore action 6, we may draw a sample that is still lower than our estimate for action 0.</p>
<p>However, this was just one choice of parameters. Perhaps there is a better combination?</p>
<div class="section" id="interactive-demo-4-changing-epsilon-and-alpha">
<h2>Interactive Demo 4: Changing Epsilon and Alpha<a class="headerlink" href="#interactive-demo-4-changing-epsilon-and-alpha" title="Permalink to this headline">¶</a></h2>
<p><em>Referred to in video as Exercise 3</em></p>
<p>Use the widget below to explore how varying the values of <span class="math notranslate nohighlight">\(\epsilon\)</span> (exploitation-exploration tradeoff), <span class="math notranslate nohighlight">\(\alpha\)</span> (learning rate), and even the number of actions <span class="math notranslate nohighlight">\(k\)</span>, changes the behavior of our agent.</p>
<div class="section" id="id2">
<h3><a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>Make sure you execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title</span>

<span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact_manual</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">15</span><span class="p">),</span>
                         <span class="n">epsilon</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
                         <span class="n">alpha</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatLogSlider</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">3</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">explore_bandit_parameters</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
  <span class="n">results</span> <span class="o">=</span> <span class="n">multi_armed_bandit</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
  <span class="n">plot_multi_armed_bandit_results</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "60c0086b2eef433ca94f9acd440c3760"}
</script></div>
</div>
<p>While we can see how changing the epsilon and alpha values impact the agent’s behavior, this doesn’t give us a great sense of which combination is optimal. Due to the stochastic nature of both our rewards and our policy, a single trial run isn’t sufficient to give us this information. Let’s run multiple trials and compare the average performance.</p>
<p>First we will look at different values for <span class="math notranslate nohighlight">\(\epsilon \in [0.0, 0.1, 0.2]\)</span> to a fixed <span class="math notranslate nohighlight">\(\alpha=0.1\)</span>. We will run 200 trials as a nice balance between speed and accuracy.</p>
<p>Execute this cell to see visualization</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to see visualization</span>

<span class="c1"># set for reproducibility, comment out / change seed value for different results</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">epsilons</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">n_trials</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">trial_rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">epsilons</span><span class="p">),</span> <span class="n">n_trials</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">))</span>
<span class="n">trial_optimal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">epsilons</span><span class="p">),</span> <span class="n">n_trials</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">epsilon</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">epsilons</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_trials</span><span class="p">):</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">multi_armed_bandit</span><span class="p">(</span><span class="n">n_arms</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
    <span class="n">trial_rewards</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">'rewards'</span><span class="p">]</span>
    <span class="n">trial_optimal</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">'optimal'</span><span class="p">]</span>

<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">'$\epsilon$=</span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s1">'</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">epsilons</span><span class="p">]</span>
<span class="n">fixed</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'$</span><span class="se">\\</span><span class="s1">alpha$=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s1">'</span>
<span class="n">plot_parameter_performance</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">trial_rewards</span><span class="p">,</span> <span class="n">trial_optimal</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W3D4_Tutorial2_48_0.png" src="../../../_images/W3D4_Tutorial2_48_0.png"/>
</div>
</div>
<p>On the left we have plotted the average reward over time, and we see that while <span class="math notranslate nohighlight">\(\epsilon=0\)</span> (the greedy policy) does well initially, <span class="math notranslate nohighlight">\(\epsilon=0.1\)</span> starts to do slightly better in the long run, while <span class="math notranslate nohighlight">\(\epsilon=0.2\)</span> does the worst. Looking on the right, we see the percentage of times the optimal action (the best possible choice at time <span class="math notranslate nohighlight">\(t\)</span>) was taken, and here again we see a similar pattern of <span class="math notranslate nohighlight">\(\epsilon=0.1\)</span> starting out a bit slower but eventually having a slight edge in the longer run.</p>
<p>We can also do the same for the learning rates. We will evaluate <span class="math notranslate nohighlight">\(\alpha \in [0.01, 0.1, 1.0]\)</span> to a fixed <span class="math notranslate nohighlight">\(\epsilon=0.1\)</span>.</p>
<p>Execute this cell to see visualization</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to see visualization</span>

<span class="c1"># set for reproducibility, comment out / change seed value for different results</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
<span class="n">n_trials</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">trial_rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">epsilons</span><span class="p">),</span> <span class="n">n_trials</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">))</span>
<span class="n">trial_optimal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">epsilons</span><span class="p">),</span> <span class="n">n_trials</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">alphas</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_trials</span><span class="p">):</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">multi_armed_bandit</span><span class="p">(</span><span class="n">n_arms</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
    <span class="n">trial_rewards</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">'rewards'</span><span class="p">]</span>
    <span class="n">trial_optimal</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">'optimal'</span><span class="p">]</span>

<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">'$</span><span class="se">\\</span><span class="s1">alpha$=</span><span class="si">{</span><span class="n">a</span><span class="si">}</span><span class="s1">'</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">]</span>
<span class="n">fixed</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'$\epsilon$=</span><span class="si">{</span><span class="n">epsilon</span><span class="si">}</span><span class="s1">'</span>
<span class="n">plot_parameter_performance</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">trial_rewards</span><span class="p">,</span> <span class="n">trial_optimal</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W3D4_Tutorial2_51_0.png" src="../../../_images/W3D4_Tutorial2_51_0.png"/>
</div>
</div>
<p>Again we see a balance between an effective learning rate. <span class="math notranslate nohighlight">\(\alpha=0.01\)</span> is too weak to quickly incorporate good values, while <span class="math notranslate nohighlight">\(\alpha=1\)</span> is too strong likely resulting in high variance in values due to the Gaussian nature of the rewards.</p>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing of tutorial: 45 min</em></p>
<p>In this tutorial you implemented both the epsilon-greedy decision algorithm and a learning rule for solving a multi-armed bandit scenario. You saw how balancing exploitation and exploration in action selection is critical in finding optimal solutions. You also saw how choosing an appropriate learning rate determines how well an agent can generalize the information they receive from rewards.</p>
</div>
<script type="application/vnd.jupyter.widget-state+json">
{"state": {"25fda21386384bd0828914b3f42a9700": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "905a49febb7140d6b687682cea8905ac": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_25fda21386384bd0828914b3f42a9700", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/BV1M54y1B7S3\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7fe1883b65d0>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1M54y1B7S3&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "08dcc5a6e41444539e0a770f61388c2f": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f5fb46fa40f143a3a0776ac131e371a3": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_08dcc5a6e41444539e0a770f61388c2f", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=kdiXr1zsfo0\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7fe18838e310>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/kdiXr1zsfo0?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "fa45e2cb8083486e9a694f9830f4af47": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "af681dff858044639e04c1dd7f88f6d6": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_f5fb46fa40f143a3a0776ac131e371a3", "IPY_MODEL_905a49febb7140d6b687682cea8905ac"], "layout": "IPY_MODEL_fa45e2cb8083486e9a694f9830f4af47", "selected_index": 0}}, "ecc1408433844a5fa443f61d64dd883c": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "9c4839c64a2945aa9bc95b7a14584e2a": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "49316bdd9650447383623d55b5196af1": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "epsilon", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_ecc1408433844a5fa443f61d64dd883c", "max": 1.0, "min": 0.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_9c4839c64a2945aa9bc95b7a14584e2a", "value": 0.1}}, "2abb1b7ce2e847ea8aed26ed199bdf25": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "d3f15c693c584810a02c68139893e1b0": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_49316bdd9650447383623d55b5196af1", "IPY_MODEL_4e74cc0b550f484faa089fca8a90047f"], "layout": "IPY_MODEL_2abb1b7ce2e847ea8aed26ed199bdf25"}}, "4447050e1c4d4937bb7eb20e11d47a8d": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "4e74cc0b550f484faa089fca8a90047f": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_4447050e1c4d4937bb7eb20e11d47a8d", "msg_id": "", "outputs": [{"output_type": "display_data", "metadata": {"image/png": {"width": 775, "height": 575}}, "data": {"text/plain": "<Figure size 800x600 with 1 Axes>", "image/png": "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\n"}}]}}, "5a339d61cd8c4a7b852edcc3d9dead1a": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e96325d046034d88a37ac7dd3411bcf8": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "433f13bd3b134983b9d59c4b6e8d9013": {"model_name": "IntSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "k", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_5a339d61cd8c4a7b852edcc3d9dead1a", "max": 15, "min": 2, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_e96325d046034d88a37ac7dd3411bcf8", "value": 10}}, "663250e3b0b24d1c99ab5d53735cad89": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "5918562bf08b44a48f786bcf9d6c66f5": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "584523cbd9f64de6a8799c6bc0327403": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "epsilon", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_663250e3b0b24d1c99ab5d53735cad89", "max": 1.0, "min": 0.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_5918562bf08b44a48f786bcf9d6c66f5", "value": 0.1}}, "3dc07c2aaabc4c56b96c29d7819da61e": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "609d6b4090d84105a8305321666db31b": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "45205f52d1de4855aabd3d7a7153490c": {"model_name": "FloatLogSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatLogSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatLogSliderView", "base": 10.0, "continuous_update": true, "description": "alpha", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_3dc07c2aaabc4c56b96c29d7819da61e", "max": 0.0, "min": -3.0, "orientation": "horizontal", "readout": true, "readout_format": ".3g", "step": 0.1, "style": "IPY_MODEL_609d6b4090d84105a8305321666db31b", "value": 0.01}}, "004d779968f4456791f8621a988fba20": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "60c0086b2eef433ca94f9acd440c3760": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_433f13bd3b134983b9d59c4b6e8d9013", "IPY_MODEL_584523cbd9f64de6a8799c6bc0327403", "IPY_MODEL_45205f52d1de4855aabd3d7a7153490c", "IPY_MODEL_1215ec157e5a423f8e232e9dfce99719", "IPY_MODEL_5a4acf76abc5403b98447118ed2bed54"], "layout": "IPY_MODEL_004d779968f4456791f8621a988fba20"}}, "bc6d70f312a94f129d37596d503f19c2": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "2ecaeb7cf81f4b66853ebb3c971f8fbd": {"model_name": "ButtonStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ButtonStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "button_color": null, "font_weight": ""}}, "1215ec157e5a423f8e232e9dfce99719": {"model_name": "ButtonModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ButtonModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ButtonView", "button_style": "", "description": "Run Interact", "disabled": false, "icon": "", "layout": "IPY_MODEL_bc6d70f312a94f129d37596d503f19c2", "style": "IPY_MODEL_2ecaeb7cf81f4b66853ebb3c971f8fbd", "tooltip": ""}}, "cd8f7e0fa3d94494959ed6675a2c5575": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "5a4acf76abc5403b98447118ed2bed54": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_cd8f7e0fa3d94494959ed6675a2c5575", "msg_id": "", "outputs": []}}}, "version_major": 2, "version_minor": 0}
</script>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W3D4_ReinforcementLearning/instructor"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="W3D4_Tutorial1.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Tutorial 1: Learning to Predict</p>
</div>
</a>
<a class="right-next" href="W3D4_Tutorial3.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Tutorial 3: Learning to Act: Q-Learning</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
    By Neuromatch<br/>
  
      © Copyright 2021.<br/>
</p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>