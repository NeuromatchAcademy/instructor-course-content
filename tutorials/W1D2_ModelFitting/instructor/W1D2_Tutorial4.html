
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 4: Multiple linear regression and polynomial regression — Neuromatch Academy: Computational Neuroscience (instructor's version)</title>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/custom.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-logo-square-4xp.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W1D2_Tutorial5.html" rel="next" title="Tutorial 5: Model Selection: Bias-variance trade-off"/>
<link href="W1D2_Tutorial3.html" rel="prev" title="Tutorial 3: Confidence intervals and bootstrapping"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
<div class="bd-sidebar__content">
<div class="bd-sidebar__top"><div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
<img alt="logo" class="logo" src="../../../_static/nma-logo-square-4xp.png"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Computational Neuroscience (instructor's version)</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../tatraining/TA_Training_CN.html">
   TA Training: Computational Neuroscience (CN)
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox">
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox">
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</input></li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using discord
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">
   Quick links and policies
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../prereqs/ComputationalNeuroscience.html">
   Prerequisites and preparatory materials for NMA Computational Neuroscience
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Pre-reqs Refresher
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/chapter_title.html">
   Neuro Video Series (W0D0)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial1.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial2.html">
     Human Psychophysics
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial3.html">
     Behavioral Readout
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial4.html">
     Live in Lab
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial5.html">
     Brain Signals: Spiking Activity
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial6.html">
     Brain Signals: LFP
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial7.html">
     Brain Signals: EEG &amp; MEG
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial8.html">
     Brain Signals: fMRI
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial9.html">
     Brain Signals: Calcium Imaging
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial10.html">
     Stimulus Representation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial11.html">
     Neurotransmitters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial12.html">
     Neurons to Consciousness
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">
   Python Workshop 1 (W0D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D1_PythonWorkshop1/instructor/W0D1_Tutorial1.html">
     Tutorial: LIF Neuron Part I
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">
   Python Workshop 2 (W0D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D2_PythonWorkshop2/instructor/W0D2_Tutorial1.html">
     Tutorial 1: LIF Neuron Part II
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D3_LinearAlgebra/chapter_title.html">
   Linear Algebra (W0D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Tutorial1.html">
     Tutorial 1: Vectors
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Tutorial2.html">
     Tutorial 2: Matrices
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Tutorial3.html">
     Bonus Tutorial: Discrete Dynamical Systems
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D4_Calculus/chapter_title.html">
   Calculus (W0D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_Tutorial1.html">
     Tutorial 1: Differentiation and Integration
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_Tutorial2.html">
     Tutorial 2: Differential Equations
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_Tutorial3.html">
     Tutorial 3: Numerical Methods
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D5_Statistics/chapter_title.html">
   Statistics (W0D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_Tutorial1.html">
     Tutorial 1: Probability Distributions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_Tutorial2.html">
     Tutorial 2: Statistical Inference
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Intro to Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_ModelTypes/chapter_title.html">
   Model Types (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial1.html">
     Tutorial 1: “What” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial2.html">
     Tutorial 2: “How” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial3.html">
     Tutorial 3: “Why” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial4.html">
     Tutorial 4: Model Discussions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_ModelingPractice/chapter_title.html">
   Modeling Practice (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_Tutorial1.html">
     Tutorial 1: Framing the Question
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Model Fitting (W1D2)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2">
<a class="reference internal" href="W1D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D2_Tutorial1.html">
     Tutorial 1: Linear regression with MSE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D2_Tutorial2.html">
     Tutorial 2: Linear regression with MLE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D2_Tutorial3.html">
     Tutorial 3: Confidence intervals and bootstrapping
    </a>
</li>
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 4: Multiple linear regression and polynomial regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D2_Tutorial5.html">
     Tutorial 5: Model Selection: Bias-variance trade-off
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D2_Tutorial6.html">
     Tutorial 6: Model Selection: Cross-validation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W1D2_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/chapter_title.html">
   Generalized Linear Models (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Tutorial1.html">
     Tutorial 1: GLMs for Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Tutorial2.html">
     Tutorial 2: Classifiers and regularizers
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/chapter_title.html">
   Dimensionality Reduction (W1D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial1.html">
     Tutorial 1: Geometric view of data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial2.html">
     Tutorial 2: Principal Component Analysis
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial3.html">
     Tutorial 3: Dimensionality Reduction &amp; Reconstruction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial4.html">
     Tutorial 4:  Nonlinear Dimensionality Reduction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_DeepLearning/chapter_title.html">
   Deep Learning (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial3.html">
     Tutorial 3: Building and Evaluating Normative Encoding Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial4.html">
     Bonus Tutorial: Diving Deeper into Decoding &amp; Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Bonus_Autoencoders/chapter_title.html">
   Autoencoders (Bonus)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial1.html">
     Tutorial 1: Intro to Autoencoders
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial2.html">
     Tutorial 2: Autoencoder extensions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial3.html">
     Tutorial 3: Autoencoders applications
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Outro.html">
     Outro
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/MachineLearning.html">
   Machine Learning Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_LinearSystems/chapter_title.html">
   Linear Systems (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial1.html">
     Tutorial 1: Linear dynamical systems
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial2.html">
     Tutorial 2: Markov Processes
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial3.html">
     Tutorial 3: Combining determinism and stochasticity
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial4.html">
     Tutorial 4: Autoregressive models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/chapter_title.html">
   Biological Neuron Models (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial1.html">
     Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial2.html">
     Tutorial 2: Effects of Input Correlation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial3.html">
     Tutorial 3: Synaptic transmission - Models of static and dynamic synapses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial4.html">
     Bonus Tutorial: Spike-timing dependent plasticity (STDP)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_DynamicNetworks/chapter_title.html">
   Dynamic Networks (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial1.html">
     Tutorial 1: Neural Rate Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial2.html">
     Tutorial 2: Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial3.html">
     Bonus Tutorial: Extending the Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/DynamicalSystems.html">
   Dynamical Systems Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Stochastic Processes
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_BayesianDecisions/chapter_title.html">
   Bayesian Decisions (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial1.html">
     Tutorial 1: Bayes with a binary hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial2.html">
     Tutorial 2: Bayesian inference and decisions with continuous hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial3.html">
     Bonus Tutorial : Fitting to data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_HiddenDynamics/chapter_title.html">
   Hidden Dynamics (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial1.html">
     Tutorial 1: Sequential Probability Ratio Test
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial2.html">
     Tutorial 2: Hidden Markov Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial3.html">
     Tutorial 3: The Kalman Filter
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial4.html">
     Bonus Tutorial 4: The Kalman Filter, part 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial5.html">
     Bonus Tutorial 5: Expectation Maximization for spiking neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_OptimalControl/chapter_title.html">
   Optimal Control (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial1.html">
     Tutorial 1: Optimal Control for Discrete States
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial2.html">
     Tutorial 2: Optimal Control for Continuous State
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/chapter_title.html">
   Reinforcement Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial4.html">
     Tutorial 4: Model-Based Reinforcement Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D5_NetworkCausality/chapter_title.html">
   Network Causality (W3D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
<label for="toctree-checkbox-24">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial1.html">
     Tutorial 1: Interventions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial2.html">
     Tutorial 2: Correlations
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial3.html">
     Tutorial 3: Simultaneous fitting/regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial4.html">
     Tutorial 4: Instrumental Variables
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/StochasticProcesses.html">
   Stochastic Processes Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
<label for="toctree-checkbox-25">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through4.html">
     Modeling Steps 1 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through10.html">
     Modeling Steps 5 - 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModel.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProject.html">
     Example Data Project: the Train Illusion
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/datasets_overview.html">
   Datasets
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
<label for="toctree-checkbox-26">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/neurons.html">
     Neurons
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
<label for="toctree-checkbox-27">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/neurons_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/fMRI.html">
     fMRI
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
<label for="toctree-checkbox-28">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/fMRI_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/ECoG.html">
     ECoG
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
<label for="toctree-checkbox-29">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/ECoG_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/behavior.html">
     Behavior
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
<label for="toctree-checkbox-30">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/behavior_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/theory.html">
     Theory
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
<label for="toctree-checkbox-31">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/theory/README.html">
       Guide
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_templates.html">
   Project Templates
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/project_2020_highlights.html">
   Projects 2020
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/>
<label for="toctree-checkbox-32">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/neurons.html">
     Neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/theory.html">
     Theory
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/behavior.html">
     Behavior
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/fMRI.html">
     fMRI
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/eeg.html">
     EEG
    </a>
</li>
</ul>
</li>
</ul>
</div>
</nav></div>
<div class="bd-sidebar__bottom">
<!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="headerbtn" data-placement="right" data-toggle="tooltip" for="__navigation" title="Toggle navigation">
<span class="headerbtn__icon-container">
<i class="fas fa-bars"></i>
</span>
</label>
</div>
<div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
<button aria-label="Launch interactive content" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-rocket"></i>
</button>
<div class="menu-dropdown__content">
<ul>
</ul>
</div>
</div>
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="menu-dropdown menu-dropdown-repository-buttons">
<button aria-label="Source repositories" class="headerbtn menu-dropdown__trigger">
<i class="fab fa-github"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="headerbtn__text-container">repository</span>
</a>
</li>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content/issues/new?title=Issue%20on%20page%20%2Ftutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial4.html&amp;body=Your%20issue%20content%20here." title="Open an issue">
<span class="headerbtn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="headerbtn__text-container">open issue</span>
</a>
</li>
</ul>
</div>
</div>
<div class="menu-dropdown menu-dropdown-download-buttons">
<button aria-label="Download this page" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-download"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial4.ipynb" title="Download source file">
<span class="headerbtn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="headerbtn__text-container">.ipynb</span>
</a>
</li>
<li>
<button class="headerbtn" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="headerbtn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="headerbtn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
</div>
<label class="headerbtn headerbtn-page-toc" for="__page-toc">
<span class="headerbtn__icon-container">
<i class="fas fa-list"></i>
</span>
</label>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
    </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 4: Multiple linear regression and polynomial regression
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-multiple-linear-regression-and-polynomial-regression">
     Video 1: Multiple Linear Regression and Polynomial Regression
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-multiple-linear-regression">
   Section 1: Multiple Linear Regression
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-ordinary-least-squares-estimator">
     Coding Exercise 1: Ordinary Least Squares Estimator
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-polynomial-regression">
   Section 2:  Polynomial Regression
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-1-design-matrix-for-polynomial-regression">
     Section 2.1: Design matrix for polynomial regression
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-1-structure-design-matrix">
       Coding Exercise 2.1: Structure design matrix
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-2-fitting-polynomial-regression-models">
     Section 2.2: Fitting polynomial regression models
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-2-fitting-polynomial-regression-models-with-different-orders">
       Coding Exercise 2.2: Fitting polynomial regression models with different orders
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-3-evaluating-fit-quality">
     Section 2.3: Evaluating fit quality
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-3-compute-mse-and-compare-models">
       Coding Exercise 2.3: Compute MSE and compare models
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#notation">
   Notation
  </a>
</li>
</ul>
</nav>
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 4: Multiple linear regression and polynomial regression</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 4: Multiple linear regression and polynomial regression
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-multiple-linear-regression-and-polynomial-regression">
     Video 1: Multiple Linear Regression and Polynomial Regression
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-multiple-linear-regression">
   Section 1: Multiple Linear Regression
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-ordinary-least-squares-estimator">
     Coding Exercise 1: Ordinary Least Squares Estimator
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-polynomial-regression">
   Section 2:  Polynomial Regression
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-1-design-matrix-for-polynomial-regression">
     Section 2.1: Design matrix for polynomial regression
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-1-structure-design-matrix">
       Coding Exercise 2.1: Structure design matrix
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-2-fitting-polynomial-regression-models">
     Section 2.2: Fitting polynomial regression models
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-2-fitting-polynomial-regression-models-with-different-orders">
       Coding Exercise 2.2: Fitting polynomial regression models with different orders
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-3-evaluating-fit-quality">
     Section 2.3: Evaluating fit quality
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-3-compute-mse-and-compare-models">
       Coding Exercise 2.3: Compute MSE and compare models
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#notation">
   Notation
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/main/tutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial4.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial4.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<div class="section" id="tutorial-4-multiple-linear-regression-and-polynomial-regression">
<h1>Tutorial 4: Multiple linear regression and polynomial regression<a class="headerlink" href="#tutorial-4-multiple-linear-regression-and-polynomial-regression" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 1, Day 2: Model Fitting</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators</strong>: Pierre-Étienne Fiquet, Anqi Wu, Alex Hyafil with help from Byron Galbraith, Ella Batty</p>
<p><strong>Content reviewers</strong>: Lina Teichmann, Saeed Salehi, Patrick Mineault, Michael Waskom</p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p></div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing of tutorial: 35 minutes</em></p>
<p>This is Tutorial 4 of a series on fitting models to data. We start with simple linear regression, using least squares optimization (Tutorial 1) and Maximum Likelihood Estimation (Tutorial 2). We will use bootstrapping to build confidence intervals around the inferred linear model parameters (Tutorial 3). We’ll finish our exploration of regression models by generalizing to multiple linear regression and polynomial regression (Tutorial 4). We end by learning how to choose between these various models. We discuss the bias-variance trade-off (Tutorial 5) and Cross Validation for model selection (Tutorial 6).</p>
<p>In this tutorial, we will generalize the regression model to incorporate multiple features.</p>
<ul class="simple">
<li><p>Learn how to structure inputs for regression using the ‘Design Matrix’</p></li>
<li><p>Generalize the MSE for multiple features using the ordinary least squares estimator</p></li>
<li><p>Visualize data and model fit in multiple dimensions</p></li>
<li><p>Fit polynomial regression models of different complexity</p></li>
<li><p>Plot and evaluate the polynomial regression fits</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Tutorial slides</span>
<span class="c1"># @markdown These are the slides for the videos in all tutorials today</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">IFrame</span>
<span class="n">link_id</span> <span class="o">=</span> <span class="s2">"2mkq4"</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"If you want to download the slides: https://osf.io/download/</span><span class="si">{</span><span class="n">link_id</span><span class="si">}</span><span class="s2">/"</span><span class="p">)</span>
<span class="n">IFrame</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="sa">f</span><span class="s2">"https://mfr.ca-1.osf.io/render?url=https://osf.io/</span><span class="si">{</span><span class="n">link_id</span><span class="si">}</span><span class="s2">/?direct%26mode=render%26action=download%26mode=render"</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="video-1-multiple-linear-regression-and-polynomial-regression">
<h2>Video 1: Multiple Linear Regression and Polynomial Regression<a class="headerlink" href="#video-1-multiple-linear-regression-and-polynomial-regression" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure Settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Figure Settings</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plotting-functions">
<h2>Plotting Functions<a class="headerlink" href="#plotting-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting Functions</span>

<span class="k">def</span> <span class="nf">evaluate_fits</span><span class="p">(</span><span class="n">order_list</span><span class="p">,</span> <span class="n">mse_list</span><span class="p">):</span>
<span class="w">  </span><span class="sd">""" Compare the quality of multiple polynomial fits</span>
<span class="sd">  by plotting their MSE values.</span>

<span class="sd">  Args:</span>
<span class="sd">    order_list (list): list of the order of polynomials to be compared</span>
<span class="sd">    mse_list (list): list of the MSE values for the corresponding polynomial fit</span>
<span class="sd">  """</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">order_list</span><span class="p">,</span> <span class="n">mse_list</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">'Comparing Polynomial Fits'</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">'Polynomial order'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'MSE'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_fitted_polynomials</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">):</span>
<span class="w">  </span><span class="sd">""" Plot polynomials of different orders</span>

<span class="sd">  Args:</span>
<span class="sd">    x (ndarray): input vector of shape (n_samples)</span>
<span class="sd">    y (ndarray): vector of measurements of shape (n_samples)</span>
<span class="sd">    theta_hat (dict): polynomial regression weights for different orders</span>
<span class="sd">  """</span>

  <span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mf">.5</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mf">.5</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

  <span class="k">for</span> <span class="n">order</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">X_design</span> <span class="o">=</span> <span class="n">make_design_matrix</span><span class="p">(</span><span class="n">x_grid</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_grid</span><span class="p">,</span> <span class="n">X_design</span> <span class="o">@</span> <span class="n">theta_hat</span><span class="p">[</span><span class="n">order</span><span class="p">]);</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'y'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'x'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">'C0.'</span><span class="p">);</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="sa">f</span><span class="s1">'order </span><span class="si">{</span><span class="n">o</span><span class="si">}</span><span class="s1">'</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)],</span> <span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'polynomial fits'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-multiple-linear-regression">
<h1>Section 1: Multiple Linear Regression<a class="headerlink" href="#section-1-multiple-linear-regression" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing to here from start of tutorial: 8 min</em></p>
<p>This video covers linear regression with multiple inputs (more than 1D) and polynomial regression.</p>
<details>
<summary> <font color="blue">Click here for text recap of video </font></summary>
<p>Now that we have considered the univariate case and how to produce confidence intervals for our estimator, we turn to the general linear regression case, where we can have more than one regressor, or feature, in our input.</p>
<p>Recall that our original univariate linear model was given as</p>
<div class="amsmath math notranslate nohighlight" id="equation-92c252d0-84d6-49a8-8fb8-7b49ba7274d4">
<span class="eqno">(161)<a class="headerlink" href="#equation-92c252d0-84d6-49a8-8fb8-7b49ba7274d4" title="Permalink to this equation">¶</a></span>\[\begin{equation}
y = \theta x + \epsilon
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta\)</span> is the slope and <span class="math notranslate nohighlight">\(\epsilon\)</span> some noise. We can easily extend this to the multivariate scenario by adding another parameter for each additional feature</p>
<div class="amsmath math notranslate nohighlight" id="equation-4d7cf5e0-5fc3-4aef-90cb-6b493c41633c">
<span class="eqno">(162)<a class="headerlink" href="#equation-4d7cf5e0-5fc3-4aef-90cb-6b493c41633c" title="Permalink to this equation">¶</a></span>\[\begin{equation}
y = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + ... +\theta_d x_d + \epsilon
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta_0\)</span> is the intercept and <span class="math notranslate nohighlight">\(d\)</span> is the number of features (it is also the dimensionality of our input).</p>
<p>We can condense this succinctly using vector notation for a single data point</p>
<div class="amsmath math notranslate nohighlight" id="equation-9b614667-b3d0-476f-b5ca-60ae680641ab">
<span class="eqno">(163)<a class="headerlink" href="#equation-9b614667-b3d0-476f-b5ca-60ae680641ab" title="Permalink to this equation">¶</a></span>\[\begin{equation}
y_i = \boldsymbol{\theta}^{\top}\mathbf{x}_i + \epsilon
\end{equation}\]</div>
<p>and fully in matrix form</p>
<div class="amsmath math notranslate nohighlight" id="equation-0de850b7-f4ae-4e65-a852-7c17346134a4">
<span class="eqno">(164)<a class="headerlink" href="#equation-0de850b7-f4ae-4e65-a852-7c17346134a4" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathbf{y} = \mathbf{X}\boldsymbol{\theta} + \mathbf{\epsilon}
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> is a vector of measurements, <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is a matrix containing the feature values (columns) for each input sample (rows), and <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> is our parameter vector.</p>
<p>This matrix <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is often referred to as the “<a class="reference external" href="https://en.wikipedia.org/wiki/Design_matrix">design matrix</a>”.</p>
<p>We want to find an optimal vector of paramters <span class="math notranslate nohighlight">\(\boldsymbol{\hat\theta}\)</span>. Recall our analytic solution to minimizing MSE for a single regressor:</p>
<div class="amsmath math notranslate nohighlight" id="equation-6604cd54-4a18-49b2-95eb-6102eab18d62">
<span class="eqno">(165)<a class="headerlink" href="#equation-6604cd54-4a18-49b2-95eb-6102eab18d62" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\hat\theta = \frac{\sum_{i=1}^N x_i y_i}{\sum_{i=1}^N x_i^2}.
\end{equation}\]</div>
<p>The same holds true for the multiple regressor case, only now expressed in matrix form</p>
<div class="amsmath math notranslate nohighlight" id="equation-8ac5b4dd-e950-43a9-962f-7e070af72826">
<span class="eqno">(166)<a class="headerlink" href="#equation-8ac5b4dd-e950-43a9-962f-7e070af72826" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\boldsymbol{\hat\theta} = (\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top\mathbf{y}.
\end{equation}\]</div>
<p>This is called the <a class="reference external" href="https://en.wikipedia.org/wiki/Ordinary_least_squares">ordinary least squares</a> (OLS) estimator.</p>
</details><p>For this tutorial we will focus on the two-dimensional case (<span class="math notranslate nohighlight">\(d=2\)</span>), which allows us to easily visualize our results. As an example, think of a situation where a scientist records the spiking response of a retinal ganglion cell to patterns of light signals that vary in contrast and in orientation. Then contrast and orientation values can be used as features / regressors to predict the cells response.</p>
<p>In this case our model can be written for a single data point as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-a4c139c4-f112-487b-a019-a63265a1ad4e">
<span class="eqno">(167)<a class="headerlink" href="#equation-a4c139c4-f112-487b-a019-a63265a1ad4e" title="Permalink to this equation">¶</a></span>\[\begin{equation}
y = \theta_0 + \theta_1 x_1 + \theta_2 x_2 + \epsilon
\end{equation}\]</div>
<p>or for multiple data points in matrix form where</p>
<div class="amsmath math notranslate nohighlight" id="equation-2c51e1fd-768c-46cd-a798-71d8b7431378">
<span class="eqno">(168)<a class="headerlink" href="#equation-2c51e1fd-768c-46cd-a798-71d8b7431378" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathbf{X} = 
\begin{bmatrix}
1 &amp; x_{1,1} &amp; x_{1,2} \\
1 &amp; x_{2,1} &amp; x_{2,2} \\
\vdots &amp; \vdots &amp; \vdots \\
1 &amp; x_{n,1} &amp; x_{n,2}
\end{bmatrix}, 
\boldsymbol{\theta} =
\begin{bmatrix}
\theta_0 \\
\theta_1 \\
\theta_2 \\
\end{bmatrix}
\end{equation}\]</div>
<p>When we refer to <span class="math notranslate nohighlight">\(x_{i, j}\)</span>, we mean that it is the i-th data point and the j-th feature of that data point.</p>
<p>For our actual exploration dataset we shall set <span class="math notranslate nohighlight">\(\boldsymbol{\theta}=[0, -2, -3]\)</span> and draw <span class="math notranslate nohighlight">\(N=40\)</span> noisy samples from <span class="math notranslate nohighlight">\(x \in [-2,2)\)</span>. Note that setting the value of <span class="math notranslate nohighlight">\(\theta_0 = 0\)</span> effectively ignores the offset term.</p>
<p>Execute this cell to simulate some data</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to simulate some data</span>

<span class="c1"># Set random seed for reproducibility</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>

<span class="c1"># Set parameters</span>
<span class="n">theta</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">]</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">40</span>

<span class="c1"># Draw x and calculate y</span>
<span class="n">n_regressors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">x0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">))</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">theta</span> <span class="o">+</span> <span class="n">noise</span>


<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s1">'3d'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s1">'$x_1$'</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s1">'$x_2$'</span><span class="p">,</span>
    <span class="n">zlabel</span><span class="o">=</span><span class="s1">'y'</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="coding-exercise-1-ordinary-least-squares-estimator">
<h2>Coding Exercise 1: Ordinary Least Squares Estimator<a class="headerlink" href="#coding-exercise-1-ordinary-least-squares-estimator" title="Permalink to this headline">¶</a></h2>
<p>In this exercise you will implement the OLS approach to estimating <span class="math notranslate nohighlight">\(\boldsymbol{\hat\theta}\)</span> from the design matrix <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> and measurement vector <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>. You can use the <code class="docutils literal notranslate"><span class="pre">@</span></code> symbol for matrix multiplication, <code class="docutils literal notranslate"><span class="pre">.T</span></code> for transpose, and <code class="docutils literal notranslate"><span class="pre">np.linalg.inv</span></code> for matrix inversion.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ordinary_least_squares</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""Ordinary least squares estimator for linear regression.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (ndarray): design matrix of shape (n_samples, n_regressors)</span>
<span class="sd">    y (ndarray): vector of measurements of shape (n_samples)</span>

<span class="sd">  Returns:</span>
<span class="sd">    ndarray: estimated parameter values of shape (n_regressors)</span>
<span class="sd">  """</span>
  <span class="c1">######################################################################</span>
  <span class="c1">## TODO for students: solve for the optimal parameter vector using OLS</span>
  <span class="c1"># Fill out function and remove</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: solve for theta_hat vector using OLS"</span><span class="p">)</span>
  <span class="c1">######################################################################</span>

  <span class="c1"># Compute theta_hat using OLS</span>
  <span class="n">theta_hat</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">theta_hat</span>


<span class="n">theta_hat</span> <span class="o">=</span> <span class="n">ordinary_least_squares</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">theta_hat</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>

<span class="k">def</span> <span class="nf">ordinary_least_squares</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""Ordinary least squares estimator for linear regression.</span>

<span class="sd">  Args:</span>
<span class="sd">    X (ndarray): design matrix of shape (n_samples, n_regressors)</span>
<span class="sd">    y (ndarray): vector of measurements of shape (n_samples)</span>

<span class="sd">  Returns:</span>
<span class="sd">    ndarray: estimated parameter values of shape (n_regressors)</span>
<span class="sd">  """</span>

  <span class="c1"># Compute theta_hat using OLS</span>
  <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>

  <span class="k">return</span> <span class="n">theta_hat</span>


<span class="n">theta_hat</span> <span class="o">=</span> <span class="n">ordinary_least_squares</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">theta_hat</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>After filling in this function, you should see that <span class="math notranslate nohighlight">\(\boldsymbol{\hat\theta} = [ 0.13861386, -2.09395731, -3.16370742]\)</span>.</p>
<p>Now that we have our <span class="math notranslate nohighlight">\(\boldsymbol{\hat\theta}\)</span>, we can obtain <span class="math notranslate nohighlight">\(\hat{\mathbf{y}}\)</span> and thus our mean squared error.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute predicted data</span>
<span class="n">theta_hat</span> <span class="o">=</span> <span class="n">ordinary_least_squares</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">theta_hat</span>

<span class="c1"># Compute MSE</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"MSE = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y_hat</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, the following code will plot a geometric visualization of the data points (blue) and fitted plane.</p>
<p>Execute this cell to visualize data and predicted plane</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to visualize data and predicted plane</span>

<span class="n">theta_hat</span> <span class="o">=</span> <span class="n">ordinary_least_squares</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mgrid</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:</span><span class="mi">2</span><span class="p">:</span><span class="mi">50</span><span class="n">j</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">:</span><span class="mi">2</span><span class="p">:</span><span class="mi">50</span><span class="n">j</span><span class="p">]</span>
<span class="n">y_hat_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">xx</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">flatten</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">theta_hat</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">y_hat_grid</span> <span class="o">=</span> <span class="n">y_hat_grid</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s1">'3d'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">y_hat_grid</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'C1'</span><span class="p">,</span>
                <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'coolwarm'</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">((</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
          <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
          <span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_hat</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span>
          <span class="s1">'g-'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s1">'$x_1$'</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s1">'$x_2$'</span><span class="p">,</span>
    <span class="n">zlabel</span><span class="o">=</span><span class="s1">'y'</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-polynomial-regression">
<h1>Section 2:  Polynomial Regression<a class="headerlink" href="#section-2-polynomial-regression" title="Permalink to this headline">¶</a></h1>
<p>So far today, you learned how to predict outputs from inputs by fitting a linear regression model. We can now model all sorts of relationships, including in neuroscience!</p>
<p>One potential problem with this approach is the simplicity of the model. Linear regression, as the name implies, can only capture a linear relationship between the inputs and outputs. Put another way, the predicted outputs are only a weighted sum of the inputs. What if there are more complicated computations happening? Luckily, many more complex models exist (and you will encounter many more over the next 3 weeks). One model that is still very simple to fit and understand, but captures more complex relationships, is <strong>polynomial regression</strong>, an extension of linear regression.</p>
<details>
<summary> <font color="blue">Click here for text recap of relevant part of video </font></summary>
<p>Since polynomial regression is an extension of linear regression, everything you learned so far will come in handy now! The goal is the same: we want to predict the dependent variable <span class="math notranslate nohighlight">\(y\)</span> given the input values <span class="math notranslate nohighlight">\(x\)</span>. The key change is the type of relationship between inputs and outputs that the model can capture.</p>
<p>Linear regression models predict the outputs as a weighted sum of the inputs:</p>
<div class="amsmath math notranslate nohighlight" id="equation-5dad09e5-28cb-47d4-b2a4-00ec03f76391">
<span class="eqno">(169)<a class="headerlink" href="#equation-5dad09e5-28cb-47d4-b2a4-00ec03f76391" title="Permalink to this equation">¶</a></span>\[\begin{equation}
y = \theta_0 + \theta x + \epsilon
\end{equation}\]</div>
<p>With polynomial regression, we model the outputs as a polynomial equation based on the inputs. For example, we can model the outputs as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-5cccb0e0-f72d-49d6-bf0a-0c09b19a0333">
<span class="eqno">(170)<a class="headerlink" href="#equation-5cccb0e0-f72d-49d6-bf0a-0c09b19a0333" title="Permalink to this equation">¶</a></span>\[\begin{equation}
y = \theta_0 + \theta_1 x + \theta_2 x^2 + \theta_3 x^3 + \epsilon
\end{equation}\]</div>
<p>We can change how complex a polynomial is fit by changing the order of the polynomial. The order of a polynomial refers to the highest power in the polynomial. The equation above is a third order polynomial because the highest value x is raised to is 3. We could add another term (<span class="math notranslate nohighlight">\(+ \theta_4 x^4\)</span>) to model an order 4 polynomial and so on.</p>
</details>
<p>First, we will simulate some data to practice fitting polynomial regression models. We will generate random inputs <span class="math notranslate nohighlight">\(x\)</span> and then compute y according to <span class="math notranslate nohighlight">\(y = x^2 - x - 2 \)</span>, with some extra noise both in the input and the output to make the model fitting exercise closer to a real life situation.</p>
<p>Execute this cell to simulate some data</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to simulate some data</span>

<span class="c1"># setting a fixed seed to our random number generator ensures we will always</span>
<span class="c1"># get the same psuedorandom number sequence</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>  <span class="c1"># inputs uniformly sampled from [-2, 2.5)</span>
<span class="n">y</span> <span class="o">=</span>  <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">x</span> <span class="o">-</span> <span class="mi">2</span>   <span class="c1"># computing the outputs</span>

<span class="n">output_noise</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">8</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
<span class="n">y</span> <span class="o">+=</span> <span class="n">output_noise</span>  <span class="c1"># adding some output noise</span>

<span class="n">input_noise</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
<span class="n">x</span> <span class="o">+=</span> <span class="n">input_noise</span>  <span class="c1"># adding some input noise</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># produces a scatter plot</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">'x'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">'y'</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="section-2-1-design-matrix-for-polynomial-regression">
<h2>Section 2.1: Design matrix for polynomial regression<a class="headerlink" href="#section-2-1-design-matrix-for-polynomial-regression" title="Permalink to this headline">¶</a></h2>
<p><em>Estimated timing to here from start of tutorial: 16 min</em></p>
<p>Now we have the basic idea of polynomial regression and some noisy data, let’s begin! The key difference between fitting a linear regression model and a polynomial regression model lies in how we structure the input variables.</p>
<p>Let’s go back to one feature for each data point. For linear regression, we used <span class="math notranslate nohighlight">\(\mathbf{X} = \mathbf{x}\)</span> as the input data, where <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is a vector where each element is the input for a single data point. To add a constant bias (a y-intercept in a 2-D plot), we use <span class="math notranslate nohighlight">\(\mathbf{X} = \big[ \boldsymbol 1, \mathbf{x} \big]\)</span>, where <span class="math notranslate nohighlight">\(\boldsymbol 1\)</span> is a column of ones.  When fitting, we learn a weight for each column of this matrix. So we learn a weight that multiples with column 1 - in this case that column is all ones so we gain the bias parameter (<span class="math notranslate nohighlight">\(+ \theta_0\)</span>).</p>
<p>This matrix <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> that we use for our inputs is known as a <strong>design matrix</strong>. We want to create our design matrix so we learn weights for <span class="math notranslate nohighlight">\(\mathbf{x}^2, \mathbf{x}^3,\)</span> etc. Thus, we want to build our design matrix <span class="math notranslate nohighlight">\(X\)</span> for polynomial regression of order <span class="math notranslate nohighlight">\(k\)</span> as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-9b7879f6-4a7c-42a5-9953-9c4bd81e79c8">
<span class="eqno">(171)<a class="headerlink" href="#equation-9b7879f6-4a7c-42a5-9953-9c4bd81e79c8" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathbf{X} = \big[ \boldsymbol 1 , \mathbf{x}^1, \mathbf{x}^2 , \ldots , \mathbf{x}^k \big],
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{1}\)</span> is the vector the same length as <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> consisting of of all ones, and <span class="math notranslate nohighlight">\(\mathbf{x}^p\)</span> is the vector <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> with all elements raised to the power <span class="math notranslate nohighlight">\(p\)</span>. Note that <span class="math notranslate nohighlight">\(\boldsymbol{1} = \mathbf{x}^0\)</span> and <span class="math notranslate nohighlight">\(\mathbf{x}^1 = \mathbf{x}\)</span>.</p>
<p>If we have inputs with more than one feature, we can use a similar design matrix but include all features raised to each power. Imagine that we have two features per data point: <span class="math notranslate nohighlight">\(\mathbf{x}_m\)</span> is a vector of one feature per data point and  <span class="math notranslate nohighlight">\(\mathbf{x}_n\)</span> is another.  Our design matrix for a polynomial regression would be:</p>
<div class="amsmath math notranslate nohighlight" id="equation-3b374bb3-16f9-454e-8ac9-991d4b7f9eaf">
<span class="eqno">(172)<a class="headerlink" href="#equation-3b374bb3-16f9-454e-8ac9-991d4b7f9eaf" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathbf{X} = \big[ \boldsymbol 1 , \mathbf{x}_m^1, \mathbf{x}_n^1, \mathbf{x}_m^2 , \mathbf{x}_n^2\ldots , \mathbf{x}_m^k , \mathbf{x}_n^k \big],
\end{equation}\]</div>
<div class="section" id="coding-exercise-2-1-structure-design-matrix">
<h3>Coding Exercise 2.1: Structure design matrix<a class="headerlink" href="#coding-exercise-2-1-structure-design-matrix" title="Permalink to this headline">¶</a></h3>
<p>Create a function (<code class="docutils literal notranslate"><span class="pre">make_design_matrix</span></code>) that structures the design matrix given the input data and the order of the polynomial you wish to fit. We will print part of this design matrix for our data and order 5.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_design_matrix</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""Create the design matrix of inputs for use in polynomial regression</span>

<span class="sd">  Args:</span>
<span class="sd">    x (ndarray): input vector of shape (n_samples)</span>
<span class="sd">    order (scalar): polynomial regression order</span>

<span class="sd">  Returns:</span>
<span class="sd">    ndarray: design matrix for polynomial regression of shape (samples, order+1)</span>
<span class="sd">  """</span>
  <span class="c1">########################################################################</span>
  <span class="c1">## TODO for students: create the design matrix ##</span>
  <span class="c1"># Fill out function and remove</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: create the design matrix"</span><span class="p">)</span>
  <span class="c1">########################################################################</span>

  <span class="c1"># Broadcast to shape (n x 1) so dimensions work</span>
  <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>

  <span class="c1">#if x has more than one feature, we don't want multiple columns of ones so we assign</span>
  <span class="c1"># x^0 here</span>
  <span class="n">design_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

  <span class="c1"># Loop through rest of degrees and stack columns (hint: np.hstack)</span>
  <span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
      <span class="n">design_matrix</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">design_matrix</span>


<span class="n">order</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">X_design</span> <span class="o">=</span> <span class="n">make_design_matrix</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X_design</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>

<span class="k">def</span> <span class="nf">make_design_matrix</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""Create the design matrix of inputs for use in polynomial regression</span>

<span class="sd">  Args:</span>
<span class="sd">    x (ndarray): input vector of shape (samples,)</span>
<span class="sd">    order (scalar): polynomial regression order</span>

<span class="sd">  Returns:</span>
<span class="sd">    ndarray: design matrix for polynomial regression of shape (samples, order+1)</span>
<span class="sd">  """</span>

  <span class="c1"># Broadcast to shape (n x 1) so dimensions work</span>
  <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>

  <span class="c1">#if x has more than one feature, we don't want multiple columns of ones so we assign</span>
  <span class="c1"># x^0 here</span>
  <span class="n">design_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

  <span class="c1"># Loop through rest of degrees and stack columns (hint: np.hstack)</span>
  <span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
      <span class="n">design_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">design_matrix</span><span class="p">,</span> <span class="n">x</span><span class="o">**</span><span class="n">degree</span><span class="p">))</span>

  <span class="k">return</span> <span class="n">design_matrix</span>


<span class="n">order</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">X_design</span> <span class="o">=</span> <span class="n">make_design_matrix</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X_design</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>You should see that the printed section of this design matrix is <code class="docutils literal notranslate"><span class="pre">[[</span> <span class="pre">1.</span>         <span class="pre">-1.51194917]</span>  <span class="pre">[</span> <span class="pre">1.</span>         <span class="pre">-0.35259945]]</span></code></p>
</div>
</div>
<div class="section" id="section-2-2-fitting-polynomial-regression-models">
<h2>Section 2.2: Fitting polynomial regression models<a class="headerlink" href="#section-2-2-fitting-polynomial-regression-models" title="Permalink to this headline">¶</a></h2>
<p><em>Estimated timing to here from start of tutorial: 24 min</em></p>
<p>Now that we have the inputs structured correctly in our design matrix, fitting a polynomial regression is the same as fitting a linear regression model! All of the polynomial structure we need to learn is contained in how the inputs are structured in the design matrix. We can use the same least squares solution we computed in previous exercises.</p>
<div class="section" id="coding-exercise-2-2-fitting-polynomial-regression-models-with-different-orders">
<h3>Coding Exercise 2.2: Fitting polynomial regression models with different orders<a class="headerlink" href="#coding-exercise-2-2-fitting-polynomial-regression-models-with-different-orders" title="Permalink to this headline">¶</a></h3>
<p>Here, we will fit polynomial regression models to find the regression coefficients (<span class="math notranslate nohighlight">\(\theta_0, \theta_1, \theta_2,\)</span> …) by solving the least squares problem. Create a function <code class="docutils literal notranslate"><span class="pre">solve_poly_reg</span></code> that loops over different order polynomials (up to <code class="docutils literal notranslate"><span class="pre">max_order</span></code>), fits that model, and saves out the weights for each. You may invoke the <code class="docutils literal notranslate"><span class="pre">ordinary_least_squares</span></code> function.</p>
<p>We will then qualitatively inspect the quality of our fits for each order by plotting the fitted polynomials on top of the data. In order to see smooth curves, we evaluate the fitted polynomials on a grid of <span class="math notranslate nohighlight">\(x\)</span> values (ranging between the largest and smallest of the inputs present in the dataset).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">solve_poly_reg</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_order</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""Fit a polynomial regression model for each order 0 through max_order.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (ndarray): input vector of shape (n_samples)</span>
<span class="sd">    y (ndarray): vector of measurements of shape (n_samples)</span>
<span class="sd">    max_order (scalar): max order for polynomial fits</span>

<span class="sd">  Returns:</span>
<span class="sd">    dict: fitted weights for each polynomial model (dict key is order)</span>
<span class="sd">  """</span>

  <span class="c1"># Create a dictionary with polynomial order as keys,</span>
  <span class="c1"># and np array of theta_hat (weights) as the values</span>
  <span class="n">theta_hats</span> <span class="o">=</span> <span class="p">{}</span>

  <span class="c1"># Loop over polynomial orders from 0 through max_order</span>
  <span class="k">for</span> <span class="n">order</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>

    <span class="c1">##################################################################################</span>
    <span class="c1">## TODO for students: Create design matrix and fit polynomial model for this order</span>
    <span class="c1"># Fill out function and remove</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: fit a polynomial model"</span><span class="p">)</span>
    <span class="c1">##################################################################################</span>

    <span class="c1"># Create design matrix</span>
    <span class="n">X_design</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># Fit polynomial model</span>
    <span class="n">this_theta</span> <span class="o">=</span> <span class="o">...</span>

    <span class="n">theta_hats</span><span class="p">[</span><span class="n">order</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_theta</span>

  <span class="k">return</span> <span class="n">theta_hats</span>


<span class="n">max_order</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">theta_hats</span> <span class="o">=</span> <span class="n">solve_poly_reg</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_order</span><span class="p">)</span>

<span class="c1"># Visualize</span>
<span class="n">plot_fitted_polynomials</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">theta_hats</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>

<span class="k">def</span> <span class="nf">solve_poly_reg</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_order</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""Fit a polynomial regression model for each order 0 through max_order.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (ndarray): input vector of shape (n_samples)</span>
<span class="sd">    y (ndarray): vector of measurements of shape (n_samples)</span>
<span class="sd">    max_order (scalar): max order for polynomial fits</span>

<span class="sd">  Returns:</span>
<span class="sd">    dict: fitted weights for each polynomial model (dict key is order)</span>
<span class="sd">  """</span>

  <span class="c1"># Create a dictionary with polynomial order as keys,</span>
  <span class="c1"># and np array of theta_hat (weights) as the values</span>
  <span class="n">theta_hats</span> <span class="o">=</span> <span class="p">{}</span>

  <span class="c1"># Loop over polynomial orders from 0 through max_order</span>
  <span class="k">for</span> <span class="n">order</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>

    <span class="c1"># Create design matrix</span>
    <span class="n">X_design</span> <span class="o">=</span> <span class="n">make_design_matrix</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>

    <span class="c1"># Fit polynomial model</span>
    <span class="n">this_theta</span> <span class="o">=</span> <span class="n">ordinary_least_squares</span><span class="p">(</span><span class="n">X_design</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="n">theta_hats</span><span class="p">[</span><span class="n">order</span><span class="p">]</span> <span class="o">=</span> <span class="n">this_theta</span>

  <span class="k">return</span> <span class="n">theta_hats</span>


<span class="n">max_order</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">theta_hats</span> <span class="o">=</span> <span class="n">solve_poly_reg</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_order</span><span class="p">)</span>

<span class="c1"># Visualize</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_fitted_polynomials</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">theta_hats</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="section-2-3-evaluating-fit-quality">
<h2>Section 2.3: Evaluating fit quality<a class="headerlink" href="#section-2-3-evaluating-fit-quality" title="Permalink to this headline">¶</a></h2>
<p><em>Estimated timing to here from start of tutorial: 29 min</em></p>
<p>As with linear regression, we can compute mean squared error (MSE) to get a sense of how well the model fits the data.</p>
<p>We compute MSE as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-e04c5ede-00c7-4d49-8204-291dff64cfcc">
<span class="eqno">(173)<a class="headerlink" href="#equation-e04c5ede-00c7-4d49-8204-291dff64cfcc" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathrm{MSE} = \frac 1 N ||\mathbf{y} - \hat{\mathbf{y}}||^2 = \frac 1 N \sum_{i=1}^N (y_i - \hat y_i)^2 
\end{equation}\]</div>
<p>where the predicted values for each model are given by <span class="math notranslate nohighlight">\( \hat{\mathbf{y}} = \mathbf{X}\boldsymbol{\hat\theta}\)</span>.</p>
<p><em>Which model (i.e. which polynomial order) do you think will have the best MSE?</em></p>
<div class="section" id="coding-exercise-2-3-compute-mse-and-compare-models">
<h3>Coding Exercise 2.3: Compute MSE and compare models<a class="headerlink" href="#coding-exercise-2-3-compute-mse-and-compare-models" title="Permalink to this headline">¶</a></h3>
<p>We will compare the MSE for different polynomial orders with a bar plot.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mse_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">order_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

<span class="k">for</span> <span class="n">order</span> <span class="ow">in</span> <span class="n">order_list</span><span class="p">:</span>

  <span class="n">X_design</span> <span class="o">=</span> <span class="n">make_design_matrix</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>

  <span class="c1">########################################################################</span>
  <span class="c1">## TODO for students</span>
  <span class="c1"># Fill out function and remove</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: compute MSE"</span><span class="p">)</span>
  <span class="c1">########################################################################</span>

  <span class="c1"># Get prediction for the polynomial regression model of this order</span>
  <span class="n">y_hat</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># Compute the residuals</span>
  <span class="n">residuals</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># Compute the MSE</span>
  <span class="n">mse</span> <span class="o">=</span> <span class="o">...</span>

  <span class="n">mse_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>


<span class="c1"># Visualize MSE of fits</span>
<span class="n">evaluate_fits</span><span class="p">(</span><span class="n">order_list</span><span class="p">,</span> <span class="n">mse_list</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>

<span class="n">mse_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">order_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

<span class="k">for</span> <span class="n">order</span> <span class="ow">in</span> <span class="n">order_list</span><span class="p">:</span>

  <span class="n">X_design</span> <span class="o">=</span> <span class="n">make_design_matrix</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">order</span><span class="p">)</span>

  <span class="c1"># Get prediction for the polynomial regression model of this order</span>
  <span class="n">y_hat</span> <span class="o">=</span> <span class="n">X_design</span> <span class="o">@</span> <span class="n">theta_hats</span><span class="p">[</span><span class="n">order</span><span class="p">]</span>

  <span class="c1"># Compute the residuals</span>
  <span class="n">residuals</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span>

  <span class="c1"># Compute the MSE</span>
  <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">residuals</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

  <span class="n">mse_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>


<span class="c1"># Visualize MSE of fits</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">evaluate_fits</span><span class="p">(</span><span class="n">order_list</span><span class="p">,</span> <span class="n">mse_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing of tutorial: 35 minutes</em></p>
<ul class="simple">
<li><p>Linear regression generalizes naturally to multiple dimensions</p></li>
<li><p>Linear algebra affords us the mathematical tools to reason and solve such problems beyond the two dimensional case</p></li>
<li><p>To change from a linear regression model to a polynomial regression model, we only have to change how the input data is structured</p></li>
<li><p>We can choose the complexity of the model by changing the order of the polynomial model fit</p></li>
<li><p>Higher order polynomial models tend to have lower MSE on the data they’re fit with</p></li>
</ul>
<p><strong>Note</strong>: In practice, multidimensional least squares problems can be solved very efficiently (thanks to numerical routines such as LAPACK).</p>
</div>
<hr class="docutils"/>
<div class="section" id="notation">
<h1>Notation<a class="headerlink" href="#notation" title="Permalink to this headline">¶</a></h1>
<div class="amsmath math notranslate nohighlight" id="equation-43db1c6f-9c53-4b65-97cc-e24eed40a616">
<span class="eqno">(174)<a class="headerlink" href="#equation-43db1c6f-9c53-4b65-97cc-e24eed40a616" title="Permalink to this equation">¶</a></span>\[\begin{align}
x &amp;\quad \text{input, independent variable}\\
y &amp;\quad \text{response measurement, dependent variable}\\
\epsilon &amp;\quad \text{measurement error, noise contribution}\\
\theta &amp;\quad \text{slope parameter}\\
\hat{\theta} &amp;\quad \text{estimated slope parameter}\\
\mathbf{x} &amp;\quad \text{vector of inputs where each element is a different data point}\\
\mathbf{X} &amp;\quad \text{design matrix}\\
\mathbf{y} &amp;\quad \text{vector of measurements}\\
\mathbf{\hat y} &amp;\quad \text{vector of estimated measurements}\\
\boldsymbol{\theta} &amp;\quad \text{vector of parameters}\\
\boldsymbol{\hat\theta} &amp;\quad \text{vector of estimated parameters}\\
d &amp;\quad \text{dimensionality of input}\\
N &amp;\quad \text{number of samples}\\
\end{align}\]</div>
<p><strong>Suggested readings</strong></p>
<p><a class="reference external" href="http://vmls-book.stanford.edu/">Introduction to Applied Linear Algebra – Vectors, Matrices, and Least Squares</a>
Stephen Boyd and Lieven Vandenberghe</p>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W1D2_ModelFitting/instructor"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="W1D2_Tutorial3.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Tutorial 3: Confidence intervals and bootstrapping</p>
</div>
</a>
<a class="right-next" href="W1D2_Tutorial5.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Tutorial 5: Model Selection: Bias-variance trade-off</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
    By Neuromatch<br/>
<div class="extra_footer">
<div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"/></a>
The contents of this repository are shared under the <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>
</div>
</p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>