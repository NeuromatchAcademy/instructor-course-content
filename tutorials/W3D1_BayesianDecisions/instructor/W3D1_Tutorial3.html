
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Bonus Tutorial : Fitting to data — Neuromatch Academy: Computational Neuroscience (instructor's version)</title>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/custom.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-logo-square-4xp.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W3D1_Outro.html" rel="next" title="Outro"/>
<link href="W3D1_Tutorial2.html" rel="prev" title="Tutorial 2: Bayesian inference and decisions with continuous hidden state"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
<div class="bd-sidebar__content">
<div class="bd-sidebar__top"><div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
<img alt="logo" class="logo" src="../../../_static/nma-logo-square-4xp.png"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Computational Neuroscience (instructor's version)</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox">
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox">
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</input></li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using discord
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">
   Quick links and policies
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../prereqs/ComputationalNeuroscience.html">
   Prerequisites and preparatory materials for NMA Computational Neuroscience
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../tatraining/TA_Training_CN.html">
   TA Training - Computational Neuroscience
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Pre-reqs Refresher
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/chapter_title.html">
   Neuro Video Series (W0D0)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial1.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial2.html">
     Human Psychophysics
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial3.html">
     Behavioral Readout
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial4.html">
     Live in Lab
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial5.html">
     Brain Signals: Spiking Activity
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial6.html">
     Brain Signals: LFP
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial7.html">
     Brain Signals: EEG &amp; MEG
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial8.html">
     Brain Signals: fMRI
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial9.html">
     Brain Signals: Calcium Imaging
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial10.html">
     Stimulus Representation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial11.html">
     Neurotransmitters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial12.html">
     Neurons to Consciousness
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">
   Python Workshop 1 (W0D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D1_PythonWorkshop1/instructor/W0D1_Tutorial1.html">
     Tutorial: LIF Neuron Part I
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">
   Python Workshop 2 (W0D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D2_PythonWorkshop2/instructor/W0D2_Tutorial1.html">
     Tutorial 1: LIF Neuron Part II
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D3_LinearAlgebra/chapter_title.html">
   Linear Algebra (W0D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Tutorial1.html">
     Tutorial 1: Vectors
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Tutorial2.html">
     Tutorial 2: Matrices
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Tutorial3.html">
     Bonus Tutorial: Discrete Dynamical Systems
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D4_Calculus/chapter_title.html">
   Calculus (W0D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_Tutorial1.html">
     Tutorial 1: Differentiation and Integration
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_Tutorial2.html">
     Tutorial 2: Differential Equations
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_Tutorial3.html">
     Tutorial 3: Numerical Methods
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D5_Statistics/chapter_title.html">
   Statistics (W0D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_Tutorial1.html">
     Tutorial 1: Probability Distributions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_Tutorial2.html">
     Tutorial 2: Statistical Inference
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Intro to Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_ModelTypes/chapter_title.html">
   Model Types (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial1.html">
     Tutorial 1: “What” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial2.html">
     Tutorial 2: “How” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial3.html">
     Tutorial 3: “Why” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial4.html">
     Tutorial 4: Model Discussions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_ModelingPractice/chapter_title.html">
   Modeling Practice (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_Tutorial1.html">
     Tutorial 1: Framing the Question
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_ModelFitting/chapter_title.html">
   Model Fitting (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial1.html">
     Tutorial 1: Linear regression with MSE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial2.html">
     Tutorial 2: Linear regression with MLE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial3.html">
     Tutorial 3: Confidence intervals and bootstrapping
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial4.html">
     Tutorial 4: Multiple linear regression and polynomial regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial5.html">
     Tutorial 5: Model Selection: Bias-variance trade-off
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial6.html">
     Tutorial 6: Model Selection: Cross-validation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/chapter_title.html">
   Generalized Linear Models (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Tutorial1.html">
     Tutorial 1: GLMs for Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Tutorial2.html">
     Tutorial 2: Classifiers and regularizers
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/chapter_title.html">
   Dimensionality Reduction (W1D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial1.html">
     Tutorial 1: Geometric view of data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial2.html">
     Tutorial 2: Principal Component Analysis
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial3.html">
     Tutorial 3: Dimensionality Reduction &amp; Reconstruction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial4.html">
     Tutorial 4:  Nonlinear Dimensionality Reduction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_DeepLearning/chapter_title.html">
   Deep Learning (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial3.html">
     Tutorial 3: Building and Evaluating Normative Encoding Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial4.html">
     Bonus Tutorial: Diving Deeper into Decoding &amp; Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Bonus_Autoencoders/chapter_title.html">
   Autoencoders (Bonus)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial1.html">
     Tutorial 1: Intro to Autoencoders
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial2.html">
     Tutorial 2: Autoencoder extensions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial3.html">
     Tutorial 3: Autoencoders applications
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Outro.html">
     Outro
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/MachineLearning.html">
   Machine Learning Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_LinearSystems/chapter_title.html">
   Linear Systems (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial1.html">
     Tutorial 1: Linear dynamical systems
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial2.html">
     Tutorial 2: Markov Processes
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial3.html">
     Tutorial 3: Combining determinism and stochasticity
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial4.html">
     Tutorial 4: Autoregressive models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/chapter_title.html">
   Biological Neuron Models (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial1.html">
     Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial2.html">
     Tutorial 2: Effects of Input Correlation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial3.html">
     Tutorial 3: Synaptic transmission - Models of static and dynamic synapses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial4.html">
     Bonus Tutorial: Spike-timing dependent plasticity (STDP)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_DynamicNetworks/chapter_title.html">
   Dynamic Networks (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial1.html">
     Tutorial 1: Neural Rate Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial2.html">
     Tutorial 2: Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial3.html">
     Bonus Tutorial: Extending the Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/DynamicalSystems.html">
   Dynamical Systems Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Stochastic Processes
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Bayesian Decisions (W3D1)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2">
<a class="reference internal" href="W3D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D1_Tutorial1.html">
     Tutorial 1: Bayes with a binary hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D1_Tutorial2.html">
     Tutorial 2: Bayesian inference and decisions with continuous hidden state
    </a>
</li>
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Bonus Tutorial : Fitting to data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D1_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_HiddenDynamics/chapter_title.html">
   Hidden Dynamics (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial1.html">
     Tutorial 1: Sequential Probability Ratio Test
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial2.html">
     Tutorial 2: Hidden Markov Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial3.html">
     Tutorial 3: The Kalman Filter
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial4.html">
     Bonus Tutorial 4: The Kalman Filter, part 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial5.html">
     Bonus Tutorial 5: Expectation Maximization for spiking neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_OptimalControl/chapter_title.html">
   Optimal Control (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial1.html">
     Tutorial 1: Optimal Control for Discrete States
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial2.html">
     Tutorial 2: Optimal Control for Continuous State
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/chapter_title.html">
   Reinforcement Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial4.html">
     Tutorial 4: Model-Based Reinforcement Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D5_NetworkCausality/chapter_title.html">
   Network Causality (W3D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
<label for="toctree-checkbox-24">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial1.html">
     Tutorial 1: Interventions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial2.html">
     Tutorial 2: Correlations
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial3.html">
     Tutorial 3: Simultaneous fitting/regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial4.html">
     Tutorial 4: Instrumental Variables
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/StochasticProcesses.html">
   Stochastic Processes Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
<label for="toctree-checkbox-25">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through4.html">
     Modeling Steps 1 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through10.html">
     Modeling Steps 5 - 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModel.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProject.html">
     Example Data Project: the Train Illusion
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/datasets_overview.html">
   Datasets
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
<label for="toctree-checkbox-26">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/neurons.html">
     Neurons
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
<label for="toctree-checkbox-27">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/neurons_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/fMRI.html">
     fMRI
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
<label for="toctree-checkbox-28">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/fMRI_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/ECoG.html">
     ECoG
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
<label for="toctree-checkbox-29">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/ECoG_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/behavior.html">
     Behavior
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
<label for="toctree-checkbox-30">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/behavior_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/theory.html">
     Theory
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
<label for="toctree-checkbox-31">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/theory/README.html">
       Guide
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_templates.html">
   Project Templates
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/project_2020_highlights.html">
   Projects 2020
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/>
<label for="toctree-checkbox-32">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/neurons.html">
     Neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/theory.html">
     Theory
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/behavior.html">
     Behavior
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/fMRI.html">
     fMRI
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/eeg.html">
     EEG
    </a>
</li>
</ul>
</li>
</ul>
</div>
</nav></div>
<div class="bd-sidebar__bottom">
<!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="headerbtn" data-placement="right" data-toggle="tooltip" for="__navigation" title="Toggle navigation">
<span class="headerbtn__icon-container">
<i class="fas fa-bars"></i>
</span>
</label>
</div>
<div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
<button aria-label="Launch interactive content" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-rocket"></i>
</button>
<div class="menu-dropdown__content">
<ul>
</ul>
</div>
</div>
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="menu-dropdown menu-dropdown-repository-buttons">
<button aria-label="Source repositories" class="headerbtn menu-dropdown__trigger">
<i class="fab fa-github"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="headerbtn__text-container">repository</span>
</a>
</li>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content/issues/new?title=Issue%20on%20page%20%2Ftutorials/W3D1_BayesianDecisions/instructor/W3D1_Tutorial3.html&amp;body=Your%20issue%20content%20here." title="Open an issue">
<span class="headerbtn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="headerbtn__text-container">open issue</span>
</a>
</li>
</ul>
</div>
</div>
<div class="menu-dropdown menu-dropdown-download-buttons">
<button aria-label="Download this page" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-download"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W3D1_BayesianDecisions/instructor/W3D1_Tutorial3.ipynb" title="Download source file">
<span class="headerbtn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="headerbtn__text-container">.ipynb</span>
</a>
</li>
<li>
<button class="headerbtn" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="headerbtn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="headerbtn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
</div>
<label class="headerbtn headerbtn-page-toc" for="__page-toc">
<span class="headerbtn__icon-container">
<i class="fas fa-list"></i>
</span>
</label>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
    </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Bonus Tutorial : Fitting to data
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial objectives
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper Functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-intro">
     Video 1: Intro
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-likelihood-array">
   Section 1: Likelihood array
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-1-implement-the-auditory-likelihood-as-a-function-of-true-stimulus-position">
     Exercise 1. Implement the auditory likelihood as a function of true stimulus position
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-causal-mixture-of-gaussian-prior">
   Section 2: Causal mixture of Gaussian prior
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-prior-array">
     Video 2: Prior array
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-2-implement-the-prior-array">
       Exercise 2: Implement the prior array
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-bayes-rule-and-posterior-array">
   Section 3: Bayes rule and Posterior array
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-posterior-array">
     Video 3: Posterior array
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-3-calculate-the-posterior-as-a-function-of-the-hypothetical-stimulus-x">
       Exercise 3: Calculate the posterior as a function of the hypothetical stimulus x
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-estimating-the-position-hat-x">
   Section 4: Estimating the position
   <span class="math notranslate nohighlight">
    \(\hat x\)
   </span>
</a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-binary-decision-matrix">
     Video 4: Binary decision matrix
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-4-calculate-the-estimated-response-as-a-function-of-the-hypothetical-stimulus-x">
       Exercise 4: Calculate the estimated response as a function of the hypothetical stimulus x
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-5-probabilities-of-encoded-stimuli">
   Section 5: Probabilities of encoded stimuli
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-input-array">
     Video 5: Input array
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-5-generate-an-input-as-a-function-of-hypothetical-stimulus-x">
       Exercise 5: Generate an input as a function of hypothetical stimulus x
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-6-normalization-and-expected-estimate-distribution">
   Section 6: Normalization and expected estimate distribution
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-6-marginalization">
     Video 6: Marginalization
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-6-implement-the-marginalization-matrix">
       Exercise 6: Implement the marginalization matrix
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#generate-some-data">
   Generate some data
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
</a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#run-the-generate-data-function-this-cell">
       Run the ‘generate_data’ function (this cell)
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-7-model-fitting">
   Section 7: Model fitting
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-7-log-likelihood">
     Video 7: Log likelihood
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-7-fitting-a-model-to-generated-data">
       Exercise 7: Fitting a model to generated data
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-8-summary">
   Section 8: Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-8-outro">
     Video 8: Outro
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>Bonus Tutorial : Fitting to data</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Bonus Tutorial : Fitting to data
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial objectives
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper Functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-intro">
     Video 1: Intro
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-likelihood-array">
   Section 1: Likelihood array
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-1-implement-the-auditory-likelihood-as-a-function-of-true-stimulus-position">
     Exercise 1. Implement the auditory likelihood as a function of true stimulus position
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-causal-mixture-of-gaussian-prior">
   Section 2: Causal mixture of Gaussian prior
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-prior-array">
     Video 2: Prior array
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-2-implement-the-prior-array">
       Exercise 2: Implement the prior array
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-bayes-rule-and-posterior-array">
   Section 3: Bayes rule and Posterior array
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-posterior-array">
     Video 3: Posterior array
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-3-calculate-the-posterior-as-a-function-of-the-hypothetical-stimulus-x">
       Exercise 3: Calculate the posterior as a function of the hypothetical stimulus x
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-estimating-the-position-hat-x">
   Section 4: Estimating the position
   <span class="math notranslate nohighlight">
    \(\hat x\)
   </span>
</a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-binary-decision-matrix">
     Video 4: Binary decision matrix
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-4-calculate-the-estimated-response-as-a-function-of-the-hypothetical-stimulus-x">
       Exercise 4: Calculate the estimated response as a function of the hypothetical stimulus x
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-5-probabilities-of-encoded-stimuli">
   Section 5: Probabilities of encoded stimuli
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-input-array">
     Video 5: Input array
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-5-generate-an-input-as-a-function-of-hypothetical-stimulus-x">
       Exercise 5: Generate an input as a function of hypothetical stimulus x
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-6-normalization-and-expected-estimate-distribution">
   Section 6: Normalization and expected estimate distribution
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-6-marginalization">
     Video 6: Marginalization
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-6-implement-the-marginalization-matrix">
       Exercise 6: Implement the marginalization matrix
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#generate-some-data">
   Generate some data
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
</a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#run-the-generate-data-function-this-cell">
       Run the ‘generate_data’ function (this cell)
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-7-model-fitting">
   Section 7: Model fitting
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-7-log-likelihood">
     Video 7: Log likelihood
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-7-fitting-a-model-to-generated-data">
       Exercise 7: Fitting a model to generated data
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-8-summary">
   Section 8: Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-8-outro">
     Video 8: Outro
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/main/tutorials/W3D1_BayesianDecisions/instructor/W3D1_Tutorial3.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/W3D1_BayesianDecisions/instructor/W3D1_Tutorial3.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<div class="section" id="bonus-tutorial-fitting-to-data">
<h1>Bonus Tutorial : Fitting to data<a class="headerlink" href="#bonus-tutorial-fitting-to-data" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 3, Day 1: Bayesian Decisions</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Vincent Valton, Konrad Kording</p>
<p><strong>Content reviewers:</strong> Matt Krause, Jesse Livezey, Karolina Stosio, Saeed Salehi, Michael Waskom</p>
<p><strong>Post-production team:</strong> Gagana B, Spiros Chavlis</p>
<br/>
<p><strong>Note: This is bonus material, included from NMA 2020. It has not been substantially revised for 2021.</strong></p>
<p>This means that the notation and standards are slightly different and some of the references to other days in NMA are outdated. We include it here because it covers fitting Bayesian models to data, which may be of interest to many students.</p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p></div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p>In the first two tutorials, we learned about Bayesian models and decisions more intuitively, using demos. In this notebook, we will dive into using math and code to fit Bayesian models to data.</p>
<p>We’ll have a look at computing all the necessary steps to perform model inversion (estimate the model parameters such as <span class="math notranslate nohighlight">\(p_{common}\)</span> that generated data similar to that of a participant). We will describe all the steps of the generative model first, and in the last exercise we will use all these steps to estimate the parameter <span class="math notranslate nohighlight">\(p_{common}\)</span> of a single participant using simulated data.</p>
<p>The generative model will be a Bayesian model we saw in Tutorial 2: a mixture of Gaussian prior  and a Gaussian likelihood.
Steps:</p>
<ul class="simple">
<li><p>First, we’ll create the prior, likelihood, posterior, etc in a form that will make it easier for us to visualize what is being computed and estimated at each step of the generative model:</p>
<ol class="simple">
<li><p>Creating a mixture of Gaussian prior for multiple possible stimulus inputs</p></li>
<li><p>Generating the likelihood for multiple possible stimulus inputs</p></li>
<li><p>Estimating our posterior as a function of the stimulus input</p></li>
<li><p>Estimating a participant response given the posterior</p></li>
</ol>
</li>
<li><p>Next, we’ll perform the model inversion/fitting:
5. Create an distribution for the input as a function of possible inputs
6. Marginalization
7. Generate some data using the generative model provided
8. Perform model inversion (model fitting) using the generated data and see if you recover the original parameters.</p></li>
</ul>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<p>Please execute the cell below to initialize the notebook environment</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure Settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Figure Settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/NMA2020/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="helper-functions">
<h2>Helper Functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper Functions</span>

<span class="k">def</span> <span class="nf">my_gaussian</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Returns a Gaussian estimated at points `x_points`, with parameters: `mu` and `sigma`</span>

<span class="sd">    Args :</span>
<span class="sd">      x_points (numpy arrays of floats)- points at which the gaussian is evaluated</span>
<span class="sd">      mu (scalar) - mean of the Gaussian</span>
<span class="sd">      sigma (scalar) - std of the gaussian</span>

<span class="sd">    Returns:</span>
<span class="sd">      Gaussian evaluated at `x`</span>
<span class="sd">    """</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">x_points</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">p</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">moments_myfunc</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">function</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  DO NOT EDIT THIS FUNCTION !!!</span>

<span class="sd">  Returns the mean, median and mode of an arbitrary function</span>

<span class="sd">  Args :</span>
<span class="sd">    x_points (numpy array of floats) - x-axis values</span>
<span class="sd">    function (numpy array of floats) - y-axis values of the function evaluated at `x_points`</span>

<span class="sd">  Returns:</span>
<span class="sd">    (tuple of 3 scalars): mean, median, mode</span>
<span class="sd">  """</span>

  <span class="c1"># Calc mode of arbitrary function</span>
  <span class="n">mode</span> <span class="o">=</span> <span class="n">x_points</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">function</span><span class="p">)]</span>

  <span class="c1"># Calc mean of arbitrary function</span>
  <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x_points</span> <span class="o">*</span> <span class="n">function</span><span class="p">)</span>

  <span class="c1"># Calc median of arbitrary function</span>
  <span class="n">cdf_function</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x_points</span><span class="p">)</span>
  <span class="n">accumulator</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">accumulator</span> <span class="o">=</span> <span class="n">accumulator</span> <span class="o">+</span> <span class="n">function</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">cdf_function</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">accumulator</span>
  <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">cdf_function</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">))</span>
  <span class="n">median</span> <span class="o">=</span> <span class="n">x_points</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

  <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">median</span><span class="p">,</span> <span class="n">mode</span>

<span class="k">def</span> <span class="nf">plot_myarray</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">xlabel</span><span class="p">,</span> <span class="n">ylabel</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
<span class="w">  </span><span class="sd">""" Plot an array with labels.</span>

<span class="sd">  Args :</span>
<span class="sd">    array (numpy array of floats)</span>
<span class="sd">    xlabel (string) - label of x-axis</span>
<span class="sd">    ylabel (string) - label of y-axis</span>
<span class="sd">    title  (string) - title of plot</span>

<span class="sd">  Returns:</span>
<span class="sd">    None</span>
<span class="sd">  """</span>
  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
  <span class="n">colormap</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">8</span><span class="p">])</span>
  <span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">colormap</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
  <span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s1">'probability'</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">'auto'</span><span class="p">)</span>
  <span class="k">return</span> <span class="kc">None</span>

<span class="k">def</span> <span class="nf">plot_my_bayes_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">  </span><span class="sd">"""Pretty-print a simple Bayes Model (ex 7), defined as a function:</span>

<span class="sd">  Args:</span>
<span class="sd">    - model: function that takes a single parameter value and returns</span>
<span class="sd">             the negative log-likelihood of the model, given that parameter</span>
<span class="sd">  Returns:</span>
<span class="sd">    None, draws plot</span>
<span class="sd">    """</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mf">0.07</span><span class="p">)</span>

  <span class="c1"># Plot neg-LogLikelihood for different values of alpha</span>
  <span class="n">alpha_tries</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
  <span class="n">nll</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">alpha_tries</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i_try</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">alpha_tries</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">nll</span><span class="p">[</span><span class="n">i_try</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">alpha_tries</span><span class="p">[</span><span class="n">i_try</span><span class="p">]]))</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alpha_tries</span><span class="p">,</span> <span class="n">nll</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'p_independent value'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'negative log-likelihood'</span><span class="p">)</span>

  <span class="c1"># Mark minima</span>
  <span class="n">ix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">nll</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">alpha_tries</span><span class="p">[</span><span class="n">ix</span><span class="p">],</span> <span class="n">nll</span><span class="p">[</span><span class="n">ix</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">'r'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">144</span><span class="p">)</span>

  <span class="c1">#plt.axvline(alpha_tries[np.argmin(nll)])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Sample Output'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

  <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">plot_simulated_behavior</span><span class="p">(</span><span class="n">true_stim</span><span class="p">,</span> <span class="n">behaviour</span><span class="p">):</span>
  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">'xkcd:light grey'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">true_stim</span><span class="p">,</span> <span class="n">true_stim</span> <span class="o">-</span> <span class="n">behaviour</span><span class="p">,</span> <span class="s1">'-k'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'data'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">'dashed'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'grey'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">'dashed'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'grey'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Position of true visual stimulus (cm)'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Participant deviation from true stimulus (cm)'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Participant behavior'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

  <span class="k">return</span> <span class="kc">None</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-1-intro">
<h2>Video 1: Intro<a class="headerlink" href="#video-1-intro" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p><img alt="Generative model" src="https://github.com/vincentvalton/figures_NMA_W2D1_T3/blob/main/Drawing%20Generative%20Model%20W2T3.png?raw=true"/></p>
<p>Here is a graphical representation of the generative model:</p>
<ol class="simple">
<li><p>We present a stimulus <span class="math notranslate nohighlight">\(x\)</span> to participants.</p></li>
<li><p>The brain encodes this true stimulus <span class="math notranslate nohighlight">\(x\)</span> noisily (this is the brain’s representation of the true visual stimulus: <span class="math notranslate nohighlight">\(p(\tilde x|x)\)</span>.</p></li>
<li><p>The brain then combines this brain-encoded stimulus (likelihood: <span class="math notranslate nohighlight">\(p(\tilde x|x)\)</span>) with prior information (the prior: <span class="math notranslate nohighlight">\(p(x)\)</span>) to make up the brain’s estimated position of the true visual stimulus, the posterior: <span class="math notranslate nohighlight">\(p(x|\tilde x)\)</span>.</p></li>
<li><p>This brain’s estimated stimulus position: <span class="math notranslate nohighlight">\(p(x|\tilde x)\)</span>, is then used to make a response:  <span class="math notranslate nohighlight">\(\hat x\)</span>, which is the participant’s noisy estimate of the stimulus position (the participant’s percept).</p></li>
</ol>
<p>Typically the response <span class="math notranslate nohighlight">\(\hat x\)</span> also includes some motor noise (noise due to the hand/arm move being not 100% accurate), but we’ll ignore it in this tutorial and assume there is no motor noise.</p>
<p>We will use the same experimental setup as in <a class="reference external" href="https://compneuro.neuromatch.io/tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial2.html">tutorial 2</a> but with slightly different probabilities. This time, participants are told that they need to estimate the sound location of a puppet that is hidden behind a curtain. The participants are told to use auditory information and are also informed that the sound could come from 2 possible causes: a common cause (95% of the time it comes from the puppet hidden behind the curtain at position 0), or an independent cause (5% of the time the sound comes from loud-speakers at more distant locations).</p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-likelihood-array">
<h1>Section 1: Likelihood array<a class="headerlink" href="#section-1-likelihood-array" title="Permalink to this headline">¶</a></h1>
<p>First, we want to create a likelihood, but for the sake of visualization (and to consider all possible brain encodings) we will create multiple likelihoods <span class="math notranslate nohighlight">\(f(x)=p(\tilde x|x)\)</span> (one for each potential encoded stimulus: <span class="math notranslate nohighlight">\(\tilde x\)</span>). We will then be able to visualize the likelihood as a function of hypothesized true stimulus positions: <span class="math notranslate nohighlight">\(x\)</span> on the x-axis and encoded position <span class="math notranslate nohighlight">\(\tilde x\)</span> on the y-axis.</p>
<p>Using the equation for the <code class="docutils literal notranslate"><span class="pre">my_gaussian</span></code> and the values in <code class="docutils literal notranslate"><span class="pre">hypothetical_stim</span></code>:</p>
<ul class="simple">
<li><p>Create a Gaussian likelihood with mean varying from <code class="docutils literal notranslate"><span class="pre">hypothetical_stim</span></code>, keeping <span class="math notranslate nohighlight">\(\sigma_{likelihood}\)</span> constant at 1.</p></li>
<li><p>Each likelihood will have a different mean and thus a different row-likelihood of your 2D array, such that you end up with a likelihood array made up of 1,000 row-Gaussians with different means. (<em>Hint</em>: <code class="docutils literal notranslate"><span class="pre">np.tile</span></code> won’t work here. You may need a for-loop).</p></li>
<li><p>Plot the array using the function <code class="docutils literal notranslate"><span class="pre">plot_myarray()</span></code> already pre-written and commented-out in your script</p></li>
</ul>
<div class="section" id="exercise-1-implement-the-auditory-likelihood-as-a-function-of-true-stimulus-position">
<h2>Exercise 1. Implement the auditory likelihood as a function of true stimulus position<a class="headerlink" href="#exercise-1-implement-the-auditory-likelihood-as-a-function-of-true-stimulus-position" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">hypothetical_stim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_likelihood_array</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">stim_array</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>

  <span class="c1"># initializing likelihood_array</span>
  <span class="n">likelihood_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stim_array</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_points</span><span class="p">)))</span>
  <span class="c1"># looping over stimulus array</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stim_array</span><span class="p">)):</span>
    <span class="c1">########################################################################</span>
    <span class="c1">## Insert your code here to:</span>
    <span class="c1">##      - Generate a likelihood array using `my_gaussian` function,</span>
    <span class="c1">##        with std=1, and varying the mean using `stim_array` values.</span>
    <span class="c1">## remove the raise below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"You need to complete the function!"</span><span class="p">)</span>
    <span class="c1">########################################################################</span>
    <span class="n">likelihood_array</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">likelihood_array</span>



<span class="n">likelihood_array</span> <span class="o">=</span> <span class="n">compute_likelihood_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">hypothetical_stim</span><span class="p">)</span>
<span class="n">plot_myarray</span><span class="p">(</span><span class="n">likelihood_array</span><span class="p">,</span>
             <span class="s1">'$x$ : Potential true stimulus $x$'</span><span class="p">,</span>
             <span class="s1">'Possible brain encoding $\~x$'</span><span class="p">,</span>
             <span class="s1">'Likelihood as a function of $\~x$ : $p(\~x | x)$'</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">hypothetical_stim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_likelihood_array</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">stim_array</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>

  <span class="c1"># initializing likelihood_array</span>
  <span class="n">likelihood_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stim_array</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_points</span><span class="p">)))</span>
  <span class="c1"># looping over stimulus array</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stim_array</span><span class="p">)):</span>
    <span class="n">likelihood_array</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">stim_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">sigma</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">likelihood_array</span>


<span class="n">likelihood_array</span> <span class="o">=</span> <span class="n">compute_likelihood_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">hypothetical_stim</span><span class="p">)</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_myarray</span><span class="p">(</span><span class="n">likelihood_array</span><span class="p">,</span>
               <span class="s1">'$x$ : Potential true stimulus $x$'</span><span class="p">,</span>
               <span class="s1">'Possible brain encoding $\~x$'</span><span class="p">,</span>
               <span class="s1">'Likelihood as a function of $\~x$ : $p(\~x | x)$'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-causal-mixture-of-gaussian-prior">
<h1>Section 2: Causal mixture of Gaussian prior<a class="headerlink" href="#section-2-causal-mixture-of-gaussian-prior" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-2-prior-array">
<h2>Video 2: Prior array<a class="headerlink" href="#video-2-prior-array" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>As in Tutorial 2, we want to create a prior that will describe the participants’ prior knowledge that, 95% of the time sounds come from a common position around the puppet, while during the remaining 5% of the time, they arise from another independent position. We will embody this information into a prior using a mixture of Gaussians. For visualization reasons, we will create a prior that has the same shape (form) as the likelihood array we created in the previous exercise. That is, we want to create a mixture of Gaussian prior as a function the the brain encoded stimulus <span class="math notranslate nohighlight">\(\tilde x\)</span>. Since the prior does not change as a function of <span class="math notranslate nohighlight">\(\tilde x\)</span> it will be identical for each row of the prior 2D array.</p>
<p>Using the equation for the Gaussian <code class="docutils literal notranslate"><span class="pre">my_gaussian</span></code>:</p>
<ul class="simple">
<li><p>Generate a Gaussian <span class="math notranslate nohighlight">\(Common\)</span> with mean 0 and standard deviation 0.5</p></li>
<li><p>Generate another Gaussian <span class="math notranslate nohighlight">\(Independent\)</span> with mean 0 and standard deviation 10</p></li>
<li><p>Combine the two Gaussians (Common + Independent) to make a new prior by mixing the two Gaussians with mixing parameter <span class="math notranslate nohighlight">\(p_{independent}\)</span> = 0.05. Make it such that the peakier Gaussian has 95% of the weight (don’t forget to normalize afterwards)</p></li>
<li><p>This will be the first row of your prior 2D array</p></li>
<li><p>Now repeat this for varying brain encodings <span class="math notranslate nohighlight">\(\tilde x\)</span>. Since the prior does not depend on <span class="math notranslate nohighlight">\(\tilde x\)</span> you can just repeat the prior for each <span class="math notranslate nohighlight">\(\tilde x\)</span> (hint: use np.tile) that row prior to make an array of 1,000 (i.e. <code class="docutils literal notranslate"><span class="pre">hypothetical_stim.shape[0]</span></code>)  row-priors.</p></li>
<li><p>Plot the matrix using the function <code class="docutils literal notranslate"><span class="pre">plot_myarray()</span></code> already pre-written and commented-out in your script</p></li>
</ul>
<div class="section" id="exercise-2-implement-the-prior-array">
<h3>Exercise 2: Implement the prior array<a class="headerlink" href="#exercise-2-implement-the-prior-array" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">calculate_prior_array</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">stim_array</span><span class="p">,</span> <span class="n">p_indep</span><span class="p">,</span>
                          <span class="n">prior_mean_common</span><span class="o">=</span><span class="mf">.0</span><span class="p">,</span> <span class="n">prior_sigma_common</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span>
                          <span class="n">prior_mean_indep</span><span class="o">=</span><span class="mf">.0</span><span class="p">,</span> <span class="n">prior_sigma_indep</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">      'common' stands for common</span>
<span class="sd">      'indep' stands for independent</span>
<span class="sd">  """</span>

  <span class="n">prior_common</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">prior_mean_common</span><span class="p">,</span> <span class="n">prior_sigma_common</span><span class="p">)</span>
  <span class="n">prior_indep</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">prior_mean_indep</span><span class="p">,</span> <span class="n">prior_sigma_indep</span><span class="p">)</span>
  <span class="c1">############################################################################</span>
  <span class="c1">## Insert your code here to:</span>
  <span class="c1">##      - Create a mixture of gaussian priors from 'prior_common'</span>
  <span class="c1">##        and 'prior_indep' with mixing parameter 'p_indep'</span>
  <span class="c1">##      - normalize</span>
  <span class="c1">##      - repeat the prior array and reshape it to make a 2D array</span>
  <span class="c1">##        of 1000 rows of priors (Hint: use np.tile() and np.reshape())</span>
  <span class="c1">## remove the raise below to test your function</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"You need to complete the function!"</span><span class="p">)</span>
  <span class="c1">############################################################################</span>
  <span class="n">prior_mixed</span> <span class="o">=</span> <span class="o">...</span>
  <span class="n">prior_mixed</span> <span class="o">/=</span> <span class="o">...</span>  <span class="c1"># normalize</span>

  <span class="n">prior_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="o">...</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">prior_array</span>


<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">p_independent</span> <span class="o">=</span> <span class="mf">.05</span>
<span class="n">prior_array</span> <span class="o">=</span> <span class="n">calculate_prior_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">hypothetical_stim</span><span class="p">,</span> <span class="n">p_independent</span><span class="p">)</span>
<span class="n">plot_myarray</span><span class="p">(</span><span class="n">prior_array</span><span class="p">,</span>
             <span class="s1">'Hypothesized position $x$'</span><span class="p">,</span> <span class="s1">'Brain encoded position $\~x$'</span><span class="p">,</span>
             <span class="s1">'Prior as a fcn of $\~x$ : $p(x|\~x)$'</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">calculate_prior_array</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">stim_array</span><span class="p">,</span> <span class="n">p_indep</span><span class="p">,</span>
                          <span class="n">prior_mean_common</span><span class="o">=</span><span class="mf">.0</span><span class="p">,</span> <span class="n">prior_sigma_common</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span>
                          <span class="n">prior_mean_indep</span><span class="o">=</span><span class="mf">.0</span><span class="p">,</span> <span class="n">prior_sigma_indep</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">      'common' stands for common</span>
<span class="sd">      'indep' stands for independent</span>
<span class="sd">  """</span>

  <span class="n">prior_common</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">prior_mean_common</span><span class="p">,</span> <span class="n">prior_sigma_common</span><span class="p">)</span>
  <span class="n">prior_indep</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">prior_mean_indep</span><span class="p">,</span> <span class="n">prior_sigma_indep</span><span class="p">)</span>

  <span class="n">prior_mixed</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p_indep</span><span class="p">)</span> <span class="o">*</span> <span class="n">prior_common</span> <span class="o">+</span> <span class="p">(</span><span class="n">p_indep</span> <span class="o">*</span> <span class="n">prior_indep</span><span class="p">)</span>
  <span class="n">prior_mixed</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">prior_mixed</span><span class="p">)</span>  <span class="c1"># normalize</span>

  <span class="n">prior_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">prior_mixed</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">stim_array</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stim_array</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">prior_array</span>


<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">p_independent</span> <span class="o">=</span> <span class="mf">.05</span>
<span class="n">prior_array</span> <span class="o">=</span> <span class="n">calculate_prior_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">hypothetical_stim</span><span class="p">,</span> <span class="n">p_independent</span><span class="p">)</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_myarray</span><span class="p">(</span><span class="n">prior_array</span><span class="p">,</span>
               <span class="s1">'Hypothesized position $x$'</span><span class="p">,</span> <span class="s1">'Brain encoded position $\~x$'</span><span class="p">,</span>
               <span class="s1">'Prior as a fcn of $\~x$ : $p(x|\~x)$'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-3-bayes-rule-and-posterior-array">
<h1>Section 3: Bayes rule and Posterior array<a class="headerlink" href="#section-3-bayes-rule-and-posterior-array" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-3-posterior-array">
<h2>Video 3: Posterior array<a class="headerlink" href="#video-3-posterior-array" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>We now want to calculate the posterior using <em>Bayes Rule</em>. Since we have already created a likelihood and a prior for each brain encoded position <span class="math notranslate nohighlight">\(\tilde x\)</span>, all we need to do is to multiply them row-wise. That is, each row of the posterior array will be the posterior resulting from the multiplication of the prior and likelihood of the same equivalent row.</p>
<p>Mathematically:</p>
<div class="amsmath math notranslate nohighlight" id="equation-bb01b6d8-3828-46a6-84f1-724a8f4ce586">
<span class="eqno">(363)<a class="headerlink" href="#equation-bb01b6d8-3828-46a6-84f1-724a8f4ce586" title="Permalink to this equation">¶</a></span>\[\begin{equation}
Posterior\left[i, :\right] \propto Likelihood\left[i, :\right] \odot Prior\left[i, :\right]
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\odot\)</span> represents the <a class="reference external" href="https://en.wikipedia.org/wiki/Hadamard_product_(matrices)">Hadamard Product</a> (i.e., element-wise multiplication) of the corresponding prior and likelihood row vectors <code class="docutils literal notranslate"><span class="pre">i</span></code> from each matrix.</p>
<p>Follow these steps to build the posterior as a function of the brain encoded stimulus <span class="math notranslate nohighlight">\(\tilde x\)</span>:</p>
<ul class="simple">
<li><p>For each row of the prior and likelihood (i.e. each possible brain encoding <span class="math notranslate nohighlight">\(\tilde x\)</span>), fill in the posterior matrix so that every row of the posterior array represents the posterior density for a different brain encode  <span class="math notranslate nohighlight">\(\tilde x\)</span>.</p></li>
<li><p>Plot the array using the function <code class="docutils literal notranslate"><span class="pre">plot_myarray()</span></code> already pre-written and commented-out in your script</p></li>
</ul>
<p>Optional:</p>
<ul class="simple">
<li><p>Do you need to operate on one element–or even one row–at a time? NumPy operations can often process an entire matrix in a single “vectorized” operation. This approach is often much faster and much easier to read than an element-by-element calculation.  Try to write a vectorized version that calculates the posterior without using any for-loops. <em>Hint</em>: look at <code class="docutils literal notranslate"><span class="pre">np.sum</span></code> and its keyword arguments.</p></li>
</ul>
<div class="section" id="exercise-3-calculate-the-posterior-as-a-function-of-the-hypothetical-stimulus-x">
<h3>Exercise 3: Calculate the posterior as a function of the hypothetical stimulus x<a class="headerlink" href="#exercise-3-calculate-the-posterior-as-a-function-of-the-hypothetical-stimulus-x" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">calculate_posterior_array</span><span class="p">(</span><span class="n">prior_array</span><span class="p">,</span> <span class="n">likelihood_array</span><span class="p">):</span>
  <span class="c1">############################################################################</span>
  <span class="c1">## Insert your code here to:</span>
  <span class="c1">##      - calculate the 'posterior_array' from the given</span>
  <span class="c1">##        'prior_array', 'likelihood_array'</span>
  <span class="c1">##      - normalize</span>
  <span class="c1">## remove the raise below to test your function</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"You need to complete the function!"</span><span class="p">)</span>
  <span class="c1">############################################################################</span>
  <span class="n">posterior_array</span> <span class="o">=</span> <span class="o">...</span>
  <span class="n">posterior_array</span> <span class="o">/=</span> <span class="o">...</span>  <span class="c1"># normalize each row separately</span>

  <span class="k">return</span> <span class="n">posterior_array</span>


<span class="n">posterior_array</span> <span class="o">=</span> <span class="n">calculate_posterior_array</span><span class="p">(</span><span class="n">prior_array</span><span class="p">,</span> <span class="n">likelihood_array</span><span class="p">)</span>
<span class="n">plot_myarray</span><span class="p">(</span><span class="n">posterior_array</span><span class="p">,</span>
             <span class="s1">'Hypothesized Position $x$'</span><span class="p">,</span>
             <span class="s1">'Brain encoded Stimulus $\~x$'</span><span class="p">,</span>
             <span class="s1">'Posterior as a fcn of $\~x$ : $p(x | \~x)$'</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">calculate_posterior_array</span><span class="p">(</span><span class="n">prior_array</span><span class="p">,</span> <span class="n">likelihood_array</span><span class="p">):</span>

  <span class="n">posterior_array</span> <span class="o">=</span> <span class="n">prior_array</span> <span class="o">*</span> <span class="n">likelihood_array</span>
  <span class="n">posterior_array</span> <span class="o">/=</span> <span class="n">posterior_array</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># normalize each row separately</span>

  <span class="k">return</span> <span class="n">posterior_array</span>


<span class="n">posterior_array</span> <span class="o">=</span> <span class="n">calculate_posterior_array</span><span class="p">(</span><span class="n">prior_array</span><span class="p">,</span> <span class="n">likelihood_array</span><span class="p">)</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_myarray</span><span class="p">(</span><span class="n">posterior_array</span><span class="p">,</span>
               <span class="s1">'Hypothesized Position $x$'</span><span class="p">,</span>
               <span class="s1">'Brain encoded Stimulus $\~x$'</span><span class="p">,</span>
               <span class="s1">'Posterior as a fcn of $\~x$ : $p(x | \~x)$'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-4-estimating-the-position-hat-x">
<h1>Section 4: Estimating the position <span class="math notranslate nohighlight">\(\hat x\)</span><a class="headerlink" href="#section-4-estimating-the-position-hat-x" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-4-binary-decision-matrix">
<h2>Video 4: Binary decision matrix<a class="headerlink" href="#video-4-binary-decision-matrix" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>Now that we have a posterior distribution (for each possible brain encoding <span class="math notranslate nohighlight">\(\tilde x\)</span>)that represents the brain’s estimated stimulus position: <span class="math notranslate nohighlight">\(p(x|\tilde x)\)</span>, we want to make an estimate (response) of the sound location <span class="math notranslate nohighlight">\(\hat x\)</span> using the posterior distribution. This would represent the subject’s estimate if their (for us as experimentalist unobservable) brain encoding took on each possible value.</p>
<p>This effectively encodes the <em>decision</em> that a participant would make for a given brain encoding <span class="math notranslate nohighlight">\(\tilde x\)</span>. In this exercise, we make the assumptions that participants take the mean of the posterior (decision rule) as a response estimate for the sound location (use the function <code class="docutils literal notranslate"><span class="pre">moments_myfunc()</span></code> provided to calculate the mean of the posterior).</p>
<p>Using this knowledge, we will now represent <span class="math notranslate nohighlight">\(\hat x\)</span> as a function of the encoded stimulus <span class="math notranslate nohighlight">\(\tilde x\)</span>. This will result in a 2D binary decision array. To do so, we will scan the posterior matrix (i.e. row-wise), and set the array cell value to 1 at the mean of the row-wise posterior.</p>
<p><strong>Suggestions</strong></p>
<ul class="simple">
<li><p>For each brain encoding <span class="math notranslate nohighlight">\(\tilde x\)</span> (row of the posterior array), calculate the mean of the posterior, and set the corresponding cell of the binary decision array to 1. (e.g., if the mean of the posterior is at position 0, then set the cell with x_column == 0 to 1).</p></li>
<li><p>Plot the matrix using the function <code class="docutils literal notranslate"><span class="pre">plot_myarray()</span></code> already pre-written and commented-out in your script</p></li>
</ul>
<div class="section" id="exercise-4-calculate-the-estimated-response-as-a-function-of-the-hypothetical-stimulus-x">
<h3>Exercise 4: Calculate the estimated response as a function of the hypothetical stimulus x<a class="headerlink" href="#exercise-4-calculate-the-estimated-response-as-a-function-of-the-hypothetical-stimulus-x" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">calculate_binary_decision_array</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">posterior_array</span><span class="p">):</span>

  <span class="n">binary_decision_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">posterior_array</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">posterior_array</span><span class="p">)):</span>
    <span class="c1">########################################################################</span>
    <span class="c1">## Insert your code here to:</span>
    <span class="c1">##      - For each hypothetical stimulus x (row of posterior),</span>
    <span class="c1">##        calculate the mean of the posterior using the provided function</span>
    <span class="c1">##        `moments_myfunc()`, and set the corresponding cell of the</span>
    <span class="c1">##        Binary Decision array to 1.</span>
    <span class="c1">##        Hint: you can run 'help(moments_myfunc)' to see the docstring</span>
    <span class="c1">## remove the raise below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"You need to complete the function!"</span><span class="p">)</span>
    <span class="c1">########################################################################</span>
    <span class="c1"># calculate mean of posterior using 'moments_myfunc'</span>
    <span class="n">mean</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="o">...</span>
    <span class="c1"># find the position of mean in x_points (closest position)</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">binary_decision_array</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

  <span class="k">return</span> <span class="n">binary_decision_array</span>


<span class="n">binary_decision_array</span> <span class="o">=</span> <span class="n">calculate_binary_decision_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">posterior_array</span><span class="p">)</span>
<span class="n">plot_myarray</span><span class="p">(</span><span class="n">binary_decision_array</span><span class="p">,</span>
             <span class="s1">'Chosen position $\hat x$'</span><span class="p">,</span> <span class="s1">'Brain-encoded Stimulus $\~ x$'</span><span class="p">,</span>
             <span class="s1">'Sample Binary Decision Array'</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">calculate_binary_decision_array</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">posterior_array</span><span class="p">):</span>

  <span class="n">binary_decision_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">posterior_array</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">posterior_array</span><span class="p">)):</span>
    <span class="c1"># calculate mean of posterior using 'moments_myfunc'</span>
    <span class="n">mean</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">moments_myfunc</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">posterior_array</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="c1"># find the position of mean in x_points (closest position)</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x_points</span> <span class="o">-</span> <span class="n">mean</span><span class="p">))</span>
    <span class="n">binary_decision_array</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

  <span class="k">return</span> <span class="n">binary_decision_array</span>


<span class="n">binary_decision_array</span> <span class="o">=</span> <span class="n">calculate_binary_decision_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">posterior_array</span><span class="p">)</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_myarray</span><span class="p">(</span><span class="n">binary_decision_array</span><span class="p">,</span>
               <span class="s1">'Chosen position $\hat x$'</span><span class="p">,</span> <span class="s1">'Brain-encoded Stimulus $\~ x$'</span><span class="p">,</span>
               <span class="s1">'Sample Binary Decision Array'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-5-probabilities-of-encoded-stimuli">
<h1>Section 5: Probabilities of encoded stimuli<a class="headerlink" href="#section-5-probabilities-of-encoded-stimuli" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-5-input-array">
<h2>Video 5: Input array<a class="headerlink" href="#video-5-input-array" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>Because we as experimentalists can not know the encoding <span class="math notranslate nohighlight">\(\tilde x\)</span> of the stimulus <span class="math notranslate nohighlight">\(x\)</span> that we do know, we had to compute the binary decision array for each possible encoding.</p>
<p>First however, we need to calculate how likely each possible encoding is given the true stimulus. That is, we will now create a Gaussian centered around the true presented stimulus, with <span class="math notranslate nohighlight">\(\sigma = 1\)</span>, and repeat that gaussian distribution across as a function of potentially encoded values <span class="math notranslate nohighlight">\(\tilde x\)</span>. That is, we want to make a <em>column</em> gaussian centered around the true presented stimulus, and repeat this <em>column</em> Gaussian across all hypothetical stimulus values <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>This, effectively encodes the distribution of the brain encoded stimulus (one single stimulus, which we as experimentalists know) and enable us to link the true stimulus <span class="math notranslate nohighlight">\(x\)</span>, to potential encodings <span class="math notranslate nohighlight">\(\tilde x\)</span>.</p>
<p><strong>Suggestions</strong></p>
<p>For this exercise, we will assume the true stimulus is presented at direction 2.5</p>
<ul class="simple">
<li><p>Create a Gaussian likelihood with <span class="math notranslate nohighlight">\(\mu = 2.5\)</span> and <span class="math notranslate nohighlight">\(\sigma = 1.0\)</span></p></li>
<li><p>Make this the first column of your array and repeat that <em>column</em> to fill in the true presented stimulus input as a function of hypothetical stimulus locations.</p></li>
<li><p>Plot the array using the function <code class="docutils literal notranslate"><span class="pre">plot_myarray()</span></code> already pre-written and commented-out in your script</p></li>
</ul>
<div class="section" id="exercise-5-generate-an-input-as-a-function-of-hypothetical-stimulus-x">
<h3>Exercise 5: Generate an input as a function of hypothetical stimulus x<a class="headerlink" href="#exercise-5-generate-an-input-as-a-function-of-hypothetical-stimulus-x" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">generate_input_array</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">stim_array</span><span class="p">,</span> <span class="n">posterior_array</span><span class="p">,</span>
                         <span class="n">mean</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>

  <span class="n">input_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">posterior_array</span><span class="p">)</span>
  <span class="c1">########################################################################</span>
  <span class="c1">## Insert your code here to:</span>
  <span class="c1">##      - Generate a gaussian centered on the true stimulus 2.5</span>
  <span class="c1">##        and sigma = 1. for each column</span>
  <span class="c1">## remove the raise below to test your function</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"You need to complete the function!"</span><span class="p">)</span>
  <span class="c1">########################################################################</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_points</span><span class="p">)):</span>
    <span class="n">input_array</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">input_array</span>


<span class="n">input_array</span> <span class="o">=</span> <span class="n">generate_input_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">hypothetical_stim</span><span class="p">,</span> <span class="n">posterior_array</span><span class="p">)</span>
<span class="n">plot_myarray</span><span class="p">(</span><span class="n">input_array</span><span class="p">,</span>
             <span class="s1">'Hypothetical Stimulus $x$'</span><span class="p">,</span> <span class="s1">'$\~x$'</span><span class="p">,</span>
             <span class="s1">'Sample Distribution over Encodings:</span><span class="se">\n</span><span class="s1"> $p(\~x | x = 2.5)$'</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">generate_input_array</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">stim_array</span><span class="p">,</span> <span class="n">posterior_array</span><span class="p">,</span>
                         <span class="n">mean</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>

  <span class="n">input_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">posterior_array</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_points</span><span class="p">)):</span>
    <span class="n">input_array</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">stim_array</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">input_array</span>


<span class="n">input_array</span> <span class="o">=</span> <span class="n">generate_input_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">hypothetical_stim</span><span class="p">,</span> <span class="n">posterior_array</span><span class="p">)</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_myarray</span><span class="p">(</span><span class="n">input_array</span><span class="p">,</span>
               <span class="s1">'Hypothetical Stimulus $x$'</span><span class="p">,</span> <span class="s1">'$\~x$'</span><span class="p">,</span>
               <span class="s1">'Sample Distribution over Encodings:</span><span class="se">\n</span><span class="s1"> $p(\~x | x = 2.5)$'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-6-normalization-and-expected-estimate-distribution">
<h1>Section 6: Normalization and expected estimate distribution<a class="headerlink" href="#section-6-normalization-and-expected-estimate-distribution" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-6-marginalization">
<h2>Video 6: Marginalization<a class="headerlink" href="#video-6-marginalization" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>Now that we have a true stimulus <span class="math notranslate nohighlight">\(x\)</span> and a way to link it to potential encodings, we will be able to calculate the distribution of encodings and ultimately estimates. To integrate over all possible hypothetical values of <span class="math notranslate nohighlight">\(\tilde x\)</span> we marginalize, that is, we first compute the dot-product from the true presented stimulus and our binary decision array and then sum over x.</p>
<p>Mathematically, this means that we want to compute:</p>
<div class="amsmath math notranslate nohighlight" id="equation-74100b5d-3079-4def-8425-ab06a1f75106">
<span class="eqno">(364)<a class="headerlink" href="#equation-74100b5d-3079-4def-8425-ab06a1f75106" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
Marginalization Array = Input Array \odot Binary Decision Array
\end{eqnarray}\]</div>
<div class="amsmath math notranslate nohighlight" id="equation-ddf6d4e4-8851-49ff-9a4f-bc168d752e69">
<span class="eqno">(365)<a class="headerlink" href="#equation-ddf6d4e4-8851-49ff-9a4f-bc168d752e69" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
Marginal = \int_{\tilde x} Marginalization Array
\end{eqnarray}\]</div>
<p>Since we are performing integration over discrete values using arrays for visualization purposes, the integration reduces to a simple sum over <span class="math notranslate nohighlight">\(\tilde x\)</span>.</p>
<p><strong>Suggestions</strong></p>
<ul class="simple">
<li><p>For each row of the input and binary arrays, calculate product of the two and fill in the 2D marginal array.</p></li>
<li><p>Plot the result using the function <code class="docutils literal notranslate"><span class="pre">plot_myarray()</span></code> already pre-written and commented-out in your script</p></li>
<li><p>Calculate and plot the marginal over <code class="docutils literal notranslate"><span class="pre">x</span></code> using the code snippet commented out in your script</p>
<ul>
<li><p>Note how the limitations of numerical integration create artifacts on your marginal</p></li>
</ul>
</li>
</ul>
<div class="section" id="exercise-6-implement-the-marginalization-matrix">
<h3>Exercise 6: Implement the marginalization matrix<a class="headerlink" href="#exercise-6-implement-the-marginalization-matrix" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">my_marginalization</span><span class="p">(</span><span class="n">input_array</span><span class="p">,</span> <span class="n">binary_decision_array</span><span class="p">):</span>

  <span class="c1">############################################################################</span>
  <span class="c1">## Insert your code here to:</span>
  <span class="c1">##  - Compute 'marginalization_array' by multiplying pointwise the Binary</span>
  <span class="c1">##    decision array over hypothetical stimuli and the Input array</span>
  <span class="c1">##  - Compute 'marginal' from the 'marginalization_array' by summing over x</span>
  <span class="c1">##    (hint: use np.sum() and only marginalize along the columns)</span>
  <span class="c1">## remove the raise below to test your function</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"You need to complete the function!"</span><span class="p">)</span>
  <span class="c1">############################################################################</span>

  <span class="n">marginalization_array</span> <span class="o">=</span> <span class="o">...</span>
  <span class="n">marginal</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># note axis</span>
  <span class="n">marginal</span> <span class="o">/=</span> <span class="o">...</span> <span class="c1"># normalize</span>

  <span class="k">return</span> <span class="n">marginalization_array</span><span class="p">,</span> <span class="n">marginal</span>


<span class="n">marginalization_array</span><span class="p">,</span> <span class="n">marginal</span> <span class="o">=</span> <span class="n">my_marginalization</span><span class="p">(</span><span class="n">input_array</span><span class="p">,</span> <span class="n">binary_decision_array</span><span class="p">)</span>

<span class="n">plot_myarray</span><span class="p">(</span><span class="n">marginalization_array</span><span class="p">,</span>
             <span class="s1">'estimated $\hat x$'</span><span class="p">,</span>
             <span class="s1">'$\~x$'</span><span class="p">,</span>
             <span class="s1">'Marginalization array: $p(\^x | \~x)$'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">marginal</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'$\^x$'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'probability'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">my_marginalization</span><span class="p">(</span><span class="n">input_array</span><span class="p">,</span> <span class="n">binary_decision_array</span><span class="p">):</span>

  <span class="n">marginalization_array</span> <span class="o">=</span> <span class="n">input_array</span> <span class="o">*</span> <span class="n">binary_decision_array</span>
  <span class="n">marginal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">marginalization_array</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># note axis</span>
  <span class="n">marginal</span> <span class="o">/=</span> <span class="n">marginal</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># normalize</span>

  <span class="k">return</span> <span class="n">marginalization_array</span><span class="p">,</span> <span class="n">marginal</span>


<span class="n">marginalization_array</span><span class="p">,</span> <span class="n">marginal</span> <span class="o">=</span> <span class="n">my_marginalization</span><span class="p">(</span><span class="n">input_array</span><span class="p">,</span> <span class="n">binary_decision_array</span><span class="p">)</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_myarray</span><span class="p">(</span><span class="n">marginalization_array</span><span class="p">,</span>
               <span class="s1">'estimated $\hat x$'</span><span class="p">,</span>
               <span class="s1">'$\~x$'</span><span class="p">,</span>
               <span class="s1">'Marginalization array: $p(\^x | \~x)$'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">marginal</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'$\^x$'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'probability'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="generate-some-data">
<h1>Generate some data<a class="headerlink" href="#generate-some-data" title="Permalink to this headline">¶</a></h1>
<p>We have seen how to calculate the posterior and marginalize to remove <span class="math notranslate nohighlight">\(\tilde x\)</span> and get <span class="math notranslate nohighlight">\(p(\hat{x} \mid x)\)</span>. Next, we will generate some artificial data for a single participant using the <code class="docutils literal notranslate"><span class="pre">generate_data()</span></code> function provided, and mixing parameter <span class="math notranslate nohighlight">\(p_{independent} = 0.1\)</span>.</p>
<p>Our goal in the next exercise will be to recover that parameter. These parameter recovery experiments are a powerful method for planning and debugging Bayesian analyses–if you cannot recover the given parameters, something has gone wrong! Note that this value for <span class="math notranslate nohighlight">\(p_{independent}\)</span> is not quite the same as our prior, which used <span class="math notranslate nohighlight">\(p_{independent} = 0.05.\)</span> This lets us test out the complete model.</p>
<p>Please run the code below to generate some synthetic data.  You do not need to edit anything, but check that the plot below matches what you would expect from the video.</p>
<div class="section" id="id1">
<h2><a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<div class="section" id="run-the-generate-data-function-this-cell">
<h3>Run the ‘generate_data’ function (this cell)<a class="headerlink" href="#run-the-generate-data-function-this-cell" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title</span>
<span class="c1">#@markdown #### Run the 'generate_data' function (this cell)</span>
<span class="k">def</span> <span class="nf">generate_data</span><span class="p">(</span><span class="n">x_stim</span><span class="p">,</span> <span class="n">p_independent</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  DO NOT EDIT THIS FUNCTION !!!</span>

<span class="sd">  Returns generated data using the mixture of Gaussian prior with mixture</span>
<span class="sd">  parameter `p_independent`</span>

<span class="sd">  Args :</span>
<span class="sd">    x_stim (numpy array of floats) - x values at which stimuli are presented</span>
<span class="sd">    p_independent (scalar) - mixture component for the Mixture of Gaussian prior</span>

<span class="sd">  Returns:</span>
<span class="sd">    (numpy array of floats): x_hat response of participant for each stimulus</span>
<span class="sd">  """</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span>
  <span class="n">x_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x_stim</span><span class="p">)</span>

  <span class="n">prior_mean</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">prior_sigma1</span> <span class="o">=</span> <span class="mf">.5</span>
  <span class="n">prior_sigma2</span> <span class="o">=</span> <span class="mi">3</span>
  <span class="n">prior1</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_sigma1</span><span class="p">)</span>
  <span class="n">prior2</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_sigma2</span><span class="p">)</span>

  <span class="n">prior_combined</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_independent</span><span class="p">)</span> <span class="o">*</span> <span class="n">prior1</span> <span class="o">+</span> <span class="p">(</span><span class="n">p_independent</span> <span class="o">*</span> <span class="n">prior2</span><span class="p">)</span>
  <span class="n">prior_combined</span> <span class="o">=</span> <span class="n">prior_combined</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">prior_combined</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">i_stim</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_stim</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">likelihood_mean</span> <span class="o">=</span> <span class="n">x_stim</span><span class="p">[</span><span class="n">i_stim</span><span class="p">]</span>
    <span class="n">likelihood_sigma</span>  <span class="o">=</span> <span class="mi">1</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">likelihood_mean</span><span class="p">,</span> <span class="n">likelihood_sigma</span><span class="p">)</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">likelihood</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">likelihood</span><span class="p">)</span>

    <span class="n">posterior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">prior_combined</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">posterior</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>

    <span class="c1"># Assumes participant takes posterior mean as 'action'</span>
    <span class="n">x_hat</span><span class="p">[</span><span class="n">i_stim</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">posterior</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">x_hat</span>

<span class="c1"># Generate data for a single participant</span>
<span class="n">true_stim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.5</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>
                      <span class="mf">2.5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="n">behaviour</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="n">true_stim</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">)</span>

<span class="n">plot_simulated_behavior</span><span class="p">(</span><span class="n">true_stim</span><span class="p">,</span> <span class="n">behaviour</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-7-model-fitting">
<h1>Section 7: Model fitting<a class="headerlink" href="#section-7-model-fitting" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-7-log-likelihood">
<h2>Video 7: Log likelihood<a class="headerlink" href="#video-7-log-likelihood" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>Now that we have generated some data, we will attempt to recover the parameter <span class="math notranslate nohighlight">\(p_{independent}\)</span> that was used to generate it.</p>
<p>We have provided you with an incomplete function called <code class="docutils literal notranslate"><span class="pre">my_Bayes_model_mse()</span></code> that needs to be completed to perform the same computations you have performed in the previous exercises but over all the participant’s trial, as opposed to a single trial.</p>
<p>The likelihood has already been constructed; since it depends  only on the hypothetical stimuli, it will not change. However, we will have to implement the prior matrix, since it depends on <span class="math notranslate nohighlight">\(p_{independent}\)</span>. We will therefore have to recompute the posterior, input and the marginal in order to get <span class="math notranslate nohighlight">\(p(\hat{x} \mid x)\)</span>.</p>
<p>Using <span class="math notranslate nohighlight">\(p(\hat{x} \mid x)\)</span>, we will then compute the negative log-likelihood for each trial and find the value of <span class="math notranslate nohighlight">\(p_{independent}\)</span> that minimizes the negative log-likelihood (i.e. maximizes the log-likelihood.  See the model fitting tutorial from W1D3 for a refresher).</p>
<p>In this experiment, we assume that trials are independent from one another. This is a common assumption–and it’s often even true! It allows us to define negative log-likelihood as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-f2738b8a-8a14-48e5-a517-e24780481805">
<span class="eqno">(366)<a class="headerlink" href="#equation-f2738b8a-8a14-48e5-a517-e24780481805" title="Permalink to this equation">¶</a></span>\[\begin{equation}
-LL = - \sum_i \log p(\hat{x}_i \mid x_i)
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{x}_i\)</span> is the participant’s response for trial <span class="math notranslate nohighlight">\(i\)</span>, with presented stimulus <span class="math notranslate nohighlight">\(x_i\)</span></p>
<ul class="simple">
<li><p>Complete the function <code class="docutils literal notranslate"><span class="pre">my_Bayes_model_mse</span></code>, we’ve already pre-completed the function to give you the prior, posterior, and input arrays on each trial</p></li>
<li><p>Compute the marginalization array as well as the marginal on each trial</p></li>
<li><p>Compute the negative log likelihood using the marginal and the participant’s response</p></li>
<li><p>Using the code snippet commented out in your script to loop over possible values of <span class="math notranslate nohighlight">\(p_{independent}\)</span></p></li>
</ul>
<div class="section" id="exercise-7-fitting-a-model-to-generated-data">
<h3>Exercise 7: Fitting a model to generated data<a class="headerlink" href="#exercise-7-fitting-a-model-to-generated-data" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">my_Bayes_model_mse</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Function fits the Bayesian model from Tutorial 4</span>

<span class="sd">  Args :</span>
<span class="sd">      params (list of positive floats):  parameters used by the model</span>
<span class="sd">      (params[0]  = posterior scaling)</span>

<span class="sd">  Returns :</span>
<span class="sd">      (scalar) negative log-likelihood :sum of log probabilities</span>
<span class="sd">  """</span>
  <span class="c1"># Create the prior array</span>
  <span class="n">p_independent</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">prior_array</span> <span class="o">=</span> <span class="n">calculate_prior_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>
                                      <span class="n">hypothetical_stim</span><span class="p">,</span>
                                      <span class="n">p_independent</span><span class="p">,</span>
                                      <span class="n">prior_sigma_indep</span><span class="o">=</span> <span class="mf">3.</span><span class="p">)</span>
  <span class="c1"># Create posterior array</span>
  <span class="n">posterior_array</span> <span class="o">=</span> <span class="n">calculate_posterior_array</span><span class="p">(</span><span class="n">prior_array</span><span class="p">,</span> <span class="n">likelihood_array</span><span class="p">)</span>
  <span class="c1"># Create Binary decision array</span>
  <span class="n">binary_decision_array</span> <span class="o">=</span> <span class="n">calculate_binary_decision_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">posterior_array</span><span class="p">)</span>
  <span class="c1"># we will use trial_ll (trial log likelihood) to register each trial</span>
  <span class="n">trial_ll</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">true_stim</span><span class="p">)</span>

  <span class="c1"># Loop over stimuli</span>
  <span class="k">for</span> <span class="n">i_stim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">true_stim</span><span class="p">)):</span>
    <span class="c1"># create the input array with true_stim as mean</span>
    <span class="n">input_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">posterior_array</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
      <span class="n">input_array</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">hypothetical_stim</span><span class="p">,</span> <span class="n">true_stim</span><span class="p">[</span><span class="n">i_stim</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">input_array</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_array</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">input_array</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>

    <span class="c1"># calculate the marginalizations</span>
    <span class="n">marginalization_array</span><span class="p">,</span> <span class="n">marginal</span> <span class="o">=</span> <span class="n">my_marginalization</span><span class="p">(</span><span class="n">input_array</span><span class="p">,</span>
                                                <span class="n">binary_decision_array</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">behaviour</span><span class="p">[</span><span class="n">i_stim</span><span class="p">]</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">action</span><span class="p">))</span>
    <span class="c1">########################################################################</span>
    <span class="c1">## Insert your code here to:</span>
    <span class="c1">##      - Compute the log likelihood of the participant</span>
    <span class="c1">## remove the raise below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"You need to complete the function!"</span><span class="p">)</span>
    <span class="c1">########################################################################</span>
    <span class="c1"># Get the marginal likelihood corresponding to the action</span>
    <span class="n">marginal_nonzero</span> <span class="o">=</span> <span class="o">...</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>  <span class="c1"># avoid log(0)</span>
    <span class="n">trial_ll</span><span class="p">[</span><span class="n">i_stim</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">marginal_nonzero</span><span class="p">)</span>

  <span class="n">neg_ll</span> <span class="o">=</span> <span class="o">-</span> <span class="n">trial_ll</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

  <span class="k">return</span> <span class="n">neg_ll</span>


<span class="n">plot_my_bayes_model</span><span class="p">(</span><span class="n">my_Bayes_model_mse</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="k">def</span> <span class="nf">my_Bayes_model_mse</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Function fits the Bayesian model from Tutorial 4</span>

<span class="sd">  Args :</span>
<span class="sd">      params (list of positive floats):  parameters used by the model</span>
<span class="sd">      (params[0]  = posterior scaling)</span>

<span class="sd">  Returns :</span>
<span class="sd">      (scalar) negative log-likelihood :sum of log probabilities</span>
<span class="sd">  """</span>
  <span class="c1"># Create the prior array</span>
  <span class="n">p_independent</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">prior_array</span> <span class="o">=</span> <span class="n">calculate_prior_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>
                                      <span class="n">hypothetical_stim</span><span class="p">,</span>
                                      <span class="n">p_independent</span><span class="p">,</span>
                                      <span class="n">prior_sigma_indep</span><span class="o">=</span> <span class="mf">3.</span><span class="p">)</span>

  <span class="c1"># Create posterior array</span>
  <span class="n">posterior_array</span> <span class="o">=</span> <span class="n">calculate_posterior_array</span><span class="p">(</span><span class="n">prior_array</span><span class="p">,</span> <span class="n">likelihood_array</span><span class="p">)</span>
  <span class="c1"># Create Binary decision array</span>
  <span class="n">binary_decision_array</span> <span class="o">=</span> <span class="n">calculate_binary_decision_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">posterior_array</span><span class="p">)</span>
  <span class="c1"># we will use trial_ll (trial log likelihood) to register each trial</span>
  <span class="n">trial_ll</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">true_stim</span><span class="p">)</span>

  <span class="c1"># Loop over stimuli</span>
  <span class="k">for</span> <span class="n">i_stim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">true_stim</span><span class="p">)):</span>
    <span class="c1"># create the input array with true_stim as mean</span>
    <span class="n">input_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">posterior_array</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
      <span class="n">input_array</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">hypothetical_stim</span><span class="p">,</span> <span class="n">true_stim</span><span class="p">[</span><span class="n">i_stim</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">input_array</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_array</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">input_array</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>

    <span class="c1"># calculate the marginalizations</span>
    <span class="n">marginalization_array</span><span class="p">,</span> <span class="n">marginal</span> <span class="o">=</span> <span class="n">my_marginalization</span><span class="p">(</span><span class="n">input_array</span><span class="p">,</span>
                                                <span class="n">binary_decision_array</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">behaviour</span><span class="p">[</span><span class="n">i_stim</span><span class="p">]</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">action</span><span class="p">))</span>
    <span class="c1"># Get the marginal likelihood corresponding to the action</span>
    <span class="n">marginal_nonzero</span> <span class="o">=</span> <span class="n">marginal</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>  <span class="c1"># avoid log(0)</span>
    <span class="n">trial_ll</span><span class="p">[</span><span class="n">i_stim</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">marginal_nonzero</span><span class="p">)</span>

  <span class="n">neg_ll</span> <span class="o">=</span> <span class="o">-</span> <span class="n">trial_ll</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

  <span class="k">return</span> <span class="n">neg_ll</span>


<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_my_bayes_model</span><span class="p">(</span><span class="n">my_Bayes_model_mse</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="section-8-summary">
<h1>Section 8: Summary<a class="headerlink" href="#section-8-summary" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-8-outro">
<h2>Video 8: Outro<a class="headerlink" href="#video-8-outro" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>Congratulations! You found <span class="math notranslate nohighlight">\(p_{independent}\)</span>, the parameter that describes how much weight subjects assign to the same-cause vs. independent-cause origins of a sound. In the preceding notebooks, we went through the entire Bayesian analysis pipeline:</p>
<ul class="simple">
<li><p>developing a model</p></li>
<li><p>simulating data, and</p></li>
<li><p>using Bayes’ Rule and marginalization to recover a hidden parameter from the data</p></li>
</ul>
<p>This example was simple, but the same principles can be used to analyze datasets with many hidden variables and complex priors and likelihoods. Bayes’ Rule will also play a crucial role in many of the other techniques you will see later this week.</p>
<br/>
<p>If you’re still intrigued as to why we decided to use the mean of the posterior as a decision rule for a response <span class="math notranslate nohighlight">\(\hat{x}\)</span>, we have an extra Bonus Tutorial 4 which goes through the most common decision rules and how these rules correspond to minimizing different cost functions.</p>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W3D1_BayesianDecisions/instructor"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="W3D1_Tutorial2.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Tutorial 2: Bayesian inference and decisions with continuous hidden state</p>
</div>
</a>
<a class="right-next" href="W3D1_Outro.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Outro</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
    By Neuromatch<br>
<div class="extra_footer">
<div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"/></a>
The contents of this repository are shared under the <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>
</div>
</br></p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>