
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 1: Bayes with a binary hidden state — Neuromatch Academy: Computational Neuroscience (instructor's version)</title>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/custom.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-logo-square-4xp.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W3D1_Tutorial2.html" rel="next" title="Tutorial 2: Bayesian inference and decisions with continuous hidden state"/>
<link href="W3D1_Intro.html" rel="prev" title="Intro"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
<div class="bd-sidebar__content">
<div class="bd-sidebar__top"><div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
<img alt="logo" class="logo" src="../../../_static/nma-logo-square-4xp.png"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Computational Neuroscience (instructor's version)</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../tatraining/TA_Training_CN.html">
   TA Training: Computational Neuroscience (CN)
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox">
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox">
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</input></li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using discord
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">
   Quick links and policies
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../prereqs/ComputationalNeuroscience.html">
   Prerequisites and preparatory materials for NMA Computational Neuroscience
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Pre-reqs Refresher
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/chapter_title.html">
   Neuro Video Series (W0D0)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial1.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial2.html">
     Human Psychophysics
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial3.html">
     Behavioral Readout
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial4.html">
     Live in Lab
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial5.html">
     Brain Signals: Spiking Activity
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial6.html">
     Brain Signals: LFP
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial7.html">
     Brain Signals: EEG &amp; MEG
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial8.html">
     Brain Signals: fMRI
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial9.html">
     Brain Signals: Calcium Imaging
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial10.html">
     Stimulus Representation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial11.html">
     Neurotransmitters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial12.html">
     Neurons to Consciousness
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">
   Python Workshop 1 (W0D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D1_PythonWorkshop1/instructor/W0D1_Tutorial1.html">
     Tutorial: LIF Neuron Part I
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">
   Python Workshop 2 (W0D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D2_PythonWorkshop2/instructor/W0D2_Tutorial1.html">
     Tutorial 1: LIF Neuron Part II
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D3_LinearAlgebra/chapter_title.html">
   Linear Algebra (W0D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Tutorial1.html">
     Tutorial 1: Vectors
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Tutorial2.html">
     Tutorial 2: Matrices
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Tutorial3.html">
     Bonus Tutorial: Discrete Dynamical Systems
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/instructor/W0D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D4_Calculus/chapter_title.html">
   Calculus (W0D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_Tutorial1.html">
     Tutorial 1: Differentiation and Integration
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_Tutorial2.html">
     Tutorial 2: Differential Equations
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_Tutorial3.html">
     Tutorial 3: Numerical Methods
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/instructor/W0D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D5_Statistics/chapter_title.html">
   Statistics (W0D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_Tutorial1.html">
     Tutorial 1: Probability Distributions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_Tutorial2.html">
     Tutorial 2: Statistical Inference
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/instructor/W0D5_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Intro to Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_ModelTypes/chapter_title.html">
   Model Types (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial1.html">
     Tutorial 1: “What” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial2.html">
     Tutorial 2: “How” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial3.html">
     Tutorial 3: “Why” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial4.html">
     Tutorial 4: Model Discussions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_ModelingPractice/chapter_title.html">
   Modeling Practice (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_Tutorial1.html">
     Tutorial 1: Framing the Question
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ModelingPractice/instructor/W2D1_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_ModelFitting/chapter_title.html">
   Model Fitting (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial1.html">
     Tutorial 1: Linear regression with MSE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial2.html">
     Tutorial 2: Linear regression with MLE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial3.html">
     Tutorial 3: Confidence intervals and bootstrapping
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial4.html">
     Tutorial 4: Multiple linear regression and polynomial regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial5.html">
     Tutorial 5: Model Selection: Bias-variance trade-off
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Tutorial6.html">
     Tutorial 6: Model Selection: Cross-validation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelFitting/instructor/W1D2_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/chapter_title.html">
   Generalized Linear Models (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Tutorial1.html">
     Tutorial 1: GLMs for Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Tutorial2.html">
     Tutorial 2: Classifiers and regularizers
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_GeneralizedLinearModels/instructor/W1D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/chapter_title.html">
   Dimensionality Reduction (W1D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial1.html">
     Tutorial 1: Geometric view of data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial2.html">
     Tutorial 2: Principal Component Analysis
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial3.html">
     Tutorial 3: Dimensionality Reduction &amp; Reconstruction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Tutorial4.html">
     Tutorial 4:  Nonlinear Dimensionality Reduction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_DimensionalityReduction/instructor/W1D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_DeepLearning/chapter_title.html">
   Deep Learning (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial3.html">
     Tutorial 3: Building and Evaluating Normative Encoding Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Tutorial4.html">
     Bonus Tutorial: Diving Deeper into Decoding &amp; Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DeepLearning/instructor/W1D5_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Bonus_Autoencoders/chapter_title.html">
   Autoencoders (Bonus)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial1.html">
     Tutorial 1: Intro to Autoencoders
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial2.html">
     Tutorial 2: Autoencoder extensions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Tutorial3.html">
     Tutorial 3: Autoencoders applications
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Bonus_Autoencoders/instructor/Bonus_Outro.html">
     Outro
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/MachineLearning.html">
   Machine Learning Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_LinearSystems/chapter_title.html">
   Linear Systems (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial1.html">
     Tutorial 1: Linear dynamical systems
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial2.html">
     Tutorial 2: Markov Processes
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial3.html">
     Tutorial 3: Combining determinism and stochasticity
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial4.html">
     Tutorial 4: Autoregressive models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/chapter_title.html">
   Biological Neuron Models (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial1.html">
     Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial2.html">
     Tutorial 2: Effects of Input Correlation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial3.html">
     Tutorial 3: Synaptic transmission - Models of static and dynamic synapses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial4.html">
     Bonus Tutorial: Spike-timing dependent plasticity (STDP)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_DynamicNetworks/chapter_title.html">
   Dynamic Networks (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial1.html">
     Tutorial 1: Neural Rate Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial2.html">
     Tutorial 2: Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial3.html">
     Bonus Tutorial: Extending the Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/DynamicalSystems.html">
   Dynamical Systems Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Stochastic Processes
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Bayesian Decisions (W3D1)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2">
<a class="reference internal" href="W3D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 1: Bayes with a binary hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D1_Tutorial2.html">
     Tutorial 2: Bayesian inference and decisions with continuous hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D1_Tutorial3.html">
     Bonus Tutorial : Fitting to data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D1_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_HiddenDynamics/chapter_title.html">
   Hidden Dynamics (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial1.html">
     Tutorial 1: Sequential Probability Ratio Test
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial2.html">
     Tutorial 2: Hidden Markov Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial3.html">
     Tutorial 3: The Kalman Filter
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial4.html">
     Bonus Tutorial 4: The Kalman Filter, part 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial5.html">
     Bonus Tutorial 5: Expectation Maximization for spiking neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_OptimalControl/chapter_title.html">
   Optimal Control (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial1.html">
     Tutorial 1: Optimal Control for Discrete States
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial2.html">
     Tutorial 2: Optimal Control for Continuous State
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/chapter_title.html">
   Reinforcement Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial4.html">
     Tutorial 4: Model-Based Reinforcement Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D5_NetworkCausality/chapter_title.html">
   Network Causality (W3D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
<label for="toctree-checkbox-24">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial1.html">
     Tutorial 1: Interventions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial2.html">
     Tutorial 2: Correlations
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial3.html">
     Tutorial 3: Simultaneous fitting/regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial4.html">
     Tutorial 4: Instrumental Variables
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/further_reading.html">
     Suggested further readings
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_DaySummary.html">
     Day Summary
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/StochasticProcesses.html">
   Stochastic Processes Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
<label for="toctree-checkbox-25">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through4.html">
     Modeling Steps 1 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through10.html">
     Modeling Steps 5 - 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModel.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProject.html">
     Example Data Project: the Train Illusion
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/datasets_overview.html">
   Datasets
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
<label for="toctree-checkbox-26">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/neurons.html">
     Neurons
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
<label for="toctree-checkbox-27">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/neurons_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/fMRI.html">
     fMRI
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
<label for="toctree-checkbox-28">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/fMRI_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/ECoG.html">
     ECoG
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
<label for="toctree-checkbox-29">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/ECoG_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/behavior.html">
     Behavior
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
<label for="toctree-checkbox-30">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/behavior_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/theory.html">
     Theory
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
<label for="toctree-checkbox-31">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/theory/README.html">
       Guide
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_templates.html">
   Project Templates
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/project_2020_highlights.html">
   Projects 2020
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/>
<label for="toctree-checkbox-32">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/neurons.html">
     Neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/theory.html">
     Theory
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/behavior.html">
     Behavior
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/fMRI.html">
     fMRI
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/eeg.html">
     EEG
    </a>
</li>
</ul>
</li>
</ul>
</div>
</nav></div>
<div class="bd-sidebar__bottom">
<!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="headerbtn" data-placement="right" data-toggle="tooltip" for="__navigation" title="Toggle navigation">
<span class="headerbtn__icon-container">
<i class="fas fa-bars"></i>
</span>
</label>
</div>
<div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
<button aria-label="Launch interactive content" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-rocket"></i>
</button>
<div class="menu-dropdown__content">
<ul>
</ul>
</div>
</div>
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="menu-dropdown menu-dropdown-repository-buttons">
<button aria-label="Source repositories" class="headerbtn menu-dropdown__trigger">
<i class="fab fa-github"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="headerbtn__text-container">repository</span>
</a>
</li>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content/issues/new?title=Issue%20on%20page%20%2Ftutorials/W3D1_BayesianDecisions/instructor/W3D1_Tutorial1.html&amp;body=Your%20issue%20content%20here." title="Open an issue">
<span class="headerbtn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="headerbtn__text-container">open issue</span>
</a>
</li>
</ul>
</div>
</div>
<div class="menu-dropdown menu-dropdown-download-buttons">
<button aria-label="Download this page" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-download"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/W3D1_BayesianDecisions/instructor/W3D1_Tutorial1.ipynb" title="Download source file">
<span class="headerbtn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="headerbtn__text-container">.ipynb</span>
</a>
</li>
<li>
<button class="headerbtn" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="headerbtn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="headerbtn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
</div>
<label class="headerbtn headerbtn-page-toc" for="__page-toc">
<span class="headerbtn__icon-container">
<i class="fas fa-list"></i>
</span>
</label>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
    </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 1: Bayes with a binary hidden state
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-introduction-to-bayesian-statistics-and-decisions">
     Video 1: Introduction to Bayesian Statistics and Decisions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper Functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-gone-fishin">
   Section 1: Gone Fishin’
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-gone-fishin">
     Video 2: Gone Fishin’
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-deciding-where-to-fish">
   Section 2: Deciding where to fish
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-utility">
     Video 3: Utility
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-2-exploring-the-decision">
     Interactive Demo 2: Exploring the decision
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-utility-demo-discussion">
       Video 4: Utility Demo Discussion
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-likelihood-of-the-fish-being-on-either-side">
   Section 3: Likelihood of the fish being on either side
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-likelihood">
     Video 5: Likelihood
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-3-guessing-the-location-of-the-fish">
     Think! 3: Guessing the location of the fish
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-correlation-and-marginalization">
   Section 4: Correlation and marginalization
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-6-correlation-and-marginalization">
     Video 6: Correlation and marginalization
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-1-correlation">
     Section 4.1: Correlation
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-4-1-covarying-probability-distributions">
       Think! 4.1: Covarying probability distributions
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-2-marginalisation">
     Section 4.2: Marginalisation
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#math-exercise-4-2-1-computing-marginal-probabilities">
       Math Exercise 4.2.1: Computing marginal probabilities
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#math-exercise-4-2-2-computing-marginal-likelihood">
       Math Exercise 4.2.2: Computing marginal likelihood
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-5-bayes-rule-and-the-posterior">
   Section 5: Bayes’ Rule and the Posterior
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-7-posterior-beliefs">
     Video 7: Posterior Beliefs
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#math-exercise-5-calculating-a-posterior-probability">
     Math Exercise 5: Calculating a posterior probability
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-5-computing-posteriors">
     Coding Exercise 5: Computing Posteriors
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-5-what-affects-the-posterior">
     Interactive Demo 5: What affects the posterior?
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-8-posterior-beliefs-exercises-discussion">
       Video 8: Posterior Beliefs Exercises Discussion
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-6-making-bayesian-fishing-decisions">
   Section 6: Making Bayesian fishing decisions
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-9-bayesian-decisions">
     Video 9: Bayesian Decisions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-6-what-is-more-important-the-probabilities-or-the-utilities">
     Interactive Demo! 6: What is more important, the probabilities or the utilities?
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-10-bayesian-decisions-demo-discussion">
       Video 10: Bayesian Decisions Demo Discussion
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus">
   Bonus
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-section-1-correlation-formula">
     Bonus Section 1: Correlation Formula
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 1: Bayes with a binary hidden state</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 1: Bayes with a binary hidden state
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-introduction-to-bayesian-statistics-and-decisions">
     Video 1: Introduction to Bayesian Statistics and Decisions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting Functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper Functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-gone-fishin">
   Section 1: Gone Fishin’
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-gone-fishin">
     Video 2: Gone Fishin’
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-deciding-where-to-fish">
   Section 2: Deciding where to fish
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-utility">
     Video 3: Utility
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-2-exploring-the-decision">
     Interactive Demo 2: Exploring the decision
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-utility-demo-discussion">
       Video 4: Utility Demo Discussion
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-likelihood-of-the-fish-being-on-either-side">
   Section 3: Likelihood of the fish being on either side
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-likelihood">
     Video 5: Likelihood
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-3-guessing-the-location-of-the-fish">
     Think! 3: Guessing the location of the fish
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-correlation-and-marginalization">
   Section 4: Correlation and marginalization
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-6-correlation-and-marginalization">
     Video 6: Correlation and marginalization
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-1-correlation">
     Section 4.1: Correlation
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-4-1-covarying-probability-distributions">
       Think! 4.1: Covarying probability distributions
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-2-marginalisation">
     Section 4.2: Marginalisation
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#math-exercise-4-2-1-computing-marginal-probabilities">
       Math Exercise 4.2.1: Computing marginal probabilities
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#math-exercise-4-2-2-computing-marginal-likelihood">
       Math Exercise 4.2.2: Computing marginal likelihood
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-5-bayes-rule-and-the-posterior">
   Section 5: Bayes’ Rule and the Posterior
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-7-posterior-beliefs">
     Video 7: Posterior Beliefs
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#math-exercise-5-calculating-a-posterior-probability">
     Math Exercise 5: Calculating a posterior probability
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-5-computing-posteriors">
     Coding Exercise 5: Computing Posteriors
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-5-what-affects-the-posterior">
     Interactive Demo 5: What affects the posterior?
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-8-posterior-beliefs-exercises-discussion">
       Video 8: Posterior Beliefs Exercises Discussion
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-6-making-bayesian-fishing-decisions">
   Section 6: Making Bayesian fishing decisions
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-9-bayesian-decisions">
     Video 9: Bayesian Decisions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-6-what-is-more-important-the-probabilities-or-the-utilities">
     Interactive Demo! 6: What is more important, the probabilities or the utilities?
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-10-bayesian-decisions-demo-discussion">
       Video 10: Bayesian Decisions Demo Discussion
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus">
   Bonus
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-section-1-correlation-formula">
     Bonus Section 1: Correlation Formula
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/main/tutorials/W3D1_BayesianDecisions/instructor/W3D1_Tutorial1.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/W3D1_BayesianDecisions/instructor/W3D1_Tutorial1.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<div class="section" id="tutorial-1-bayes-with-a-binary-hidden-state">
<h1>Tutorial 1: Bayes with a binary hidden state<a class="headerlink" href="#tutorial-1-bayes-with-a-binary-hidden-state" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 3, Day 1: Bayesian Decisions</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Eric DeWitt, Xaq Pitkow, Ella Batty, Saeed Salehi</p>
<p><strong>Content reviewers:</strong> Hyosub Kim, Zahra Arjmandi, Anoop Kulkarni</p>
<p><strong>Production editor:</strong> Ella Batty</p>
<p><strong>Post-Production team:</strong> Gagana B, Spiros Chavlis</p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p></div>
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing of tutorial: 1 hour, 30 minutes</em></p>
<p>This is the first of two core tutorials on Bayesian statistics. In these tutorials, we will explore the fundamental concepts of the Bayesian approach. In this tutorial you will work through an example of Bayesian inference and decision making using a binary hidden state. The second tutorial extends these concepts to a continuous hidden state. In the related NMA days, each of these basic ideas will be extended. In Hidden Dynamics, we consider these ideas through time as you explore what happens when we infer a hidden state using repeated observations and when the hidden state changes across time. On the Optimal Control day, we will introduce the notion of how to use inference and decisions to select actions for optimal control.</p>
<p>This notebook will introduce the fundamental building blocks for Bayesian statistics:</p>
<ol class="simple">
<li><p>How do we combine the possible loss (or gain) for making a decision with our probabilistic knowledge?</p></li>
<li><p>How do we use probability distributions to represent hidden states?</p></li>
<li><p>How does marginalization work and how can we use it?</p></li>
<li><p>How do we combine new information with our prior knowledge?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Tutorial slides</span>
<span class="c1"># @markdown These are the slides for the videos in this tutorial</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">IFrame</span>
<span class="n">link_id</span> <span class="o">=</span> <span class="s2">"dx7jt"</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"If you want to download the slides: https://osf.io/download/</span><span class="si">{</span><span class="n">link_id</span><span class="si">}</span><span class="s2">/"</span><span class="p">)</span>
<span class="n">IFrame</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="sa">f</span><span class="s2">"https://mfr.ca-1.osf.io/render?url=https://osf.io/</span><span class="si">{</span><span class="n">link_id</span><span class="si">}</span><span class="s2">/?direct%26mode=render%26action=download%26mode=render"</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="video-1-introduction-to-bayesian-statistics-and-decisions">
<h2>Video 1: Introduction to Bayesian Statistics and Decisions<a class="headerlink" href="#video-1-introduction-to-bayesian-statistics-and-decisions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">patches</span><span class="p">,</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">gridspec</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">fsolve</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure Settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Figure Settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>       <span class="c1"># interactive display</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">GridspecLayout</span><span class="p">,</span> <span class="n">HBox</span><span class="p">,</span> <span class="n">VBox</span><span class="p">,</span> <span class="n">FloatSlider</span><span class="p">,</span> <span class="n">Layout</span><span class="p">,</span> <span class="n">ToggleButtons</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">interactive_output</span><span class="p">,</span> <span class="n">Checkbox</span><span class="p">,</span> <span class="n">Select</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">clear_output</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle"</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">"ignore"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plotting-functions">
<h2>Plotting Functions<a class="headerlink" href="#plotting-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting Functions</span>

<span class="k">def</span> <span class="nf">plot_joint_probs</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="p">):</span>
    <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">P</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">),</span> <span class="s2">"probabilities should be &gt;= 0"</span>
    <span class="c1"># normalize if not</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">P</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="n">marginal_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">P</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">marginal_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">P</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># definitions for the axes</span>
    <span class="n">left</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.65</span>
    <span class="n">bottom</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.65</span>
    <span class="n">spacing</span> <span class="o">=</span> <span class="mf">0.005</span>

    <span class="c1"># start with a square Figure</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

    <span class="n">joint_prob</span> <span class="o">=</span> <span class="p">[</span><span class="n">left</span><span class="p">,</span> <span class="n">bottom</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>
    <span class="n">rect_histx</span> <span class="o">=</span> <span class="p">[</span><span class="n">left</span><span class="p">,</span> <span class="n">bottom</span> <span class="o">+</span> <span class="n">height</span> <span class="o">+</span> <span class="n">spacing</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]</span>
    <span class="n">rect_histy</span> <span class="o">=</span> <span class="p">[</span><span class="n">left</span> <span class="o">+</span> <span class="n">width</span> <span class="o">+</span> <span class="n">spacing</span><span class="p">,</span> <span class="n">bottom</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>

    <span class="n">rect_x_cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span>
    <span class="n">rect_y_cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Reds</span>

    <span class="c1"># Show joint probs and marginals</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">joint_prob</span><span class="p">)</span>
    <span class="n">ax_x</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_histx</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax_y</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_histy</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

    <span class="c1"># Show joint probs and marginals</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">P</span><span class="p">,</span><span class="n">vmin</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'Greys'</span><span class="p">)</span>
    <span class="n">ax_x</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">marginal_x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">facecolor</span><span class="o">=</span><span class="n">rect_x_cmap</span><span class="p">(</span><span class="n">marginal_x</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">ax_x</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">marginal_x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">facecolor</span><span class="o">=</span><span class="n">rect_x_cmap</span><span class="p">(</span><span class="n">marginal_x</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">ax_y</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">marginal_y</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">facecolor</span><span class="o">=</span><span class="n">rect_y_cmap</span><span class="p">(</span><span class="n">marginal_y</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">ax_y</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">marginal_y</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">facecolor</span><span class="o">=</span><span class="n">rect_y_cmap</span><span class="p">(</span><span class="n">marginal_y</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="c1"># set limits</span>
    <span class="n">ax_x</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">ax_y</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># show values</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span><span class="n">ind</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ind</span><span class="p">:</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">marginal_x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_x</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="o">+</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">marginal_y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_y</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">v</span><span class="o">+</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>

    <span class="c1"># set up labels</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">tick_bottom</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">tick_left</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s1">'Silver'</span><span class="p">,</span><span class="s1">'Gold'</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="s1">'Small'</span><span class="p">,</span> <span class="s1">'Large'</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'color'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'size'</span><span class="p">)</span>
    <span class="n">ax_x</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
    <span class="n">ax_y</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span>


<span class="k">def</span> <span class="nf">plot_prior_likelihood_posterior</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">posterior</span><span class="p">):</span>

    <span class="c1"># definitions for the axes</span>
    <span class="n">left</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.3</span>
    <span class="n">bottom</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.9</span>
    <span class="n">padding</span> <span class="o">=</span> <span class="mf">0.12</span>
    <span class="n">small_width</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="n">left_space</span> <span class="o">=</span> <span class="n">left</span> <span class="o">+</span> <span class="n">small_width</span> <span class="o">+</span> <span class="n">padding</span>
    <span class="n">added_space</span> <span class="o">=</span> <span class="n">padding</span> <span class="o">+</span> <span class="n">width</span>

    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

    <span class="n">rect_prior</span> <span class="o">=</span> <span class="p">[</span><span class="n">left</span><span class="p">,</span> <span class="n">bottom</span><span class="p">,</span> <span class="n">small_width</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>
    <span class="n">rect_likelihood</span> <span class="o">=</span> <span class="p">[</span><span class="n">left_space</span> <span class="p">,</span> <span class="n">bottom</span> <span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>
    <span class="n">rect_posterior</span> <span class="o">=</span> <span class="p">[</span><span class="n">left_space</span> <span class="o">+</span>  <span class="n">added_space</span><span class="p">,</span> <span class="n">bottom</span> <span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>

    <span class="n">ax_prior</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_prior</span><span class="p">)</span>
    <span class="n">ax_likelihood</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_likelihood</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="n">ax_prior</span><span class="p">)</span>
    <span class="n">ax_posterior</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_posterior</span><span class="p">,</span> <span class="n">sharey</span> <span class="o">=</span> <span class="n">ax_prior</span><span class="p">)</span>

    <span class="n">rect_colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span>

    <span class="c1"># Show posterior probs and marginals</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">prior</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">rect_colormap</span><span class="p">(</span><span class="n">prior</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">prior</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">rect_colormap</span><span class="p">(</span><span class="n">prior</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]))</span>
    <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'Reds'</span><span class="p">)</span>
    <span class="n">ax_posterior</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'Greens'</span><span class="p">)</span>


    <span class="c1"># Probabilities plot details</span>
    <span class="c1"># ax_prior.set(xlim = [1, 0], yticks = [0, 1], yticklabels = ['left', 'right'],</span>
    <span class="c1">#              ylabel = 'state (s)', title = "Prior p(s)")</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">xticks</span> <span class="o">=</span> <span class="p">[],</span> <span class="n">yticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">yticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span>
                 <span class="n">title</span> <span class="o">=</span> <span class="s2">"Prior p(s)"</span><span class="p">)</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">tick_right</span><span class="p">()</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'left'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'bottom'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Likelihood plot details</span>
    <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">xticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'fish'</span><span class="p">,</span> <span class="s1">'no fish'</span><span class="p">],</span>
                  <span class="n">yticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">yticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span>
                   <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">'state (s)'</span><span class="p">,</span> <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">'measurement (m)'</span><span class="p">,</span>
                   <span class="n">title</span> <span class="o">=</span> <span class="s1">'Likelihood p(m (left) | s)'</span><span class="p">)</span>
    <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_ticks_position</span><span class="p">(</span><span class="s1">'bottom'</span><span class="p">)</span>
    <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'left'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'bottom'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Posterior plot details</span>

    <span class="n">ax_posterior</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">xticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'fish'</span><span class="p">,</span> <span class="s1">'no fish'</span><span class="p">],</span>
                  <span class="n">yticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">yticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span>
                   <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">'state (s)'</span><span class="p">,</span> <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">'measurement (m)'</span><span class="p">,</span>
                   <span class="n">title</span> <span class="o">=</span> <span class="s1">'Posterior p(s | m)'</span><span class="p">)</span>
    <span class="n">ax_posterior</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_ticks_position</span><span class="p">(</span><span class="s1">'bottom'</span><span class="p">)</span>
    <span class="n">ax_posterior</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'left'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax_posterior</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'bottom'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>


    <span class="c1"># show values</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span><span class="n">ind</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">posterior</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_posterior</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">likelihood</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ind</span><span class="p">:</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">prior</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_prior</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">v</span><span class="o">+</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_prior_likelihood</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="n">p_a_s1</span><span class="p">,</span> <span class="n">p_a_s0</span><span class="p">,</span> <span class="n">measurement</span><span class="p">):</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="n">p_a_s1</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">p_a_s1</span><span class="p">],[</span><span class="n">p_a_s0</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">p_a_s0</span><span class="p">]])</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">ps</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">ps</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">ps</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">measurement</span> <span class="o">==</span> <span class="s2">"Fish"</span><span class="p">:</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="n">likelihood</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">prior</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="p">(</span><span class="n">likelihood</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">prior</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">posterior</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>

    <span class="c1"># definitions for the axes</span>
    <span class="n">left</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.3</span>
    <span class="n">bottom</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.9</span>
    <span class="n">padding</span> <span class="o">=</span> <span class="mf">0.12</span>
    <span class="n">small_width</span> <span class="o">=</span> <span class="mf">0.2</span>
    <span class="n">left_space</span> <span class="o">=</span> <span class="n">left</span> <span class="o">+</span> <span class="n">small_width</span> <span class="o">+</span> <span class="n">padding</span>
    <span class="n">small_padding</span> <span class="o">=</span> <span class="mf">0.05</span>

    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

    <span class="n">rect_prior</span> <span class="o">=</span> <span class="p">[</span><span class="n">left</span><span class="p">,</span> <span class="n">bottom</span><span class="p">,</span> <span class="n">small_width</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>
    <span class="n">rect_likelihood</span> <span class="o">=</span> <span class="p">[</span><span class="n">left_space</span> <span class="p">,</span> <span class="n">bottom</span> <span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>
    <span class="n">rect_posterior</span> <span class="o">=</span> <span class="p">[</span><span class="n">left_space</span> <span class="o">+</span> <span class="n">width</span> <span class="o">+</span> <span class="n">small_padding</span><span class="p">,</span> <span class="n">bottom</span> <span class="p">,</span> <span class="n">small_width</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>

    <span class="n">ax_prior</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_prior</span><span class="p">)</span>
    <span class="n">ax_likelihood</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_likelihood</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="n">ax_prior</span><span class="p">)</span>
    <span class="n">ax_posterior</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_posterior</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="n">ax_prior</span><span class="p">)</span>

    <span class="n">prior_colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span>
    <span class="n">posterior_colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Greens</span>

    <span class="c1"># Show posterior probs and marginals</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">prior</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">prior_colormap</span><span class="p">(</span><span class="n">prior</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">prior</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">prior_colormap</span><span class="p">(</span><span class="n">prior</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'Reds'</span><span class="p">)</span>
    <span class="c1"># ax_posterior.matshow(posterior, vmin=0., vmax=1., cmap='')</span>
    <span class="n">ax_posterior</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">posterior</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">posterior_colormap</span><span class="p">(</span><span class="n">posterior</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">ax_posterior</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">posterior</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">posterior_colormap</span><span class="p">(</span><span class="n">posterior</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1"># Probabilities plot details</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">yticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span>
                 <span class="n">title</span> <span class="o">=</span> <span class="s2">"Prior p(s)"</span><span class="p">,</span> <span class="n">xticks</span> <span class="o">=</span> <span class="p">[])</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">tick_right</span><span class="p">()</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'left'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'bottom'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Likelihood plot details</span>
    <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">xticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'fish'</span><span class="p">,</span> <span class="s1">'no fish'</span><span class="p">],</span>
                  <span class="n">yticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">yticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span>
                   <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">'state (s)'</span><span class="p">,</span> <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">'measurement (m)'</span><span class="p">,</span>
                   <span class="n">title</span> <span class="o">=</span> <span class="s1">'Likelihood p(m | s)'</span><span class="p">)</span>
    <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_ticks_position</span><span class="p">(</span><span class="s1">'bottom'</span><span class="p">)</span>
    <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'left'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'bottom'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Posterior plot details</span>
    <span class="n">ax_posterior</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">xticks</span> <span class="o">=</span> <span class="p">[],</span> <span class="n">yticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                     <span class="n">yticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span> <span class="n">title</span> <span class="o">=</span> <span class="s2">"Posterior p(s | m)"</span><span class="p">)</span>
    <span class="n">ax_posterior</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'left'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax_posterior</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'bottom'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># show values</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span><span class="n">ind</span><span class="p">)</span>
    <span class="c1"># for i,j in zip(x.flatten(), y.flatten()):</span>
    <span class="c1">#     c = f"{posterior[i,j]:.2f}"</span>
    <span class="c1">#     ax_posterior.text(j,i, c, va='center', ha='center', color='black')</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ind</span><span class="p">:</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">posterior</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_posterior</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">v</span><span class="o">+</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">likelihood</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ind</span><span class="p">:</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">prior</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_prior</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">v</span><span class="o">+</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span>


<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">colors</span>
<span class="k">def</span> <span class="nf">plot_utility</span><span class="p">(</span><span class="n">ps</span><span class="p">):</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">ps</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">ps</span><span class="p">])</span>

    <span class="n">utility</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

    <span class="n">expected</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">@</span> <span class="n">utility</span>

    <span class="c1"># definitions for the axes</span>
    <span class="n">left</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.16</span>
    <span class="n">bottom</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.9</span>
    <span class="n">padding</span> <span class="o">=</span> <span class="mf">0.02</span>
    <span class="n">small_width</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="n">left_space</span> <span class="o">=</span> <span class="n">left</span> <span class="o">+</span> <span class="n">small_width</span> <span class="o">+</span> <span class="n">padding</span>
    <span class="n">added_space</span> <span class="o">=</span> <span class="n">padding</span> <span class="o">+</span> <span class="n">width</span>

    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

    <span class="n">rect_prior</span> <span class="o">=</span> <span class="p">[</span><span class="n">left</span><span class="p">,</span> <span class="n">bottom</span><span class="p">,</span> <span class="n">small_width</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>
    <span class="n">rect_utility</span> <span class="o">=</span> <span class="p">[</span><span class="n">left</span> <span class="o">+</span> <span class="n">added_space</span> <span class="p">,</span> <span class="n">bottom</span> <span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>
    <span class="n">rect_expected</span> <span class="o">=</span> <span class="p">[</span><span class="n">left</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span> <span class="n">added_space</span><span class="p">,</span> <span class="n">bottom</span> <span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>

    <span class="n">ax_prior</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_prior</span><span class="p">)</span>
    <span class="n">ax_utility</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_utility</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="n">ax_prior</span><span class="p">)</span>
    <span class="n">ax_expected</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_expected</span><span class="p">)</span>

    <span class="n">rect_colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span>

    <span class="c1"># Data of plots</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">prior</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">rect_colormap</span><span class="p">(</span><span class="n">prior</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">prior</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">rect_colormap</span><span class="p">(</span><span class="n">prior</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">ax_utility</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">utility</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'cool'</span><span class="p">)</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="n">colors</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">vmin</span><span class="o">=-</span><span class="mi">3</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">ax_expected</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">expected</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">rect_colormap</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">expected</span><span class="p">[</span><span class="mi">0</span><span class="p">])))</span>
    <span class="n">ax_expected</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">expected</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">rect_colormap</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">expected</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>

    <span class="c1"># Probabilities plot details</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">xticks</span> <span class="o">=</span> <span class="p">[],</span> <span class="n">yticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">yticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span>
                 <span class="n">title</span> <span class="o">=</span> <span class="s2">"Probability of state"</span><span class="p">)</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">tick_right</span><span class="p">()</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'left'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'bottom'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Utility plot details</span>
    <span class="n">ax_utility</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">xticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span>
                  <span class="n">yticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">yticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span>
                   <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">'state (s)'</span><span class="p">,</span> <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">'action (a)'</span><span class="p">,</span>
                   <span class="n">title</span> <span class="o">=</span> <span class="s1">'Utility'</span><span class="p">)</span>
    <span class="n">ax_utility</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_ticks_position</span><span class="p">(</span><span class="s1">'bottom'</span><span class="p">)</span>
    <span class="n">ax_utility</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'left'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax_utility</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'bottom'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Expected utility plot details</span>
    <span class="n">ax_expected</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s1">'Expected utility'</span><span class="p">,</span> <span class="n">ylim</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                    <span class="n">xticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">xticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span>
                    <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">'action (a)'</span><span class="p">,</span>
                    <span class="n">yticks</span> <span class="o">=</span> <span class="p">[])</span>
    <span class="n">ax_expected</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_ticks_position</span><span class="p">(</span><span class="s1">'bottom'</span><span class="p">)</span>
    <span class="n">ax_expected</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'left'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax_expected</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'bottom'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># show values</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span><span class="n">ind</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">utility</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_utility</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ind</span><span class="p">:</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">prior</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_prior</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">v</span><span class="o">+</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ind</span><span class="p">:</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">expected</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_expected</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fig</span>


<span class="k">def</span> <span class="nf">plot_prior_likelihood_utility</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="n">p_a_s1</span><span class="p">,</span> <span class="n">p_a_s0</span><span class="p">,</span> <span class="n">measurement</span><span class="p">):</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">ps</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">p_a_s1</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>
    <span class="k">assert</span> <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">p_a_s0</span> <span class="o">&lt;=</span> <span class="mf">1.0</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">ps</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">ps</span><span class="p">])</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="n">p_a_s1</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">p_a_s1</span><span class="p">],[</span><span class="n">p_a_s0</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">p_a_s0</span><span class="p">]])</span>
    <span class="n">utility</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]])</span>
    <span class="c1"># expected = np.zeros_like(utility)</span>

    <span class="k">if</span> <span class="n">measurement</span> <span class="o">==</span> <span class="s2">"Fish"</span><span class="p">:</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="n">likelihood</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">prior</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="p">(</span><span class="n">likelihood</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">prior</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">posterior</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
    <span class="c1"># expected[:, 0] = utility[:, 0] * posterior</span>
    <span class="c1"># expected[:, 1] = utility[:, 1] * posterior</span>
    <span class="n">expected</span> <span class="o">=</span> <span class="n">posterior</span> <span class="o">@</span> <span class="n">utility</span>

    <span class="c1"># definitions for the axes</span>
    <span class="n">left</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.3</span>
    <span class="n">bottom</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.3</span>
    <span class="n">padding</span> <span class="o">=</span> <span class="mf">0.12</span>
    <span class="n">small_width</span> <span class="o">=</span> <span class="mf">0.2</span>
    <span class="n">left_space</span> <span class="o">=</span> <span class="n">left</span> <span class="o">+</span> <span class="n">small_width</span> <span class="o">+</span> <span class="n">padding</span>
    <span class="n">small_padding</span> <span class="o">=</span> <span class="mf">0.05</span>

    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>

    <span class="n">rect_prior</span> <span class="o">=</span> <span class="p">[</span><span class="n">left</span><span class="p">,</span> <span class="n">bottom</span> <span class="o">+</span> <span class="n">height</span> <span class="o">+</span> <span class="n">padding</span><span class="p">,</span> <span class="n">small_width</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>
    <span class="n">rect_likelihood</span> <span class="o">=</span> <span class="p">[</span><span class="n">left_space</span> <span class="p">,</span> <span class="n">bottom</span> <span class="o">+</span> <span class="n">height</span> <span class="o">+</span> <span class="n">padding</span> <span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>
    <span class="n">rect_posterior</span> <span class="o">=</span> <span class="p">[</span><span class="n">left_space</span> <span class="o">+</span> <span class="n">width</span> <span class="o">+</span> <span class="n">small_padding</span><span class="p">,</span> <span class="n">bottom</span> <span class="o">+</span> <span class="n">height</span> <span class="o">+</span> <span class="n">padding</span> <span class="p">,</span> <span class="n">small_width</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>

    <span class="n">rect_utility</span> <span class="o">=</span> <span class="p">[</span><span class="n">padding</span><span class="p">,</span> <span class="n">bottom</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>
    <span class="n">rect_expected</span> <span class="o">=</span> <span class="p">[</span><span class="n">padding</span> <span class="o">+</span> <span class="n">width</span> <span class="o">+</span> <span class="n">padding</span> <span class="o">+</span> <span class="n">left</span><span class="p">,</span> <span class="n">bottom</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">]</span>

    <span class="n">ax_likelihood</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_likelihood</span><span class="p">)</span>
    <span class="n">ax_prior</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_prior</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="n">ax_likelihood</span><span class="p">)</span>
    <span class="n">ax_posterior</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_posterior</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="n">ax_likelihood</span><span class="p">)</span>
    <span class="n">ax_utility</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_utility</span><span class="p">)</span>
    <span class="n">ax_expected</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">(</span><span class="n">rect_expected</span><span class="p">)</span>

    <span class="n">prior_colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span>
    <span class="n">posterior_colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Greens</span>
    <span class="n">expected_colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Wistia</span>

    <span class="c1"># Show posterior probs and marginals</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">prior</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">prior_colormap</span><span class="p">(</span><span class="n">prior</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">prior</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">prior_colormap</span><span class="p">(</span><span class="n">prior</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'Reds'</span><span class="p">)</span>
    <span class="n">ax_posterior</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">posterior</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">posterior_colormap</span><span class="p">(</span><span class="n">posterior</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">ax_posterior</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">posterior</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">posterior_colormap</span><span class="p">(</span><span class="n">posterior</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">ax_utility</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">utility</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'cool'</span><span class="p">)</span>
    <span class="c1"># ax_expected.matshow(expected, vmin=0., vmax=1., cmap='Wistia')</span>
    <span class="n">ax_expected</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">expected</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">expected_colormap</span><span class="p">(</span><span class="n">expected</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">ax_expected</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">expected</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">facecolor</span> <span class="o">=</span> <span class="n">expected_colormap</span><span class="p">(</span><span class="n">expected</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1"># Probabilities plot details</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">yticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">yticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span>
                 <span class="n">title</span> <span class="o">=</span> <span class="s2">"Prior p(s)"</span><span class="p">,</span> <span class="n">xticks</span> <span class="o">=</span> <span class="p">[])</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">tick_right</span><span class="p">()</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'left'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax_prior</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'bottom'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Likelihood plot details</span>
    <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">xticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'fish'</span><span class="p">,</span> <span class="s1">'no fish'</span><span class="p">],</span>
                  <span class="n">yticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">yticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span>
                   <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">'state (s)'</span><span class="p">,</span> <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">'measurement (m)'</span><span class="p">,</span>
                   <span class="n">title</span> <span class="o">=</span> <span class="s1">'Likelihood p(m | s)'</span><span class="p">)</span>
    <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_ticks_position</span><span class="p">(</span><span class="s1">'bottom'</span><span class="p">)</span>
    <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'left'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'bottom'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Posterior plot details</span>
    <span class="n">ax_posterior</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">xticks</span> <span class="o">=</span> <span class="p">[],</span> <span class="n">yticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                     <span class="n">yticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span> <span class="n">title</span> <span class="o">=</span> <span class="s2">"Posterior p(s | m)"</span><span class="p">)</span>
    <span class="n">ax_posterior</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'left'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax_posterior</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'bottom'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Utility plot details</span>
    <span class="n">ax_utility</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">xticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span>
                   <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">'action (a)'</span><span class="p">,</span> <span class="n">yticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">yticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span>
                   <span class="n">title</span> <span class="o">=</span> <span class="s1">'Utility'</span><span class="p">,</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">'state (s)'</span><span class="p">)</span>
    <span class="n">ax_utility</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_ticks_position</span><span class="p">(</span><span class="s1">'bottom'</span><span class="p">)</span>
    <span class="n">ax_utility</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'left'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax_utility</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'bottom'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Expected Utility plot details</span>
    <span class="n">ax_expected</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylim</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">xticks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">xticklabels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'left'</span><span class="p">,</span> <span class="s1">'right'</span><span class="p">],</span>
                 <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">'action (a)'</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s1">'Expected utility'</span><span class="p">,</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
    <span class="c1"># ax_expected.axis('off')</span>
    <span class="n">ax_expected</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'left'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># ax_expected.set(xticks = [0, 1], xticklabels = ['left', 'right'],</span>
    <span class="c1">#                 xlabel = 'action (a)',</span>
    <span class="c1">#                title = 'Expected utility')</span>
    <span class="c1"># ax_expected.xaxis.set_ticks_position('bottom')</span>
    <span class="c1"># ax_expected.spines['left'].set_visible(False)</span>
    <span class="c1"># ax_expected.spines['bottom'].set_visible(False)</span>

    <span class="c1"># show values</span>
    <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span><span class="n">ind</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ind</span><span class="p">:</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">posterior</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_posterior</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">v</span><span class="o">+</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">likelihood</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_likelihood</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">utility</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_utility</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="c1"># for i,j in zip(x.flatten(), y.flatten()):</span>
    <span class="c1">#     c = f"{expected[i,j]:.2f}"</span>
    <span class="c1">#     ax_expected.text(j,i, c, va='center', ha='center', color='black')</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ind</span><span class="p">:</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">prior</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_prior</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">v</span><span class="o">+</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ind</span><span class="p">:</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">expected</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">c</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">ax_expected</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'black'</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fig</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="helper-functions">
<h2>Helper Functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper Functions</span>

<span class="k">def</span> <span class="nf">compute_marginal</span><span class="p">(</span><span class="n">px</span><span class="p">,</span> <span class="n">py</span><span class="p">,</span> <span class="n">cor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">""" Calculate 2x2 joint probabilities given marginals p(x=1), p(y=1) and correlation</span>

<span class="sd">      Args:</span>
<span class="sd">        px (scalar): marginal probability of x</span>
<span class="sd">        py (scalar): marginal probability of y</span>
<span class="sd">        cor (scalar): correlation value</span>

<span class="sd">      Returns:</span>
<span class="sd">        ndarray of size (2, 2): joint probability array of x and y</span>
<span class="sd">    """</span>

    <span class="n">p11</span> <span class="o">=</span> <span class="n">px</span><span class="o">*</span><span class="n">py</span> <span class="o">+</span> <span class="n">cor</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">px</span><span class="o">*</span><span class="n">py</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">px</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">py</span><span class="p">))</span>
    <span class="n">p01</span> <span class="o">=</span> <span class="n">px</span> <span class="o">-</span> <span class="n">p11</span>
    <span class="n">p10</span> <span class="o">=</span> <span class="n">py</span> <span class="o">-</span> <span class="n">p11</span>
    <span class="n">p00</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">p11</span> <span class="o">-</span> <span class="n">p01</span> <span class="o">-</span> <span class="n">p10</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="n">p00</span><span class="p">,</span> <span class="n">p01</span><span class="p">],</span> <span class="p">[</span><span class="n">p10</span><span class="p">,</span> <span class="n">p11</span><span class="p">]])</span>


<span class="k">def</span> <span class="nf">compute_cor_range</span><span class="p">(</span><span class="n">px</span><span class="p">,</span><span class="n">py</span><span class="p">):</span>
<span class="w">    </span><span class="sd">""" Calculate the allowed range of correlation values given marginals p(x=1)</span>
<span class="sd">      and p(y=1)</span>

<span class="sd">    Args:</span>
<span class="sd">      px (scalar): marginal probability of x</span>
<span class="sd">      py (scalar): marginal probability of y</span>

<span class="sd">    Returns:</span>
<span class="sd">      scalar, scalar: minimum and maximum possible values of correlation</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">p11</span><span class="p">(</span><span class="n">corr</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">px</span><span class="o">*</span><span class="n">py</span> <span class="o">+</span> <span class="n">corr</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">px</span><span class="o">*</span><span class="n">py</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">px</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">py</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">p01</span><span class="p">(</span><span class="n">corr</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">px</span> <span class="o">-</span> <span class="n">p11</span><span class="p">(</span><span class="n">corr</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">p10</span><span class="p">(</span><span class="n">corr</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">py</span> <span class="o">-</span> <span class="n">p11</span><span class="p">(</span><span class="n">corr</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">p00</span><span class="p">(</span><span class="n">corr</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">p11</span><span class="p">(</span><span class="n">corr</span><span class="p">)</span> <span class="o">-</span> <span class="n">p01</span><span class="p">(</span><span class="n">corr</span><span class="p">)</span> <span class="o">-</span> <span class="n">p10</span><span class="p">(</span><span class="n">corr</span><span class="p">)</span>
    <span class="n">Cmax</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">fsolve</span><span class="p">(</span><span class="n">p01</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span> <span class="n">fsolve</span><span class="p">(</span><span class="n">p10</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">))</span>
    <span class="n">Cmin</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">fsolve</span><span class="p">(</span><span class="n">p11</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span> <span class="n">fsolve</span><span class="p">(</span><span class="n">p00</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">Cmin</span><span class="p">,</span> <span class="n">Cmax</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-gone-fishin">
<h1>Section 1: Gone Fishin’<a class="headerlink" href="#section-1-gone-fishin" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-2-gone-fishin">
<h2>Video 2: Gone Fishin’<a class="headerlink" href="#video-2-gone-fishin" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>This video covers the example problem of fishing that we will cover in this tutorial.</p>
<details>
<summary> <font color="‘blue’">Click here for text recap of video </font></summary>
<p>You were just introduced to the <strong>binary hidden state problem</strong> we are going to explore. You need to decide which side to fish on–the hidden state. We know fish like to school together. On different days the school of fish is either on the left or right side, but we don’t know what the case is today. We define our knowledge about the fish location as a distribution over the random hidden state variable. Using our probabilistic knowledge, also called our <strong>belief</strong> about the hidden state, we will explore how to make the decision about where to fish today, based on what to expect in terms of gains or losses for the decision.
The gains and losss are defined by the utility of choosing an action, which is fishing on the left or right. The details of the utilities are described</p>
</details>
<p>In the next two sections we will consider just the probability of where the fish might be and what you gain or lose by choosing where to fish (leaving Bayesian approaches to the last few sections).</p>
<p>Remember, you can either think of yourself as a scientist conducting an experiment or as a brain trying to make a decision. The Bayesian approach is the same!</p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-deciding-where-to-fish">
<h1>Section 2: Deciding where to fish<a class="headerlink" href="#section-2-deciding-where-to-fish" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing to here from start of tutorial: 10 min</em></p>
<div class="section" id="video-3-utility">
<h2>Video 3: Utility<a class="headerlink" href="#video-3-utility" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>This video covers utility and expected utility.</p>
<details>
<summary> <font color="‘blue’">Click here for text recap of video </font></summary>
<p>You need to decide where to fish. It may seem obvious - you could just fish on the side where the probability of the fish being is higher! Unfortunately, decisions and actions are always a little more complicated. Deciding to fish may be influenced by more than just the probability of the school of fish being there as we saw by the potential issues of submarines and sunburn. The consequences of the action you take is based on the true (but hidden) state of the world and the action you choose! In our example, fishing on the wrong side, where there aren’t many fish, is likely to lead to you spending your afternoon not catching fish and therefore getting a sunburn. The submarine represents a risk to fishing on the right side that is greater than the left side. If you want to know what to expect from taking the action of fishing on one side or the other, you need to calculate the expected utility.</p>
<p>You know the (prior) probability that the school of fish is on the left side of the dock today, <span class="math notranslate nohighlight">\(P(s = \textrm{left})\)</span>. So, you also know the probability the school is on the right, <span class="math notranslate nohighlight">\(P(s = \textrm{right})\)</span>, because these two probabilities must add up to 1.</p>
<p>We quantify gains and losses numerically using a <strong>utility</strong> function <span class="math notranslate nohighlight">\(U(s,a)\)</span>, which describes the consequences of your actions: how much value you gain (or if negative, lose) given the state of the world (<span class="math notranslate nohighlight">\(s\)</span>) and the action you take (<span class="math notranslate nohighlight">\(a\)</span>). In our example, our utility can be summarized as:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Utility: U(s,a)</p></th>
<th class="head"><p>a = left</p></th>
<th class="head"><p>a = right</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>s = Left</p></td>
<td><p>+2</p></td>
<td><p>-3</p></td>
</tr>
<tr class="row-odd"><td><p>s = right</p></td>
<td><p>-2</p></td>
<td><p>+1</p></td>
</tr>
</tbody>
</table>
<p>To use possible gains and losses to choose an action, we calculate the <strong>expected utility</strong> of that action by weighing these utilities with the probability of that state occuring. This allows us to choose actions by taking probabilities of events into account: we don’t care if the outcome of an action-state pair is a loss if the probability of that state is very low. We can formalize this as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-44b906eb-4b33-418d-870c-a06afbb34959">
<span class="eqno">(349)<a class="headerlink" href="#equation-44b906eb-4b33-418d-870c-a06afbb34959" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\text{Expected utility of action a} = \sum_{s}U(s,a)P(s)
\end{equation}\]</div>
<p>In other words, the expected utility of an action a is the sum over possible states of the utility of that action and state times the probability of that state.</p>
</details></div>
<div class="section" id="interactive-demo-2-exploring-the-decision">
<h2>Interactive Demo 2: Exploring the decision<a class="headerlink" href="#interactive-demo-2-exploring-the-decision" title="Permalink to this headline">¶</a></h2>
<p>Let’s start to get a sense of how all this works using the interactive demo below. You can change the probability that the school of fish is on the left side,<span class="math notranslate nohighlight">\(p(s = \textrm{left})\)</span>, using the slider. You will see the utility function (a matrix) in the middle and the corresponding expected utility for each action on the right.</p>
<p>First, make sure you understand how the expected utility of each action is being computed from the probabilities and the utility values. In the initial state: the probability of the fish being on the left is 0.9 and on the right is 0.1. The expected utility of the action of fishing on the left is then <span class="math notranslate nohighlight">\(U(s = \textrm{left},a = \textrm{left})p(s = \textrm{left}) + U(s = \textrm{right},a = \textrm{left})p(s = \textrm{right}) = 2(0.9) + -2(0.1) = 1.6\)</span>. Essentially, to get the expected utility of action <span class="math notranslate nohighlight">\(a\)</span>, you are doing a weighted sum over the relevant column of the utility matrix (corresponding to action <span class="math notranslate nohighlight">\(a\)</span>) where the weights are the state probabilities.</p>
<p>For each of these scenarios, think and discuss first. Then use the demo to try out each and see if your action would have been correct (that is, if the expected value of that action is the highest).</p>
<ol class="simple">
<li><p>You just arrived at the dock for the first time and have no sense of where the fish might be. So you guess that the probability of the school being on the left side is 0.5 (so the probability on the right side is also 0.5). Which side would you choose to fish on given our utility values?</p></li>
<li><p>You think that the probability of the school being on the left side is very low (0.1) and correspondingly high on the right side (0.9). Which side would you choose to fish on given our utility values?</p></li>
<li><p>What would you choose if the probability of the school being on the left side is slightly lower than on the right side (0. 4 vs 0.6)?</p></li>
</ol>
<p>Execute this cell to use the widget</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to use the widget</span>
<span class="n">ps_widget</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'p(s = left)'</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">ps_widget</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">make_utility_plot</span><span class="p">(</span><span class="n">ps</span><span class="p">):</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plot_utility</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">None</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove explanation</span>

<span class="sd">"""</span>

<span class="sd">1)  With equal probabilities, the expected utility is higher on the left side,</span>
<span class="sd">   since that is the side without submarines, so you would choose to fish there.</span>

<span class="sd">2)  If the probability that the fish is on the right side is high, you would</span>
<span class="sd">    choose to fish there. The high probability of fish being on the right far outweighs</span>
<span class="sd">   the slightly higher utilities from fishing on the left (as you are unlikely to gain these)</span>

<span class="sd">3)  If the probability that the fish is on the right side is just slightly higher</span>
<span class="sd">    than on the left, you would choose the left side as the expected utility is still</span>
<span class="sd">    higher on the left. Note that in this situation, you are not simply choosing the</span>
<span class="sd">    side with the higher probability - the utility really matters here for the decision</span>

<span class="sd">"""</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="video-4-utility-demo-discussion">
<h3>Video 4: Utility Demo Discussion<a class="headerlink" href="#video-4-utility-demo-discussion" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
<p>In this section, you have seen that both the utility of various state and action pairs and our knowledge of the probability of each state affects your decision. Importantly, we want our knowledge of the probability of each state to be as accurate as possible!</p>
<p>So how do we know these probabilities? We may have prior knowledge from years of fishing at the same dock, learning that the fish are more likely to be on the left side, for example. Of course, we need to update our knowledge (our belief)! To do this, we need to collect more information, or take some measurements! In the next few sections, we will focus on how we improve our knowledge of the probabilities.</p>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-3-likelihood-of-the-fish-being-on-either-side">
<h1>Section 3: Likelihood of the fish being on either side<a class="headerlink" href="#section-3-likelihood-of-the-fish-being-on-either-side" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing to here from start of tutorial: 25 min</em></p>
<div class="section" id="video-5-likelihood">
<h2>Video 5: Likelihood<a class="headerlink" href="#video-5-likelihood" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<details>
<summary> <font color="‘blue’">Click here for text recap of video </font></summary>
<p>First, we’ll think about what it means to take a measurement (also often called an observation or just data) and what it tells you about what the hidden state may be. Specifically, we’ll be looking at the <strong>likelihood</strong>, which is the probability of your measurement (<span class="math notranslate nohighlight">\(m\)</span>) given the hidden state (<span class="math notranslate nohighlight">\(s\)</span>): <span class="math notranslate nohighlight">\(P(m | s)\)</span>. Remember that in this case, the hidden state is which side of the dock the school of fish is on.
We will watch someone fish (for let’s say 10 minutes) and our measurement is whether they catch a fish or not. We know something about what catching a fish means for the likelihood of the fish being on one side or the other.</p>
</details></div>
<div class="section" id="think-3-guessing-the-location-of-the-fish">
<h2>Think! 3: Guessing the location of the fish<a class="headerlink" href="#think-3-guessing-the-location-of-the-fish" title="Permalink to this headline">¶</a></h2>
<p>Let’s say we go to a different dock to fish. Here, there are different probabilities of catching fish given the state of the world. At this dock, if you fish on the side of the dock where the fish are, you have a 70% chance of catching a fish. If you fish on the wrong side, you will catch a fish with only 20% probability. These are the likelihoods of observing someone catching a fish! That is, you are taking a measurement by seeing if someone else catches a fish!</p>
<p>You see a fisher-person is fishing on the left side.</p>
<ol class="simple">
<li><p>Please figure out each of the following (might be easiest to do this separately and then compare notes):</p></li>
</ol>
<ul class="simple">
<li><p>probability of catching a fish given that the school of fish is on the left side, <span class="math notranslate nohighlight">\(P(m = \textrm{catch fish} | s = \textrm{left} )\)</span></p></li>
<li><p>probability of not catching a fish given that the school of fish is on the left side, <span class="math notranslate nohighlight">\(P(m = \textrm{no fish} | s = \textrm{left})\)</span></p></li>
<li><p>probability of catching a fish given that the school of fish is on the right side, <span class="math notranslate nohighlight">\(P(m = \textrm{catch  fish} | s = \textrm{right})\)</span></p></li>
<li><p>probability of not catching a fish given that the school of fish is on the right side, <span class="math notranslate nohighlight">\(P(m = \textrm{no fish} | s = \textrm{right})\)</span></p></li>
</ul>
<ol class="simple">
<li><p>If the fisher-person catches a fish, which side would you guess the school is on? Why?</p></li>
<li><p>If the fisher-person does not catch a fish, which side would you guess the school is on? Why?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove explanation</span>

<span class="sd">"""</span>
<span class="sd">1) The fisher-person is on the left side so:</span>
<span class="sd">      - P(m = fish | s = left) = 0.7 because they have a 70% chance of catching</span>
<span class="sd">        a fish when on the same side as the school</span>
<span class="sd">      - P(m = no fish | s = left) = 0.3 because the probability of catching a fish</span>
<span class="sd">        and not catching a fish for a given state must add up to 1 as these</span>
<span class="sd">        are the only options: 1 - 0.7 = 0.3</span>
<span class="sd">      - P(m = fish | s = right) = 0.2</span>
<span class="sd">      - P(m = no fish | s = right) = 0.8</span>

<span class="sd">2) If the fisher-person catches a fish, you would guess the school of fish is on the</span>
<span class="sd">    left side. This is because the probability of catching a fish given that the</span>
<span class="sd">   school is on the left side (0.7) is higher than the probability given that</span>
<span class="sd">   the school is on the right side (0.2).</span>

<span class="sd">3) If the fisher-person does not catch a fish, you would guess the school of fish is on the</span>
<span class="sd">    right side. This is because the probability of not catching a fish given that the</span>
<span class="sd">   school is on the right side (0.8) is higher than the probability given that</span>
<span class="sd">   the school is on the left side (0.3).</span>
<span class="sd">"""</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
<p>In the prior exercise, you tried to guess where the school of fish was based on the measurement you took (watching someone fish). You did this by choosing the state (side where you think the fish are) that maximized the probability of the measurement. In other words, you estimated the state by maximizing the likelihood (the side with the highest probability of measurement given state <span class="math notranslate nohighlight">\(P(m|s\)</span>)). This is called maximum likelihood estimation (MLE) and you’ve encountered it before during this course, in the <a class="reference external" href="https://compneuro.neuromatch.io/tutorials/W0D5_Statistics/student/W0D5_Tutorial2.html#section-2-2-maximum-likelihood">pre-reqs statistics day</a> and on <a class="reference external" href="https://compneuro.neuromatch.io/tutorials/W1D3_ModelFitting/student/W1D3_Tutorial2.html">Model Fitting day</a>!</p>
<p>But, what if you had been going to this dock for years and you knew that the fish were almost always on the left side? This should probably affect how you make your estimate – you would rely less on the single new measurement and more on your prior knowledge. This is the fundamental idea behind Bayesian inference, as we will see later in this tutorial!</p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-4-correlation-and-marginalization">
<h1>Section 4: Correlation and marginalization<a class="headerlink" href="#section-4-correlation-and-marginalization" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing to here from start of tutorial: 35 min</em></p>
<div class="section" id="video-6-correlation-and-marginalization">
<h2>Video 6: Correlation and marginalization<a class="headerlink" href="#video-6-correlation-and-marginalization" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</div>
<div class="section" id="section-4-1-correlation">
<h2>Section 4.1: Correlation<a class="headerlink" href="#section-4-1-correlation" title="Permalink to this headline">¶</a></h2>
<p>In this section, we are going to take a step back for a bit and think more generally about the amount of information shared between two random variables. We want to know how much information you gain when you observe one variable (take a measurement) if you know something about another. We will see that the fundamental concept is the same if we think about two attributes, for example the size and color of the fish, or the prior information and the likelihood.</p>
<div class="section" id="think-4-1-covarying-probability-distributions">
<h3>Think! 4.1: Covarying probability distributions<a class="headerlink" href="#think-4-1-covarying-probability-distributions" title="Permalink to this headline">¶</a></h3>
<p>The relationship between the marginal probabilities and the joint probabilities is determined by the correlation between the two random variables - a normalized measure of how much the variables covary. We can also think of this as gaining some information about one of the variables when we observe a measurement from the other. We will think about this more formally in Tutorial 2.</p>
<p>Here, we want to think about how the correlation between size and color of these fish changes how much information we gain about one attribute based on the other. See Bonus Section 1 for the formula for correlation.</p>
<p>Use the widget below and answer the following questions:</p>
<ol class="simple">
<li><p>When the correlation is zero, <span class="math notranslate nohighlight">\(\rho = 0\)</span>, what does the distribution of size tell you about color?</p></li>
<li><p>Set <span class="math notranslate nohighlight">\(\rho\)</span> to something small. As you change the probability of golden fish, what happens to the ratio of size probabilities? Set <span class="math notranslate nohighlight">\(\rho\)</span> larger (can be negative). Can you explain the pattern of changes in the probabilities of size as you change the probability of golden fish?</p></li>
<li><p>Set the probability of golden fish and of large fish to around 65%. As the correlation goes towards 1, how often will you see silver large fish?</p></li>
<li><p>What is increasing the (absolute) correlation telling you about how likely you are to see one of the properties if you see a fish with the other?</p></li>
</ol>
<p>Execute this cell to enable the widget</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to enable the widget</span>
<span class="n">style</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'description_width'</span><span class="p">:</span> <span class="s1">'initial'</span><span class="p">}</span>
<span class="n">gs</span> <span class="o">=</span> <span class="n">GridspecLayout</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

<span class="n">cor_widget</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'ρ'</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">px_widget</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'p(color=golden)'</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">)</span>
<span class="n">py_widget</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'p(size=large)'</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">)</span>
<span class="n">gs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">cor_widget</span>
<span class="n">gs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">px_widget</span>
<span class="n">gs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">py_widget</span>


<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span>
    <span class="n">px</span><span class="o">=</span><span class="n">px_widget</span><span class="p">,</span>
    <span class="n">py</span><span class="o">=</span><span class="n">py_widget</span><span class="p">,</span>
    <span class="n">cor</span><span class="o">=</span><span class="n">cor_widget</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">make_corr_plot</span><span class="p">(</span><span class="n">px</span><span class="p">,</span> <span class="n">py</span><span class="p">,</span> <span class="n">cor</span><span class="p">):</span>
    <span class="n">Cmin</span><span class="p">,</span> <span class="n">Cmax</span> <span class="o">=</span> <span class="n">compute_cor_range</span><span class="p">(</span><span class="n">px</span><span class="p">,</span> <span class="n">py</span><span class="p">)</span> <span class="c1">#allow correlation values</span>
    <span class="n">cor_widget</span><span class="o">.</span><span class="n">min</span><span class="p">,</span> <span class="n">cor_widget</span><span class="o">.</span><span class="n">max</span> <span class="o">=</span> <span class="n">Cmin</span><span class="o">+</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">Cmax</span><span class="o">-</span><span class="mf">0.01</span>
    <span class="k">if</span> <span class="n">cor_widget</span><span class="o">.</span><span class="n">value</span> <span class="o">&gt;</span> <span class="n">Cmax</span><span class="p">:</span>
        <span class="n">cor_widget</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">Cmax</span>
    <span class="k">if</span> <span class="n">cor_widget</span><span class="o">.</span><span class="n">value</span> <span class="o">&lt;</span> <span class="n">Cmin</span><span class="p">:</span>
        <span class="n">cor_widget</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">Cmin</span>
    <span class="n">cor</span> <span class="o">=</span> <span class="n">cor_widget</span><span class="o">.</span><span class="n">value</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">compute_marginal</span><span class="p">(</span><span class="n">px</span><span class="p">,</span><span class="n">py</span><span class="p">,</span><span class="n">cor</span><span class="p">)</span>
    <span class="c1"># print(P)</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plot_joint_probs</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">None</span>

<span class="c1"># gs[1,1] = make_corr_plot()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove explanation</span>

<span class="sd">"""</span>
<span class="sd">1. When the correlation is zero, the two properties are completely independent.</span>
<span class="sd">   This means you don't gain any information about one variable from observing the other.</span>
<span class="sd">   Importantly, the marginal distribution of one variable is therefore independent of the other.</span>

<span class="sd">2. The correlation controls the distribution of probability across the joint probability table.</span>
<span class="sd">   The higher the correlation, the more the probabilities are restricted by the fact that both rows</span>
<span class="sd">   and columns need to sum to one! While the marginal probabilities show the relative weighting, the</span>
<span class="sd">   absolute probabilities for one quality will become more dependent on the other as the correlation</span>
<span class="sd">   goes to 1 or -1.</span>

<span class="sd">3. The correlation will control how much probability mass is located on the diagonals. As the</span>
<span class="sd">   correlation goes to 1 (or -1), the probability of seeing the one of the two pairings has to goes</span>
<span class="sd">   towards zero!</span>

<span class="sd">4. If we think about what information we gain by observing one quality, the intuition from (3.) tells</span>
<span class="sd">   us that we know more (have more information) about the other quality as a function of the correlation.</span>
<span class="sd">"""</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
<p>We have just seen how two random variables can be more or less independent. The more correlated, the less independent, and the more shared information. We also learned that we can marginalize to determine the marginal likelihood of a measurement or to find the marginal probability distribution of two random variables. We are going to now complete our journey towards being fully Bayesian!</p>
</div>
</div>
<div class="section" id="section-4-2-marginalisation">
<h2>Section 4.2: Marginalisation<a class="headerlink" href="#section-4-2-marginalisation" title="Permalink to this headline">¶</a></h2>
<details>
<summary> <font color="‘blue’">Click here for text recap of relevant part of video </font></summary>
<p>We may want to find the probability of one variable while ignoring another: we will do this by averaging out, or marginalizing, the irrelevant variable.</p>
<p>We will think of this in two different ways.</p>
<p>In the first math exercise, you will think about the case where you know the joint probabilities of two variables and want to figure out the probability of just one variable. To make this explicit, let’s assume that a fish has a color that is either gold or silver (our first variable) and a size that is either small or large (our second). We could write out the the <strong>joint probabilities</strong>: the probability of both specific attributes occuring together. For example, the probability of a fish being small and silver, <span class="math notranslate nohighlight">\(P(X = \textrm{small}, Y = \textrm{silver})\)</span>, is 0.4. The following table summarizes our joint probabilities:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>P(X, Y)</p></th>
<th class="head"><p>Y = silver</p></th>
<th class="head"><p>Y = gold</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>X = small</p></td>
<td><p>0.4</p></td>
<td><p>0.2</p></td>
</tr>
<tr class="row-odd"><td><p>X = large</p></td>
<td><p>0.1</p></td>
<td><p>0.3</p></td>
</tr>
</tbody>
</table>
<p>We want to know what the probability of a fish being small  regardless of color. Since the fish are either silver or gold, this would be the probability of a fish being small and silver plus the probability of a fish being small and gold. This is an example of marginalizing, or averaging out, the variable we are not interested in across the rows or columns.. In math speak: <span class="math notranslate nohighlight">\(P(X = \textrm{small}) = \sum_y{P(X = \textrm{small}, Y)}\)</span>. This gives us a <strong>marginal probability</strong>, a probability of a variable outcome (in this case size), regardless of the other variables (in this case color).</p>
<p>More generally, we can marginalize out a second irrelevant variable <span class="math notranslate nohighlight">\(y\)</span> by summing over the relevant joint probabilities:</p>
<div class="math notranslate nohighlight">
\[p(x) = \sum_y p(x, y) \]</div>
<p>In the second math exercise, you will remove an unknown (the hidden state) to find the marginal probability of a measurement. You will do this by marginalizing out the hidden state. In this case, you know the conditional probabilities of the measurement given state and the probabilities of each state. You can marginalize using:</p>
<div class="math notranslate nohighlight">
\[p(m) = \sum_s p(m | s) p(s) \]</div>
<p>These two ways of thinking about marginalization (as averaging over joint probabilities or conditioning on some variable) are equivalent because the joint probability of two variables equals the conditional probability of the first given the second times the marginal probability of the second:</p>
<div class="math notranslate nohighlight">
\[p(x, y) = p(x|y)p(y)\]</div>
<div class="section" id="math-exercise-4-2-1-computing-marginal-probabilities">
<h3>Math Exercise 4.2.1: Computing marginal probabilities<a class="headerlink" href="#math-exercise-4-2-1-computing-marginal-probabilities" title="Permalink to this headline">¶</a></h3>
<p>To understand the information between two variables, let’s first consider the joint probabilities over the size and color of the fish.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>P(X, Y)</p></th>
<th class="head"><p>Y = silver</p></th>
<th class="head"><p>Y = gold</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>X = small</p></td>
<td><p>0.4</p></td>
<td><p>0.2</p></td>
</tr>
<tr class="row-odd"><td><p>X = large</p></td>
<td><p>0.1</p></td>
<td><p>0.3</p></td>
</tr>
</tbody>
</table>
<p>Please complete the following math problems to further practice thinking through probabilities:</p>
<ol class="simple">
<li><p>Calculate the probability of a fish being silver.</p></li>
<li><p>Calculate the probability of a fish being small, large, silver, or gold.</p></li>
<li><p>Calculate the probability of a fish being small OR gold. <strong>Hint:</strong> <span class="math notranslate nohighlight">\(P(A\ \textrm{or}\ B) = P(A) + P(B) - P(A\ \textrm{and}\ B)\)</span>.</p></li>
</ol>
<p><strong>We don’t typically have math exercises in NMA but feel it is important for you to really compute this out yourself. Feel free to use the next cell to write out the math if helpful, or use paper and pen. We recommend doing this exercise individually first and then comparing notes and discussing.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">"""</span>
<span class="sd">Joint probabilities</span>

<span class="sd">P( X = small, Y = silver) = 0.4</span>
<span class="sd">P( X = large, Y = silver) = 0.1</span>
<span class="sd">P( X = small, Y = gold) = 0.2</span>
<span class="sd">P( X = large, Y = gold) = 0.3</span>


<span class="sd">1. P(Y = silver) = ...</span>

<span class="sd">2. P(X = small or large, Y = silver or gold) = ...</span>

<span class="sd">3. P( X = small or Y = gold) = ...</span>

<span class="sd">"""</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove explanation</span>

<span class="sd">"""</span>
<span class="sd">1. The probability of a fish being silver is the joint probability of it being</span>
<span class="sd">     small and silver plus the joint probability of it being large and silver:</span>

<span class="sd">    P(Y = silver) = P(X = small, Y = silver) + P(X = large, Y = silver)</span>
<span class="sd">                  = 0.4 + 0.1</span>
<span class="sd">                  = 0.5</span>


<span class="sd">2. This is all the possibilities as in this scenario, our fish can only be small</span>
<span class="sd">   or large, silver or gold. So the probability is 1 - the fish has to be at</span>
<span class="sd">   least one of these.</span>


<span class="sd">3. First we compute the marginal probabilities</span>
<span class="sd">   P(X = small) = P(X = small, Y = silver) + P(X = small, Y = gold) = 0.6</span>
<span class="sd">   P(Y = gold) = P(X = small, Y = gold) + P(X = large, Y = gold) = 0.5</span>

<span class="sd">   We already know the joint probability: P(X = small, Y = gold) = 0.2</span>

<span class="sd">   We can now use the given formula:</span>
<span class="sd">   P( X = small or Y = gold) = P(X = small) + P(Y = gold) - P(X = small, Y = gold)</span>
<span class="sd">                             = 0.6 + 0.5 - 0.2</span>
<span class="sd">                             = 0.9</span>
<span class="sd">"""</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="math-exercise-4-2-2-computing-marginal-likelihood">
<h3>Math Exercise 4.2.2: Computing marginal likelihood<a class="headerlink" href="#math-exercise-4-2-2-computing-marginal-likelihood" title="Permalink to this headline">¶</a></h3>
<p>When we normalize to find the posterior, we need to determine the marginal likelihood–or evidence–for the measurement we observed. To do this, we need to marginalize as we just did above to find the probabilities of a color or size. Only, in this case, we are marginalizing to remove a conditioning variable! In this case, let’s consider the likelihood of fish (if we observed a fisher-person fishing on the <strong>right</strong>).</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>p(m|s)</p></th>
<th class="head"><p>m = fish</p></th>
<th class="head"><p>m = no fish</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>s = left</p></td>
<td><p>0.1</p></td>
<td><p>0.9</p></td>
</tr>
<tr class="row-odd"><td><p>s = right</p></td>
<td><p>0.5</p></td>
<td><p>0.5</p></td>
</tr>
</tbody>
</table>
<p>The table above shows us the <strong>likelihoods</strong>, just as we explored earlier.</p>
<p>You want to know the total probability of a fish being caught, <span class="math notranslate nohighlight">\(P(m = \textrm{fish})\)</span>, by the fisher-person fishing on the right. (You would need this to calculate the posterior.) To do this, you will need to consider the prior probability, <span class="math notranslate nohighlight">\(p(s)\)</span>, and marginalize over the hidden states!</p>
<p>This is an example of marginalizing, or conditioning away, the variable we are not interested in as well.</p>
<p>Please complete the following math problems to further practice thinking through probabilities:</p>
<ol class="simple">
<li><p>Calculate the marginal likelihood of the fish being caught, <span class="math notranslate nohighlight">\(P(m = \textrm{fish})\)</span>, if the priors are: <span class="math notranslate nohighlight">\(p(s = \textrm{left}) = 0.3\)</span> and <span class="math notranslate nohighlight">\(p(s = \textrm{right}) = 0.7\)</span>.</p></li>
<li><p>Calculate the marginal likelihood of the fish being caught,  <span class="math notranslate nohighlight">\(P(m = \textrm{fish})\)</span>, if the priors are: <span class="math notranslate nohighlight">\(p(s = \textrm{left}) = 0.6\)</span> and <span class="math notranslate nohighlight">\(p(s = \textrm{right}) = 0.4\)</span>.</p></li>
</ol>
<p><strong>We don’t typically have math exercises in NMA but feel it is important for you to really compute this out yourself. Feel free to use the next cell to write out the math if helpful, or use paper and pen. We recommend doing this exercise individually first and then comparing notes and discussing.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">"""</span>

<span class="sd">Priors</span>
<span class="sd">P(s = left) = 0.3</span>
<span class="sd">P(s = right) = 0.7</span>

<span class="sd">Likelihoods</span>
<span class="sd">P(m = fish | s = left) = 0.1</span>
<span class="sd">P(m = fish | s = right) = 0.5</span>
<span class="sd">P(m = no fish | s = left) = 0.9</span>
<span class="sd">P(m = no fish | s = right) = 0.5</span>

<span class="sd">1. P(m = fish) = ...</span>

<span class="sd">2. P(m = fish) = ...</span>

<span class="sd">"""</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove explanation</span>

<span class="sd">"""</span>

<span class="sd">1. The marginal likelihood (evidence) is</span>

<span class="sd">    P(m = fish) = P(m = fish, s = left) + P(m = fish, s = right)</span>
<span class="sd">                = P(m = fish | s = left)P(s = left) + P(m = fish | s = right)P(s = right)</span>
<span class="sd">                = 0.1 * 0.3 + .5 * .7</span>
<span class="sd">            = 0.38</span>


<span class="sd">2. The marginal likelihood (evidence) is</span>

<span class="sd">    P(m = fish) = P(m = fish, s = left) + P(m = fish, s = right)</span>
<span class="sd">                = P(m = fish | s = left)P(s = left) + P(m = fish | s = right)P(s = right)</span>
<span class="sd">                = 0.1 * 0.6 + .5 * .4</span>
<span class="sd">                = 0.26</span>
<span class="sd">"""</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
</div>
</details></div>
</div>
<hr class="docutils"/>
<div class="section" id="section-5-bayes-rule-and-the-posterior">
<h1>Section 5: Bayes’ Rule and the Posterior<a class="headerlink" href="#section-5-bayes-rule-and-the-posterior" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing to here from start of tutorial: 55 min</em></p>
<div class="section" id="video-7-posterior-beliefs">
<h2>Video 7: Posterior Beliefs<a class="headerlink" href="#video-7-posterior-beliefs" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>Marginalization is going to be used to combine our prior knowledge, which we call the <strong>prior</strong>, and our new information from a measurement, the <strong>likelihood</strong>. Only in this case, the information we gain about the hidden state we are interested in, where the fish are, is based on the relationship between the probabilities of the measurement and our prior.</p>
<p>We can now calculate the full posterior distribution for the hidden state (<span class="math notranslate nohighlight">\(s\)</span>) using Bayes’ Rule. As we’ve seen, the posterior is proportional to the prior times the likelihood. This means that the posterior probability of the hidden state (<span class="math notranslate nohighlight">\(s\)</span>) given a measurement (<span class="math notranslate nohighlight">\(m\)</span>) is proportional to the likelihood of the measurement given the state times the prior probability of that state:</p>
<div class="amsmath math notranslate nohighlight" id="equation-ddddf0b2-8e02-4911-9e21-c5f397f583d5">
<span class="eqno">(350)<a class="headerlink" href="#equation-ddddf0b2-8e02-4911-9e21-c5f397f583d5" title="Permalink to this equation">¶</a></span>\[\begin{equation}
P(s | m) \propto P(m | s) P(s)
\end{equation}\]</div>
<p>We say proportional to instead of equal because we need to normalize to produce a full probability distribution:</p>
<div class="amsmath math notranslate nohighlight" id="equation-16ccf810-e40d-430f-a60c-3ecaa6189cab">
<span class="eqno">(351)<a class="headerlink" href="#equation-16ccf810-e40d-430f-a60c-3ecaa6189cab" title="Permalink to this equation">¶</a></span>\[\begin{equation}
P(s | m) = \frac{P(m | s) P(s)}{P(m)}
\end{equation}\]</div>
<p>Normalizing by this <span class="math notranslate nohighlight">\(P(m)\)</span> means that our posterior is a complete probability distribution that sums or integrates to 1 appropriately. We now can use this new, complete probability distribution for any future inference or decisions we like! In fact, as we will see tomorrow, we can use it as a new prior! Finally, we often call this probability distribution our beliefs over the hidden states, to emphasize that it is our subjective knowledge about the hidden state.</p>
<p>For many complicated cases, like those we might be using to model behavioral or brain inferences, the normalization term can be intractable or extremely complex to calculate. We can be careful to choose probability distributions whfere we can analytically calculate the posterior probability or numerical approximation is reliable. Better yet, we sometimes don’t need to bother with this normalization! The normalization term, <span class="math notranslate nohighlight">\(P(m)\)</span>, is the probability of the measurement. This does not depend on state so is essentially a constant we can often ignore. We can compare the unnormalized posterior distribution values for different states because how they relate to each other is unchanged when divided by the same constant. We will see how to do this to compare evidence for different hypotheses tomorrow. (It’s also used to compare the likelihood of models fit using maximum likelihood estimation)</p>
<p>In this relatively simple example, we can compute the marginal likelihood <span class="math notranslate nohighlight">\(P(m)\)</span> easily by using:</p>
<div class="amsmath math notranslate nohighlight" id="equation-9b7921c6-f667-4362-9c58-0f47e51158b4">
<span class="eqno">(352)<a class="headerlink" href="#equation-9b7921c6-f667-4362-9c58-0f47e51158b4" title="Permalink to this equation">¶</a></span>\[\begin{equation}
P(m) = \sum_s P(m | s) P(s)
\end{equation}\]</div>
<p>We can then normalize so that we deal with the full posterior distribution.</p>
</div>
<div class="section" id="math-exercise-5-calculating-a-posterior-probability">
<h2>Math Exercise 5: Calculating a posterior probability<a class="headerlink" href="#math-exercise-5-calculating-a-posterior-probability" title="Permalink to this headline">¶</a></h2>
<p>Our prior is <span class="math notranslate nohighlight">\(p(s = \textrm{left}) = 0.3\)</span> and <span class="math notranslate nohighlight">\(p(s = \textrm{right}) = 0.7\)</span>. In the video, we learned that the chance of catching a fish given they fish on the same side as the school was 50%. Otherwise, it was 10%. We observe a person fishing on the left side. Our likelihood is:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Likelihood: p(m | s)</p></th>
<th class="head"><p>m = fish</p></th>
<th class="head"><p>m = no fish</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>s = left</p></td>
<td><p>0.5</p></td>
<td><p>0.5</p></td>
</tr>
<tr class="row-odd"><td><p>s = right</p></td>
<td><p>0.1</p></td>
<td><p>0.9</p></td>
</tr>
</tbody>
</table>
<p>Calculate the posterior probability (on paper) that:</p>
<ol class="simple">
<li><p>The school is on the left if the fisher-person catches a fish: <span class="math notranslate nohighlight">\(p(s = \textrm{left} | m = \textrm{fish})\)</span> (hint: normalize by computing <span class="math notranslate nohighlight">\(p(m = \textrm{fish})\)</span>)</p></li>
<li><p>The school is on the right if the fisher-person does not catch a fish: <span class="math notranslate nohighlight">\(p(s = \textrm{right} | m = \textrm{no fish})\)</span></p></li>
</ol>
<p><strong>We don’t typically have math exercises in NMA but feel it is important for you to really compute this out yourself. Feel free to use the next cell to write out the math if helpful, or use paper and pen. We recommend doing this exercise individually first and then comparing notes and discussing.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">"""</span>
<span class="sd">Priors</span>
<span class="sd">p(s = left) = 0.3</span>
<span class="sd">p(s = right) = 0.7</span>

<span class="sd">Likelihoods</span>
<span class="sd">P(m = fish | s = left) = 0.5</span>
<span class="sd">P(m = fish | s = right) = 0.1</span>
<span class="sd">P(m = no fish | s = left) = 0.5</span>
<span class="sd">P(m = no fish | s = right) = 0.9</span>

<span class="sd">1. p( s = left | m = fish) = ...</span>

<span class="sd">2. p( s = right | m = no fish ) = ...</span>

<span class="sd">"""</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove explanation</span>

<span class="sd">"""</span>
<span class="sd">1. Using Bayes rule, we know that P(s = left | m = fish) = P(m = fish | s = left)P(s = left) / P(m = fish)</span>

<span class="sd">   Let's first compute P(m = fish):</span>
<span class="sd">   P(m = fish) =  P(m = fish | s = left)P(s = left) +  P(m = fish | s = right)P(s = right)</span>
<span class="sd">               = 0.5 * 0.3 + .1 * .7</span>
<span class="sd">               = 0.22</span>

<span class="sd">   Now we can plug in all parts of Bayes rule:</span>
<span class="sd">   P(s = left | m = fish) = P(m = fish | s = left)P(s = left) / P(m = fish)</span>
<span class="sd">                          = 0.5 * 0.3 / 0.22</span>
<span class="sd">                          = 0.68</span>

<span class="sd">2. Using Bayes rule, we know that P(s = right | m = no fish) = P(m = no fish | s = right)P(s = right) / P(m = no fish)</span>

<span class="sd">   Let's first compute P(m = no fish):</span>
<span class="sd">   P(m = no fish) = P(m = no fish | s = left)P(s = left) +  P(m = no fish | s = right)P(s = right)</span>
<span class="sd">                  = 0.5 * 0.3 + .9 * .7</span>
<span class="sd">                  = 0.78</span>

<span class="sd">   Now we can plug in all parts of Bayes rule:</span>
<span class="sd">   P(s = right | m = no fish) = P(m = no fish | s = right)P(s = right) / P(m = no fish)</span>
<span class="sd">                              = 0.9 * 0.7 / 0.78</span>
<span class="sd">                              = 0.81</span>
<span class="sd">"""</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="coding-exercise-5-computing-posteriors">
<h2>Coding Exercise 5: Computing Posteriors<a class="headerlink" href="#coding-exercise-5-computing-posteriors" title="Permalink to this headline">¶</a></h2>
<p>Let’s implement our above math to be able to compute posteriors for different priors and likelihoods.</p>
<p>As before, our prior is <span class="math notranslate nohighlight">\(p(s = \textrm{left}) = 0.3\)</span> and <span class="math notranslate nohighlight">\(p(s = \textrm{right}) = 0.7\)</span>. In the video, we learned that the chance of catching a fish given they fish on the same side as the school was 50%. Otherwise, it was 10%. We observe a person fishing on the left side. Our likelihood is:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Likelihood: p(m | s)</p></th>
<th class="head"><p>m = fish</p></th>
<th class="head"><p>m = no fish</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>s = left</p></td>
<td><p>0.5</p></td>
<td><p>0.5</p></td>
</tr>
<tr class="row-odd"><td><p>s = right</p></td>
<td><p>0.1</p></td>
<td><p>0.9</p></td>
</tr>
</tbody>
</table>
<p>We want our full posterior to take the same 2 by 2 form. Make sure the outputs match your math answers!</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_posterior</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">prior</span><span class="p">):</span>
<span class="w">  </span><span class="sd">""" Use Bayes' Rule to compute posterior from likelihood and prior</span>

<span class="sd">  Args:</span>
<span class="sd">    likelihood (ndarray): i x j array with likelihood probabilities where i is</span>
<span class="sd">                    number of state options, j is number of measurement options</span>
<span class="sd">    prior (ndarray): i x 1 array with prior probability of each state</span>

<span class="sd">  Returns:</span>
<span class="sd">    ndarray: i x j array with posterior probabilities where i is</span>
<span class="sd">            number of state options, j is number of measurement options</span>

<span class="sd">  """</span>

  <span class="c1">#################################################</span>
  <span class="c1">## TODO for students ##</span>
  <span class="c1"># Fill out function and remove</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: implement compute_posterior"</span><span class="p">)</span>
  <span class="c1">#################################################</span>

  <span class="c1"># Compute unnormalized posterior (likelihood times prior)</span>
  <span class="n">posterior</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># first row is s = left, second row is s = right</span>

  <span class="c1"># Compute p(m)</span>
  <span class="n">p_m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

  <span class="c1"># Normalize posterior (divide elements by p_m)</span>
  <span class="n">posterior</span> <span class="o">/=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">posterior</span>


<span class="c1"># Make prior</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># first row is s = left, second row is s = right</span>

<span class="c1"># Make likelihood</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]])</span> <span class="c1"># first row is s = left, second row is s = right</span>

<span class="c1"># Compute posterior</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">compute_posterior</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">prior</span><span class="p">)</span>

<span class="c1"># Visualize</span>
<span class="n">plot_prior_likelihood_posterior</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">posterior</span><span class="p">)</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>

<span class="k">def</span> <span class="nf">compute_posterior</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">prior</span><span class="p">):</span>
<span class="w">  </span><span class="sd">""" Use Bayes' Rule to compute posterior from likelihood and prior</span>

<span class="sd">  Args:</span>
<span class="sd">    likelihood (ndarray): i x j array with likelihood probabilities where i is</span>
<span class="sd">                    number of state options, j is number of measurement options</span>
<span class="sd">    prior (ndarray): i x 1 array with prior probability of each state</span>

<span class="sd">  Returns:</span>
<span class="sd">    ndarray: i x j array with posterior probabilities where i is</span>
<span class="sd">            number of state options, j is number of measurement options</span>

<span class="sd">  """</span>

  <span class="c1"># Compute unnormalized posterior (likelihood times prior)</span>
  <span class="n">posterior</span> <span class="o">=</span> <span class="n">likelihood</span> <span class="o">*</span> <span class="n">prior</span> <span class="c1"># first row is s = left, second row is s = right</span>

  <span class="c1"># Compute p(m)</span>
  <span class="n">p_m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

  <span class="c1"># Normalize posterior (divide elements by p_m)</span>
  <span class="n">posterior</span> <span class="o">/=</span> <span class="n">p_m</span>

  <span class="k">return</span> <span class="n">posterior</span>


<span class="c1"># Make prior</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># first row is s = left, second row is s = right</span>

<span class="c1"># Make likelihood</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]])</span> <span class="c1"># first row is s = left, second row is s = right</span>

<span class="c1"># Compute posterior</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">compute_posterior</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">prior</span><span class="p">)</span>

<span class="c1"># Visualize</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">plot_prior_likelihood_posterior</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">posterior</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="interactive-demo-5-what-affects-the-posterior">
<h2>Interactive Demo 5: What affects the posterior?<a class="headerlink" href="#interactive-demo-5-what-affects-the-posterior" title="Permalink to this headline">¶</a></h2>
<p>Now that we can understand the implementation of <em>Bayes rule</em>, let’s vary the parameters of the prior and likelihood to see how changing the prior and likelihood affect the posterior.</p>
<p>In the demo below, you can change the prior by playing with the slider for <span class="math notranslate nohighlight">\(p( s = left)\)</span>. You can also change the likelihood by changing the probability of catching a fish given that the school is on the left and the probability of catching a fish given that the school is on the right. The fisher-person you are observing is fishing on the left.</p>
<ol class="simple">
<li><p>Keeping the likelihood constant, when does the prior have the strongest influence over the posterior? Meaning, when does the posterior look most like the prior no matter whether a fish was caught or not?</p></li>
<li><p>What happens if the likelihoods for catching a fish are similar when you fish on the correct or incorrect side?</p></li>
<li><p>Set the prior probability of the state = left to 0.6 and play with the likelihood. When does the likelihood exert the most influence over the posterior?</p></li>
</ol>
<p>Execute this cell to enable the widget</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to enable the widget</span>
<span class="c1"># style = {'description_width': 'initial'}</span>
<span class="n">ps_widget</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'p(s = left)'</span><span class="p">,</span>
                                <span class="nb">min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">p_a_s1_widget</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'p(fish on left | state = left)'</span><span class="p">,</span>
                                    <span class="nb">min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">Layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s1">'370px'</span><span class="p">))</span>
<span class="n">p_a_s0_widget</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'p(fish on left | state = right)'</span><span class="p">,</span>
                                    <span class="nb">min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">Layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s1">'370px'</span><span class="p">))</span>
<span class="c1"># observed_widget = widgets.Checkbox(value=False, description='Observed fish (m)',</span>
<span class="c1">#                                  disabled=False, indent=False,</span>
<span class="c1">#                                  layout=Layout(display="flex", justify_content="center"))</span>

<span class="n">observed_widget</span> <span class="o">=</span> <span class="n">ToggleButtons</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="s1">'Fish'</span><span class="p">,</span> <span class="s1">'No Fish'</span><span class="p">],</span>
    <span class="n">description</span><span class="o">=</span><span class="s1">'Observation (m) on the left:'</span><span class="p">,</span> <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">button_style</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span>
    <span class="n">layout</span><span class="o">=</span><span class="n">Layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s1">'auto'</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="s2">"flex"</span><span class="p">),</span>
    <span class="n">style</span><span class="o">=</span><span class="p">{</span><span class="s1">'description_width'</span><span class="p">:</span> <span class="s1">'initial'</span><span class="p">}</span>
<span class="p">)</span>

<span class="n">widget_ui</span> <span class="o">=</span> <span class="n">VBox</span><span class="p">([</span><span class="n">ps_widget</span><span class="p">,</span>
                  <span class="n">HBox</span><span class="p">([</span><span class="n">p_a_s1_widget</span><span class="p">,</span> <span class="n">p_a_s0_widget</span><span class="p">]),</span>
                  <span class="n">observed_widget</span><span class="p">])</span>
<span class="n">widget_out</span> <span class="o">=</span> <span class="n">interactive_output</span><span class="p">(</span><span class="n">plot_prior_likelihood</span><span class="p">,</span>
                                <span class="p">{</span><span class="s1">'ps'</span><span class="p">:</span> <span class="n">ps_widget</span><span class="p">,</span>
                                <span class="s1">'p_a_s1'</span><span class="p">:</span> <span class="n">p_a_s1_widget</span><span class="p">,</span>
                                <span class="s1">'p_a_s0'</span><span class="p">:</span> <span class="n">p_a_s0_widget</span><span class="p">,</span>
                                <span class="s1">'measurement'</span><span class="p">:</span> <span class="n">observed_widget</span><span class="p">})</span>
<span class="n">display</span><span class="p">(</span><span class="n">widget_ui</span><span class="p">,</span> <span class="n">widget_out</span><span class="p">)</span>

<span class="c1"># @widgets.interact(</span>
<span class="c1">#     ps=ps_widget,</span>
<span class="c1">#     p_a_s1=p_a_s1_widget,</span>
<span class="c1">#     p_a_s0=p_a_s0_widget,</span>
<span class="c1">#     m_right=observed_widget</span>
<span class="c1"># )</span>
<span class="c1"># def make_prior_likelihood_plot(ps,p_a_s1,p_a_s0,m_right):</span>
<span class="c1">#     fig = plot_prior_likelihood(ps,p_a_s1,p_a_s0,m_right)</span>
<span class="c1">#     plt.show(fig)</span>
<span class="c1">#     plt.close(fig)</span>
<span class="c1">#     return None</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove explanation</span>

<span class="sd">"""</span>
<span class="sd">1)  The prior exerts a strong influence over the posterior when it is very informative: when</span>
<span class="sd">    the probability of the school being on one side or the other. If the prior that the fish are</span>
<span class="sd">    on the left side is very high (like 0.9), the posterior probability of the state being left is</span>
<span class="sd">    high regardless of the measurement.</span>

<span class="sd">2)  When the likelihoods are similar, the information gained from catching a fish or not is less informative.</span>
<span class="sd">    Intuitively, if you were about as likely to catch a fish regardless of the true location, then catching a fish</span>
<span class="sd">    doesn't tell you very much! The differences between the likelihoods is a way of thinking about how much information</span>
<span class="sd">    we can gain. You can try to figure out why, as we've given you all the clues...</span>

<span class="sd">3)  Similarly to the prior, the likelihood exerts the most influence when it is informative: when catching</span>
<span class="sd">    a fish tells you a lot of information about which state is likely. For example, if the probability of the</span>
<span class="sd">    fisher-person catching a fish if he is fishing on the right side and the school is on the left is 0</span>
<span class="sd">    (p fish | s = left) = 0 and the probability of catching a fish if the school is on the right is 1, the</span>
<span class="sd">     prior does not affect the posterior at all. The measurement tells you the hidden state completely.</span>
<span class="sd">"""</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="video-8-posterior-beliefs-exercises-discussion">
<h3>Video 8: Posterior Beliefs Exercises Discussion<a class="headerlink" href="#video-8-posterior-beliefs-exercises-discussion" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
</div>
<div class="section" id="section-6-making-bayesian-fishing-decisions">
<h1>Section 6: Making Bayesian fishing decisions<a class="headerlink" href="#section-6-making-bayesian-fishing-decisions" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing to here from start of tutorial: 1 hr, 15 min</em></p>
<div class="section" id="video-9-bayesian-decisions">
<h2>Video 9: Bayesian Decisions<a class="headerlink" href="#video-9-bayesian-decisions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>We will explore how to consider the expected utility of an action based on our belief (the posterior distribution) about where we think the fish are. Now we have all the components of a Bayesian decision: our prior information, the likelihood given a measurement, the posterior distribution (belief) and our utility (the gains and losses). This allows us to consider the relationship between the true value of the hidden state, <span class="math notranslate nohighlight">\(s\)</span>, and what we <em>expect</em> to get if we take action, <span class="math notranslate nohighlight">\(a\)</span>, based on our belief!</p>
<p>Let’s use the following widget to think about the relationship between these probability distributions and utility function.</p>
</div>
<div class="section" id="interactive-demo-6-what-is-more-important-the-probabilities-or-the-utilities">
<h2>Interactive Demo! 6: What is more important, the probabilities or the utilities?<a class="headerlink" href="#interactive-demo-6-what-is-more-important-the-probabilities-or-the-utilities" title="Permalink to this headline">¶</a></h2>
<p>We are now going to put everything we’ve learned together to gain some intuitions for how each of the elements that goes into a Bayesian decision comes together. Remember, the common assumption in neuroscience, psychology, economics, ecology, etc. is that we (humans and animals) are trying to maximize our expected utility. There is a lot going on in this demo as it brings everything in this tutorial together in one place - please spend time making sure you understand the controls and the plots, especially how everything relates together.</p>
<ol class="simple">
<li><p>Can you find a situation where the expected utility is the same for both actions?</p></li>
<li><p>What is more important for determining the expected utility: the prior or a new measurement (the likelihood)?</p></li>
<li><p>Why is this a normative model?</p></li>
<li><p>Can you think of ways in which this model would need to be extended to describe human or animal behavior?</p></li>
</ol>
<p>Execute this cell to enable the widget</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to enable the widget</span>
<span class="c1"># style = {'description_width': 'initial'}</span>

<span class="n">ps_widget</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'p(s = left)'</span><span class="p">,</span>
                                <span class="nb">min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">Layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s1">'300px'</span><span class="p">))</span>
<span class="n">p_a_s1_widget</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'p(fish on left | state = left)'</span><span class="p">,</span>
                                    <span class="nb">min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">Layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s1">'370px'</span><span class="p">))</span>
<span class="n">p_a_s0_widget</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'p(fish on left | state = right)'</span><span class="p">,</span>
                                    <span class="nb">min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">Layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s1">'370px'</span><span class="p">))</span>

<span class="n">observed_widget</span> <span class="o">=</span> <span class="n">ToggleButtons</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="s1">'Fish'</span><span class="p">,</span> <span class="s1">'No Fish'</span><span class="p">],</span>
    <span class="n">description</span><span class="o">=</span><span class="s1">'Observation (m) on the left:'</span><span class="p">,</span> <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">button_style</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span>
    <span class="n">layout</span><span class="o">=</span><span class="n">Layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s1">'auto'</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="s2">"flex"</span><span class="p">),</span>
    <span class="n">style</span><span class="o">=</span><span class="p">{</span><span class="s1">'description_width'</span><span class="p">:</span> <span class="s1">'initial'</span><span class="p">}</span>
<span class="p">)</span>

<span class="n">widget_ui</span> <span class="o">=</span> <span class="n">VBox</span><span class="p">([</span><span class="n">ps_widget</span><span class="p">,</span>
                  <span class="n">HBox</span><span class="p">([</span><span class="n">p_a_s1_widget</span><span class="p">,</span> <span class="n">p_a_s0_widget</span><span class="p">]),</span>
                  <span class="n">observed_widget</span><span class="p">])</span>

<span class="n">widget_out</span> <span class="o">=</span> <span class="n">interactive_output</span><span class="p">(</span><span class="n">plot_prior_likelihood_utility</span><span class="p">,</span>
                                <span class="p">{</span><span class="s1">'ps'</span><span class="p">:</span> <span class="n">ps_widget</span><span class="p">,</span>
                                <span class="s1">'p_a_s1'</span><span class="p">:</span> <span class="n">p_a_s1_widget</span><span class="p">,</span>
                                <span class="s1">'p_a_s0'</span><span class="p">:</span> <span class="n">p_a_s0_widget</span><span class="p">,</span>
                                <span class="s1">'measurement'</span><span class="p">:</span> <span class="n">observed_widget</span><span class="p">})</span>
<span class="n">display</span><span class="p">(</span><span class="n">widget_ui</span><span class="p">,</span> <span class="n">widget_out</span><span class="p">)</span>

<span class="c1"># @widgets.interact(</span>
<span class="c1">#     ps=ps_widget,</span>
<span class="c1">#     p_a_s1=p_a_s1_widget,</span>
<span class="c1">#     p_a_s0=p_a_s0_widget,</span>
<span class="c1">#     m_right=observed_widget</span>
<span class="c1"># )</span>
<span class="c1"># def make_prior_likelihood_utility_plot(ps, p_a_s1, p_a_s0,m_right):</span>
<span class="c1">#     fig = plot_prior_likelihood_utility(ps, p_a_s1, p_a_s0,m_right)</span>
<span class="c1">#     plt.show(fig)</span>
<span class="c1">#     plt.close(fig)</span>
<span class="c1">#     return None</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove explanation</span>

<span class="sd">"""</span>
<span class="sd">1. There are actually many (infinite) combinations that can produce the same</span>
<span class="sd">   expected utility for both actions: but the posterior probabilities will always</span>
<span class="sd">   have to balance out the differences in the utility function. So, what is</span>
<span class="sd">   important is that for a given utility function, there will be some 'point</span>
<span class="sd">   of indifference'</span>

<span class="sd">2. What matters is the relative information: if the prior is close to 50/50,</span>
<span class="sd">   then the likelihood has more influence, if the likelihood is 50/50 given a</span>
<span class="sd">   measurement (the measurement is uninformative), the prior is more important.</span>
<span class="sd">   But the critical insight from Bayes Rule and the Bayesian approach is that what</span>
<span class="sd">   matters is the relative information you gain from a measurement, and that</span>
<span class="sd">   you can use all of this information for your decision.</span>

<span class="sd">3. The model gives us a very precise way to think about how we *should* combine</span>
<span class="sd">   information and how we *should* act, GIVEN some assumption about our goals.</span>
<span class="sd">   In this case, if we assume we are trying to maximize expected utility--we can</span>
<span class="sd">   state what an animal or subject should do.</span>

<span class="sd">4. There are lots of possible extensions. Humans may not always try to maximize</span>
<span class="sd">   utility; humans and animals might not be able to calculate or represent probability</span>
<span class="sd">   distributions exactly; The utility function might be more complicated; etc.</span>
<span class="sd">"""</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="video-10-bayesian-decisions-demo-discussion">
<h3>Video 10: Bayesian Decisions Demo Discussion<a class="headerlink" href="#video-10-bayesian-decisions-demo-discussion" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p><em>Estimated timing of tutorial: 1 hour, 30 minutes</em></p>
<p>In this tutorial, you learned about combining prior information with new measurements to update your knowledge using Bayes Rule, in the context of a fishing problem.</p>
<p>Specifically, we covered:</p>
<ul class="simple">
<li><p>That the likelihood is the probability of the measurement given some hidden state</p></li>
<li><p>That how the prior and likelihood interact to create the posterior, the probability of the hidden state given a measurement, depends on how they covary</p></li>
<li><p>That utility is the gain from each action and state pair, and the expected utility for an action is the sum of the utility for all state pairs, weighted by the probability of that state happening. You can then choose the action with the highest expected utility.</p></li>
</ul>
</div>
<hr class="docutils"/>
<div class="section" id="bonus">
<h1>Bonus<a class="headerlink" href="#bonus" title="Permalink to this headline">¶</a></h1>
<div class="section" id="bonus-section-1-correlation-formula">
<h2>Bonus Section 1: Correlation Formula<a class="headerlink" href="#bonus-section-1-correlation-formula" title="Permalink to this headline">¶</a></h2>
<p>To understand the way we calculate the correlation, we need to review the definition of covariance and correlation.</p>
<p>Covariance:</p>
<div class="amsmath math notranslate nohighlight" id="equation-b2b2806e-0d9f-489a-837c-6a63504e247d">
<span class="eqno">(353)<a class="headerlink" href="#equation-b2b2806e-0d9f-489a-837c-6a63504e247d" title="Permalink to this equation">¶</a></span>\[\begin{equation}
cov(X,Y) = \sigma_{XY} = \mathbb{E}[(X - \mu_{x})(Y - \mu_{y})] = \mathbb{E}[X]\mathbb{E}[Y] - \mu_{x}\mu_{y}
\end{equation}\]</div>
<p>Correlation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-579232a4-eb3b-4963-8492-6a438cd32f6c">
<span class="eqno">(354)<a class="headerlink" href="#equation-579232a4-eb3b-4963-8492-6a438cd32f6c" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\rho_{XY} = \frac{cov(Y,Y)}{\sqrt{\text{var}(X)\text{var}(Y)}} = \frac{\sigma_{XY}}{\sigma_{X}\sigma_{Y}}
\end{equation}\]</div>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W3D1_BayesianDecisions/instructor"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="W3D1_Intro.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Intro</p>
</div>
</a>
<a class="right-next" href="W3D1_Tutorial2.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Tutorial 2: Bayesian inference and decisions with continuous hidden state</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
    By Neuromatch<br/>
<div class="extra_footer">
<div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"/></a>
The contents of this repository are shared under the <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>
</div>
</p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>