
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 2: Autoencoder extensions — Neuromatch Academy: Computational Neuroscience (instructor's version)</title>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-logo-square-4xp.jpg" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="Bonus_Tutorial3.html" rel="next" title="Tutorial 3: Autoencoders applications"/>
<link href="Bonus_Tutorial1.html" rel="prev" title="Tutorial 1: Intro to Autoencoders"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="60" data-spy="scroll" data-target="#bd-toc-nav">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay overlay-navbar" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input aria-label="Toggle in-page Table of Contents" class="sidebar-toggle" id="__page-toc" name="__page-toc" type="checkbox"/>
<label class="overlay overlay-pagetoc" for="__page-toc">
<div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
<div class="bd-sidebar__content">
<div class="bd-sidebar__top"><div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
<img alt="logo" class="logo" src="../../../_static/nma-logo-square-4xp.jpg"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Computational Neuroscience (instructor's version)</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox">
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox">
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</input></li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using discord
    </a>
</li>
</ul>
</input></li>
</ul>
<p class="caption">
<span class="caption-text">
  Intro to Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_ModelTypes/chapter_title.html">
   Model Types (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial1.html">
     Tutorial 1: “What” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial2.html">
     Tutorial 2: “How” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial3.html">
     Tutorial 3: “Why” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Tutorial4.html">
     Tutorial 4: Model Discussions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/instructor/W1D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_ModelingPractice/chapter_title.html">
   Modeling Practice (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelingPractice/instructor/W1D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelingPractice/instructor/W1D2_Tutorial1.html">
     Tutorial 1: Framing the Question
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelingPractice/instructor/W1D2_Outro.html">
     Outro
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_ModelFitting/chapter_title.html">
   Model Fitting (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial1.html">
     Tutorial 1: Linear regression with MSE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial2.html">
     Tutorial 2: Linear regression with MLE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial3.html">
     Tutorial 3: Confidence intervals and bootstrapping
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial4.html">
     Tutorial 4: Multiple linear regression and polynomial regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial5.html">
     Tutorial 5: Model Selection: Bias-variance trade-off
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Tutorial6.html">
     Tutorial 6: Model Selection: Cross-validation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/instructor/W1D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/chapter_title.html">
   Generalized Linear Models (W1D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/instructor/W1D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/instructor/W1D4_Tutorial1.html">
     Tutorial 1: GLMs for Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/instructor/W1D4_Tutorial2.html">
     Tutorial 2: Classifiers and regularizers
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/instructor/W1D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/chapter_title.html">
   Dimensionality Reduction (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Tutorial1.html">
     Tutorial 1: Geometric view of data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Tutorial2.html">
     Tutorial 2: Principal Component Analysis
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Tutorial3.html">
     Tutorial 3: Dimensionality Reduction &amp; Reconstruction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Tutorial4.html">
     Tutorial 4:  Nonlinear Dimensionality Reduction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/instructor/W1D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_DeepLearning/chapter_title.html">
   Deep Learning (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Tutorial3.html">
     Tutorial 3: Building and Evaluating Normative Encoding Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Tutorial4.html">
     Bonus Tutorial: Diving Deeper into Decoding &amp; Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/instructor/W2D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Autoencoders (Bonus)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2">
<a class="reference internal" href="Bonus_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="Bonus_Tutorial1.html">
     Tutorial 1: Intro to Autoencoders
    </a>
</li>
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 2: Autoencoder extensions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="Bonus_Tutorial3.html">
     Tutorial 3: Autoencoders applications
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="Bonus_Outro.html">
     Outro
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/MachineLearning.html">
   Machine Learning Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_LinearSystems/chapter_title.html">
   Linear Systems (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial1.html">
     Tutorial 1: Linear dynamical systems
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial2.html">
     Tutorial 2: Markov Processes
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial3.html">
     Tutorial 3: Combining determinism and stochasticity
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Tutorial4.html">
     Tutorial 4: Autoregressive models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/instructor/W2D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/chapter_title.html">
   Biological Neuron Models (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial1.html">
     Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial2.html">
     Tutorial 2: Effects of Input Correlation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial3.html">
     Tutorial 3: Synaptic transmission - Models of static and dynamic synapses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial4.html">
     Bonus Tutorial: Spike-timing dependent plasticity (STDP)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/instructor/W2D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_DynamicNetworks/chapter_title.html">
   Dynamic Networks (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial1.html">
     Tutorial 1: Neural Rate Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial2.html">
     Tutorial 2: Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Tutorial3.html">
     Bonus Tutorial: Extending the Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/instructor/W2D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/DynamicalSystems.html">
   Dynamical Systems Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Stochastic Processes
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_BayesianDecisions/chapter_title.html">
   Bayesian Decisions (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial1.html">
     Tutorial 1: Bayes with a binary hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial2.html">
     Tutorial 2: Bayesian inference and decisions with continuous hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Tutorial3.html">
     Bonus Tutorial : Fitting to data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/instructor/W3D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_HiddenDynamics/chapter_title.html">
   Hidden Dynamics (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial1.html">
     Tutorial 1: Sequential Probability Ratio Test
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial2.html">
     Tutorial 2: Hidden Markov Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial3.html">
     Tutorial 3: The Kalman Filter
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial4.html">
     Bonus Tutorial 4: The Kalman Filter, part 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Tutorial5.html">
     Bonus Tutorial 5: Expectation Maximization for spiking neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/instructor/W3D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_OptimalControl/chapter_title.html">
   Optimal Control (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial1.html">
     Tutorial 1: Optimal Control for Discrete States
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Tutorial2.html">
     Tutorial 2: Optimal Control for Continuous State
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/instructor/W3D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/chapter_title.html">
   Reinforcement Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Tutorial4.html">
     Tutorial 4: From Reinforcement Learning to Planning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/instructor/W3D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D5_NetworkCausality/chapter_title.html">
   Network Causality (W3D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial1.html">
     Tutorial 1: Interventions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial2.html">
     Tutorial 2: Correlations
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial3.html">
     Tutorial 3: Simultaneous fitting/regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Tutorial4.html">
     Tutorial 4: Instrumental Variables
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/instructor/W3D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/StochasticProcesses.html">
   Stochastic Processes Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through4.html">
     Modeling Steps 1 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through10.html">
     Modeling Steps 5 - 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModel.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProject.html">
     Example Data Project: the Train Illusion
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/datasets_overview.html">
   Datasets
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/neurons.html">
     Neurons
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/neurons_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/fMRI.html">
     fMRI
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/fMRI_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/ECoG.html">
     ECoG
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/ECoG_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/behavior.html">
     Behavior
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
<label for="toctree-checkbox-24">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/behavior_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/theory.html">
     Theory
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
<label for="toctree-checkbox-25">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/theory/README.html">
       Guide
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_templates.html">
   Project Templates
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/project_2020_highlights.html">
   Projects 2020
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
<label for="toctree-checkbox-26">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/neurons.html">
     Neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/theory.html">
     Theory
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/behavior.html">
     Behavior
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/fMRI.html">
     fMRI
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/eeg.html">
     EEG
    </a>
</li>
</ul>
</li>
</ul>
</div>
</nav></div>
<div class="bd-sidebar__bottom">
<!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
<div class="header-article row sticky-top noprint">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="headerbtn" data-placement="right" data-toggle="tooltip" for="__navigation" title="Toggle navigation">
<span class="headerbtn__icon-container">
<i class="fas fa-bars"></i>
</span>
</label>
</div>
<div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
<button aria-label="Launch interactive content" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-rocket"></i>
</button>
<div class="menu-dropdown__content">
<ul>
</ul>
</div>
</div>
<button class="headerbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="headerbtn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="menu-dropdown menu-dropdown-repository-buttons">
<button aria-label="Source repositories" class="headerbtn menu-dropdown__trigger">
<i class="fab fa-github"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content" title="Source repository">
<span class="headerbtn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="headerbtn__text-container">repository</span>
</a>
</li>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/instructor-course-content/issues/new?title=Issue%20on%20page%20%2Ftutorials/Bonus_Autoencoders/instructor/Bonus_Tutorial2.html&amp;body=Your%20issue%20content%20here." title="Open an issue">
<span class="headerbtn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="headerbtn__text-container">open issue</span>
</a>
</li>
</ul>
</div>
</div>
<div class="menu-dropdown menu-dropdown-download-buttons">
<button aria-label="Download this page" class="headerbtn menu-dropdown__trigger">
<i class="fas fa-download"></i>
</button>
<div class="menu-dropdown__content">
<ul>
<li>
<a class="headerbtn" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/Bonus_Autoencoders/instructor/Bonus_Tutorial2.ipynb" title="Download source file">
<span class="headerbtn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="headerbtn__text-container">.ipynb</span>
</a>
</li>
<li>
<button class="headerbtn" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="headerbtn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="headerbtn__text-container">.pdf</span>
</button>
</li>
</ul>
</div>
</div>
<label class="headerbtn headerbtn-page-toc" for="__page-toc">
<span class="headerbtn__icon-container">
<i class="fas fa-list"></i>
</span>
</label>
</div>
</div>
<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
    </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 2: Autoencoder extensions
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#architecture">
     Architecture
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-extensions">
     Video 1: Extensions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-download-and-prepare-mnist-dataset">
   Section 1: Download  and prepare MNIST dataset
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-deeper-autoencoder-2d">
   Section 2: Deeper autoencoder (2D)
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-1-build-deeper-autoencoder-2d">
     Exercise 1: Build deeper autoencoder (2D)
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#train-the-autoencoder">
     Train the autoencoder
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-spherical-latent-space">
   Section 3: Spherical latent space
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-1-build-and-train-autoencoder-3d">
     Section 3.1: Build and train autoencoder (3D)
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-2-train-the-autoencoder">
     Section 3.2: Train the autoencoder
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-3-visualize-the-latent-space-in-3d">
     Section 3.3: Visualize the latent space in 3D
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-2-build-deep-autoencoder-2d-with-latent-spherical-space">
       Exercise 2: Build deep autoencoder (2D) with latent spherical space
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-4-train-the-autoencoder">
     Section 3.4: Train the autoencoder
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-5-visualize-latent-space-on-surface-of-s-2">
     Section 3.5: Visualize latent space on surface of
     <span class="math notranslate nohighlight">
      \(S_2\)
     </span>
</a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-wrap-up">
     Video 2: Wrap-up
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus">
   Bonus
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#deep-and-thick-autoencoder">
     Deep and thick autoencoder
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="article row">
<div class="col pl-md-3 pl-lg-5 content-container">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 2: Autoencoder extensions</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 2: Autoencoder extensions
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#architecture">
     Architecture
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-extensions">
     Video 1: Extensions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-download-and-prepare-mnist-dataset">
   Section 1: Download  and prepare MNIST dataset
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-deeper-autoencoder-2d">
   Section 2: Deeper autoencoder (2D)
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-1-build-deeper-autoencoder-2d">
     Exercise 1: Build deeper autoencoder (2D)
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#train-the-autoencoder">
     Train the autoencoder
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-spherical-latent-space">
   Section 3: Spherical latent space
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-1-build-and-train-autoencoder-3d">
     Section 3.1: Build and train autoencoder (3D)
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-2-train-the-autoencoder">
     Section 3.2: Train the autoencoder
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-3-visualize-the-latent-space-in-3d">
     Section 3.3: Visualize the latent space in 3D
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-2-build-deep-autoencoder-2d-with-latent-spherical-space">
       Exercise 2: Build deep autoencoder (2D) with latent spherical space
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-4-train-the-autoencoder">
     Section 3.4: Train the autoencoder
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-5-visualize-latent-space-on-surface-of-s-2">
     Section 3.5: Visualize latent space on surface of
     <span class="math notranslate nohighlight">
      \(S_2\)
     </span>
</a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-wrap-up">
     Video 2: Wrap-up
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus">
   Bonus
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#deep-and-thick-autoencoder">
     Deep and thick autoencoder
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<main id="main-content" role="main">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/main/tutorials/Bonus_Autoencoders/Bonus_Tutorial2.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/Bonus_Autoencoders/Bonus_Tutorial2.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<div class="section" id="tutorial-2-autoencoder-extensions">
<h1>Tutorial 2: Autoencoder extensions<a class="headerlink" href="#tutorial-2-autoencoder-extensions" title="Permalink to this headline">¶</a></h1>
<p><strong>Bonus Day: Autoencoders</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Marco Brigham and the <a class="reference external" href="https://www.ccnss.org/">CCNSS</a> team (2014-2018)</p>
<p><strong>Content reviewers:</strong> Itzel Olivos, Karen Schroeder, Karolina Stosio, Kshitij Dwivedi, Spiros Chavlis, Michael Waskom</p>
<p><strong>Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs</strong></p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p></div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<div class="section" id="architecture">
<h2>Architecture<a class="headerlink" href="#architecture" title="Permalink to this headline">¶</a></h2>
<p>How can we improve the internal representation of shallow autoencoder with 2D bottleneck layer?</p>
<p>We may try the following architecture changes:</p>
<ul class="simple">
<li><p>Introducing additional hidden layers</p></li>
<li><p>Wrapping latent space as a sphere</p></li>
</ul>
<br/>
<p><img alt="Deep ANN autoencoder" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/ae-ann-3h.png"/></p>
<p>Adding hidden layers increases the number of learnable parameters to better use non-linear operations in encoding/decoding. Spherical geometry of latent space forces the network to use these additional degrees of freedom more efficiently.</p>
<p>Let’s dive deeper into the technical aspects of autoencoders and improve their internal representations to reach the levels required for the <em>MNIST cognitive task</em>.</p>
<p>In this tutorial, you will:</p>
<ul class="simple">
<li><p>Increase the capacity of the network by introducing additional hidden layers</p></li>
<li><p>Understand the effect of constraints in the geometry of latent space</p></li>
</ul>
</div>
<div class="section" id="video-1-extensions">
<h2>Video 1: Extensions<a class="headerlink" href="#video-1-extensions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "ba378ed8545c4aeeacce788212a544cb"}
</script></div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<p>Please execute the cell(s) below to initialize the notebook environment.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure settings</span>
<span class="o">!</span>pip install plotly --quiet
<span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="nn">go</span>
<span class="kn">from</span> <span class="nn">plotly.colors</span> <span class="kn">import</span> <span class="n">qualitative</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/NMA2020/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper functions</span>


<span class="k">def</span> <span class="nf">downloadMNIST</span><span class="p">():</span>
  <span class="sd">"""</span>
<span class="sd">  Download MNIST dataset and transform it to torch.Tensor</span>

<span class="sd">  Args:</span>
<span class="sd">    None</span>

<span class="sd">  Returns:</span>
<span class="sd">    x_train : training images (torch.Tensor) (60000, 28, 28)</span>
<span class="sd">    x_test  : test images (torch.Tensor) (10000, 28, 28)</span>
<span class="sd">    y_train : training labels (torch.Tensor) (60000, )</span>
<span class="sd">    y_train : test labels (torch.Tensor) (10000, )</span>
<span class="sd">  """</span>
  <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="s1">'mnist_784'</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="c1"># Trunk the data</span>
  <span class="n">n_train</span> <span class="o">=</span> <span class="mi">60000</span>
  <span class="n">n_test</span> <span class="o">=</span> <span class="mi">10000</span>

  <span class="n">train_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_train</span><span class="p">)</span>
  <span class="n">test_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_train</span> <span class="o">+</span> <span class="n">n_test</span><span class="p">)</span>

  <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
  <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">test_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>

  <span class="c1"># Transform np.ndarrays to torch.Tensor</span>
  <span class="n">x_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span>
                                        <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span>
                                         <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
  <span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span>
                                       <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span>
                                        <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

  <span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>
  <span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>

  <span class="k">return</span> <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">init_weights_kaiming_uniform</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Initializes weights from linear PyTorch layer</span>
<span class="sd">  with kaiming uniform distribution.</span>

<span class="sd">  Args:</span>
<span class="sd">    layer (torch.Module)</span>
<span class="sd">        Pytorch layer</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>
  <span class="c1"># check for linear PyTorch layer</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
    <span class="c1"># initialize weights with kaiming uniform distribution</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">init_weights_kaiming_normal</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Initializes weights from linear PyTorch layer</span>
<span class="sd">  with kaiming normal distribution.</span>

<span class="sd">  Args:</span>
<span class="sd">    layer (torch.Module)</span>
<span class="sd">        Pytorch layer</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>
  <span class="c1"># check for linear PyTorch layer</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
    <span class="c1"># initialize weights with kaiming normal distribution</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_layer_weights</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Retrieves learnable parameters from PyTorch layer.</span>

<span class="sd">  Args:</span>
<span class="sd">    layer (torch.Module)</span>
<span class="sd">        Pytorch layer</span>

<span class="sd">  Returns:</span>
<span class="sd">    list with learnable parameters</span>
<span class="sd">  """</span>
  <span class="c1"># initialize output list</span>
  <span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="c1"># check whether layer has learnable parameters</span>
  <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="c1"># copy numpy array representation of each set of learnable parameters</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
      <span class="n">weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

  <span class="k">return</span> <span class="n">weights</span>


<span class="k">def</span> <span class="nf">print_parameter_count</span><span class="p">(</span><span class="n">net</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Prints count of learnable parameters per layer from PyTorch network.</span>

<span class="sd">  Args:</span>
<span class="sd">    net (torch.Sequential)</span>
<span class="sd">        Pytorch network</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="n">params_n</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="c1"># loop all layers in network</span>
  <span class="k">for</span> <span class="n">layer_idx</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="p">):</span>

    <span class="c1"># retrieve learnable parameters</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">get_layer_weights</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
    <span class="n">params_layer_n</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># loop list of learnable parameters and count them</span>
    <span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">weights</span><span class="p">:</span>
      <span class="n">params_layer_n</span> <span class="o">+=</span> <span class="n">params</span><span class="o">.</span><span class="n">size</span>

    <span class="n">params_n</span> <span class="o">+=</span> <span class="n">params_layer_n</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">layer_idx</span><span class="si">}</span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">params_layer_n</span><span class="si">}</span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">layer</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Total:</span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">params_n</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">eval_mse</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Evaluates mean square error (MSE) between y_pred and y_true</span>

<span class="sd">  Args:</span>
<span class="sd">    y_pred (torch.Tensor)</span>
<span class="sd">        prediction samples</span>

<span class="sd">    v (numpy array of floats)</span>
<span class="sd">        ground truth samples</span>

<span class="sd">  Returns:</span>
<span class="sd">    MSE(y_pred, y_true)</span>
<span class="sd">  """</span>

  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>

  <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">eval_bce</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Evaluates binary cross-entropy (BCE) between y_pred and y_true</span>

<span class="sd">  Args:</span>
<span class="sd">    y_pred (torch.Tensor)</span>
<span class="sd">        prediction samples</span>

<span class="sd">    v (numpy array of floats)</span>
<span class="sd">        ground truth samples</span>

<span class="sd">  Returns:</span>
<span class="sd">    BCE(y_pred, y_true)</span>
<span class="sd">  """</span>

  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>

  <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_row</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">show_n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">image_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Plots rows of images from list of iterables (iterables: list, numpy array</span>
<span class="sd">  or torch.Tensor). Also accepts single iterable.</span>
<span class="sd">  Randomly selects images in each list element if item count &gt; show_n.</span>

<span class="sd">  Args:</span>
<span class="sd">    images (iterable or list of iterables)</span>
<span class="sd">        single iterable with images, or list of iterables</span>

<span class="sd">    show_n (integer)</span>
<span class="sd">        maximum number of images per row</span>

<span class="sd">    image_shape (tuple or list)</span>
<span class="sd">        original shape of image if vectorized form</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">images</span><span class="p">]</span>

  <span class="k">for</span> <span class="n">items_idx</span><span class="p">,</span> <span class="n">items</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">images</span><span class="p">):</span>

    <span class="n">items</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">items</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">items</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">show_n</span><span class="p">:</span>
      <span class="n">selected</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">),</span> <span class="n">show_n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="n">items</span> <span class="o">=</span> <span class="n">items</span><span class="p">[</span><span class="n">selected</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">image_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">items</span> <span class="o">=</span> <span class="n">items</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="nb">list</span><span class="p">(</span><span class="n">image_shape</span><span class="p">))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">image_idx</span><span class="p">,</span> <span class="n">image</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">items</span><span class="p">):</span>

      <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">),</span> <span class="n">image_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">vmax</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">to_s2</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Projects 3D coordinates to spherical coordinates (theta, phi) surface of</span>
<span class="sd">  unit sphere S2.</span>
<span class="sd">  theta: [0, pi]</span>
<span class="sd">  phi: [-pi, pi]</span>

<span class="sd">  Args:</span>
<span class="sd">    u (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        3D coordinates</span>

<span class="sd">  Returns:</span>
<span class="sd">    Sperical coordinates (theta, phi) on surface of unit sphere S2.</span>
<span class="sd">  """</span>

  <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">u</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">u</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">u</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>
  <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">z</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
  <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arccos</span><span class="p">(</span><span class="n">z</span> <span class="o">/</span> <span class="n">r</span><span class="p">)</span>
  <span class="n">phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arctan2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">theta</span><span class="p">,</span> <span class="n">phi</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>


<span class="k">def</span> <span class="nf">to_u3</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Converts from 2D coordinates on surface of unit sphere S2 to 3D coordinates</span>
<span class="sd">  (on surface of S2), i.e. (theta, phi) ---&gt; (1, theta, phi).</span>

<span class="sd">  Args:</span>
<span class="sd">    s (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        2D coordinates on unit sphere S_2</span>

<span class="sd">  Returns:</span>
<span class="sd">    3D coordinates on surface of unit sphere S_2</span>
<span class="sd">  """</span>

  <span class="n">theta</span><span class="p">,</span> <span class="n">phi</span> <span class="o">=</span> <span class="p">(</span><span class="n">s</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">s</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>


<span class="k">def</span> <span class="nf">xy_lim</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Return arguments for plt.xlim and plt.ylim calculated from minimum</span>
<span class="sd">  and maximum of x.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        data to be plotted</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="n">x_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">x_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="n">x_min</span> <span class="o">=</span> <span class="n">x_min</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.05</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>
  <span class="n">x_max</span> <span class="o">=</span> <span class="n">x_max</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.05</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>

  <span class="k">return</span> <span class="p">[</span><span class="n">x_min</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_max</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">x_min</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x_max</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>


<span class="k">def</span> <span class="nf">plot_generative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">decoder_fn</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">n_row</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Plots images reconstructed by decoder_fn from a 2D grid in</span>
<span class="sd">  latent space that is determined by minimum and maximum values in x.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        2D or 3D coordinates in latent space</span>

<span class="sd">    decoder_fn (integer)</span>
<span class="sd">        function returning vectorized images from 2D latent space coordinates</span>

<span class="sd">    image_shape (tuple or list)</span>
<span class="sd">        original shape of image</span>

<span class="sd">    n_row (integer)</span>
<span class="sd">        number of rows in grid</span>

<span class="sd">    s2 (boolean)</span>
<span class="sd">        convert 3D coordinates (x, y, z) to spherical coordinates (theta, phi)</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="k">if</span> <span class="n">s2</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">to_s2</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

  <span class="n">xlim</span><span class="p">,</span> <span class="n">ylim</span> <span class="o">=</span> <span class="n">xy_lim</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

  <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">xlim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">xlim</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">n_row</span>
  <span class="n">grid</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ylim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">dx</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">ylim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">dx</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_row</span><span class="p">),</span>
          <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xlim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">dx</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">xlim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">dx</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_row</span><span class="p">)]</span>

  <span class="n">canvas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_row</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_row</span><span class="p">))</span>

  <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'gray'</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">latent_y</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">latent_x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>

      <span class="n">latent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">latent_x</span><span class="p">,</span> <span class="n">latent_y</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">s2</span><span class="p">:</span>
        <span class="n">latent</span> <span class="o">=</span> <span class="n">to_u3</span><span class="p">(</span><span class="n">latent</span><span class="p">)</span>

      <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">x_decoded</span> <span class="o">=</span> <span class="n">decoder_fn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">latent</span><span class="p">))</span>

      <span class="n">x_decoded</span> <span class="o">=</span> <span class="n">x_decoded</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">image_shape</span><span class="p">)</span>

      <span class="n">canvas</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
             <span class="n">i</span> <span class="o">*</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">x_decoded</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">canvas</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">canvas</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">vmax</span><span class="o">=</span><span class="n">canvas</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_latent</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">show_n</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xy_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Plots digit class of each sample in 2D latent space coordinates.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        2D coordinates in latent space</span>

<span class="sd">    y (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        digit class of each sample</span>

<span class="sd">    n_row (integer)</span>
<span class="sd">        number of samples</span>

<span class="sd">    s2 (boolean)</span>
<span class="sd">        convert 3D coordinates (x, y, z) to spherical coordinates (theta, phi)</span>

<span class="sd">    fontdict (dictionary)</span>
<span class="sd">        style option for plt.text</span>

<span class="sd">    xy_labels (list)</span>
<span class="sd">        optional list with [xlabel, ylabel]</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="k">if</span> <span class="n">fontdict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">fontdict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'weight'</span><span class="p">:</span> <span class="s1">'bold'</span><span class="p">,</span> <span class="s1">'size'</span><span class="p">:</span> <span class="mi">12</span><span class="p">}</span>

  <span class="k">if</span> <span class="n">s2</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">to_s2</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

  <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'tab10'</span><span class="p">)</span>

  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">show_n</span><span class="p">:</span>
    <span class="n">selected</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">show_n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">selected</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">selected</span><span class="p">]</span>

  <span class="k">for</span> <span class="n">my_x</span><span class="p">,</span> <span class="n">my_y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">my_x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">my_x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">my_y</span><span class="p">)),</span>
             <span class="n">color</span><span class="o">=</span><span class="n">cmap</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">my_y</span><span class="p">)</span> <span class="o">/</span> <span class="mf">10.</span><span class="p">),</span>
             <span class="n">fontdict</span><span class="o">=</span><span class="n">fontdict</span><span class="p">,</span>
             <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span>
             <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span>
             <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

  <span class="n">xlim</span><span class="p">,</span> <span class="n">ylim</span> <span class="o">=</span> <span class="n">xy_lim</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xlim</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ylim</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">s2</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">xy_labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">xy_labels</span> <span class="o">=</span> <span class="p">[</span><span class="sa">r</span><span class="s1">'$\varphi$'</span><span class="p">,</span> <span class="sa">r</span><span class="s1">'$\theta$'</span><span class="p">]</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">6</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">6</span><span class="p">),</span>
               <span class="p">[</span><span class="s1">'0'</span><span class="p">,</span> <span class="s1">'$\pi/6$'</span><span class="p">,</span> <span class="s1">'$\pi/3$'</span><span class="p">,</span> <span class="s1">'$\pi/2$'</span><span class="p">,</span>
                <span class="s1">'$2\pi/3$'</span><span class="p">,</span> <span class="s1">'$5\pi/6$'</span><span class="p">,</span> <span class="s1">'$\pi$'</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">3</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">3</span><span class="p">),</span>
               <span class="p">[</span><span class="s1">'$-\pi$'</span><span class="p">,</span> <span class="s1">'$-2\pi/3$'</span><span class="p">,</span> <span class="s1">'$-\pi/3$'</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">,</span>
                <span class="s1">'$\pi/3$'</span><span class="p">,</span> <span class="s1">'$2\pi/3$'</span><span class="p">,</span> <span class="s1">'$\pi$'</span><span class="p">])</span>

  <span class="k">if</span> <span class="n">xy_labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">xy_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'$Z_1$'</span><span class="p">,</span> <span class="s1">'$Z_2$'</span><span class="p">]</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">xy_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">xy_labels</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">plot_latent_generative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">decoder_fn</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                           <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xy_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Two horizontal subplots generated with encoder map and decoder grid.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        2D coordinates in latent space</span>

<span class="sd">    y (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        digit class of each sample</span>

<span class="sd">    decoder_fn (integer)</span>
<span class="sd">        function returning vectorized images from 2D latent space coordinates</span>

<span class="sd">    image_shape (tuple or list)</span>
<span class="sd">        original shape of image</span>

<span class="sd">    s2 (boolean)</span>
<span class="sd">        convert 3D coordinates (x, y, z) to spherical coordinates (theta, phi)</span>

<span class="sd">    title (string)</span>
<span class="sd">        plot title</span>

<span class="sd">    xy_labels (list)</span>
<span class="sd">        optional list with [xlabel, ylabel]</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

  <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>

  <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Encoder map'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
  <span class="n">plot_latent</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">,</span> <span class="n">xy_labels</span><span class="o">=</span><span class="n">xy_labels</span><span class="p">)</span>

  <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Decoder grid'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
  <span class="n">plot_generative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">decoder_fn</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_latent_3d</span><span class="p">(</span><span class="n">my_x</span><span class="p">,</span> <span class="n">my_y</span><span class="p">,</span> <span class="n">show_text</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_n</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Plot digit class or marker in 3D latent space coordinates.</span>

<span class="sd">  Args:</span>
<span class="sd">    my_x (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        2D coordinates in latent space</span>

<span class="sd">    my_y (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        digit class of each sample</span>

<span class="sd">    show_text (boolean)</span>
<span class="sd">        whether to show text</span>

<span class="sd">    image_shape (tuple or list)</span>
<span class="sd">        original shape of image</span>

<span class="sd">    s2 (boolean)</span>
<span class="sd">        convert 3D coordinates (x, y, z) to spherical coordinates (theta, phi)</span>

<span class="sd">    title (string)</span>
<span class="sd">        plot title</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="n">layout</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'margin'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'l'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">'b'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">'t'</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span>
            <span class="s1">'scene'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'xaxis'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'showspikes'</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="s1">'title'</span><span class="p">:</span> <span class="s1">'z1'</span><span class="p">},</span>
                      <span class="s1">'yaxis'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'showspikes'</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="s1">'title'</span><span class="p">:</span> <span class="s1">'z2'</span><span class="p">},</span>
                      <span class="s1">'zaxis'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'showspikes'</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                                <span class="s1">'title'</span><span class="p">:</span> <span class="s1">'z3'</span><span class="p">}}</span>
            <span class="p">}</span>

  <span class="n">selected_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">my_x</span><span class="p">),</span> <span class="n">show_n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

  <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="n">qualitative</span><span class="o">.</span><span class="n">T10</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">my_y</span><span class="p">[</span><span class="n">selected_idx</span><span class="p">]]</span>

  <span class="n">x</span> <span class="o">=</span> <span class="n">my_x</span><span class="p">[</span><span class="n">selected_idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">my_x</span><span class="p">[</span><span class="n">selected_idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">my_x</span><span class="p">[</span><span class="n">selected_idx</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

  <span class="n">text</span> <span class="o">=</span> <span class="n">my_y</span><span class="p">[</span><span class="n">selected_idx</span><span class="p">]</span>

  <span class="k">if</span> <span class="n">show_text</span><span class="p">:</span>

    <span class="n">trace</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Scatter3d</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
                         <span class="n">mode</span><span class="o">=</span><span class="s1">'text'</span><span class="p">,</span>
                         <span class="n">textfont</span><span class="o">=</span><span class="p">{</span><span class="s1">'color'</span><span class="p">:</span> <span class="n">colors</span><span class="p">,</span> <span class="s1">'size'</span><span class="p">:</span> <span class="mi">12</span><span class="p">}</span>
                         <span class="p">)</span>

    <span class="n">layout</span><span class="p">[</span><span class="s1">'hovermode'</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="k">else</span><span class="p">:</span>

    <span class="n">trace</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Scatter3d</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
                         <span class="n">hoverinfo</span><span class="o">=</span><span class="s1">'text'</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">'markers'</span><span class="p">,</span>
                         <span class="n">marker</span><span class="o">=</span><span class="p">{</span><span class="s1">'size'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">'color'</span><span class="p">:</span> <span class="n">colors</span><span class="p">,</span> <span class="s1">'opacity'</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">}</span>
                         <span class="p">)</span>

  <span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">trace</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">layout</span><span class="p">)</span>

  <span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">runSGD</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">input_train</span><span class="p">,</span> <span class="n">input_test</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">'bce'</span><span class="p">,</span>
           <span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Trains autoencoder network with stochastic gradient descent with Adam</span>
<span class="sd">  optimizer and loss criterion. Train samples are shuffled, and loss is</span>
<span class="sd">  displayed at the end of each opoch for both MSE and BCE. Plots training loss</span>
<span class="sd">  at each minibatch (maximum of 500 randomly selected values).</span>

<span class="sd">  Args:</span>
<span class="sd">    net (torch network)</span>
<span class="sd">        ANN object (nn.Module)</span>

<span class="sd">    input_train (torch.Tensor)</span>
<span class="sd">        vectorized input images from train set</span>

<span class="sd">    input_test (torch.Tensor)</span>
<span class="sd">        vectorized input images from test set</span>

<span class="sd">    criterion (string)</span>
<span class="sd">        train loss: 'bce' or 'mse'</span>

<span class="sd">    n_epochs (boolean)</span>
<span class="sd">        number of full iterations of training data</span>

<span class="sd">    batch_size (integer)</span>
<span class="sd">        number of element in mini-batches</span>

<span class="sd">    verbose (boolean)</span>
<span class="sd">        print final loss</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="c1"># Initialize loss function</span>
  <span class="k">if</span> <span class="n">criterion</span> <span class="o">==</span> <span class="s1">'mse'</span><span class="p">:</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
  <span class="k">elif</span> <span class="n">criterion</span> <span class="o">==</span> <span class="s1">'bce'</span><span class="p">:</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Please specify either "mse" or "bce" for loss criterion'</span><span class="p">)</span>

  <span class="c1"># Initialize SGD optimizer</span>
  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

  <span class="c1"># Placeholder for loss</span>
  <span class="n">track_loss</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="nb">print</span><span class="p">(</span><span class="s1">'Epoch'</span><span class="p">,</span> <span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'Loss train'</span><span class="p">,</span> <span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'Loss test'</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>

    <span class="n">shuffle_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_train</span><span class="p">))</span>
    <span class="n">batches</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">input_train</span><span class="p">[</span><span class="n">shuffle_idx</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>

      <span class="n">output_train</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

      <span class="c1"># Keep track of loss at each epoch</span>
      <span class="n">track_loss</span> <span class="o">+=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">)]</span>

    <span class="n">loss_epoch</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">n_epochs</span><span class="si">}</span><span class="s1">'</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="n">output_train</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_train</span><span class="p">)</span>
      <span class="n">loss_train</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span> <span class="n">input_train</span><span class="p">)</span>
      <span class="n">loss_epoch</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">loss_train</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">'</span>

      <span class="n">output_test</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>
      <span class="n">loss_test</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output_test</span><span class="p">,</span> <span class="n">input_test</span><span class="p">)</span>
      <span class="n">loss_epoch</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\t\t</span><span class="s1"> </span><span class="si">{</span><span class="n">loss_test</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">'</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">loss_epoch</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
    <span class="c1"># Print loss</span>
    <span class="n">loss_mse</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">MSE</span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_mse</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span> <span class="n">input_train</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
    <span class="n">loss_mse</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\t\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_mse</span><span class="p">(</span><span class="n">output_test</span><span class="p">,</span> <span class="n">input_test</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">loss_mse</span><span class="p">)</span>

    <span class="n">loss_bce</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'BCE</span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_bce</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span> <span class="n">input_train</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
    <span class="n">loss_bce</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\t\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_bce</span><span class="p">(</span><span class="n">output_test</span><span class="p">,</span> <span class="n">input_test</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">loss_bce</span><span class="p">)</span>

  <span class="c1"># Plot loss</span>
  <span class="n">step</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">track_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">500</span><span class="p">))</span>
  <span class="n">x_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">track_loss</span><span class="p">),</span> <span class="n">step</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">track_loss</span><span class="p">[::</span><span class="n">step</span><span class="p">],</span> <span class="s1">'C0'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Iterations'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">NormalizeLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  pyTorch layer (nn.Module) that normalizes activations by their L2 norm.</span>

<span class="sd">  Args:</span>
<span class="sd">      None.</span>

<span class="sd">  Returns:</span>
<span class="sd">      Object inherited from nn.Module class.</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-download-and-prepare-mnist-dataset">
<h1>Section 1: Download  and prepare MNIST dataset<a class="headerlink" href="#section-1-download-and-prepare-mnist-dataset" title="Permalink to this headline">¶</a></h1>
<p>We use the helper function <code class="docutils literal notranslate"><span class="pre">downloadMNIST</span></code> to download the dataset and transform it into <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code> and assign train and test sets to (<code class="docutils literal notranslate"><span class="pre">x_train</span></code>, <code class="docutils literal notranslate"><span class="pre">y_train</span></code>) and (<code class="docutils literal notranslate"><span class="pre">x_test</span></code>, <code class="docutils literal notranslate"><span class="pre">y_test</span></code>).</p>
<p>The variable <code class="docutils literal notranslate"><span class="pre">input_size</span></code> stores the length of <em>vectorized</em> versions of the images <code class="docutils literal notranslate"><span class="pre">input_train</span></code> and <code class="docutils literal notranslate"><span class="pre">input_test</span></code> for training and test images.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download MNIST</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">downloadMNIST</span><span class="p">()</span>

<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mi">255</span>

<span class="n">image_shape</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

<span class="n">input_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">input_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_size</span><span class="p">])</span>
<span class="n">input_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_size</span><span class="p">])</span>

<span class="n">test_selected_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="mi">10</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">train_selected_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span> <span class="mi">10</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'shape image </span><span class="se">\t</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">image_shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'shape input_train </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">input_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'shape input_test </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">input_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">SSLCertVerificationError</span><span class="g g-Whitespace">                  </span>Traceback (most recent call last)
<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/urllib/request.py</span> in <span class="ni">do_open</span><span class="nt">(self, http_class, req, **http_conn_args)</span>
<span class="g g-Whitespace">   </span><span class="mi">1349</span>                 <span class="n">h</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><span class="n">req</span><span class="o">.</span><span class="n">get_method</span><span class="p">(),</span> <span class="n">req</span><span class="o">.</span><span class="n">selector</span><span class="p">,</span> <span class="n">req</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span><span class="p">,</span>
<span class="ne">-&gt; </span><span class="mi">1350</span>                           <span class="n">encode_chunked</span><span class="o">=</span><span class="n">req</span><span class="o">.</span><span class="n">has_header</span><span class="p">(</span><span class="s1">'Transfer-encoding'</span><span class="p">))</span>
<span class="g g-Whitespace">   </span><span class="mi">1351</span>             <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span> <span class="c1"># timeout error</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/http/client.py</span> in <span class="ni">request</span><span class="nt">(self, method, url, body, headers, encode_chunked)</span>
<span class="g g-Whitespace">   </span><span class="mi">1280</span>         <span class="sd">"""Send a complete request to the server."""</span>
<span class="ne">-&gt; </span><span class="mi">1281</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_send_request</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="n">headers</span><span class="p">,</span> <span class="n">encode_chunked</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1282</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/http/client.py</span> in <span class="ni">_send_request</span><span class="nt">(self, method, url, body, headers, encode_chunked)</span>
<span class="g g-Whitespace">   </span><span class="mi">1326</span>             <span class="n">body</span> <span class="o">=</span> <span class="n">_encode</span><span class="p">(</span><span class="n">body</span><span class="p">,</span> <span class="s1">'body'</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1327</span>         <span class="bp">self</span><span class="o">.</span><span class="n">endheaders</span><span class="p">(</span><span class="n">body</span><span class="p">,</span> <span class="n">encode_chunked</span><span class="o">=</span><span class="n">encode_chunked</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1328</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/http/client.py</span> in <span class="ni">endheaders</span><span class="nt">(self, message_body, encode_chunked)</span>
<span class="g g-Whitespace">   </span><span class="mi">1275</span>             <span class="k">raise</span> <span class="n">CannotSendHeader</span><span class="p">()</span>
<span class="ne">-&gt; </span><span class="mi">1276</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_send_output</span><span class="p">(</span><span class="n">message_body</span><span class="p">,</span> <span class="n">encode_chunked</span><span class="o">=</span><span class="n">encode_chunked</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1277</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/http/client.py</span> in <span class="ni">_send_output</span><span class="nt">(self, message_body, encode_chunked)</span>
<span class="g g-Whitespace">   </span><span class="mi">1035</span>         <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span><span class="p">[:]</span>
<span class="ne">-&gt; </span><span class="mi">1036</span>         <span class="bp">self</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1037</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/http/client.py</span> in <span class="ni">send</span><span class="nt">(self, data)</span>
<span class="g g-Whitespace">    </span><span class="mi">975</span>             <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">auto_open</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">976</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">connect</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">977</span>             <span class="k">else</span><span class="p">:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/http/client.py</span> in <span class="ni">connect</span><span class="nt">(self)</span>
<span class="g g-Whitespace">   </span><span class="mi">1450</span>             <span class="bp">self</span><span class="o">.</span><span class="n">sock</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="o">.</span><span class="n">wrap_socket</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sock</span><span class="p">,</span>
<span class="ne">-&gt; </span><span class="mi">1451</span>                                                   <span class="n">server_hostname</span><span class="o">=</span><span class="n">server_hostname</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1452</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/ssl.py</span> in <span class="ni">wrap_socket</span><span class="nt">(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)</span>
<span class="g g-Whitespace">    </span><span class="mi">422</span>             <span class="n">context</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">423</span>             <span class="n">session</span><span class="o">=</span><span class="n">session</span>
<span class="g g-Whitespace">    </span><span class="mi">424</span>         <span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/ssl.py</span> in <span class="ni">_create</span><span class="nt">(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)</span>
<span class="g g-Whitespace">    </span><span class="mi">869</span>                         <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"do_handshake_on_connect should not be specified for non-blocking sockets"</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">870</span>                     <span class="bp">self</span><span class="o">.</span><span class="n">do_handshake</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">871</span>             <span class="k">except</span> <span class="p">(</span><span class="ne">OSError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/ssl.py</span> in <span class="ni">do_handshake</span><span class="nt">(self, block)</span>
<span class="g g-Whitespace">   </span><span class="mi">1138</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">settimeout</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1139</span>             <span class="bp">self</span><span class="o">.</span><span class="n">_sslobj</span><span class="o">.</span><span class="n">do_handshake</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1140</span>         <span class="k">finally</span><span class="p">:</span>

<span class="ne">SSLCertVerificationError</span>: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1091)

<span class="n">During</span> <span class="n">handling</span> <span class="n">of</span> <span class="n">the</span> <span class="n">above</span> <span class="n">exception</span><span class="p">,</span> <span class="n">another</span> <span class="n">exception</span> <span class="n">occurred</span><span class="p">:</span>

<span class="ne">URLError</span><span class="g g-Whitespace">                                  </span>Traceback (most recent call last)
<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/sklearn/datasets/_openml.py</span> in <span class="ni">wrapper</span><span class="nt">(*args, **kw)</span>
<span class="g g-Whitespace">     </span><span class="mi">60</span>             <span class="k">try</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">61</span>                 <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kw</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">62</span>             <span class="k">except</span> <span class="n">HTTPError</span><span class="p">:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/sklearn/datasets/_openml.py</span> in <span class="ni">_load_json</span><span class="nt">()</span>
<span class="g g-Whitespace">    </span><span class="mi">170</span>     <span class="k">def</span> <span class="nf">_load_json</span><span class="p">():</span>
<span class="ne">--&gt; </span><span class="mi">171</span>         <span class="k">with</span> <span class="n">closing</span><span class="p">(</span><span class="n">_open_openml_url</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">data_home</span><span class="p">))</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">172</span>             <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">))</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/sklearn/datasets/_openml.py</span> in <span class="ni">_open_openml_url</span><span class="nt">(openml_path, data_home)</span>
<span class="g g-Whitespace">    </span><span class="mi">117</span>             <span class="k">with</span> <span class="n">TemporaryDirectory</span><span class="p">(</span><span class="nb">dir</span><span class="o">=</span><span class="n">dir_name</span><span class="p">)</span> <span class="k">as</span> <span class="n">tmpdir</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">118</span>                 <span class="k">with</span> <span class="n">closing</span><span class="p">(</span><span class="n">urlopen</span><span class="p">(</span><span class="n">req</span><span class="p">))</span> <span class="k">as</span> <span class="n">fsrc</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">119</span>                     <span class="n">opener</span><span class="p">:</span> <span class="n">Callable</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/urllib/request.py</span> in <span class="ni">urlopen</span><span class="nt">(url, data, timeout, cafile, capath, cadefault, context)</span>
<span class="g g-Whitespace">    </span><span class="mi">221</span>         <span class="n">opener</span> <span class="o">=</span> <span class="n">_opener</span>
<span class="ne">--&gt; </span><span class="mi">222</span>     <span class="k">return</span> <span class="n">opener</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">timeout</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">223</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/urllib/request.py</span> in <span class="ni">open</span><span class="nt">(self, fullurl, data, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">524</span> 
<span class="ne">--&gt; </span><span class="mi">525</span>         <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_open</span><span class="p">(</span><span class="n">req</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">526</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/urllib/request.py</span> in <span class="ni">_open</span><span class="nt">(self, req, data)</span>
<span class="g g-Whitespace">    </span><span class="mi">542</span>         <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_chain</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">handle_open</span><span class="p">,</span> <span class="n">protocol</span><span class="p">,</span> <span class="n">protocol</span> <span class="o">+</span>
<span class="ne">--&gt; </span><span class="mi">543</span>                                   <span class="s1">'_open'</span><span class="p">,</span> <span class="n">req</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">544</span>         <span class="k">if</span> <span class="n">result</span><span class="p">:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/urllib/request.py</span> in <span class="ni">_call_chain</span><span class="nt">(self, chain, kind, meth_name, *args)</span>
<span class="g g-Whitespace">    </span><span class="mi">502</span>             <span class="n">func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">handler</span><span class="p">,</span> <span class="n">meth_name</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">503</span>             <span class="n">result</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">504</span>             <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/urllib/request.py</span> in <span class="ni">https_open</span><span class="nt">(self, req)</span>
<span class="g g-Whitespace">   </span><span class="mi">1392</span>             <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_open</span><span class="p">(</span><span class="n">http</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">HTTPSConnection</span><span class="p">,</span> <span class="n">req</span><span class="p">,</span>
<span class="ne">-&gt; </span><span class="mi">1393</span>                 <span class="n">context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="p">,</span> <span class="n">check_hostname</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_check_hostname</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1394</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/urllib/request.py</span> in <span class="ni">do_open</span><span class="nt">(self, http_class, req, **http_conn_args)</span>
<span class="g g-Whitespace">   </span><span class="mi">1351</span>             <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span> <span class="c1"># timeout error</span>
<span class="ne">-&gt; </span><span class="mi">1352</span>                 <span class="k">raise</span> <span class="n">URLError</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1353</span>             <span class="n">r</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">getresponse</span><span class="p">()</span>

<span class="ne">URLError</span>: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1091)&gt;

<span class="n">During</span> <span class="n">handling</span> <span class="n">of</span> <span class="n">the</span> <span class="n">above</span> <span class="n">exception</span><span class="p">,</span> <span class="n">another</span> <span class="n">exception</span> <span class="n">occurred</span><span class="p">:</span>

<span class="ne">SSLCertVerificationError</span><span class="g g-Whitespace">                  </span>Traceback (most recent call last)
<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/urllib/request.py</span> in <span class="ni">do_open</span><span class="nt">(self, http_class, req, **http_conn_args)</span>
<span class="g g-Whitespace">   </span><span class="mi">1349</span>                 <span class="n">h</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><span class="n">req</span><span class="o">.</span><span class="n">get_method</span><span class="p">(),</span> <span class="n">req</span><span class="o">.</span><span class="n">selector</span><span class="p">,</span> <span class="n">req</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span><span class="p">,</span>
<span class="ne">-&gt; </span><span class="mi">1350</span>                           <span class="n">encode_chunked</span><span class="o">=</span><span class="n">req</span><span class="o">.</span><span class="n">has_header</span><span class="p">(</span><span class="s1">'Transfer-encoding'</span><span class="p">))</span>
<span class="g g-Whitespace">   </span><span class="mi">1351</span>             <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span> <span class="c1"># timeout error</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/http/client.py</span> in <span class="ni">request</span><span class="nt">(self, method, url, body, headers, encode_chunked)</span>
<span class="g g-Whitespace">   </span><span class="mi">1280</span>         <span class="sd">"""Send a complete request to the server."""</span>
<span class="ne">-&gt; </span><span class="mi">1281</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_send_request</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="n">headers</span><span class="p">,</span> <span class="n">encode_chunked</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1282</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/http/client.py</span> in <span class="ni">_send_request</span><span class="nt">(self, method, url, body, headers, encode_chunked)</span>
<span class="g g-Whitespace">   </span><span class="mi">1326</span>             <span class="n">body</span> <span class="o">=</span> <span class="n">_encode</span><span class="p">(</span><span class="n">body</span><span class="p">,</span> <span class="s1">'body'</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1327</span>         <span class="bp">self</span><span class="o">.</span><span class="n">endheaders</span><span class="p">(</span><span class="n">body</span><span class="p">,</span> <span class="n">encode_chunked</span><span class="o">=</span><span class="n">encode_chunked</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1328</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/http/client.py</span> in <span class="ni">endheaders</span><span class="nt">(self, message_body, encode_chunked)</span>
<span class="g g-Whitespace">   </span><span class="mi">1275</span>             <span class="k">raise</span> <span class="n">CannotSendHeader</span><span class="p">()</span>
<span class="ne">-&gt; </span><span class="mi">1276</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_send_output</span><span class="p">(</span><span class="n">message_body</span><span class="p">,</span> <span class="n">encode_chunked</span><span class="o">=</span><span class="n">encode_chunked</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1277</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/http/client.py</span> in <span class="ni">_send_output</span><span class="nt">(self, message_body, encode_chunked)</span>
<span class="g g-Whitespace">   </span><span class="mi">1035</span>         <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_buffer</span><span class="p">[:]</span>
<span class="ne">-&gt; </span><span class="mi">1036</span>         <span class="bp">self</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1037</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/http/client.py</span> in <span class="ni">send</span><span class="nt">(self, data)</span>
<span class="g g-Whitespace">    </span><span class="mi">975</span>             <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">auto_open</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">976</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">connect</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">977</span>             <span class="k">else</span><span class="p">:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/http/client.py</span> in <span class="ni">connect</span><span class="nt">(self)</span>
<span class="g g-Whitespace">   </span><span class="mi">1450</span>             <span class="bp">self</span><span class="o">.</span><span class="n">sock</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_context</span><span class="o">.</span><span class="n">wrap_socket</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sock</span><span class="p">,</span>
<span class="ne">-&gt; </span><span class="mi">1451</span>                                                   <span class="n">server_hostname</span><span class="o">=</span><span class="n">server_hostname</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1452</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/ssl.py</span> in <span class="ni">wrap_socket</span><span class="nt">(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)</span>
<span class="g g-Whitespace">    </span><span class="mi">422</span>             <span class="n">context</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">423</span>             <span class="n">session</span><span class="o">=</span><span class="n">session</span>
<span class="g g-Whitespace">    </span><span class="mi">424</span>         <span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/ssl.py</span> in <span class="ni">_create</span><span class="nt">(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)</span>
<span class="g g-Whitespace">    </span><span class="mi">869</span>                         <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"do_handshake_on_connect should not be specified for non-blocking sockets"</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">870</span>                     <span class="bp">self</span><span class="o">.</span><span class="n">do_handshake</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">871</span>             <span class="k">except</span> <span class="p">(</span><span class="ne">OSError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/ssl.py</span> in <span class="ni">do_handshake</span><span class="nt">(self, block)</span>
<span class="g g-Whitespace">   </span><span class="mi">1138</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">settimeout</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1139</span>             <span class="bp">self</span><span class="o">.</span><span class="n">_sslobj</span><span class="o">.</span><span class="n">do_handshake</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1140</span>         <span class="k">finally</span><span class="p">:</span>

<span class="ne">SSLCertVerificationError</span>: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1091)

<span class="n">During</span> <span class="n">handling</span> <span class="n">of</span> <span class="n">the</span> <span class="n">above</span> <span class="n">exception</span><span class="p">,</span> <span class="n">another</span> <span class="n">exception</span> <span class="n">occurred</span><span class="p">:</span>

<span class="ne">URLError</span><span class="g g-Whitespace">                                  </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_3198</span><span class="o">/</span><span class="mf">1325464790.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># Download MNIST</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">downloadMNIST</span><span class="p">()</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> 
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mi">255</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mi">255</span>

<span class="nn">/tmp/ipykernel_3198/3487241110.py</span> in <span class="ni">downloadMNIST</span><span class="nt">()</span>
<span class="g g-Whitespace">     </span><span class="mi">15</span>     <span class="n">y_train</span> <span class="p">:</span> <span class="n">test</span> <span class="n">labels</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span>   <span class="s2">"""</span>
<span class="ne">---&gt; </span><span class="mi">17</span><span class="s2">   X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)</span>
<span class="g g-Whitespace">     </span><span class="mi">18</span><span class="s2">   # Trunk the data</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span><span class="s2">   n_train = 60000</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/sklearn/datasets/_openml.py</span> in <span class="ni">fetch_openml</span><span class="nt">(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame)</span>
<span class="g g-Whitespace">    </span><span class="mi">860</span><span class="s2">                 "both.".format(data_id, name)</span>
<span class="g g-Whitespace">    </span><span class="mi">861</span><span class="s2">             )</span>
<span class="ne">--&gt; </span><span class="mi">862</span><span class="s2">         data_info = _get_data_info_by_name(name, version, data_home)</span>
<span class="g g-Whitespace">    </span><span class="mi">863</span><span class="s2">         data_id = data_info["did"]</span>
<span class="g g-Whitespace">    </span><span class="mi">864</span><span class="s2">     elif data_id is not None:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/sklearn/datasets/_openml.py</span> in <span class="ni">_get_data_info_by_name</span><span class="nt">(name, version, data_home)</span>
<span class="g g-Whitespace">    </span><span class="mi">427</span><span class="s2">     try:</span>
<span class="g g-Whitespace">    </span><span class="mi">428</span><span class="s2">         json_data = _get_json_content_from_openml_api(</span>
<span class="ne">--&gt; </span><span class="mi">429</span><span class="s2">             url, error_message=None, data_home=data_home</span>
<span class="g g-Whitespace">    </span><span class="mi">430</span><span class="s2">         )</span>
<span class="g g-Whitespace">    </span><span class="mi">431</span><span class="s2">     except OpenMLError:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/sklearn/datasets/_openml.py</span> in <span class="ni">_get_json_content_from_openml_api</span><span class="nt">(url, error_message, data_home)</span>
<span class="g g-Whitespace">    </span><span class="mi">173</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">174</span><span class="s2">     try:</span>
<span class="ne">--&gt; </span><span class="mi">175</span><span class="s2">         return _load_json()</span>
<span class="g g-Whitespace">    </span><span class="mi">176</span><span class="s2">     except HTTPError as error:</span>
<span class="g g-Whitespace">    </span><span class="mi">177</span><span class="s2">         # 412 is an OpenML specific error code, indicating a generic error</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/sklearn/datasets/_openml.py</span> in <span class="ni">wrapper</span><span class="nt">(*args, **kw)</span>
<span class="g g-Whitespace">     </span><span class="mi">67</span><span class="s2">                 if os.path.exists(local_path):</span>
<span class="g g-Whitespace">     </span><span class="mi">68</span><span class="s2">                     os.unlink(local_path)</span>
<span class="ne">---&gt; </span><span class="mi">69</span><span class="s2">                 return f(*args, **kw)</span>
<span class="g g-Whitespace">     </span><span class="mi">70</span><span class="s2"> </span>
<span class="g g-Whitespace">     </span><span class="mi">71</span><span class="s2">         return wrapper</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/sklearn/datasets/_openml.py</span> in <span class="ni">_load_json</span><span class="nt">()</span>
<span class="g g-Whitespace">    </span><span class="mi">169</span><span class="s2">     @_retry_with_clean_cache(url, data_home)</span>
<span class="g g-Whitespace">    </span><span class="mi">170</span><span class="s2">     def _load_json():</span>
<span class="ne">--&gt; </span><span class="mi">171</span><span class="s2">         with closing(_open_openml_url(url, data_home)) as response:</span>
<span class="g g-Whitespace">    </span><span class="mi">172</span><span class="s2">             return json.loads(response.read().decode("utf-8"))</span>
<span class="g g-Whitespace">    </span><span class="mi">173</span><span class="s2"> </span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/site-packages/sklearn/datasets/_openml.py</span> in <span class="ni">_open_openml_url</span><span class="nt">(openml_path, data_home)</span>
<span class="g g-Whitespace">    </span><span class="mi">116</span><span class="s2">             # concurrence safety of the dataset caching mechanism.</span>
<span class="g g-Whitespace">    </span><span class="mi">117</span><span class="s2">             with TemporaryDirectory(dir=dir_name) as tmpdir:</span>
<span class="ne">--&gt; </span><span class="mi">118</span><span class="s2">                 with closing(urlopen(req)) as fsrc:</span>
<span class="g g-Whitespace">    </span><span class="mi">119</span><span class="s2">                     opener: Callable</span>
<span class="g g-Whitespace">    </span><span class="mi">120</span><span class="s2">                     if is_gzip_encoded(fsrc):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/urllib/request.py</span> in <span class="ni">urlopen</span><span class="nt">(url, data, timeout, cafile, capath, cadefault, context)</span>
<span class="g g-Whitespace">    </span><span class="mi">220</span><span class="s2">     else:</span>
<span class="g g-Whitespace">    </span><span class="mi">221</span><span class="s2">         opener = _opener</span>
<span class="ne">--&gt; </span><span class="mi">222</span><span class="s2">     return opener.open(url, data, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">223</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">224</span><span class="s2"> def install_opener(opener):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/urllib/request.py</span> in <span class="ni">open</span><span class="nt">(self, fullurl, data, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">523</span><span class="s2">             req = meth(req)</span>
<span class="g g-Whitespace">    </span><span class="mi">524</span><span class="s2"> </span>
<span class="ne">--&gt; </span><span class="mi">525</span><span class="s2">         response = self._open(req, data)</span>
<span class="g g-Whitespace">    </span><span class="mi">526</span><span class="s2"> </span>
<span class="g g-Whitespace">    </span><span class="mi">527</span><span class="s2">         # post-process response</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/urllib/request.py</span> in <span class="ni">_open</span><span class="nt">(self, req, data)</span>
<span class="g g-Whitespace">    </span><span class="mi">541</span><span class="s2">         protocol = req.type</span>
<span class="g g-Whitespace">    </span><span class="mi">542</span><span class="s2">         result = self._call_chain(self.handle_open, protocol, protocol +</span>
<span class="ne">--&gt; </span><span class="mi">543</span><span class="s2">                                   '_open', req)</span>
<span class="g g-Whitespace">    </span><span class="mi">544</span><span class="s2">         if result:</span>
<span class="g g-Whitespace">    </span><span class="mi">545</span><span class="s2">             return result</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/urllib/request.py</span> in <span class="ni">_call_chain</span><span class="nt">(self, chain, kind, meth_name, *args)</span>
<span class="g g-Whitespace">    </span><span class="mi">501</span><span class="s2">         for handler in handlers:</span>
<span class="g g-Whitespace">    </span><span class="mi">502</span><span class="s2">             func = getattr(handler, meth_name)</span>
<span class="ne">--&gt; </span><span class="mi">503</span><span class="s2">             result = func(*args)</span>
<span class="g g-Whitespace">    </span><span class="mi">504</span><span class="s2">             if result is not None:</span>
<span class="g g-Whitespace">    </span><span class="mi">505</span><span class="s2">                 return result</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/urllib/request.py</span> in <span class="ni">https_open</span><span class="nt">(self, req)</span>
<span class="g g-Whitespace">   </span><span class="mi">1391</span><span class="s2">         def https_open(self, req):</span>
<span class="g g-Whitespace">   </span><span class="mi">1392</span><span class="s2">             return self.do_open(http.client.HTTPSConnection, req,</span>
<span class="ne">-&gt; </span><span class="mi">1393</span><span class="s2">                 context=self._context, check_hostname=self._check_hostname)</span>
<span class="g g-Whitespace">   </span><span class="mi">1394</span><span class="s2"> </span>
<span class="g g-Whitespace">   </span><span class="mi">1395</span><span class="s2">         https_request = AbstractHTTPHandler.do_request_</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.13/x64/lib/python3.7/urllib/request.py</span> in <span class="ni">do_open</span><span class="nt">(self, http_class, req, **http_conn_args)</span>
<span class="g g-Whitespace">   </span><span class="mi">1350</span><span class="s2">                           encode_chunked=req.has_header('Transfer-encoding'))</span>
<span class="g g-Whitespace">   </span><span class="mi">1351</span><span class="s2">             except OSError as err: # timeout error</span>
<span class="ne">-&gt; </span><span class="mi">1352</span><span class="s2">                 raise URLError(err)</span>
<span class="g g-Whitespace">   </span><span class="mi">1353</span><span class="s2">             r = h.getresponse()</span>
<span class="g g-Whitespace">   </span><span class="mi">1354</span><span class="s2">         except:</span>

<span class="ne">URLError</span>: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1091)&gt;
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-deeper-autoencoder-2d">
<h1>Section 2: Deeper autoencoder (2D)<a class="headerlink" href="#section-2-deeper-autoencoder-2d" title="Permalink to this headline">¶</a></h1>
<p>The internal representation of shallow autoencoder with 2D latent space is similar to PCA, which shows that the autoencoder is not fully leveraging non-linear capabilities to model data. Adding capacity in terms of learnable parameters takes advantage of non-linear operations in encoding/decoding to capture non-linear patterns in data.</p>
<p>Adding hidden layers enables us to introduce additional parameters, either layerwise or depthwise. The same amount <span class="math notranslate nohighlight">\(N\)</span> of additional parameters can be added in a single layer or distributed among several layers. Adding several hidden layers reduces the compression/decompression ratio of each layer.</p>
<div class="section" id="exercise-1-build-deeper-autoencoder-2d">
<h2>Exercise 1: Build deeper autoencoder (2D)<a class="headerlink" href="#exercise-1-build-deeper-autoencoder-2d" title="Permalink to this headline">¶</a></h2>
<p>Implement this deeper version of the ANN autoencoder by adding four hidden layers. The number of units per layer in the encoder is the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">784</span> <span class="o">-&gt;</span> <span class="mi">392</span> <span class="o">-&gt;</span> <span class="mi">64</span> <span class="o">-&gt;</span> <span class="mi">2</span>
</pre></div>
</div>
<p>The shallow autoencoder has a compression ratio of <strong>784:2 = 392:1</strong>. The first additional hidden layer has a compression ratio of <strong>2:1</strong>,  followed by a hidden layer that sets the bottleneck compression ratio of <strong>32:1</strong>.</p>
<p>The choice of hidden layer size aims to reduce the compression rate in the bottleneck layer while increasing the count of trainable parameters.  For example, if the compression rate of the first hidden layer doubles from <strong>2:1</strong> to <strong>4:1</strong>, the count of trainable parameters halves from 667K to 333K.</p>
<p> </p>
<p>This deep autoencoder’s performance may be further improved by adding additional hidden layers and by increasing the count of trainable parameters in each layer. These improvements have a diminishing return due to challenges associated with training under high parameter count and depth. One option explored in the <em>Bonus</em> section is to add a first hidden layer with 2x - 3x the input size. This size increase results in millions of parameters at the cost of longer training time.</p>
<p> </p>
<p>Weight initialization is particularly important in deep networks. The availability of large datasets and weight initialization likely drove the deep learning revolution of 2010. We’ll implement Kaiming normal as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights_kaiming_normal</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Add four additional layers and activation functions to the network</p></li>
<li><p>Adjust the definitions of <code class="docutils literal notranslate"><span class="pre">encoder</span></code> and <code class="docutils literal notranslate"><span class="pre">decoder</span></code></p></li>
<li><p>Check learnable parameter count for this autoencoder by executing the last cell</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">),</span>
    <span class="c1">#################################################</span>
    <span class="c1">## TODO for students: add layers to build deeper autoencoder</span>
    <span class="c1">#################################################</span>
    <span class="c1"># Add activation function</span>
    <span class="c1"># ...,</span>
    <span class="c1"># Add another layer</span>
    <span class="c1"># nn.Linear(..., ...),</span>
    <span class="c1"># Add activation function</span>
    <span class="c1"># ...,</span>
    <span class="c1"># Add another layer</span>
    <span class="c1"># nn.Linear(..., ...),</span>
    <span class="c1"># Add activation function</span>
    <span class="c1"># ...,</span>
    <span class="c1"># Add another layer</span>
    <span class="c1"># nn.Linear(..., ...),</span>
    <span class="c1"># Add activation function</span>
    <span class="c1"># ...,</span>
    <span class="c1"># Add another layer</span>
    <span class="c1"># nn.Linear(..., ...),</span>
    <span class="c1"># Add activation function</span>
    <span class="c1"># ....</span>
    <span class="p">)</span>

<span class="n">model</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights_kaiming_normal</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Autoencoder </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># Adjust the value n_l to split your model correctly</span>
<span class="c1"># n_l = ...</span>

<span class="c1"># uncomment when you fill the code</span>
<span class="c1"># encoder = model[:n_l]</span>
<span class="c1"># decoder = model[n_l:]</span>
<span class="c1"># print(f'Encoder \n\n {encoder}\n')</span>
<span class="c1"># print(f'Decoder \n\n {decoder}')</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">),</span>
    <span class="c1"># Add activation function</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="c1"># Add another layer</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">,</span> <span class="n">encoding_size</span><span class="p">),</span>
    <span class="c1"># Add activation function</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="c1"># Add another layer</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span><span class="p">,</span> <span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">),</span>
    <span class="c1"># Add activation function</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="c1"># Add another layer</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="c1"># Add activation function</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="c1"># Add another layer</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">input_size</span><span class="p">),</span>
    <span class="c1"># Add activation function</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
    <span class="p">)</span>

<span class="n">model</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights_kaiming_normal</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Autoencoder </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># Adjust the value n_l to split your model correctly</span>
<span class="n">n_l</span> <span class="o">=</span> <span class="mi">6</span>

<span class="c1"># uncomment when you fill the code</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[:</span><span class="n">n_l</span><span class="p">]</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="n">n_l</span><span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Encoder </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">encoder</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Decoder </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">decoder</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<p><strong>Helper function:</strong> <code class="docutils literal notranslate"><span class="pre">print_parameter_count</span></code></p>
<p>Please uncomment the line below to inspect this function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># help(print_parameter_count)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="train-the-autoencoder">
<h2>Train the autoencoder<a class="headerlink" href="#train-the-autoencoder" title="Permalink to this headline">¶</a></h2>
<p>Train the network for <code class="docutils literal notranslate"><span class="pre">n_epochs=10</span></code> epochs with <code class="docutils literal notranslate"><span class="pre">batch_size=128</span></code>, and observe how the internal representation successfully captures additional digit classes.</p>
<p>The encoder map shows well-separated clusters that correspond to the associated digits in the decoder grid. The decoder grid also shows that the network is robust to digit skewness, i.e., digits leaning to the left or the right are recognized in the same digit class.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cells below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_train</span><span class="p">,</span> <span class="n">input_test</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
       <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>
  <span class="n">latent_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span> <span class="n">output_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">]],</span>
         <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">plot_latent_generative</span><span class="p">(</span><span class="n">latent_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-3-spherical-latent-space">
<h1>Section 3: Spherical latent space<a class="headerlink" href="#section-3-spherical-latent-space" title="Permalink to this headline">¶</a></h1>
<p>The previous architecture generates representations that typically spread in different directions from coordinate <span class="math notranslate nohighlight">\((z_1, z_2)=(0,0)\)</span>. This effect is due to the initialization of weights distributed randomly around <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p>
<p>Adding a third unit to the bottleneck layer defines a coordinate <span class="math notranslate nohighlight">\((z_1, z_2, z_3)\)</span> in 3D space. The latent space from such a network will still spread out from <span class="math notranslate nohighlight">\((z_1, z_2, z_3)=(0, 0, 0)\)</span>.</p>
<p>Collapsing the latent space on the surface of a sphere removes the possibility of spreading indefinitely from the origin <span class="math notranslate nohighlight">\((0, 0, 0)\)</span> in any direction since this will eventually lead back to the origin. This constraint generates a representation that fills the surface of the sphere.</p>
<br/>
<p><img alt="Unit sphere S2" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/unit_sphere.png"/></p>
<br/>
<p>Projecting to the surface of the sphere is implemented by dividing the coordinates <span class="math notranslate nohighlight">\((z_1, z_2, z_3)\)</span> by their <span class="math notranslate nohighlight">\(L_2\)</span> norm.</p>
<div class="amsmath math notranslate nohighlight" id="equation-8c2524de-29f1-409f-9f49-e2fce9a2b75d">
<span class="eqno">(135)<a class="headerlink" href="#equation-8c2524de-29f1-409f-9f49-e2fce9a2b75d" title="Permalink to this equation">¶</a></span>\[\begin{equation}
(z_1, z_2, z_3)\longmapsto (s_1, s_2, s_3)=(z_1, z_2, z_3)/\|(z_1, z_2, z_3)\|_2=(z_1, z_2, z_3)/ \sqrt{z_1^2+z_2^2+z_3^2}
\end{equation}\]</div>
<p>This mapping projects to the surface of the <a class="reference external" href="https://en.wikipedia.org/wiki/N-sphere"><span class="math notranslate nohighlight">\(S_2\)</span> sphere</a> with unit radius. (Why?)</p>
<div class="section" id="section-3-1-build-and-train-autoencoder-3d">
<h2>Section 3.1: Build and train autoencoder (3D)<a class="headerlink" href="#section-3-1-build-and-train-autoencoder-3d" title="Permalink to this headline">¶</a></h2>
<p>We start by adding one unit to the bottleneck layer and visualize the latent space in 3D.</p>
<p>Please execute the cell below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">,</span> <span class="n">encoding_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span><span class="p">,</span> <span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">input_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
    <span class="p">)</span>

<span class="n">model</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights_kaiming_normal</span><span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="mi">6</span><span class="p">:]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Autoencoder </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
</div>
<div class="section" id="section-3-2-train-the-autoencoder">
<h2>Section 3.2: Train the autoencoder<a class="headerlink" href="#section-3-2-train-the-autoencoder" title="Permalink to this headline">¶</a></h2>
<p>Train the network for <code class="docutils literal notranslate"><span class="pre">n_epochs=10</span></code> epochs with <code class="docutils literal notranslate"><span class="pre">batch_size=128</span></code>. Observe how the internal representation spreads from the origin and reaches much lower loss due to the additional degree of freedom in the bottleneck layer.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_train</span><span class="p">,</span> <span class="n">input_test</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
       <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
</div>
<div class="section" id="section-3-3-visualize-the-latent-space-in-3d">
<h2>Section 3.3: Visualize the latent space in 3D<a class="headerlink" href="#section-3-3-visualize-the-latent-space-in-3d" title="Permalink to this headline">¶</a></h2>
<p><strong>Helper function</strong>: <code class="docutils literal notranslate"><span class="pre">plot_latent_3d</span></code></p>
<p>Please uncomment the line below to inspect this function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># help(plot_latent_3d)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">latent_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_latent_3d</span><span class="p">(</span><span class="n">latent_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<div class="section" id="exercise-2-build-deep-autoencoder-2d-with-latent-spherical-space">
<h3>Exercise 2: Build deep autoencoder (2D) with latent spherical space<a class="headerlink" href="#exercise-2-build-deep-autoencoder-2d-with-latent-spherical-space" title="Permalink to this headline">¶</a></h3>
<p>We now constrain the latent space to the surface of a sphere <span class="math notranslate nohighlight">\(S_2\)</span>.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Add the custom layer <code class="docutils literal notranslate"><span class="pre">NormalizeLayer</span></code> after the bottleneck layer</p></li>
<li><p>Adjust the definitions of <code class="docutils literal notranslate"><span class="pre">encoder</span></code> and <code class="docutils literal notranslate"><span class="pre">decoder</span></code></p></li>
<li><p>Experiment with keyword <code class="docutils literal notranslate"><span class="pre">show_text=False</span></code> for <code class="docutils literal notranslate"><span class="pre">plot_latent_3d</span></code></p></li>
</ul>
<p><strong>Helper function</strong>: <code class="docutils literal notranslate"><span class="pre">NormalizeLayer</span></code></p>
<p>Please uncomment the line below to inspect this function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># help(NormalizeLayer)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">,</span> <span class="n">encoding_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="c1">#################################################</span>
    <span class="c1">## TODO for students: add custom normalize layer</span>
    <span class="c1">#################################################</span>
    <span class="c1"># add the normalization layer</span>
    <span class="c1"># ...,</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span><span class="p">,</span> <span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">input_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
    <span class="p">)</span>

<span class="n">model</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights_kaiming_normal</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Autoencoder </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># Adjust the value n_l to split your model correctly</span>
<span class="c1"># n_l = ...</span>

<span class="c1"># uncomment when you fill the code</span>
<span class="c1"># encoder = model[:n_l]</span>
<span class="c1"># decoder = model[n_l:]</span>
<span class="c1"># print(f'Encoder \n\n {encoder}\n')</span>
<span class="c1"># print(f'Decoder \n\n {decoder}')</span>

</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># to_remove solution</span>
<span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">,</span> <span class="n">encoding_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="c1"># add the normalization layer</span>
    <span class="n">NormalizeLayer</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span><span class="p">,</span> <span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">input_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
    <span class="p">)</span>

<span class="n">model</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights_kaiming_normal</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Autoencoder </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># Adjust the value n_l to split your model correctly</span>
<span class="n">n_l</span> <span class="o">=</span> <span class="mi">7</span>

<span class="c1"># uncomment when you fill the code</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[:</span><span class="n">n_l</span><span class="p">]</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="n">n_l</span><span class="p">:]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Encoder </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">encoder</span><span class="si">}</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Decoder </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">decoder</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
</div>
</div>
<div class="section" id="section-3-4-train-the-autoencoder">
<h2>Section 3.4: Train the autoencoder<a class="headerlink" href="#section-3-4-train-the-autoencoder" title="Permalink to this headline">¶</a></h2>
<p>Train the network for <code class="docutils literal notranslate"><span class="pre">n_epochs=10</span></code> epochs with <code class="docutils literal notranslate"><span class="pre">batch_size=128</span></code> and observe how loss raises again and is comparable to the model with 2D latent space.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_train</span><span class="p">,</span> <span class="n">input_test</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
       <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">latent_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_latent_3d</span><span class="p">(</span><span class="n">latent_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
</div>
<div class="section" id="section-3-5-visualize-latent-space-on-surface-of-s-2">
<h2>Section 3.5: Visualize latent space on surface of <span class="math notranslate nohighlight">\(S_2\)</span><a class="headerlink" href="#section-3-5-visualize-latent-space-on-surface-of-s-2" title="Permalink to this headline">¶</a></h2>
<p>The 3D coordinates <span class="math notranslate nohighlight">\((s_1, s_2, s_3)\)</span> on the surface of the unit sphere <span class="math notranslate nohighlight">\(S_2\)</span>  can be mapped to <a class="reference external" href="https://en.wikipedia.org/wiki/Spherical_coordinate_system">spherical coordinates</a> <span class="math notranslate nohighlight">\((r, \theta, \phi)\)</span>, as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-0388c271-3a80-4468-933e-c20ee309a4e2">
<span class="eqno">(136)<a class="headerlink" href="#equation-0388c271-3a80-4468-933e-c20ee309a4e2" title="Permalink to this equation">¶</a></span>\[\begin{align}
r &amp;= \sqrt{s_1^2 + s_2^2 + s_3^2} \\
\phi &amp;= \arctan \frac{s_2}{s_1} \\
\theta &amp;= \arccos\frac{s_3}{r}
\end{align}\]</div>
<p><img alt="Spherical coordinates" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/spherical_coords.png"/></p>
<p>What is the domain (numerical range) spanned by (<span class="math notranslate nohighlight">\(\theta, \phi)\)</span>?</p>
<p>We return to a 2D representation since the angles <span class="math notranslate nohighlight">\((\theta, \phi)\)</span> are the only degrees of freedom on the surface of the sphere. Add the keyword <code class="docutils literal notranslate"><span class="pre">s2=True</span></code> to <code class="docutils literal notranslate"><span class="pre">plot_latent_generative</span></code> to un-wrap the sphere’s surface similar to a world map.</p>
<p>Task: Check the numerical range of the plot axis to help identify <span class="math notranslate nohighlight">\(\theta\)</span> and <span class="math notranslate nohighlight">\(\phi\)</span>, and visualize the unfolding of the 3D plot from the previous exercise.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cells below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span> <span class="n">output_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">]],</span>
         <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">plot_latent_generative</span><span class="p">(</span><span class="n">latent_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span>
                       <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>

</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p>We learned two techniques to improve representation capacity: adding a few hidden layers and projecting latent space on the sphere <span class="math notranslate nohighlight">\(S_2\)</span>.</p>
<p>The expressive power of autoencoder improves with additional hidden layers. Projecting latent space on the surface of <span class="math notranslate nohighlight">\(S_2\)</span> spreads out digits classes in a more visually pleasing way but may not always produce a lower loss.</p>
<p><strong>Deep autoencoder architectures have rich internal representations to deal with sophisticated tasks such as the MNIST cognitive task.</strong></p>
<p>We now have powerful tools to explore how simple algorithms build robust models of the world by capturing relevant data patterns.</p>
<div class="section" id="video-2-wrap-up">
<h2>Video 2: Wrap-up<a class="headerlink" href="#video-2-wrap-up" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "f12a99279f80437b9d6d6717d3840c42"}
</script></div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="bonus">
<h1>Bonus<a class="headerlink" href="#bonus" title="Permalink to this headline">¶</a></h1>
<div class="section" id="deep-and-thick-autoencoder">
<h2>Deep and thick autoencoder<a class="headerlink" href="#deep-and-thick-autoencoder" title="Permalink to this headline">¶</a></h2>
<p>In this exercise, we first expand the first hidden layer to double the input size, followed by compression to half the input size leading to 3.8M parameters. Please <strong>do not train this network during tutorial</strong> due to long training time.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please uncomment and execute the cells below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># encoding_size = 3</span>

<span class="c1"># model = nn.Sequential(</span>
<span class="c1">#     nn.Linear(input_size, int(input_size * 2)),</span>
<span class="c1">#     nn.PReLU(),</span>
<span class="c1">#     nn.Linear(int(input_size * 2), int(input_size / 2)),</span>
<span class="c1">#     nn.PReLU(),</span>
<span class="c1">#     nn.Linear(int(input_size / 2), encoding_size * 32),</span>
<span class="c1">#     nn.PReLU(),</span>
<span class="c1">#     nn.Linear(encoding_size * 32, encoding_size),</span>
<span class="c1">#     nn.PReLU(),</span>
<span class="c1">#     NormalizeLayer(),</span>
<span class="c1">#     nn.Linear(encoding_size, encoding_size * 32),</span>
<span class="c1">#     nn.PReLU(),</span>
<span class="c1">#     nn.Linear(encoding_size * 32, int(input_size / 2)),</span>
<span class="c1">#     nn.PReLU(),</span>
<span class="c1">#     nn.Linear(int(input_size / 2), int(input_size * 2)),</span>
<span class="c1">#     nn.PReLU(),</span>
<span class="c1">#     nn.Linear(int(input_size * 2), input_size),</span>
<span class="c1">#     nn.Sigmoid()</span>
<span class="c1">#     )</span>

<span class="c1"># model[:-2].apply(init_weights_kaiming_normal)</span>

<span class="c1"># encoder = model[:9]</span>
<span class="c1"># decoder = model[9:]</span>

<span class="c1"># print_parameter_count(model)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># n_epochs = 5</span>
<span class="c1"># batch_size = 128</span>

<span class="c1"># runSGD(model, input_train, input_test, n_epochs=n_epochs,</span>
<span class="c1">#        batch_size=batch_size)</span>

<span class="c1"># Visualization</span>
<span class="c1"># with torch.no_grad():</span>
<span class="c1">#   output_test = model(input_test)</span>

<span class="c1"># plot_row([input_test[test_selected_idx], output_test[test_selected_idx]],</span>
<span class="c1">#          image_shape=image_shape)</span>

<span class="c1"># plot_latent_generative(latent_test, y_test, decoder,</span>
<span class="c1">#                        image_shape=image_shape, s2=True)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<script type="application/vnd.jupyter.widget-state+json">
{"state": {"4d3200271aa842fd931a63154527bf29": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "0feda56945154da1897b506f6d73e72e": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_4d3200271aa842fd931a63154527bf29", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/BV175411a7j9\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7f34acb01ad0>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV175411a7j9&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "13a58f3f1e0d46349192c8129dc5612f": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "137feebb99a14d28bae6445fbe16d86b": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_13a58f3f1e0d46349192c8129dc5612f", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=pgkrU9UqXiU\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f34aca5ce90>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/pgkrU9UqXiU?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "ef26d15c81a0467aaa49bd4bf71c7c81": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ba378ed8545c4aeeacce788212a544cb": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_137feebb99a14d28bae6445fbe16d86b", "IPY_MODEL_0feda56945154da1897b506f6d73e72e"], "layout": "IPY_MODEL_ef26d15c81a0467aaa49bd4bf71c7c81", "selected_index": 0}}, "9b09810930f143e39dbda19beb2588fe": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "4ca06afb3fee4678b32386186e67aada": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_9b09810930f143e39dbda19beb2588fe", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://www.bilibili.com/video/BV1ED4y1U7DK\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<__main__.BiliVideo at 0x7f341af6c550>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://player.bilibili.com/player.html?bvid=BV1ED4y1U7DK&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "}}]}}, "06172770401f49a0ae16ff94c89542bf": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "2a126b89b151471dbcbf0f4fd1a70727": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_06172770401f49a0ae16ff94c89542bf", "msg_id": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Video available at https://youtube.com/watch?v=GnkmzCqEK3E\n"}, {"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f34acaf6dd0>", "text/html": "\n        <iframe\n            width=\"730\"\n            height=\"410\"\n            src=\"https://www.youtube.com/embed/GnkmzCqEK3E?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ", "image/jpeg": "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\n"}}]}}, "6b4c52682c3d4df1b9af854a68537a7f": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f12a99279f80437b9d6d6717d3840c42": {"model_name": "TabModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "TabModel", "_titles": {"0": "Youtube", "1": "Bilibili"}, "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "TabView", "box_style": "", "children": ["IPY_MODEL_2a126b89b151471dbcbf0f4fd1a70727", "IPY_MODEL_4ca06afb3fee4678b32386186e67aada"], "layout": "IPY_MODEL_6b4c52682c3d4df1b9af854a68537a7f", "selected_index": 0}}}, "version_major": 2, "version_minor": 0}
</script>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/Bonus_Autoencoders/instructor"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
</main>
<footer class="footer-article noprint">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="Bonus_Tutorial1.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Tutorial 1: Intro to Autoencoders</p>
</div>
</a>
<a class="right-next" href="Bonus_Tutorial3.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Tutorial 3: Autoencoders applications</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</footer>
</div>
</div>
<div class="footer-content row">
<footer class="col footer"><p>
  
    By Neuromatch<br>
  
      © Copyright 2021.<br>
</br></br></p>
</footer>
</div>
</div>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
</body>
</html>