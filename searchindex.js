Search.setIndex({"docnames": ["prereqs/ComputationalNeuroscience", "projects/ECoG/ECoG_videos", "projects/ECoG/README", "projects/README", "projects/behavior/README", "projects/behavior/behavior_videos", "projects/docs/ECoG", "projects/docs/behavior", "projects/docs/datasets_overview", "projects/docs/fMRI", "projects/docs/neurons", "projects/docs/project_2020_highlights", "projects/docs/project_guidance", "projects/docs/project_templates", "projects/docs/projects_2020/behavior", "projects/docs/projects_2020/eeg", "projects/docs/projects_2020/fMRI", "projects/docs/projects_2020/neurons", "projects/docs/projects_2020/theory", "projects/docs/theory", "projects/fMRI/README", "projects/fMRI/fMRI_videos", "projects/modelingsteps/ModelingSteps_1through4", "projects/modelingsteps/ModelingSteps_5through10", "projects/modelingsteps/TrainIllusionDataProject", "projects/modelingsteps/TrainIllusionModel", "projects/modelingsteps/intro", "projects/neurons/README", "projects/neurons/neurons_videos", "projects/theory/README", "tatraining/TA_Training_CN", "tutorials/Bonus_Autoencoders/chapter_title", "tutorials/Bonus_Autoencoders/instructor/Bonus_Intro", "tutorials/Bonus_Autoencoders/instructor/Bonus_Outro", "tutorials/Bonus_Autoencoders/instructor/Bonus_Tutorial1", "tutorials/Bonus_Autoencoders/instructor/Bonus_Tutorial2", "tutorials/Bonus_Autoencoders/instructor/Bonus_Tutorial3", "tutorials/Module_WrapUps/DynamicalSystems", "tutorials/Module_WrapUps/MachineLearning", "tutorials/Module_WrapUps/StochasticProcesses", "tutorials/Schedule/daily_schedules", "tutorials/Schedule/schedule_intro", "tutorials/Schedule/shared_calendars", "tutorials/Schedule/timezone_widget", "tutorials/TechnicalHelp/Discord", "tutorials/TechnicalHelp/Jupyterbook", "tutorials/TechnicalHelp/Links_Policy", "tutorials/TechnicalHelp/Tutorial_colab", "tutorials/TechnicalHelp/Tutorial_kaggle", "tutorials/TechnicalHelp/tech_intro", "tutorials/W0D0_NeuroVideoSeries/chapter_title", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial1", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial10", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial11", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial12", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial2", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial3", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial4", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial5", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial6", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial7", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial8", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial9", "tutorials/W0D1_PythonWorkshop1/chapter_title", "tutorials/W0D1_PythonWorkshop1/instructor/W0D1_Tutorial1", "tutorials/W0D2_PythonWorkshop2/chapter_title", "tutorials/W0D2_PythonWorkshop2/instructor/W0D2_Tutorial1", "tutorials/W0D3_LinearAlgebra/chapter_title", "tutorials/W0D3_LinearAlgebra/instructor/W0D3_DaySummary", "tutorials/W0D3_LinearAlgebra/instructor/W0D3_Outro", "tutorials/W0D3_LinearAlgebra/instructor/W0D3_Tutorial1", "tutorials/W0D3_LinearAlgebra/instructor/W0D3_Tutorial2", "tutorials/W0D3_LinearAlgebra/instructor/W0D3_Tutorial3", "tutorials/W0D4_Calculus/chapter_title", "tutorials/W0D4_Calculus/instructor/W0D4_DaySummary", "tutorials/W0D4_Calculus/instructor/W0D4_Tutorial1", "tutorials/W0D4_Calculus/instructor/W0D4_Tutorial2", "tutorials/W0D4_Calculus/instructor/W0D4_Tutorial3", "tutorials/W0D5_Statistics/chapter_title", "tutorials/W0D5_Statistics/instructor/W0D5_DaySummary", "tutorials/W0D5_Statistics/instructor/W0D5_Outro", "tutorials/W0D5_Statistics/instructor/W0D5_Tutorial1", "tutorials/W0D5_Statistics/instructor/W0D5_Tutorial2", "tutorials/W1D1_ModelTypes/chapter_title", "tutorials/W1D1_ModelTypes/further_reading", "tutorials/W1D1_ModelTypes/instructor/W1D1_DaySummary", "tutorials/W1D1_ModelTypes/instructor/W1D1_Intro", "tutorials/W1D1_ModelTypes/instructor/W1D1_Outro", "tutorials/W1D1_ModelTypes/instructor/W1D1_Tutorial1", "tutorials/W1D1_ModelTypes/instructor/W1D1_Tutorial2", "tutorials/W1D1_ModelTypes/instructor/W1D1_Tutorial3", "tutorials/W1D1_ModelTypes/instructor/W1D1_Tutorial4", "tutorials/W1D2_ModelFitting/chapter_title", "tutorials/W1D2_ModelFitting/further_reading", "tutorials/W1D2_ModelFitting/instructor/W1D2_DaySummary", "tutorials/W1D2_ModelFitting/instructor/W1D2_Intro", "tutorials/W1D2_ModelFitting/instructor/W1D2_Outro", "tutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial1", "tutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial2", "tutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial3", "tutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial4", "tutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial5", "tutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial6", "tutorials/W1D3_GeneralizedLinearModels/chapter_title", "tutorials/W1D3_GeneralizedLinearModels/further_reading", "tutorials/W1D3_GeneralizedLinearModels/instructor/W1D3_DaySummary", "tutorials/W1D3_GeneralizedLinearModels/instructor/W1D3_Intro", "tutorials/W1D3_GeneralizedLinearModels/instructor/W1D3_Outro", "tutorials/W1D3_GeneralizedLinearModels/instructor/W1D3_Tutorial1", "tutorials/W1D3_GeneralizedLinearModels/instructor/W1D3_Tutorial2", "tutorials/W1D4_DimensionalityReduction/chapter_title", "tutorials/W1D4_DimensionalityReduction/further_reading", "tutorials/W1D4_DimensionalityReduction/instructor/W1D4_DaySummary", "tutorials/W1D4_DimensionalityReduction/instructor/W1D4_Intro", "tutorials/W1D4_DimensionalityReduction/instructor/W1D4_Outro", "tutorials/W1D4_DimensionalityReduction/instructor/W1D4_Tutorial1", "tutorials/W1D4_DimensionalityReduction/instructor/W1D4_Tutorial2", "tutorials/W1D4_DimensionalityReduction/instructor/W1D4_Tutorial3", "tutorials/W1D4_DimensionalityReduction/instructor/W1D4_Tutorial4", "tutorials/W1D5_DeepLearning/chapter_title", "tutorials/W1D5_DeepLearning/further_reading", "tutorials/W1D5_DeepLearning/instructor/W1D5_DaySummary", "tutorials/W1D5_DeepLearning/instructor/W1D5_Intro", "tutorials/W1D5_DeepLearning/instructor/W1D5_Outro", "tutorials/W1D5_DeepLearning/instructor/W1D5_Tutorial1", "tutorials/W1D5_DeepLearning/instructor/W1D5_Tutorial2", "tutorials/W1D5_DeepLearning/instructor/W1D5_Tutorial3", "tutorials/W1D5_DeepLearning/instructor/W1D5_Tutorial4", "tutorials/W2D1_ModelingPractice/chapter_title", "tutorials/W2D1_ModelingPractice/instructor/W2D1_DaySummary", "tutorials/W2D1_ModelingPractice/instructor/W2D1_Intro", "tutorials/W2D1_ModelingPractice/instructor/W2D1_Outro", "tutorials/W2D1_ModelingPractice/instructor/W2D1_Tutorial1", "tutorials/W2D2_LinearSystems/chapter_title", "tutorials/W2D2_LinearSystems/further_reading", "tutorials/W2D2_LinearSystems/instructor/W2D2_DaySummary", "tutorials/W2D2_LinearSystems/instructor/W2D2_Intro", "tutorials/W2D2_LinearSystems/instructor/W2D2_Outro", "tutorials/W2D2_LinearSystems/instructor/W2D2_Tutorial1", "tutorials/W2D2_LinearSystems/instructor/W2D2_Tutorial2", "tutorials/W2D2_LinearSystems/instructor/W2D2_Tutorial3", "tutorials/W2D2_LinearSystems/instructor/W2D2_Tutorial4", "tutorials/W2D3_BiologicalNeuronModels/chapter_title", "tutorials/W2D3_BiologicalNeuronModels/further_reading", "tutorials/W2D3_BiologicalNeuronModels/instructor/W2D3_DaySummary", "tutorials/W2D3_BiologicalNeuronModels/instructor/W2D3_Intro", "tutorials/W2D3_BiologicalNeuronModels/instructor/W2D3_Outro", "tutorials/W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial1", "tutorials/W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial2", "tutorials/W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial3", "tutorials/W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial4", "tutorials/W2D4_DynamicNetworks/chapter_title", "tutorials/W2D4_DynamicNetworks/further_reading", "tutorials/W2D4_DynamicNetworks/instructor/W2D4_DaySummary", "tutorials/W2D4_DynamicNetworks/instructor/W2D4_Intro", "tutorials/W2D4_DynamicNetworks/instructor/W2D4_Outro", "tutorials/W2D4_DynamicNetworks/instructor/W2D4_Tutorial1", "tutorials/W2D4_DynamicNetworks/instructor/W2D4_Tutorial2", "tutorials/W2D4_DynamicNetworks/instructor/W2D4_Tutorial3", "tutorials/W3D1_BayesianDecisions/chapter_title", "tutorials/W3D1_BayesianDecisions/further_reading", "tutorials/W3D1_BayesianDecisions/instructor/W3D1_DaySummary", "tutorials/W3D1_BayesianDecisions/instructor/W3D1_Intro", "tutorials/W3D1_BayesianDecisions/instructor/W3D1_Outro", "tutorials/W3D1_BayesianDecisions/instructor/W3D1_Tutorial1", "tutorials/W3D1_BayesianDecisions/instructor/W3D1_Tutorial2", "tutorials/W3D1_BayesianDecisions/instructor/W3D1_Tutorial3", "tutorials/W3D2_HiddenDynamics/chapter_title", "tutorials/W3D2_HiddenDynamics/further_reading", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_DaySummary", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_Intro", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_Outro", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_Tutorial1", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_Tutorial2", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_Tutorial3", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_Tutorial4", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_Tutorial5", "tutorials/W3D3_OptimalControl/chapter_title", "tutorials/W3D3_OptimalControl/further_reading", "tutorials/W3D3_OptimalControl/instructor/W3D3_DaySummary", "tutorials/W3D3_OptimalControl/instructor/W3D3_Intro", "tutorials/W3D3_OptimalControl/instructor/W3D3_Outro", "tutorials/W3D3_OptimalControl/instructor/W3D3_Tutorial1", "tutorials/W3D3_OptimalControl/instructor/W3D3_Tutorial2", "tutorials/W3D4_ReinforcementLearning/chapter_title", "tutorials/W3D4_ReinforcementLearning/further_reading", "tutorials/W3D4_ReinforcementLearning/instructor/W3D4_DaySummary", "tutorials/W3D4_ReinforcementLearning/instructor/W3D4_Intro", "tutorials/W3D4_ReinforcementLearning/instructor/W3D4_Outro", "tutorials/W3D4_ReinforcementLearning/instructor/W3D4_Tutorial1", "tutorials/W3D4_ReinforcementLearning/instructor/W3D4_Tutorial2", "tutorials/W3D4_ReinforcementLearning/instructor/W3D4_Tutorial3", "tutorials/W3D4_ReinforcementLearning/instructor/W3D4_Tutorial4", "tutorials/W3D5_NetworkCausality/chapter_title", "tutorials/W3D5_NetworkCausality/further_reading", "tutorials/W3D5_NetworkCausality/instructor/W3D5_DaySummary", "tutorials/W3D5_NetworkCausality/instructor/W3D5_Intro", "tutorials/W3D5_NetworkCausality/instructor/W3D5_Outro", "tutorials/W3D5_NetworkCausality/instructor/W3D5_Tutorial1", "tutorials/W3D5_NetworkCausality/instructor/W3D5_Tutorial2", "tutorials/W3D5_NetworkCausality/instructor/W3D5_Tutorial3", "tutorials/W3D5_NetworkCausality/instructor/W3D5_Tutorial4", "tutorials/intro"], "filenames": ["prereqs/ComputationalNeuroscience.md", "projects/ECoG/ECoG_videos.ipynb", "projects/ECoG/README.md", "projects/README.md", "projects/behavior/README.md", "projects/behavior/behavior_videos.ipynb", "projects/docs/ECoG.md", "projects/docs/behavior.md", "projects/docs/datasets_overview.md", "projects/docs/fMRI.md", "projects/docs/neurons.md", "projects/docs/project_2020_highlights.md", "projects/docs/project_guidance.md", "projects/docs/project_templates.md", "projects/docs/projects_2020/behavior.md", "projects/docs/projects_2020/eeg.md", "projects/docs/projects_2020/fMRI.md", "projects/docs/projects_2020/neurons.md", "projects/docs/projects_2020/theory.md", "projects/docs/theory.md", "projects/fMRI/README.md", "projects/fMRI/fMRI_videos.ipynb", "projects/modelingsteps/ModelingSteps_1through4.ipynb", "projects/modelingsteps/ModelingSteps_5through10.ipynb", "projects/modelingsteps/TrainIllusionDataProject.ipynb", "projects/modelingsteps/TrainIllusionModel.ipynb", "projects/modelingsteps/intro.md", "projects/neurons/README.md", "projects/neurons/neurons_videos.ipynb", "projects/theory/README.md", "tatraining/TA_Training_CN.ipynb", "tutorials/Bonus_Autoencoders/chapter_title.md", "tutorials/Bonus_Autoencoders/instructor/Bonus_Intro.ipynb", "tutorials/Bonus_Autoencoders/instructor/Bonus_Outro.ipynb", "tutorials/Bonus_Autoencoders/instructor/Bonus_Tutorial1.ipynb", "tutorials/Bonus_Autoencoders/instructor/Bonus_Tutorial2.ipynb", "tutorials/Bonus_Autoencoders/instructor/Bonus_Tutorial3.ipynb", "tutorials/Module_WrapUps/DynamicalSystems.ipynb", "tutorials/Module_WrapUps/MachineLearning.ipynb", "tutorials/Module_WrapUps/StochasticProcesses.ipynb", "tutorials/Schedule/daily_schedules.md", "tutorials/Schedule/schedule_intro.md", "tutorials/Schedule/shared_calendars.md", "tutorials/Schedule/timezone_widget.md", "tutorials/TechnicalHelp/Discord.md", "tutorials/TechnicalHelp/Jupyterbook.md", "tutorials/TechnicalHelp/Links_Policy.md", "tutorials/TechnicalHelp/Tutorial_colab.md", "tutorials/TechnicalHelp/Tutorial_kaggle.md", "tutorials/TechnicalHelp/tech_intro.md", "tutorials/W0D0_NeuroVideoSeries/chapter_title.md", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial1.ipynb", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial10.ipynb", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial11.ipynb", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial12.ipynb", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial2.ipynb", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial3.ipynb", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial4.ipynb", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial5.ipynb", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial6.ipynb", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial7.ipynb", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial8.ipynb", "tutorials/W0D0_NeuroVideoSeries/instructor/W0D0_Tutorial9.ipynb", "tutorials/W0D1_PythonWorkshop1/chapter_title.md", "tutorials/W0D1_PythonWorkshop1/instructor/W0D1_Tutorial1.ipynb", "tutorials/W0D2_PythonWorkshop2/chapter_title.md", "tutorials/W0D2_PythonWorkshop2/instructor/W0D2_Tutorial1.ipynb", "tutorials/W0D3_LinearAlgebra/chapter_title.md", "tutorials/W0D3_LinearAlgebra/instructor/W0D3_DaySummary.ipynb", "tutorials/W0D3_LinearAlgebra/instructor/W0D3_Outro.ipynb", "tutorials/W0D3_LinearAlgebra/instructor/W0D3_Tutorial1.ipynb", "tutorials/W0D3_LinearAlgebra/instructor/W0D3_Tutorial2.ipynb", "tutorials/W0D3_LinearAlgebra/instructor/W0D3_Tutorial3.ipynb", "tutorials/W0D4_Calculus/chapter_title.md", "tutorials/W0D4_Calculus/instructor/W0D4_DaySummary.ipynb", "tutorials/W0D4_Calculus/instructor/W0D4_Tutorial1.ipynb", "tutorials/W0D4_Calculus/instructor/W0D4_Tutorial2.ipynb", "tutorials/W0D4_Calculus/instructor/W0D4_Tutorial3.ipynb", "tutorials/W0D5_Statistics/chapter_title.md", "tutorials/W0D5_Statistics/instructor/W0D5_DaySummary.ipynb", "tutorials/W0D5_Statistics/instructor/W0D5_Outro.ipynb", "tutorials/W0D5_Statistics/instructor/W0D5_Tutorial1.ipynb", "tutorials/W0D5_Statistics/instructor/W0D5_Tutorial2.ipynb", "tutorials/W1D1_ModelTypes/chapter_title.md", "tutorials/W1D1_ModelTypes/further_reading.md", "tutorials/W1D1_ModelTypes/instructor/W1D1_DaySummary.ipynb", "tutorials/W1D1_ModelTypes/instructor/W1D1_Intro.ipynb", "tutorials/W1D1_ModelTypes/instructor/W1D1_Outro.ipynb", "tutorials/W1D1_ModelTypes/instructor/W1D1_Tutorial1.ipynb", "tutorials/W1D1_ModelTypes/instructor/W1D1_Tutorial2.ipynb", "tutorials/W1D1_ModelTypes/instructor/W1D1_Tutorial3.ipynb", "tutorials/W1D1_ModelTypes/instructor/W1D1_Tutorial4.ipynb", "tutorials/W1D2_ModelFitting/chapter_title.md", "tutorials/W1D2_ModelFitting/further_reading.md", "tutorials/W1D2_ModelFitting/instructor/W1D2_DaySummary.ipynb", "tutorials/W1D2_ModelFitting/instructor/W1D2_Intro.ipynb", "tutorials/W1D2_ModelFitting/instructor/W1D2_Outro.ipynb", "tutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial1.ipynb", "tutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial2.ipynb", "tutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial3.ipynb", "tutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial4.ipynb", "tutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial5.ipynb", "tutorials/W1D2_ModelFitting/instructor/W1D2_Tutorial6.ipynb", "tutorials/W1D3_GeneralizedLinearModels/chapter_title.md", "tutorials/W1D3_GeneralizedLinearModels/further_reading.md", "tutorials/W1D3_GeneralizedLinearModels/instructor/W1D3_DaySummary.ipynb", "tutorials/W1D3_GeneralizedLinearModels/instructor/W1D3_Intro.ipynb", "tutorials/W1D3_GeneralizedLinearModels/instructor/W1D3_Outro.ipynb", "tutorials/W1D3_GeneralizedLinearModels/instructor/W1D3_Tutorial1.ipynb", "tutorials/W1D3_GeneralizedLinearModels/instructor/W1D3_Tutorial2.ipynb", "tutorials/W1D4_DimensionalityReduction/chapter_title.md", "tutorials/W1D4_DimensionalityReduction/further_reading.md", "tutorials/W1D4_DimensionalityReduction/instructor/W1D4_DaySummary.ipynb", "tutorials/W1D4_DimensionalityReduction/instructor/W1D4_Intro.ipynb", "tutorials/W1D4_DimensionalityReduction/instructor/W1D4_Outro.ipynb", "tutorials/W1D4_DimensionalityReduction/instructor/W1D4_Tutorial1.ipynb", "tutorials/W1D4_DimensionalityReduction/instructor/W1D4_Tutorial2.ipynb", "tutorials/W1D4_DimensionalityReduction/instructor/W1D4_Tutorial3.ipynb", "tutorials/W1D4_DimensionalityReduction/instructor/W1D4_Tutorial4.ipynb", "tutorials/W1D5_DeepLearning/chapter_title.md", "tutorials/W1D5_DeepLearning/further_reading.md", "tutorials/W1D5_DeepLearning/instructor/W1D5_DaySummary.ipynb", "tutorials/W1D5_DeepLearning/instructor/W1D5_Intro.ipynb", "tutorials/W1D5_DeepLearning/instructor/W1D5_Outro.ipynb", "tutorials/W1D5_DeepLearning/instructor/W1D5_Tutorial1.ipynb", "tutorials/W1D5_DeepLearning/instructor/W1D5_Tutorial2.ipynb", "tutorials/W1D5_DeepLearning/instructor/W1D5_Tutorial3.ipynb", "tutorials/W1D5_DeepLearning/instructor/W1D5_Tutorial4.ipynb", "tutorials/W2D1_ModelingPractice/chapter_title.md", "tutorials/W2D1_ModelingPractice/instructor/W2D1_DaySummary.ipynb", "tutorials/W2D1_ModelingPractice/instructor/W2D1_Intro.ipynb", "tutorials/W2D1_ModelingPractice/instructor/W2D1_Outro.ipynb", "tutorials/W2D1_ModelingPractice/instructor/W2D1_Tutorial1.ipynb", "tutorials/W2D2_LinearSystems/chapter_title.md", "tutorials/W2D2_LinearSystems/further_reading.md", "tutorials/W2D2_LinearSystems/instructor/W2D2_DaySummary.ipynb", "tutorials/W2D2_LinearSystems/instructor/W2D2_Intro.ipynb", "tutorials/W2D2_LinearSystems/instructor/W2D2_Outro.ipynb", "tutorials/W2D2_LinearSystems/instructor/W2D2_Tutorial1.ipynb", "tutorials/W2D2_LinearSystems/instructor/W2D2_Tutorial2.ipynb", "tutorials/W2D2_LinearSystems/instructor/W2D2_Tutorial3.ipynb", "tutorials/W2D2_LinearSystems/instructor/W2D2_Tutorial4.ipynb", "tutorials/W2D3_BiologicalNeuronModels/chapter_title.md", "tutorials/W2D3_BiologicalNeuronModels/further_reading.md", "tutorials/W2D3_BiologicalNeuronModels/instructor/W2D3_DaySummary.ipynb", "tutorials/W2D3_BiologicalNeuronModels/instructor/W2D3_Intro.ipynb", "tutorials/W2D3_BiologicalNeuronModels/instructor/W2D3_Outro.ipynb", "tutorials/W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial1.ipynb", "tutorials/W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial2.ipynb", "tutorials/W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial3.ipynb", "tutorials/W2D3_BiologicalNeuronModels/instructor/W2D3_Tutorial4.ipynb", "tutorials/W2D4_DynamicNetworks/chapter_title.md", "tutorials/W2D4_DynamicNetworks/further_reading.md", "tutorials/W2D4_DynamicNetworks/instructor/W2D4_DaySummary.ipynb", "tutorials/W2D4_DynamicNetworks/instructor/W2D4_Intro.ipynb", "tutorials/W2D4_DynamicNetworks/instructor/W2D4_Outro.ipynb", "tutorials/W2D4_DynamicNetworks/instructor/W2D4_Tutorial1.ipynb", "tutorials/W2D4_DynamicNetworks/instructor/W2D4_Tutorial2.ipynb", "tutorials/W2D4_DynamicNetworks/instructor/W2D4_Tutorial3.ipynb", "tutorials/W3D1_BayesianDecisions/chapter_title.md", "tutorials/W3D1_BayesianDecisions/further_reading.md", "tutorials/W3D1_BayesianDecisions/instructor/W3D1_DaySummary.ipynb", "tutorials/W3D1_BayesianDecisions/instructor/W3D1_Intro.ipynb", "tutorials/W3D1_BayesianDecisions/instructor/W3D1_Outro.ipynb", "tutorials/W3D1_BayesianDecisions/instructor/W3D1_Tutorial1.ipynb", "tutorials/W3D1_BayesianDecisions/instructor/W3D1_Tutorial2.ipynb", "tutorials/W3D1_BayesianDecisions/instructor/W3D1_Tutorial3.ipynb", "tutorials/W3D2_HiddenDynamics/chapter_title.md", "tutorials/W3D2_HiddenDynamics/further_reading.md", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_DaySummary.ipynb", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_Intro.ipynb", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_Outro.ipynb", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_Tutorial1.ipynb", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_Tutorial2.ipynb", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_Tutorial3.ipynb", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_Tutorial4.ipynb", "tutorials/W3D2_HiddenDynamics/instructor/W3D2_Tutorial5.ipynb", "tutorials/W3D3_OptimalControl/chapter_title.md", "tutorials/W3D3_OptimalControl/further_reading.md", "tutorials/W3D3_OptimalControl/instructor/W3D3_DaySummary.ipynb", "tutorials/W3D3_OptimalControl/instructor/W3D3_Intro.ipynb", "tutorials/W3D3_OptimalControl/instructor/W3D3_Outro.ipynb", "tutorials/W3D3_OptimalControl/instructor/W3D3_Tutorial1.ipynb", "tutorials/W3D3_OptimalControl/instructor/W3D3_Tutorial2.ipynb", "tutorials/W3D4_ReinforcementLearning/chapter_title.md", "tutorials/W3D4_ReinforcementLearning/further_reading.md", "tutorials/W3D4_ReinforcementLearning/instructor/W3D4_DaySummary.ipynb", "tutorials/W3D4_ReinforcementLearning/instructor/W3D4_Intro.ipynb", "tutorials/W3D4_ReinforcementLearning/instructor/W3D4_Outro.ipynb", "tutorials/W3D4_ReinforcementLearning/instructor/W3D4_Tutorial1.ipynb", "tutorials/W3D4_ReinforcementLearning/instructor/W3D4_Tutorial2.ipynb", "tutorials/W3D4_ReinforcementLearning/instructor/W3D4_Tutorial3.ipynb", "tutorials/W3D4_ReinforcementLearning/instructor/W3D4_Tutorial4.ipynb", "tutorials/W3D5_NetworkCausality/chapter_title.md", "tutorials/W3D5_NetworkCausality/further_reading.md", "tutorials/W3D5_NetworkCausality/instructor/W3D5_DaySummary.ipynb", "tutorials/W3D5_NetworkCausality/instructor/W3D5_Intro.ipynb", "tutorials/W3D5_NetworkCausality/instructor/W3D5_Outro.ipynb", "tutorials/W3D5_NetworkCausality/instructor/W3D5_Tutorial1.ipynb", "tutorials/W3D5_NetworkCausality/instructor/W3D5_Tutorial2.ipynb", "tutorials/W3D5_NetworkCausality/instructor/W3D5_Tutorial3.ipynb", "tutorials/W3D5_NetworkCausality/instructor/W3D5_Tutorial4.ipynb", "tutorials/intro.ipynb"], "titles": ["Prerequisites and preparatory materials for NMA Computational Neuroscience", "Overview videos", "Guide to choosing an EEG/ECoG/LFP dataset", "Projects", "Guide to choosing a Behavior dataset", "Overview videos", "ECoG", "Behavior", "Datasets", "fMRI", "Neurons", "Projects 2020", "Daily guide for projects", "Project Templates", "Behavior", "EEG", "fMRI", "Neurons", "Theory", "Theory", "Guide to choosing an FMRI dataset", "Overview videos", "Modeling Steps 1 - 4", "Modeling Steps 5 - 10", "Example Data Project: the Train Illusion", "Example Model Project: the Train Illusion", "Modeling Step-by-Step Guide", "Guide to choosing a Neurons dataset", "Overview videos", "Guide to choosing a Theory project", "TA Training: Computational Neuroscience (CN)", "Autoencoders", "Intro", "Outro", "Tutorial 1: Intro to Autoencoders", "Tutorial 2: Autoencoder extensions", "Tutorial 3: Autoencoders applications", "Dynamical Systems Wrap-Up", "Machine Learning Wrap-Up", "Stochastic Processes Wrap-Up", "General schedule", "Schedule", "Shared calendars", "Timezone widget", "Using discord", "Using jupyterbook", "Quick links and policies", "Using Google Colab", "Using Kaggle", "Technical Help", "Neuro Video Series", "Intro", "Stimulus Representation", "Neurotransmitters", "Neurons to Consciousness", "Human Psychophysics", "Behavioral Readout", "Live in Lab", "Brain Signals: Spiking Activity", "Brain Signals: LFP", "Brain Signals: EEG &amp; MEG", "Brain Signals: fMRI", "Brain Signals: Calcium Imaging", "Python Workshop 1", "Tutorial: LIF Neuron Part I", "Python Workshop 2", "Tutorial 1: LIF Neuron Part II", "Linear Algebra", "Day Summary", "Outro", "Tutorial 1: Vectors", "Tutorial 2: Matrices", "Bonus Tutorial: Discrete Dynamical Systems", "Calculus", "Day Summary", "Tutorial 1: Differentiation and Integration", "Tutorial 2: Differential Equations", "Tutorial 3: Numerical Methods", "Statistics", "Day Summary", "Outro", "Tutorial 1: Probability Distributions", "Tutorial 2: Statistical Inference", "Model Types", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: \u201cWhat\u201d models", "Tutorial 2: \u201cHow\u201d models", "Tutorial 3: \u201cWhy\u201d models", "Tutorial 4: Model Discussions", "Model Fitting", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Linear regression with MSE", "Tutorial 2: Linear regression with MLE", "Tutorial 3: Confidence intervals and bootstrapping", "Tutorial 4: Multiple linear regression and polynomial regression", "Tutorial 5: Model Selection: Bias-variance trade-off", "Tutorial 6: Model Selection: Cross-validation", "Generalized Linear Models", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: GLMs for Encoding", "Tutorial 2: Classifiers and regularizers", "Dimensionality Reduction", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Geometric view of data", "Tutorial 2: Principal Component Analysis", "Tutorial 3: Dimensionality Reduction &amp; Reconstruction", "Tutorial 4:  Nonlinear Dimensionality Reduction", "Deep Learning", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Decoding Neural Responses", "Tutorial 2: Convolutional Neural Networks", "Tutorial 3: Building and Evaluating Normative Encoding Models", "Bonus Tutorial: Diving Deeper into Decoding &amp; Encoding", "Modeling Practice", "Day Summary", "Intro", "Outro", "Tutorial 1: Framing the Question", "Linear Systems", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Linear dynamical systems", "Tutorial 2: Markov Processes", "Tutorial 3: Combining determinism and stochasticity", "Tutorial 4: Autoregressive models", "Biological Neuron Models", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model", "Tutorial 2: Effects of Input Correlation", "Tutorial 3: Synaptic transmission - Models of static and dynamic synapses", "Bonus Tutorial: Spike-timing dependent plasticity (STDP)", "Dynamic Networks", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Neural Rate Models", "Tutorial 2: Wilson-Cowan Model", "Bonus Tutorial: Extending the Wilson-Cowan Model", "Bayesian Decisions", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Bayes with a binary hidden state", "Tutorial 2: Bayesian inference and decisions with continuous hidden state", "Bonus Tutorial: Fitting to data", "Hidden Dynamics", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Sequential Probability Ratio Test", "Tutorial 2: Hidden Markov Model", "Tutorial 3: The Kalman Filter", "Bonus Tutorial 4: The Kalman Filter, part 2", "Bonus Tutorial 5: Expectation Maximization for spiking neurons", "Optimal Control", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Optimal Control for Discrete States", "Tutorial 2: Optimal Control for Continuous State", "Reinforcement Learning", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Learning to Predict", "Tutorial 2: Learning to Act: Multi-Armed Bandits", "Tutorial 3: Learning to Act: Q-Learning", "Tutorial 4: Model-Based Reinforcement Learning", "Network Causality", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Interventions", "Tutorial 2: Correlations", "Tutorial 3: Simultaneous fitting/regression", "Tutorial 4: Instrumental Variables", "Introduction"], "terms": {"welcom": [0, 106, 202], "neuromatch": [0, 12, 22, 30, 34, 35, 36, 37, 38, 39, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 79, 81, 82, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 106, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201, 202], "academi": [0, 2, 20, 22, 30, 34, 35, 36, 37, 38, 39, 46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 120, 124, 125, 126, 127, 132, 134, 138, 139, 140, 141, 143, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 178, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "we": [0, 2, 4, 12, 22, 23, 24, 25, 29, 34, 35, 40, 42, 48, 64, 66, 71, 72, 77, 81, 82, 86, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 106, 108, 113, 115, 116, 117, 118, 122, 124, 125, 126, 127, 130, 132, 136, 138, 139, 140, 141, 145, 147, 148, 149, 150, 154, 156, 157, 158, 162, 164, 165, 166, 170, 172, 173, 174, 175, 176, 180, 182, 183, 187, 189, 190, 191, 192, 194, 196, 198, 199, 200, 201, 202], "re": [0, 12, 22, 23, 25, 36, 48, 64, 66, 70, 71, 75, 76, 77, 88, 95, 100, 102, 108, 109, 113, 115, 116, 117, 118, 124, 125, 126, 127, 130, 132, 139, 141, 149, 156, 157, 158, 165, 173, 174, 176, 182, 189, 198, 199, 201], "realli": [0, 12, 22, 23, 25, 70, 82, 95, 97, 99, 106, 109, 120, 124, 126, 132, 138, 141, 164, 165, 168, 202], "excit": [0, 12, 27, 70, 75, 77, 86, 89, 120, 134, 138, 143, 149, 152, 158, 192], "bring": [0, 24, 29, 164, 187, 189], "wide": [0, 2, 81, 98, 99, 106, 122, 124, 162, 172, 176, 187], "vari": [0, 4, 25, 40, 70, 75, 82, 88, 89, 90, 95, 98, 100, 101, 115, 124, 134, 147, 149, 150, 156, 158, 164, 166, 172, 175, 190, 199], "audienc": [0, 12, 23], "an": [0, 12, 22, 23, 24, 25, 29, 34, 36, 45, 46, 47, 48, 66, 70, 71, 75, 76, 81, 82, 86, 89, 90, 95, 97, 98, 99, 100, 101, 102, 106, 108, 109, 113, 116, 117, 118, 120, 122, 124, 125, 126, 127, 130, 132, 134, 138, 139, 140, 141, 145, 148, 149, 154, 156, 157, 158, 164, 165, 168, 170, 174, 175, 176, 180, 182, 185, 187, 189, 191, 192, 196, 198, 199, 200, 202], "amaz": 0, "set": [0, 2, 4, 12, 22, 23, 24, 25, 48, 113, 130, 170, 194], "lectur": [0, 40, 116, 117, 127, 139, 145, 147, 148, 154, 160, 176, 183], "tutori": [0, 12, 40, 43, 48, 86, 95, 106, 111, 113, 122, 130, 145, 154, 160, 162, 168, 170, 180, 187, 196], "you": [0, 2, 12, 22, 23, 24, 25, 27, 29, 30, 32, 34, 35, 36, 40, 42, 45, 47, 48, 64, 66, 69, 70, 71, 72, 75, 76, 77, 80, 81, 82, 86, 87, 88, 89, 90, 91, 95, 96, 97, 98, 99, 100, 101, 102, 106, 107, 108, 109, 113, 114, 115, 116, 117, 118, 122, 123, 124, 125, 126, 127, 130, 131, 132, 137, 138, 139, 140, 141, 145, 146, 147, 148, 149, 150, 154, 155, 156, 157, 158, 162, 163, 164, 165, 166, 170, 171, 172, 173, 174, 175, 176, 180, 181, 183, 187, 188, 189, 190, 191, 192, 197, 198, 199, 200, 201, 202], "peopl": [0, 12, 22, 24, 25, 93, 102, 132, 134, 189, 198, 200], "ar": [0, 2, 4, 11, 12, 20, 22, 23, 24, 25, 27, 29, 32, 34, 35, 36, 40, 46, 48, 64, 66, 70, 71, 72, 75, 76, 81, 82, 84, 86, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 106, 108, 109, 115, 116, 117, 118, 122, 124, 125, 126, 127, 132, 138, 139, 140, 143, 145, 147, 148, 149, 150, 154, 156, 157, 158, 160, 162, 164, 165, 166, 168, 172, 173, 174, 175, 176, 180, 183, 189, 190, 191, 192, 194, 196, 198, 199, 200, 201, 202], "come": [0, 12, 22, 23, 24, 27, 64, 71, 75, 77, 81, 82, 88, 100, 102, 109, 124, 132, 149, 160, 164, 165, 166, 172, 173, 176, 189, 190, 191, 192, 196], "thi": [0, 2, 11, 12, 20, 22, 23, 24, 25, 29, 32, 34, 35, 36, 37, 38, 39, 40, 43, 45, 46, 47, 48, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 91, 95, 97, 98, 99, 100, 101, 102, 106, 108, 109, 113, 115, 116, 117, 118, 122, 124, 125, 126, 127, 130, 132, 138, 139, 140, 141, 145, 147, 148, 149, 150, 154, 156, 157, 158, 160, 162, 164, 165, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 194, 196, 198, 199, 200, 201, 202], "from": [0, 2, 4, 11, 12, 20, 22, 23, 24, 25, 27, 32, 33, 34, 35, 36, 37, 38, 39, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 72, 74, 75, 76, 77, 79, 82, 84, 85, 86, 87, 88, 89, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 112, 113, 114, 116, 117, 118, 120, 121, 122, 123, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 158, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 176, 179, 180, 181, 183, 186, 187, 188, 189, 191, 192, 194, 195, 196, 197, 199, 200, 201, 202], "rang": [0, 12, 22, 23, 24, 25, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 97, 99, 100, 101, 102, 106, 108, 109, 115, 117, 118, 122, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "disciplin": [0, 34], "level": [0, 2, 12, 20, 22, 23, 25, 34, 35, 76, 82, 88, 109, 122, 124, 125, 126, 127, 132, 147, 148, 156, 157, 172, 173, 174, 178, 183, 185, 190, 199, 200], "background": [0, 20, 23], "want": [0, 12, 22, 23, 24, 25, 29, 47, 48, 64, 70, 71, 76, 77, 81, 82, 86, 88, 97, 98, 100, 101, 102, 106, 108, 109, 124, 125, 127, 132, 138, 139, 147, 148, 149, 156, 162, 164, 165, 166, 172, 175, 176, 183, 189, 190, 192, 198, 199, 200, 201], "make": [0, 4, 12, 20, 22, 23, 24, 25, 34, 46, 47, 48, 64, 70, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 97, 98, 100, 101, 102, 104, 106, 108, 109, 115, 116, 117, 118, 122, 124, 125, 126, 127, 130, 132, 134, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 162, 165, 166, 172, 173, 174, 175, 176, 178, 182, 183, 187, 189, 190, 191, 192, 196, 198, 199, 200, 201, 202], "sure": [0, 12, 22, 23, 25, 48, 70, 72, 76, 77, 81, 82, 88, 90, 97, 98, 108, 115, 116, 117, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 172, 173, 175, 176, 182, 183, 189, 190, 199, 201], "everybodi": 0, "abl": [0, 12, 25, 70, 71, 75, 76, 81, 82, 88, 89, 95, 115, 117, 118, 124, 141, 154, 164, 165, 166, 172, 173, 175, 183, 190, 192, 196, 201], "follow": [0, 12, 22, 23, 24, 25, 32, 34, 35, 36, 40, 48, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 91, 98, 100, 101, 102, 106, 108, 109, 115, 116, 117, 118, 124, 125, 126, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 183, 187, 189, 190, 191, 192, 198, 199, 200, 201], "enjoi": [0, 22, 36, 106, 132, 148], "school": [0, 164, 173, 182, 200], "dai": [0, 22, 24, 32, 34, 35, 36, 46, 64, 66, 70, 71, 72, 75, 81, 82, 86, 88, 89, 90, 91, 95, 97, 98, 99, 100, 101, 102, 106, 108, 109, 113, 115, 116, 117, 118, 122, 124, 125, 126, 127, 130, 132, 134, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 162, 164, 165, 166, 170, 172, 173, 174, 175, 176, 180, 182, 183, 189, 190, 191, 192, 196, 198, 199, 200, 201, 202], "1": [0, 2, 23, 24, 27, 29, 32, 33, 40, 42, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 68, 74, 79, 84, 85, 86, 87, 93, 94, 95, 96, 104, 105, 106, 107, 112, 113, 114, 121, 122, 129, 130, 131, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 155, 161, 162, 163, 169, 170, 171, 178, 179, 180, 181, 186, 187, 188, 194, 195, 196, 197], "mean": [0, 12, 22, 23, 24, 25, 34, 35, 36, 40, 66, 70, 72, 75, 76, 77, 81, 82, 89, 90, 98, 99, 100, 101, 102, 106, 108, 109, 113, 115, 116, 117, 122, 124, 125, 126, 127, 130, 132, 138, 139, 141, 145, 147, 150, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 190, 192, 198, 199, 200, 201], "need": [0, 12, 22, 23, 24, 25, 40, 48, 64, 66, 70, 71, 75, 76, 81, 82, 88, 89, 90, 95, 99, 100, 101, 102, 106, 108, 109, 113, 115, 117, 118, 122, 124, 125, 126, 127, 130, 132, 138, 139, 140, 147, 148, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 196, 200, 201, 202], "know": [0, 12, 22, 23, 34, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 99, 102, 106, 108, 109, 125, 126, 130, 132, 138, 140, 147, 149, 150, 164, 165, 166, 173, 175, 176, 180, 183, 187, 190, 191, 198, 199], "basic": [0, 23, 24, 34, 47, 66, 70, 71, 72, 75, 81, 84, 86, 88, 89, 95, 100, 106, 109, 116, 122, 125, 140, 147, 164, 165, 172, 174, 191, 194, 196, 202], "python": [0, 12, 22, 24, 66, 71, 76, 77, 81, 82, 88, 106, 108, 124, 126, 127, 132, 140, 160, 202], "some": [0, 12, 22, 23, 24, 25, 34, 36, 40, 70, 71, 72, 75, 76, 81, 82, 86, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 106, 108, 109, 117, 118, 120, 122, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 172, 174, 175, 183, 187, 189, 190, 191, 192, 198, 199, 200, 201], "core": [0, 22, 113, 132, 164, 170, 174, 180, 182, 187], "concept": [0, 12, 22, 23, 29, 36, 64, 72, 75, 77, 81, 90, 95, 101, 106, 109, 115, 116, 132, 141, 145, 148, 149, 150, 156, 157, 162, 164, 165, 170, 182, 183, 187, 189, 191, 196], "exposur": [0, 82], "below": [0, 12, 13, 23, 24, 34, 35, 36, 37, 38, 39, 42, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 98, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 138, 139, 140, 141, 147, 148, 149, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 182, 183, 189, 190, 192, 198, 199, 200, 201], "provid": [0, 2, 12, 22, 23, 27, 29, 34, 36, 64, 66, 70, 71, 82, 86, 89, 90, 93, 95, 98, 106, 108, 115, 116, 124, 125, 126, 127, 130, 132, 140, 145, 148, 149, 150, 154, 156, 158, 162, 165, 166, 170, 172, 173, 174, 175, 176, 180, 182, 183, 187, 189, 198, 199, 200, 201], "more": [0, 2, 12, 22, 23, 24, 25, 27, 29, 34, 35, 36, 40, 46, 64, 66, 70, 71, 72, 75, 76, 81, 82, 86, 88, 89, 90, 95, 97, 99, 100, 101, 102, 106, 108, 113, 115, 116, 117, 118, 122, 124, 125, 126, 127, 132, 138, 141, 145, 147, 148, 149, 150, 156, 157, 158, 162, 166, 168, 172, 173, 174, 175, 176, 182, 183, 187, 189, 190, 191, 192, 198, 199, 200, 201, 202], "detail": [0, 12, 22, 23, 24, 34, 64, 66, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 106, 124, 125, 126, 132, 143, 147, 164, 174, 183, 192], "run": [0, 2, 4, 12, 20, 22, 23, 24, 25, 27, 29, 34, 36, 45, 47, 48, 64, 66, 71, 72, 75, 77, 81, 88, 89, 90, 99, 106, 108, 109, 115, 116, 117, 124, 125, 126, 127, 132, 138, 139, 140, 147, 148, 149, 150, 156, 170, 172, 175, 180, 183, 189, 190, 191, 192, 196, 198, 199, 200, 201], "us": [0, 2, 4, 11, 12, 20, 22, 23, 24, 25, 27, 29, 32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 68, 71, 74, 76, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 121, 122, 123, 125, 126, 127, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 175, 176, 179, 180, 181, 182, 186, 187, 188, 190, 191, 192, 194, 195, 196, 197, 199, 202], "If": [0, 12, 22, 23, 24, 25, 29, 36, 42, 46, 47, 48, 64, 70, 71, 72, 75, 76, 81, 82, 88, 89, 90, 97, 100, 102, 109, 115, 116, 118, 124, 125, 126, 127, 132, 138, 139, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 172, 173, 174, 175, 182, 183, 189, 190, 191, 192, 194, 198, 199, 200, 201], "ve": [0, 12, 23, 36, 66, 70, 72, 82, 88, 90, 109, 113, 116, 117, 118, 126, 127, 138, 139, 140, 141, 147, 149, 150, 156, 158, 164, 166, 170, 172, 175, 182, 190, 192, 199, 200, 201], "never": [0, 12, 20, 23, 72, 108, 109, 124, 141, 149, 150, 157, 175, 182, 189, 190, 199], "now": [0, 12, 22, 23, 24, 25, 35, 36, 66, 70, 72, 75, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 106, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 130, 132, 138, 139, 140, 141, 147, 148, 149, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 180, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201, 202], "good": [0, 12, 22, 23, 24, 25, 34, 64, 71, 76, 82, 90, 97, 98, 99, 101, 102, 106, 108, 109, 116, 124, 126, 127, 130, 132, 140, 141, 143, 154, 160, 165, 172, 175, 176, 180, 182, 183, 185, 189, 190, 196, 198, 199, 201], "time": [0, 2, 4, 20, 22, 23, 24, 25, 30, 34, 35, 42, 43, 48, 66, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 108, 109, 113, 115, 116, 117, 118, 124, 125, 126, 127, 130, 132, 134, 138, 140, 141, 145, 149, 156, 158, 164, 165, 166, 168, 170, 173, 175, 176, 182, 189, 190, 191, 192, 196, 198, 199, 200, 201, 202], "start": [0, 22, 23, 24, 34, 35, 36, 40, 48, 64, 66, 70, 71, 72, 75, 76, 81, 82, 86, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 122, 124, 125, 126, 130, 132, 138, 139, 140, 141, 145, 147, 148, 149, 154, 156, 157, 158, 160, 164, 165, 170, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201, 202], "practic": [0, 12, 24, 34, 64, 66, 75, 81, 82, 93, 97, 98, 99, 100, 108, 109, 124, 126, 127, 130, 132, 164, 176, 183, 190, 192, 194, 200, 201, 202], "expect": [0, 22, 23, 24, 25, 36, 66, 75, 77, 81, 82, 88, 90, 108, 109, 124, 125, 126, 127, 132, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 168, 180, 182, 189, 190, 191, 192, 198, 199, 200], "student": [0, 2, 11, 12, 29, 34, 35, 40, 46, 64, 66, 70, 72, 75, 77, 81, 82, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 109, 115, 116, 117, 118, 124, 125, 126, 127, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 166, 172, 174, 175, 182, 189, 190, 191, 192, 198, 199, 201], "familiar": [0, 2, 12, 27, 75, 82, 140, 157, 200], "variabl": [0, 2, 4, 12, 22, 23, 24, 27, 34, 35, 36, 64, 66, 77, 81, 82, 88, 89, 90, 95, 97, 98, 99, 100, 101, 108, 109, 115, 116, 117, 122, 124, 125, 126, 127, 132, 138, 139, 140, 141, 148, 149, 150, 152, 157, 158, 164, 165, 166, 170, 172, 173, 174, 175, 176, 180, 182, 183, 189, 190, 194, 196, 198, 199], "list": [0, 12, 22, 24, 25, 29, 34, 35, 36, 66, 70, 71, 72, 75, 82, 88, 100, 101, 102, 109, 118, 120, 124, 126, 127, 132, 138, 139, 166, 172, 173, 176, 189, 198, 199, 201], "dict": [0, 25, 88, 100, 101, 102, 108, 109, 124, 125, 126, 127, 173, 175, 190, 191, 192, 200, 201], "numpi": [0, 22, 24, 25, 34, 35, 36, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "scipi": [0, 22, 24, 25, 36, 75, 81, 82, 89, 90, 98, 126, 127, 132, 138, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 191, 192], "librari": [0, 12, 22, 75, 88, 106, 109, 120, 124, 132, 150, 175, 201], "well": [0, 2, 4, 12, 22, 23, 24, 25, 27, 34, 35, 36, 66, 76, 77, 81, 82, 88, 89, 90, 99, 100, 101, 102, 109, 115, 116, 120, 124, 125, 126, 127, 132, 138, 140, 141, 149, 162, 164, 165, 166, 173, 174, 175, 182, 183, 189, 190, 191, 192, 200, 201], "plot": [0, 12, 25, 34, 35, 36], "matplotlib": [0, 22, 24, 25, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "littl": [0, 12, 24, 25, 27, 34, 36, 70, 72, 75, 81, 82, 88, 127, 140, 141, 164, 172, 174, 182, 183, 189, 199], "bit": [0, 22, 24, 34, 75, 76, 77, 81, 82, 88, 89, 90, 108, 127, 132, 138, 164, 165, 190, 192, 199], "everi": [0, 12, 23, 29, 48, 70, 71, 75, 81, 82, 86, 88, 90, 91, 108, 109, 124, 125, 139, 140, 141, 147, 149, 160, 166, 173, 176, 182, 183, 189, 190, 191, 198, 199, 200], "ll": [0, 12, 22, 23, 24, 34, 35, 64, 66, 70, 71, 72, 75, 76, 81, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 113, 115, 116, 117, 118, 124, 125, 126, 127, 132, 136, 149, 156, 158, 164, 165, 166, 170, 172, 173, 176, 180, 182, 189, 198, 199, 200, 201, 202], "great": [0, 12, 20, 23, 27, 34, 76, 77, 82, 86, 89, 98, 106, 108, 160, 190], "shape": [0, 22, 24, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 126, 127, 132, 138, 139, 145, 147, 148, 149, 150, 154, 157, 158, 165, 166, 172, 173, 175, 176, 182, 183, 189, 191, 192, 198, 199, 200, 201], "class": [0, 24, 34, 35, 46, 70, 71, 88, 89, 97, 108, 109, 124, 125, 126, 127, 175, 182, 183, 191, 192], "have": [0, 2, 4, 12, 22, 23, 24, 25, 27, 29, 32, 34, 35, 36, 40, 42, 45, 47, 48, 64, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 97, 98, 99, 100, 101, 102, 106, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 130, 132, 138, 139, 140, 141, 145, 147, 148, 149, 150, 154, 156, 157, 158, 162, 164, 165, 166, 168, 172, 173, 175, 176, 180, 182, 183, 187, 189, 190, 191, 192, 198, 199, 200, 201, 202], "workshop": [0, 12, 40, 64, 66], "w0d1": [0, 76], "w0d2": [0, 76], "here": [0, 12, 22, 23, 24, 25, 29, 30, 34, 36, 37, 38, 39, 40, 44, 48, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 170, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "should": [0, 2, 4, 12, 22, 23, 24, 25, 27, 29, 42, 48, 64, 66, 71, 72, 75, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 102, 108, 109, 115, 116, 117, 124, 126, 127, 130, 132, 138, 139, 140, 141, 145, 147, 148, 149, 150, 154, 162, 164, 165, 170, 172, 173, 175, 180, 183, 189, 190, 191, 192, 196, 198, 199, 200, 201, 202], "go": [0, 12, 20, 22, 23, 24, 25, 29, 35, 48, 71, 72, 75, 77, 81, 82, 88, 97, 100, 101, 106, 108, 109, 124, 125, 127, 130, 132, 140, 141, 147, 148, 150, 156, 164, 165, 175, 176, 182, 185, 190, 191, 192, 198, 199, 202], "through": [0, 12, 22, 23, 24, 25, 34, 71, 72, 75, 82, 86, 88, 100, 101, 102, 106, 109, 113, 124, 125, 126, 127, 130, 132, 134, 138, 139, 140, 141, 143, 156, 162, 164, 165, 166, 170, 172, 173, 176, 185, 189, 190, 191, 199, 201, 202], "made": [0, 12, 23, 88, 98, 124, 125, 127, 165, 166, 172, 175, 191, 201, 202], "content": [0, 2, 22, 23, 30, 34, 35, 36, 37, 38, 39, 40, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 69, 70, 71, 72, 75, 76, 77, 80, 81, 82, 86, 87, 88, 89, 90, 91, 95, 96, 97, 98, 99, 100, 101, 102, 107, 108, 109, 114, 115, 116, 117, 118, 120, 123, 124, 125, 126, 127, 131, 132, 137, 138, 139, 140, 141, 145, 146, 147, 148, 149, 150, 154, 155, 156, 157, 158, 162, 163, 164, 165, 166, 170, 171, 172, 173, 174, 175, 176, 181, 182, 183, 188, 189, 190, 191, 192, 197, 198, 199, 200, 201], "your": [0, 12, 23, 24, 25, 29, 40, 42, 43, 47, 48, 69, 80, 202], "own": [0, 12, 23, 24, 25, 81, 86, 109, 125, 130, 148, 149, 150, 165, 176, 192, 200, 202], "pace": 0, "befor": [0, 12, 22, 23, 24, 34, 40, 64, 66, 69, 71, 72, 75, 77, 80, 81, 82, 86, 87, 88, 89, 90, 96, 97, 98, 101, 102, 107, 108, 109, 114, 116, 118, 123, 124, 127, 131, 132, 137, 141, 146, 147, 149, 150, 155, 156, 157, 163, 164, 171, 172, 174, 175, 176, 180, 181, 182, 183, 188, 189, 190, 191, 192, 197, 200], "besid": [0, 34, 174], "recommend": [0, 12, 48, 118, 127, 164, 194], "softwar": [0, 29, 71, 108], "carpentri": [0, 30], "free": [0, 12, 22, 25, 29, 36, 81, 118, 124, 126, 132, 160, 164, 174, 182, 189, 191, 192], "edx": 0, "research": [0, 2, 12, 22, 23, 24, 25, 29, 34, 36, 47, 70, 82, 86, 95, 122, 124, 132, 178, 192, 194, 199], "For": [0, 2, 12, 22, 23, 25, 27, 34, 35, 36, 40, 66, 70, 71, 72, 75, 76, 77, 81, 82, 89, 90, 91, 97, 99, 100, 102, 108, 109, 113, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 145, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 170, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 196, 201], "depth": [0, 34, 35, 93, 116, 126, 160, 165], "intro": [0, 12, 22, 23, 25, 30, 40, 47, 125, 132, 173, 176, 194, 202], "see": [0, 3, 12, 13, 22, 23, 24, 25, 34, 36, 40, 42, 45, 46, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 108, 109, 113, 115, 116, 117, 118, 124, 125, 126, 127, 130, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 170, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 196, 198, 199, 200, 201], "note": [0, 12, 22, 23, 24, 25, 40, 46, 47, 48, 64, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 104, 108, 109, 115, 116, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 160, 164, 165, 166, 172, 173, 174, 175, 176, 178, 182, 183, 189, 194, 198, 199, 200, 201], "final": [0, 23, 34, 35, 36, 48, 82, 86, 97, 99, 100, 102, 106, 108, 109, 113, 115, 116, 122, 126, 145, 148, 149, 150, 154, 156, 157, 164, 165, 172, 175, 176, 182, 183, 187, 189, 192, 201, 202], "can": [0, 2, 12, 20, 22, 23, 24, 25, 29, 34, 35, 36, 40, 45, 46, 47, 48, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 106, 108, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 130, 132, 134, 138, 139, 140, 141, 145, 147, 148, 149, 150, 154, 156, 157, 158, 164, 165, 166, 168, 172, 173, 174, 175, 176, 182, 183, 187, 189, 190, 191, 192, 194, 196, 198, 199, 200, 201, 202], "data": [0, 2, 4, 12, 20, 23, 25, 27, 29, 34, 35, 36, 64, 66, 70, 71, 75, 81, 82, 84, 86, 89, 93, 95, 97, 98, 99, 100, 102, 106, 113, 118, 122, 130, 134, 140, 148, 150, 154, 164, 170, 172, 173, 174, 194, 196, 198, 199, 200, 201, 202], "scienc": [0, 2, 12, 20, 22, 23, 24, 27, 76, 77, 84, 93, 97, 99, 120, 132, 134, 143, 152, 174, 175, 178, 185, 187, 189, 194, 196, 198, 202], "handbook": [0, 84, 189], "which": [0, 2, 4, 12, 20, 22, 23, 24, 25, 27, 32, 34, 35, 36, 40, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 91, 95, 97, 98, 99, 100, 102, 106, 108, 109, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 132, 138, 139, 140, 145, 147, 148, 149, 150, 156, 157, 158, 160, 162, 164, 165, 166, 170, 172, 173, 174, 175, 176, 180, 182, 183, 187, 189, 190, 191, 192, 198, 199, 200, 201, 202], "also": [0, 2, 11, 12, 22, 23, 24, 25, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 106, 108, 109, 113, 115, 116, 117, 118, 124, 125, 126, 127, 130, 132, 138, 139, 140, 141, 145, 147, 148, 149, 150, 154, 156, 157, 158, 160, 164, 165, 166, 170, 172, 173, 174, 175, 176, 180, 182, 183, 189, 190, 191, 192, 196, 199, 200, 201], "ha": [0, 2, 4, 12, 20, 22, 23, 24, 25, 34, 35, 36, 37, 38, 39, 47, 48, 70, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 173, 174, 175, 176, 182, 183, 187, 189, 190, 191, 192, 198, 199, 200, 201], "print": [0, 22, 24, 25, 34, 35, 36, 66, 71, 75, 81, 82, 88, 90, 97, 98, 99, 100, 108, 109, 116, 124, 125, 126, 127, 132, 139, 141, 147, 148, 149, 150, 156, 157, 158, 166, 172, 173, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "edit": [0, 12, 40, 47, 76, 77, 166], "matlab": [0, 93, 108], "quickli": [0, 12, 34, 88, 89, 97, 116, 149, 156, 173, 182, 183, 189, 190, 192], "get": [0, 11, 22, 23, 24, 25, 34, 46, 48, 64, 70, 71, 72, 75, 76, 77, 81, 82, 89, 90, 97, 98, 99, 100, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 130, 132, 138, 140, 141, 147, 148, 149, 150, 156, 157, 158, 160, 164, 165, 166, 172, 173, 174, 175, 176, 180, 182, 183, 189, 190, 191, 192, 194, 198, 199, 200, 201], "up": [0, 12, 22, 23, 24, 25, 29, 64, 70, 71, 72, 75, 76, 77, 81, 82, 90, 98, 99, 100, 102, 108, 113, 115, 117, 124, 125, 127, 130, 132, 141, 147, 149, 156, 164, 165, 166, 170, 172, 173, 174, 175, 182, 189, 190, 191, 192, 198, 199, 200, 201, 202], "speed": [0, 24, 64, 89, 108, 120, 127, 157, 174, 178, 189, 190, 192], "cheatsheet": 0, "mai": [0, 12, 23, 24, 25, 34, 35, 36, 40, 46, 48, 64, 66, 71, 75, 76, 77, 81, 82, 88, 89, 90, 99, 100, 102, 109, 117, 118, 120, 124, 125, 126, 127, 138, 139, 140, 145, 147, 148, 149, 150, 154, 164, 165, 166, 172, 173, 175, 182, 183, 189, 190, 191, 192, 196, 199, 200, 201], "paperback": 0, "neural": [0, 2, 12, 20, 24, 29, 32, 34, 76, 81, 82, 84, 88, 89, 90, 93, 95, 104, 106, 108, 111, 113, 117, 120, 122, 134, 143, 145, 148, 149, 152, 162, 168, 170, 172, 173, 174, 176, 178, 185, 194, 199, 202], "both": [0, 22, 24, 25, 34, 35, 36, 40, 70, 75, 76, 77, 81, 82, 89, 100, 101, 102, 109, 115, 116, 117, 125, 127, 130, 132, 138, 139, 140, 145, 147, 148, 149, 156, 157, 158, 164, 165, 170, 173, 175, 182, 183, 189, 190, 191, 198, 200, 201, 202], "version": [0, 12, 13, 34, 35, 36, 47, 64, 70, 77, 82, 108, 113, 115, 126, 140, 166, 170, 174, 176, 196], "analysi": [0, 2, 12, 20, 22, 23, 24, 75, 82, 84, 86, 95, 99, 104, 106, 108, 113, 120, 122, 124, 126, 130, 132, 134, 139, 154, 166, 170, 174, 194, 199, 201], "reli": [0, 12, 23, 24, 25, 95, 97, 99, 164, 165, 175, 200], "linear": [0, 12, 22, 24, 25, 34, 35, 36, 40, 72, 75, 77, 81, 82, 86, 88, 90, 95, 99, 101, 102, 104, 106, 109, 113, 118, 122, 124, 125, 126, 132, 136, 139, 140, 141, 145, 147, 148, 154, 157, 158, 170, 172, 173, 174, 182, 194, 201, 202], "algebra": [0, 64, 71, 72, 82, 97, 100, 113, 134, 138, 175, 202], "probabl": [0, 12, 22, 23, 24, 25, 34, 42, 86, 88, 89, 95, 98, 102, 106, 108, 109, 117, 126, 127, 132, 140, 148, 149, 150, 162, 170, 173, 174, 175, 176, 182, 187, 189, 190, 191, 192, 196, 200, 202], "statist": [0, 23, 29, 66, 81, 93, 95, 99, 101, 104, 108, 125, 139, 145, 147, 148, 150, 154, 156, 162, 165, 168, 170, 173, 174, 176, 182, 183, 196, 198, 202], "calculu": [0, 76, 77, 97, 138, 147, 157, 202], "deriv": [0, 23, 34, 64, 76, 82, 86, 90, 93, 98, 99, 102, 109, 122, 124, 138, 139, 156, 157, 158, 165, 172, 175, 187, 189, 190], "od": [0, 64, 138, 149], "highli": [0, 23, 101, 124, 150, 156, 194], "our": [0, 12, 22, 23, 24, 25, 34, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 97, 98, 99, 100, 101, 102, 106, 108, 109, 115, 117, 118, 124, 125, 126, 127, 130, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 162, 164, 165, 166, 170, 172, 173, 174, 175, 176, 180, 182, 183, 187, 189, 190, 191, 192, 199, 200], "refresh": [0, 72, 108, 115, 116, 117, 165, 166, 182, 183, 202], "w0d3": [0, 82, 95, 106], "w0d4": [0, 86], "w0d5": [0, 86, 95, 106, 162, 165], "ask": [0, 12, 24, 25, 27, 36, 40, 76, 81, 86, 88, 102, 109, 141, 149, 165, 196, 198, 199, 200, 202], "question": [0, 23, 27, 34, 36, 70, 71, 72, 76, 77, 81, 82, 86, 88, 89, 90, 91, 95, 99, 106, 117, 122, 124, 126, 127, 130, 145, 147, 148, 149, 154, 156, 164, 165, 173, 174, 182, 196, 198, 199, 202], "discord": [0, 12, 30, 40], "grasp": 0, "along": [0, 12, 22, 70, 71, 75, 81, 88, 97, 98, 99, 115, 116, 124, 125, 132, 138, 156, 157, 158, 165, 166, 190], "crucial": [0, 12, 22, 23, 36, 95, 127, 132, 156, 180], "almost": [0, 22, 81, 82, 95, 109, 124, 132, 140, 147, 149, 150, 164, 165, 191, 192, 198], "anyth": [0, 12, 24, 47, 76, 124, 127, 130, 141, 148, 149, 166, 175, 182, 189, 190], "quantit": [0, 22, 23, 108, 125, 132, 134, 143, 156, 175], "involv": [0, 23, 75, 82, 108, 122, 124, 126, 139, 165, 182, 192], "than": [0, 12, 22, 23, 24, 27, 34, 36, 46, 64, 66, 70, 72, 75, 76, 81, 82, 88, 90, 97, 98, 100, 101, 102, 108, 117, 118, 124, 125, 126, 127, 132, 138, 139, 141, 147, 148, 149, 150, 158, 162, 164, 165, 166, 172, 174, 175, 176, 182, 183, 189, 190, 191, 192, 194, 199, 200, 201], "one": [0, 2, 4, 12, 20, 22, 23, 24, 25, 27, 34, 35, 40, 47, 48, 66, 70, 71, 72, 75, 77, 81, 82, 86, 88, 89, 90, 91, 95, 97, 98, 99, 100, 101, 102, 106, 108, 109, 115, 116, 122, 124, 125, 126, 127, 130, 132, 134, 138, 139, 140, 141, 147, 149, 150, 156, 157, 158, 164, 165, 166, 168, 172, 173, 174, 175, 176, 182, 183, 187, 189, 190, 191, 192, 196, 198, 199, 201, 202], "number": [0, 22, 24, 34, 35, 36, 48, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 102, 108, 109, 113, 115, 116, 118, 124, 125, 126, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 160, 164, 165, 172, 173, 174, 175, 176, 182, 183, 189, 190, 192, 194, 198, 201], "vector": [0, 24, 25, 34, 35, 36, 71, 72, 75, 82, 88, 95, 97, 98, 99, 100, 101, 102, 106, 108, 109, 116, 117, 118, 124, 125, 126, 127, 138, 139, 141, 147, 148, 149, 150, 156, 158, 165, 166, 172, 173, 174, 176, 182, 198, 199], "matrix": [0, 22, 24, 34, 72, 75, 76, 82, 101, 102, 106, 109, 111, 115, 118, 124, 125, 127, 132, 138, 139, 140, 148, 149, 150, 157, 164, 173, 174, 175, 176, 183, 192, 199, 200, 201], "addit": [0, 4, 12, 20, 22, 23, 34, 35, 36, 40, 64, 66, 70, 75, 77, 81, 89, 100, 101, 106, 108, 109, 125, 127, 132, 138, 147, 148, 158, 165, 174, 175, 176, 183, 191, 192, 201], "multipl": [0, 12, 27, 64, 66, 70, 72, 81, 82, 88, 97, 98, 99, 101, 102, 106, 115, 124, 125, 126, 130, 134, 138, 141, 148, 149, 154, 165, 166, 172, 176, 190, 191, 192, 194, 200, 201], "rank": [0, 116, 124, 134, 199], "base": [0, 2, 12, 22, 23, 24, 29, 34, 40, 70, 71, 72, 75, 77, 81, 82, 90, 98, 99, 100, 102, 104, 108, 113, 116, 117, 120, 124, 130, 132, 138, 139, 141, 150, 154, 156, 157, 164, 165, 168, 172, 173, 174, 175, 176, 183, 185, 189, 190, 191, 194, 196, 202], "determin": [0, 12, 23, 24, 25, 34, 35, 36, 70, 75, 81, 86, 102, 109, 117, 118, 122, 124, 125, 127, 130, 138, 139, 147, 149, 150, 152, 154, 156, 157, 158, 164, 165, 172, 173, 174, 178, 182, 183, 189, 190, 198, 199, 200, 201, 202], "invers": [0, 70, 71, 88, 90, 100, 109, 147, 157, 158, 165, 166, 172, 174, 200, 201], "eigenvalu": [0, 116, 117, 139], "decomposit": [0, 34, 118, 126, 134], "In": [0, 12, 22, 23, 24, 25, 34, 35, 36, 40, 48, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 84, 86, 88, 89, 90, 91, 95, 97, 98, 99, 100, 101, 102, 104, 106, 108, 109, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 132, 134, 138, 139, 140, 141, 143, 145, 147, 148, 149, 150, 154, 156, 157, 158, 162, 164, 165, 166, 168, 170, 172, 173, 174, 175, 176, 180, 182, 183, 187, 189, 190, 191, 192, 194, 196, 198, 199, 200, 201, 202], "beauti": [0, 34, 76, 77, 84, 148, 160, 194], "seri": [0, 12, 25, 30, 34, 37, 38, 39, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 75, 76, 77, 82, 86, 88, 89, 90, 97, 98, 99, 100, 101, 102, 106, 108, 109, 141, 145, 147, 148, 172, 173, 175, 183, 192, 194, 201, 202], "anoth": [0, 12, 20, 22, 24, 25, 34, 35, 36, 47, 48, 66, 70, 71, 75, 76, 77, 82, 88, 89, 90, 97, 100, 102, 108, 117, 124, 125, 127, 132, 139, 140, 147, 148, 164, 165, 166, 175, 183, 189, 194, 196, 199, 201], "resourc": [0, 75, 76, 81, 82, 89, 149, 160], "khan": 0, "exercis": [0, 22, 23, 76, 132, 165], "understand": [0, 12, 23, 24, 34, 35, 36, 64, 70, 76, 81, 82, 84, 88, 89, 90, 100, 101, 108, 109, 111, 115, 116, 122, 124, 127, 130, 138, 139, 145, 148, 149, 154, 156, 157, 158, 164, 165, 168, 170, 173, 174, 175, 176, 180, 183, 189, 190, 192, 196, 198, 199, 200, 201], "import": [0, 12, 22, 23, 24, 25, 37, 38, 39, 48, 79, 93, 202], "comfort": [0, 34, 162], "varianc": [0, 64, 81, 82, 97, 98, 99, 100, 102, 109, 115, 116, 148, 150, 165, 172, 173, 174, 183, 190, 198], "normal": [0, 12, 22, 24, 25, 34, 35, 36, 40, 66, 72, 75, 76, 77, 81, 82, 88, 90, 97, 98, 99, 101, 102, 108, 109, 115, 116, 117, 120, 124, 125, 126, 127, 132, 139, 140, 141, 164, 165, 172, 173, 174, 176, 190, 198, 199], "distribut": [0, 4, 12, 22, 24, 27, 34, 35, 36, 64, 66, 86, 89, 95, 97, 99, 101, 102, 106, 108, 109, 125, 126, 132, 140, 141, 145, 147, 148, 149, 162, 170, 172, 173, 174, 176, 185, 189, 190, 199], "select": [0, 2, 12, 29, 34, 35, 36, 48, 66, 81, 82, 88, 95, 97, 98, 99, 100, 117, 124, 127, 134, 152, 164, 165, 180, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "read": [0, 12, 25, 34, 55, 64, 66, 81, 99, 100, 101, 165, 166, 172, 176, 190], "i": [0, 12, 22, 23, 24, 25, 27, 34, 35, 36, 40, 66, 70, 71, 72, 75, 76, 77, 81, 82, 84, 86, 88, 89, 90, 97, 98, 99, 100, 104, 106, 108, 109, 111, 115, 116, 117, 118, 120, 124, 125, 126, 127, 130, 132, 134, 138, 140, 141, 148, 150, 152, 154, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 194, 198, 199, 200, 201], "e": [0, 2, 12, 20, 22, 23, 24, 25, 27, 34, 35, 36, 47, 64, 66, 70, 71, 75, 76, 77, 81, 82, 84, 86, 88, 89, 90, 93, 95, 98, 99, 100, 101, 102, 104, 106, 109, 111, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 130, 132, 134, 138, 143, 147, 148, 150, 152, 154, 160, 164, 165, 166, 168, 172, 173, 174, 175, 178, 182, 183, 189, 190, 191, 192, 194, 196, 198, 199, 200], "chapter": [0, 12, 93, 143, 152, 160, 175, 189], "6": [0, 12, 20, 22, 24, 25, 34, 35, 40, 71, 76, 81, 90, 93, 95, 97, 98, 99, 100, 101, 108, 109, 120, 124, 125, 126, 127, 130, 132, 134, 138, 140, 143, 147, 148, 149, 150, 156, 157, 158, 168, 175, 176, 178, 183, 185, 189, 190, 191, 192, 198, 199], "7": [0, 20, 22, 24, 25, 32, 34, 35, 40, 71, 72, 75, 76, 77, 81, 84, 89, 98, 99, 104, 109, 125, 126, 127, 132, 138, 148, 149, 150, 156, 157, 158, 172, 175, 176, 178, 189, 194, 198, 199], "russ": 0, "poldrack": 0, "s": [0, 2, 12, 20, 22, 23, 24, 25, 27, 29, 30, 32, 34, 35, 36, 47, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 84, 86, 88, 89, 90, 93, 95, 97, 98, 99, 100, 104, 106, 108, 109, 111, 115, 116, 117, 118, 120, 124, 127, 130, 132, 134, 138, 139, 140, 141, 143, 145, 147, 148, 149, 150, 152, 156, 157, 158, 160, 164, 165, 166, 170, 172, 173, 175, 176, 178, 180, 182, 183, 185, 187, 189, 190, 191, 192, 194, 196, 198, 199, 200, 201, 202], "book": [0, 12, 84, 108, 147, 160, 176, 194], "think": [0, 12, 23, 24, 25, 64, 72, 75, 86, 100, 101, 102, 106, 109, 113, 117, 124, 130, 145, 160, 165, 172, 173, 174, 175, 182, 183, 191, 192, 198, 200], "21st": 0, "centuri": 0, "what": [0, 11, 12, 22, 23, 24, 25, 27, 34, 35, 64, 66, 71, 72, 76, 81, 82, 86, 89, 90, 91, 93, 97, 98, 100, 101, 102, 106, 108, 115, 116, 117, 118, 120, 122, 124, 126, 127, 130, 132, 138, 139, 140, 141, 147, 149, 150, 152, 154, 156, 157, 158, 162, 165, 166, 170, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 194, 196, 198, 199, 200, 201, 202], "integr": [0, 12, 22, 24, 46, 66, 81, 82, 86, 125, 132, 134, 143, 145, 148, 149, 152, 160, 164, 165, 166, 172, 174, 175, 176, 182, 202], "differenti": [0, 64, 102, 117, 120, 124, 127, 139, 140, 143, 149, 156, 157, 176], "equat": [0, 23, 25, 35, 64, 66, 70, 72, 75, 81, 82, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 125, 126, 127, 139, 140, 141, 147, 148, 149, 150, 156, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 189, 190, 191, 198, 200, 201], "memori": [0, 20, 71, 72, 82, 124, 140, 157, 185, 192], "gilbert": 0, "strang": [0, 165], "studi": [0, 12, 75, 76, 77, 88, 106, 124, 125, 126, 127, 139, 140, 147, 148, 149, 150, 156, 157, 158, 165, 187, 189, 192, 201], "0": [0, 2, 12, 22, 24, 25, 32, 40, 64, 66, 71, 72, 77, 81, 82, 84, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 120, 125, 126, 127, 134, 138, 139, 140, 141, 143, 147, 148, 150, 156, 157, 158, 166, 174, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "includ": [0, 4, 12, 23, 24, 25, 27, 29, 34, 64, 70, 71, 72, 76, 81, 82, 90, 100, 108, 109, 115, 116, 117, 122, 124, 127, 138, 140, 141, 145, 156, 157, 158, 162, 166, 172, 173, 175, 176, 182, 183, 189, 190, 198, 200, 201, 202], "jiri": 0, "lebl": 0, "engin": [0, 2, 23, 34, 76, 77, 120, 134, 168, 180, 183], "outsid": [0, 22, 24, 25, 98, 124, 132, 140, 150], "fundament": [0, 12, 36, 84, 99, 108, 109, 164, 165, 190, 201], "watch": [0, 2, 12, 40, 116, 147, 160, 164, 182, 202], "neuro": [0, 12, 20, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 70, 72, 86, 106, 109, 120, 134, 202], "video": [0, 2, 12, 20, 25, 40, 45, 160], "w0d0": 0, "short": [0, 12, 23, 36, 64, 75, 82, 88, 116, 125, 138, 139, 140, 145, 147, 148, 165, 183], "subject": [0, 4, 12, 20, 36, 95, 157, 164, 166, 172, 175, 178, 189], "brain": [0, 12, 20, 22, 24, 25, 27, 29, 36, 37, 38, 39, 75, 76, 84, 86, 88, 109, 113, 122, 124, 125, 126, 127, 132, 134, 145, 148, 149, 154, 156, 157, 164, 165, 166, 168, 170, 172, 173, 174, 175, 176, 178, 180, 182, 187, 189, 196, 198, 199, 200, 202], "fact": [0, 12, 22, 24, 70, 71, 81, 82, 89, 98, 115, 117, 124, 125, 126, 127, 132, 140, 147, 148, 149, 150, 156, 157, 162, 164, 165, 172, 175, 183, 190, 191, 192, 199, 201], "societi": [0, 194], "so": [0, 12, 22, 24, 25, 27, 30, 64, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 91, 95, 97, 98, 99, 100, 101, 102, 106, 108, 109, 113, 115, 116, 117, 118, 124, 125, 126, 127, 130, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 194, 198, 199, 200, 201, 202], "look": [0, 12, 22, 24, 25, 29, 34, 70, 71, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 101, 106, 108, 109, 113, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 149, 158, 164, 165, 166, 172, 173, 175, 176, 182, 190, 191, 192, 198, 199, 201, 202], "forward": [0, 35, 36, 75, 77, 125, 126, 127, 140, 156, 175], "meet": [0, 12, 23, 40, 108], "soon": [0, 24, 34], "The": [0, 2, 4, 12, 20, 22, 23, 24, 25, 27, 35, 36, 40, 48, 66, 71, 72, 75, 81, 82, 84, 86, 88, 93, 95, 97, 98, 99, 100, 101, 102, 104, 106, 108, 111, 115, 116, 117, 118, 122, 124, 125, 126, 127, 130, 132, 134, 138, 139, 141, 143, 145, 148, 149, 150, 152, 154, 156, 157, 158, 160, 162, 164, 166, 168, 170, 173, 176, 178, 180, 182, 189, 190, 191, 192, 194, 196, 198, 199, 200, 201, 202], "team": [0, 4, 12, 34, 35, 36, 64, 66, 90, 91, 141, 148, 149], "juli": [2, 4, 20, 27, 29, 40], "5": [2, 4, 12, 20, 24, 25, 27, 29, 32, 34, 36, 40, 42, 72, 84, 89, 97, 98, 99, 100, 102, 104, 108, 111, 115, 116, 118, 120, 124, 125, 126, 127, 134, 138, 140, 141, 143, 147, 148, 149, 150, 152, 156, 157, 158, 168, 178, 183, 189, 190, 191, 192, 194, 199, 200], "23": [2, 4, 20, 27, 29, 40, 84, 98, 99, 120, 134, 178, 191, 192, 201], "2021": [2, 4, 11, 20, 27, 29, 76, 77, 120, 124, 125, 126, 134, 152, 158], "new": [2, 12, 23, 27, 29, 34, 36, 64, 66, 70, 72, 75, 82, 84, 93, 99, 102, 106, 109, 116, 117, 118, 124, 139, 140, 143, 147, 148, 149, 152, 156, 157, 158, 160, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 192, 194, 199], "youtub": [2, 4, 20, 27, 30, 160], "kai": [2, 22, 84, 132], "miller": [2, 104, 134, 143, 152, 154], "rare": [2, 81, 97, 130, 182, 189, 201], "intracrani": 2, "electrocorticograph": 2, "record": [2, 4, 12, 22, 24, 27, 66, 70, 71, 76, 81, 82, 88, 89, 90, 95, 100, 104, 108, 109, 111, 115, 122, 124, 125, 126, 127, 132, 134, 143, 147, 148, 149, 150, 157, 174, 175, 176, 183, 190], "clinic": [2, 122, 134], "pleas": [2, 12, 22, 23, 30, 34, 35, 36, 40, 43, 44, 46, 47, 48, 64, 66, 69, 71, 72, 80, 86, 87, 88, 89, 90, 91, 95, 96, 97, 101, 107, 108, 109, 114, 118, 123, 124, 125, 127, 131, 132, 137, 146, 148, 155, 156, 158, 162, 163, 164, 165, 166, 171, 172, 173, 174, 175, 176, 181, 182, 183, 188, 189, 197, 198, 199, 200, 201], "ted": 2, "talk": [2, 12, 70, 90, 95, 98, 106, 125, 180, 196, 201], "yourself": [2, 12, 23, 71, 76, 81, 141, 147, 164, 165, 172, 174, 201], "type": [2, 22, 23, 24, 34, 40, 64, 70, 72, 75, 76, 77, 88, 89, 91, 95, 100, 101, 106, 108, 109, 113, 118, 122, 124, 125, 126, 127, 130, 132, 134, 139, 140, 141, 143, 148, 149, 150, 154, 156, 158, 165, 174, 176, 190, 192, 194, 199, 202], "less": [2, 12, 25, 36, 72, 75, 76, 81, 82, 86, 88, 89, 108, 109, 117, 124, 147, 164, 173, 182, 190, 191, 199, 201], "same": [2, 12, 22, 23, 24, 34, 35, 47, 64, 66, 70, 71, 72, 75, 77, 81, 82, 86, 88, 89, 90, 91, 97, 98, 99, 100, 101, 108, 109, 118, 122, 124, 125, 126, 127, 132, 138, 139, 140, 143, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200], "difficulti": [2, 34], "all": [2, 12, 20, 22, 23, 24, 25, 27, 32, 34, 35, 36, 40, 64, 66, 70, 71, 72, 75, 81, 82, 86, 88, 89, 90, 93, 95, 98, 99, 100, 102, 106, 108, 109, 113, 115, 116, 117, 118, 120, 124, 125, 126, 127, 130, 132, 138, 139, 140, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 189, 190, 191, 192, 196, 198, 199, 200, 201, 202], "group": [2, 12, 20, 22, 24, 27, 29, 47, 70, 71, 88, 89, 90, 91, 126, 127, 130, 132, 150, 182, 189, 196, 201], "method": [2, 12, 22, 23, 30, 34, 64, 66, 72, 75, 76, 82, 84, 86, 89, 90, 95, 97, 98, 99, 102, 106, 108, 109, 113, 124, 127, 132, 134, 138, 139, 143, 147, 148, 149, 156, 157, 158, 166, 172, 175, 180, 183, 190, 191, 192, 194, 196, 198, 199, 200, 201, 202], "standard": [2, 22, 23, 25, 27, 29, 70, 71, 75, 81, 82, 97, 98, 99, 101, 102, 108, 109, 124, 126, 132, 140, 141, 147, 149, 160, 166, 172, 173, 174, 175, 176, 189, 196, 198, 199, 201], "protocol": 2, "particular": [2, 12, 22, 24, 25, 71, 88, 90, 97, 102, 106, 109, 113, 115, 124, 125, 126, 127, 132, 138, 139, 141, 147, 148, 156, 157, 162, 173, 191, 192, 198, 201], "interest": [2, 12, 20, 22, 23, 24, 25, 70, 86, 88, 89, 90, 95, 108, 118, 125, 127, 132, 138, 140, 145, 148, 149, 154, 156, 164, 165, 166, 189, 191, 192, 198, 199, 201], "sensori": [2, 4, 12, 22, 24, 76, 104, 124, 125, 132, 152, 160, 165, 172, 173, 174, 175, 176], "bci": 2, "slightli": [2, 12, 64, 125, 140, 149, 158, 164, 166, 172, 174, 175, 190, 191], "advanc": [2, 20, 22, 27, 29, 71, 81, 82, 93, 102, 104, 120, 132, 134, 157, 162, 168, 174, 200], "definit": [2, 12, 23, 35, 66, 71, 75, 76, 77, 89, 90, 118, 138, 139, 147, 149, 157, 158, 164, 165, 172, 178, 189, 196, 198, 199, 200, 201], "consid": [2, 4, 12, 23, 29, 70, 76, 77, 82, 88, 89, 90, 98, 100, 101, 109, 117, 124, 127, 138, 139, 140, 150, 156, 158, 164, 165, 166, 172, 174, 175, 176, 183, 189, 190, 191, 198, 199, 201], "steinmetz": [2, 4, 90, 109], "much": [2, 12, 22, 23, 24, 25, 35, 64, 66, 70, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 102, 106, 108, 109, 116, 117, 118, 122, 124, 125, 126, 130, 132, 147, 149, 150, 164, 165, 166, 172, 175, 176, 182, 183, 189, 190, 194, 199], "better": [2, 12, 22, 23, 24, 34, 35, 36, 64, 66, 70, 72, 75, 76, 82, 86, 88, 95, 97, 98, 102, 108, 109, 113, 118, 124, 125, 126, 127, 130, 132, 138, 141, 148, 150, 154, 157, 164, 165, 172, 174, 175, 182, 183, 189, 190, 196, 199, 200, 201], "suit": [2, 12, 34, 102, 113, 124, 125, 126], "exploratori": [2, 12, 27], "analys": [2, 4, 12, 20, 23, 27, 29, 81, 124, 158, 166, 202], "divers": [2, 23, 84, 86, 120, 127, 156], "topic": [2, 12, 22, 70, 71, 81, 132, 140, 162, 172, 187, 189, 192, 202], "thei": [2, 12, 22, 23, 24, 25, 27, 40, 42, 46, 70, 71, 76, 77, 81, 82, 86, 88, 89, 90, 98, 99, 100, 101, 106, 108, 109, 113, 115, 116, 117, 118, 122, 124, 125, 126, 127, 132, 138, 139, 140, 141, 148, 149, 150, 157, 164, 165, 166, 172, 174, 175, 176, 182, 189, 190, 191, 192, 198, 199, 200, 201], "comput": [2, 12, 22, 23, 24, 25, 29, 34, 46, 48, 64, 66, 70, 72, 75, 81, 84, 88, 93, 95, 98, 99, 104, 108, 109, 113, 115, 117, 120, 124, 125, 127, 130, 132, 134, 138, 141, 143, 145, 149, 152, 154, 162, 165, 166, 168, 170, 172, 174, 175, 176, 178, 180, 182, 183, 187, 189, 190, 191, 194, 200, 202], "project": [2, 4, 20, 23, 27, 34, 35, 36, 43, 47, 48, 70, 71, 75, 100, 113, 117, 118, 130, 154, 175, 202], "becaus": [2, 12, 20, 22, 23, 24, 25, 27, 70, 72, 75, 76, 81, 82, 86, 88, 89, 90, 98, 100, 102, 108, 109, 116, 117, 118, 124, 125, 126, 127, 130, 132, 140, 141, 147, 148, 149, 150, 154, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 180, 182, 189, 190, 191, 198, 199, 200, 201], "high": [2, 12, 23, 27, 34, 35, 75, 101, 102, 113, 115, 116, 118, 120, 124, 126, 127, 134, 138, 141, 143, 147, 149, 156, 158, 164, 165, 168, 172, 173, 182, 183, 189, 190, 199, 200], "dimension": [2, 12, 27, 32, 34, 36, 40, 70, 71, 75, 86, 100, 108, 113, 115, 116, 124, 127, 134, 140, 148, 156, 165, 173, 175, 182, 183, 196, 198, 199, 202], "lot": [2, 11, 12, 20, 22, 23, 24, 70, 72, 75, 81, 82, 99, 101, 102, 118, 124, 126, 132, 140, 164, 165, 172, 182, 199, 202], "neuron": [2, 12, 20, 22, 24, 36, 40, 70, 71, 72, 76, 77, 81, 82, 86, 95, 98, 104, 106, 108, 109, 115, 116, 120, 122, 124, 125, 126, 127, 132, 134, 138, 139, 145, 154, 157, 158, 165, 168, 172, 178, 180, 182, 189, 196, 202], "trial": [2, 4, 12, 22, 24, 25, 81, 109, 115, 125, 127, 132, 134, 147, 148, 149, 166, 172, 176, 189, 190, 191, 192, 199, 200, 201], "support": [2, 4, 27, 29, 64, 76, 77, 88, 90, 95, 109, 183, 199], "nma": [2, 11, 12, 24, 30, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 130, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 160, 162, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 187, 189, 190, 191, 192, 198, 199, 200, 201], "been": [2, 12, 22, 23, 24, 25, 40, 47, 48, 70, 72, 76, 81, 82, 99, 101, 102, 106, 115, 116, 124, 125, 126, 127, 132, 140, 149, 150, 156, 157, 158, 164, 165, 166, 168, 175, 176, 182, 189, 192, 198, 199, 201], "curat": [2, 4, 20, 27, 202], "annot": [2, 20, 71, 109, 190], "gener": [2, 12, 23, 24, 34, 35, 36, 64, 66, 70, 75, 76, 77, 86, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 104, 106, 109, 116, 122, 124, 125, 126, 138, 139, 140, 141, 145, 148, 149, 150, 156, 157, 158, 164, 165, 172, 173, 174, 175, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201, 202], "credit": [2, 4, 20, 27, 71], "mariu": [2, 20, 22, 23, 24, 25, 27, 132], "pachitariu": [2, 20, 22, 27, 120, 132], "ta": [2, 40, 77], "view": [2, 4, 20, 22, 23, 24, 25, 27, 29, 70, 75, 84, 88, 90, 98, 124, 125, 126, 127, 132, 156, 173, 176, 183], "faceshous": 2, "joysticktrack": 2, "memorynback": 2, "motorimageri": 2, "exploreajile12": 2, "k": [2, 12, 20, 22, 23, 25, 27, 64, 66, 70, 71, 72, 77, 81, 84, 93, 98, 100, 102, 104, 109, 111, 115, 116, 117, 118, 120, 125, 126, 127, 132, 134, 138, 139, 140, 141, 143, 147, 148, 149, 150, 152, 156, 157, 158, 160, 165, 166, 168, 174, 175, 176, 183, 185, 189, 190, 192, 194, 198, 199, 200, 201], "j": [2, 12, 20, 27, 34, 35, 36, 64, 66, 70, 71, 72, 75, 82, 84, 93, 100, 104, 108, 109, 111, 116, 120, 134, 143, 148, 152, 157, 158, 160, 164, 168, 173, 175, 176, 178, 183, 185, 189, 194, 198, 199, 200, 201], "herm": 2, "d": [2, 20, 22, 23, 24, 25, 27, 34, 64, 70, 71, 72, 75, 76, 77, 84, 93, 97, 100, 104, 108, 109, 111, 120, 126, 127, 132, 134, 140, 141, 143, 147, 152, 156, 157, 158, 160, 168, 173, 174, 175, 176, 178, 182, 183, 185, 189, 191, 192, 194, 199], "pestilli": 2, "f": [2, 20, 22, 24, 25, 32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 153, 154, 155, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201], "wig": 2, "g": [2, 12, 20, 22, 23, 24, 25, 27, 47, 70, 71, 72, 75, 76, 77, 81, 82, 84, 88, 89, 90, 93, 95, 97, 98, 99, 100, 101, 102, 104, 106, 108, 117, 118, 120, 122, 124, 125, 126, 127, 132, 134, 138, 143, 147, 148, 149, 150, 152, 154, 156, 157, 165, 166, 172, 173, 174, 175, 178, 182, 183, 185, 189, 190, 191, 192, 194, 196, 199], "ojemann": [2, 134], "2017": [2, 20, 23, 84, 93, 104, 120, 134, 194], "percept": [2, 22, 24, 25, 84, 104, 132, 160, 166, 174, 182], "format": [2, 12, 25, 29, 88, 116, 124, 140, 141, 148, 172, 173, 175, 176, 183, 201], "human": [2, 4, 20, 34, 36, 76, 81, 82, 120, 122, 124, 125, 134, 140, 141, 164, 165, 172, 185, 187, 189, 194], "ventral": [2, 120], "tempor": [2, 23, 104, 108, 120, 134, 147, 148, 150, 157, 174, 175, 191, 192, 201], "cortex": [2, 27, 82, 104, 109, 120, 122, 124, 125, 126, 127, 134, 152, 154, 176, 185], "journal": [2, 20, 23, 77, 84, 93, 104, 120, 134, 143, 148, 152, 157, 158, 168, 178, 194], "neurophysiolog": [2, 77, 93, 104, 134, 143, 152, 178], "118": [2, 120], "2614": 2, "2627": 2, "doi": [2, 20, 22, 23, 27, 76, 77, 84, 93, 104, 111, 120, 132, 134, 143, 148, 152, 157, 158, 168, 178, 185, 194], "10": [2, 12, 20, 22, 24, 25, 27, 34, 35, 36, 40, 70, 72, 75, 76, 77, 81, 82, 84, 88, 89, 90, 93, 97, 98, 99, 101, 102, 104, 108, 109, 111, 117, 118, 120, 124, 125, 126, 127, 130, 132, 134, 138, 140, 141, 143, 147, 148, 149, 150, 152, 156, 157, 158, 165, 166, 168, 172, 173, 175, 176, 178, 182, 183, 185, 189, 190, 191, 192, 194, 198, 199, 200, 201], "1152": [2, 93, 104, 127, 134, 143, 152, 178], "jn": [2, 93, 104, 134, 143, 152, 178], "00113": 2, "witthoft": 2, "n": [2, 20, 22, 24, 25, 27, 34, 35, 64, 66, 70, 72, 75, 76, 77, 81, 82, 84, 88, 90, 93, 97, 98, 99, 100, 101, 102, 104, 108, 109, 111, 115, 116, 117, 120, 124, 125, 126, 127, 132, 134, 138, 140, 141, 143, 147, 148, 149, 150, 152, 157, 158, 160, 164, 165, 166, 172, 173, 174, 175, 176, 178, 182, 183, 185, 189, 190, 191, 192, 194, 198, 199, 200, 201], "rao": [2, 134], "r": [2, 20, 22, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 84, 88, 89, 90, 93, 97, 98, 99, 104, 108, 109, 111, 115, 116, 120, 124, 125, 126, 127, 132, 134, 138, 140, 141, 143, 147, 148, 149, 150, 152, 156, 157, 158, 160, 165, 166, 168, 172, 173, 175, 176, 178, 182, 183, 185, 189, 191, 192, 194, 198, 199, 200, 201], "p": [2, 20, 22, 27, 35, 36, 70, 71, 75, 76, 77, 81, 82, 84, 90, 93, 98, 100, 104, 108, 109, 111, 120, 124, 126, 127, 132, 134, 139, 141, 143, 148, 164, 165, 166, 172, 173, 174, 175, 176, 178, 182, 183, 185, 189, 190, 194, 198, 199, 200, 201], "2015": [2, 111, 120, 134, 148, 152, 185, 194], "physiolog": [2, 27, 29, 75, 88, 89, 104, 134, 143], "lobe": 2, "special": [2, 70, 71, 72, 82, 106, 108, 109, 124, 126, 127, 138, 147, 149, 156, 165, 172, 192], "contextu": 2, "novelti": 2, "114": [2, 20, 84, 191], "256": [2, 108, 199], "263": [2, 127], "2fjn": 2, "00131": 2, "schalk": 2, "2016": [2, 84, 104, 111, 118, 120, 134, 185, 194], "spontan": [2, 27, 76, 77, 124, 125, 126, 127], "decod": [2, 12, 24, 34, 35, 36, 71, 98, 104, 106, 113, 122, 125, 148, 160, 168, 202], "object": [2, 20, 24, 25, 82, 120, 122, 170, 180], "cortic": [2, 27, 120, 125, 134, 147, 149, 152, 160], "surfac": [2, 36, 75, 98], "reveal": [2, 27, 120], "complementari": [2, 22, 23, 27, 82, 86, 132], "inform": [2, 12, 20, 22, 23, 24, 25, 27, 29, 34, 36, 66, 71, 76, 81, 82, 86, 88, 89, 93, 104, 108, 109, 116, 117, 118, 120, 122, 124, 125, 126, 127, 132, 134, 139, 147, 149, 154, 156, 157, 160, 164, 166, 168, 172, 173, 174, 175, 176, 178, 182, 189, 190, 192], "event": [2, 40, 42, 71, 81, 82, 89, 90, 139, 147, 148, 149, 150, 164, 165, 176, 182], "relat": [2, 12, 20, 22, 23, 29, 34, 36, 70, 71, 75, 76, 77, 81, 88, 101, 104, 106, 109, 117, 126, 132, 134, 138, 139, 140, 143, 147, 156, 157, 158, 164, 165, 172, 174, 178, 198, 200, 202], "potenti": [2, 12, 22, 66, 77, 81, 82, 86, 88, 89, 90, 99, 100, 102, 106, 108, 124, 126, 132, 145, 147, 148, 150, 164, 165, 166, 176, 190, 191, 192, 201], "broadband": 2, "spectral": [2, 12], "chang": [2, 12, 22, 23, 24, 34, 35, 36, 47, 66, 70, 71, 81, 82, 89, 90, 95, 97, 98, 99, 100, 101, 108, 109, 113, 116, 118, 124, 125, 127, 132, 138, 139, 140, 145, 147, 148, 149, 154, 156, 157, 164, 165, 166, 170, 172, 174, 175, 176, 182, 183, 189, 191, 198, 199, 200, 201, 202], "plo": [2, 23, 29, 77, 84, 104, 120, 134, 168], "biologi": [2, 29, 76, 77, 84, 104, 120, 134, 178, 202], "12": [2, 4, 24, 25, 34, 35, 36, 40, 71, 75, 76, 77, 82, 89, 99, 104, 111, 120, 125, 126, 127, 134, 138, 147, 148, 149, 150, 152, 156, 157, 158, 164, 165, 172, 173, 176, 182, 183, 185, 189, 191, 192, 194, 198, 199, 200, 201, 202], "e1004660": 2, "1371": [2, 23, 77, 84, 104, 120, 134, 168], "pcbi": [2, 23, 84, 104, 120, 134], "1004660": 2, "zano": 2, "fetz": 2, "den": [2, 185], "nij": 2, "m": [2, 12, 20, 22, 24, 27, 70, 77, 84, 89, 93, 98, 104, 109, 111, 120, 124, 126, 127, 132, 134, 141, 143, 149, 150, 152, 157, 158, 160, 164, 165, 168, 172, 173, 174, 178, 183, 185, 189, 194], "2009": [2, 20, 84, 93, 134, 143, 152, 175, 178, 194], "decoupl": 2, "power": [2, 12, 35, 72, 81, 82, 97, 99, 100, 106, 118, 124, 157, 165, 166, 172, 176, 201], "spectrum": [2, 147, 149], "real": [2, 12, 22, 24, 36, 70, 72, 82, 86, 89, 90, 95, 97, 100, 109, 116, 117, 125, 127, 132, 138, 141, 147, 156, 158, 165, 172, 175, 183, 192, 194, 199, 200], "represent": [2, 20, 23, 29, 35, 36, 66, 71, 77, 84, 88, 98, 106, 108, 109, 113, 118, 120, 122, 124, 125, 127, 139, 156, 160, 165, 166, 176, 189, 191, 192], "individu": [2, 12, 20, 23, 40, 66, 70, 88, 117, 124, 126, 127, 145, 150, 156, 157, 158, 164, 172, 191, 192, 201, 202], "finger": 2, "movement": [2, 22, 24, 25, 71, 81, 132, 134, 165, 168, 178, 183, 191], "neurosci": [2, 12, 20, 22, 23, 24, 27, 29, 36, 46, 48, 64, 70, 71, 81, 82, 84, 88, 95, 100, 102, 104, 106, 109, 113, 115, 120, 122, 126, 127, 130, 132, 138, 140, 143, 145, 147, 148, 152, 154, 162, 164, 165, 170, 172, 175, 178, 180, 187, 192, 194, 196, 198, 199, 202], "29": [2, 100, 104, 120, 191, 192, 201], "3132": 2, "3137": 2, "1523": [2, 22, 23, 84, 104, 120, 132, 143, 148, 152, 178], "2fjneurosci": 2, "5506": 2, "08": [2, 12, 70, 72, 97, 108, 185], "honei": 2, "c": [2, 20, 22, 24, 25, 27, 70, 71, 72, 75, 84, 93, 97, 99, 104, 108, 111, 118, 120, 125, 126, 127, 132, 134, 139, 141, 143, 148, 149, 150, 152, 157, 158, 160, 164, 165, 166, 168, 172, 173, 175, 176, 178, 182, 183, 185, 192, 194, 198, 199, 200, 201], "hebb": 2, "A": [2, 12, 20, 22, 23, 24, 25, 27, 29, 34, 36, 64, 66, 70, 71, 76, 81, 84, 88, 89, 90, 93, 95, 102, 104, 108, 109, 111, 115, 116, 120, 122, 124, 125, 132, 134, 139, 140, 143, 147, 148, 149, 150, 152, 156, 157, 160, 164, 168, 172, 174, 175, 176, 178, 182, 183, 185, 189, 190, 192, 198, 200], "o": [2, 64, 70, 75, 76, 77, 81, 97, 100, 104, 108, 109, 116, 117, 120, 124, 125, 126, 127, 134, 139, 148, 149, 157, 158, 160, 172, 174, 176, 191, 192, 194, 198], "ramsei": 2, "knight": 2, "t": [2, 12, 20, 22, 23, 24, 25, 27, 34, 35, 36, 48, 64, 66, 69, 70, 71, 72, 75, 76, 77, 80, 81, 82, 84, 87, 88, 89, 90, 96, 97, 99, 100, 101, 102, 104, 107, 108, 109, 111, 113, 114, 116, 117, 120, 123, 124, 125, 126, 127, 130, 131, 132, 134, 137, 138, 140, 141, 143, 146, 147, 148, 149, 150, 152, 155, 156, 157, 158, 160, 163, 164, 165, 166, 170, 171, 172, 173, 174, 175, 176, 178, 181, 182, 183, 188, 189, 190, 191, 192, 194, 197, 198, 199, 200, 201], "2012": [2, 84, 104, 134, 178], "activ": [2, 12, 20, 22, 24, 27, 35, 36, 70, 71, 75, 76, 82, 89, 90, 95, 104, 106, 109, 113, 115, 116, 122, 127, 132, 134, 143, 145, 147, 149, 152, 154, 168, 170, 173, 174, 176, 180, 192, 198, 200, 201], "phase": [2, 34, 101, 125, 126, 127, 138, 154, 156, 189, 192], "entrain": 2, "underli": [2, 24, 70, 71, 86, 97, 98, 109, 111, 113, 134, 138, 141, 152, 154, 165, 168, 173, 175, 176, 189, 199, 202], "rhythm": 2, "e1002655": 2, "1002655": 2, "kubanek": 2, "anderson": 2, "leuthardt": 2, "wolpaw": 2, "2007": [2, 76, 77, 104, 134, 143, 148], "two": [2, 12, 20, 22, 23, 24, 29, 34, 35, 36, 46, 66, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 95, 98, 100, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 130, 132, 139, 141, 143, 147, 148, 149, 150, 154, 157, 158, 162, 164, 165, 166, 170, 172, 173, 175, 176, 180, 182, 183, 189, 190, 191, 192, 199], "trajectori": [2, 72, 140, 141, 158, 173, 174, 175, 183], "signal": [2, 12, 22, 23, 24, 75, 77, 81, 98, 100, 104, 132, 134, 143, 172, 174, 187, 189, 190, 191, 192, 201], "4": [2, 12, 20, 23, 24, 25, 32, 40, 42, 48, 72, 84, 89, 93, 95, 97, 99, 101, 102, 104, 108, 111, 113, 116, 120, 124, 125, 126, 127, 130, 134, 140, 143, 147, 149, 152, 156, 157, 178, 187, 189, 191, 194, 196], "3": [2, 12, 20, 23, 24, 32, 40, 42, 48, 84, 86, 93, 95, 97, 101, 102, 104, 106, 108, 111, 113, 116, 120, 122, 134, 141, 143, 152, 157, 178, 187, 196], "264": 2, "275": [2, 120, 134, 185], "1088": [2, 104], "1741": 2, "2560": 2, "012": [2, 71, 178], "wilson": [2, 84, 93, 120, 134, 152, 154, 178], "smyth": 2, "2008": [2, 20, 93, 104, 120, 134, 143, 178, 185, 194], "control": [2, 12, 22, 40, 46, 47, 64, 75, 77, 81, 82, 86, 89, 90, 95, 98, 108, 111, 115, 124, 125, 126, 127, 132, 134, 148, 149, 154, 156, 157, 158, 162, 164, 165, 170, 172, 173, 174, 180, 185, 187, 189, 191, 192, 196, 200, 201, 202], "75": [2, 71, 75, 76, 77, 97, 99, 125, 126, 127, 147, 148, 149, 150, 172, 173, 176, 189, 192, 200], "84": [2, 134, 192], "008": [2, 64, 104, 150], "brouwer": 2, "hogervorst": 2, "van": [2, 20, 22, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 70, 71, 76, 77, 81, 82, 120, 132, 134, 143, 152, 172, 185], "erp": [2, 29], "b": [2, 12, 20, 22, 23, 24, 25, 27, 34, 35, 66, 70, 71, 72, 75, 77, 81, 84, 88, 89, 90, 91, 98, 99, 104, 108, 111, 115, 116, 120, 124, 127, 132, 134, 138, 139, 140, 141, 143, 147, 148, 149, 150, 152, 156, 157, 158, 160, 164, 165, 166, 172, 173, 174, 175, 176, 178, 182, 183, 189, 190, 192, 194, 198, 199, 200, 201], "heffelaar": 2, "zimmerman": 2, "h": [2, 27, 34, 71, 75, 82, 84, 90, 104, 108, 109, 120, 124, 125, 126, 127, 134, 143, 152, 157, 158, 160, 175, 178, 185], "oostenveld": 2, "estim": [2, 4, 22, 25, 70, 71, 75, 76, 77, 81, 88, 89, 90, 91, 95, 101, 102, 104, 106, 108, 109, 115, 116, 117, 118, 122, 124, 125, 126, 127, 132, 134, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 164, 172, 173, 175, 176, 182, 183, 189, 190, 191, 192, 194, 196, 202], "workload": 2, "back": [2, 12, 22, 23, 24, 25, 34, 35, 76, 98, 100, 101, 108, 122, 124, 127, 132, 140, 141, 149, 156, 158, 164, 165, 172, 174, 175, 176, 182, 183, 191, 201], "task": [2, 4, 12, 27, 29, 34, 35, 36, 82, 86, 97, 99, 106, 108, 109, 122, 125, 134, 141, 172, 175, 183, 189, 190, 191, 192, 201, 202], "9": [2, 12, 24, 25, 27, 34, 35, 40, 71, 72, 75, 76, 77, 81, 82, 84, 97, 104, 109, 117, 118, 120, 127, 134, 140, 141, 143, 148, 149, 152, 156, 157, 158, 168, 172, 175, 176, 178, 182, 183, 189, 191, 192, 194, 198, 199, 200, 201], "045008": 2, "grissmann": 2, "faller": 2, "scharing": 2, "sp\u00fcler": 2, "gerjet": 2, "electroencephalographi": 2, "work": [2, 12, 20, 22, 23, 24, 25, 27, 34, 40, 46, 48, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 100, 101, 108, 117, 120, 124, 126, 127, 130, 132, 138, 141, 157, 162, 164, 165, 166, 172, 174, 175, 176, 180, 182, 183, 190, 192, 194, 196, 198, 199, 200], "load": [2, 12, 36, 88, 90, 116, 117, 118, 189], "affect": [2, 12, 36, 72, 75, 76, 77, 82, 89, 98, 102, 109, 115, 117, 118, 124, 138, 140, 145, 147, 149, 156, 165, 172, 173, 174, 178, 183, 189, 190, 191, 192, 196, 198, 200, 201, 202], "valenc": 2, "emot": [2, 20], "stimuli": [2, 22, 24, 27, 82, 104, 122, 124, 125, 126, 127, 132, 175, 178], "frontier": [2, 20, 120, 192], "11": [2, 40, 82, 88, 98, 104, 109, 111, 120, 134, 138, 143, 147, 149, 152, 156, 157, 158, 165, 173, 185, 189, 191, 192], "616": [2, 111], "3389": [2, 20, 120], "2ffnhum": 2, "00616": 2, "2010": [2, 35, 93, 104, 168], "dure": [2, 12, 24, 27, 34, 35, 36, 40, 64, 66, 70, 71, 72, 75, 81, 86, 95, 101, 102, 104, 122, 125, 127, 130, 134, 139, 147, 164, 166, 168, 175, 178, 189, 192, 202], "execut": [2, 32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "onlin": [2, 75, 81, 84, 152, 160, 175], "feedback": [2, 12, 40, 134, 178], "proceed": [2, 20, 76, 77, 104, 120, 134, 143, 178], "nation": [2, 20, 76, 77, 120, 134, 143, 178], "107": 2, "4430": 2, "4435": 2, "1073": [2, 20, 76, 77, 120, 134, 143, 178], "pna": [2, 20, 76, 77, 120, 134, 143, 178], "0913697107": 2, "peterson": 2, "singh": [2, 56], "wang": [2, 71, 134, 143, 152, 185, 189, 190, 191, 192], "x": [2, 12, 22, 24, 25, 27, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 84, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 120, 124, 125, 126, 127, 132, 138, 139, 140, 141, 148, 149, 152, 156, 157, 158, 164, 165, 173, 174, 175, 176, 182, 183, 185, 189, 191, 192, 198, 199, 200, 201], "brunton": [2, 37, 134, 138, 139, 140, 141], "w": [2, 20, 34, 70, 71, 72, 75, 77, 82, 84, 93, 104, 109, 115, 116, 117, 120, 124, 125, 126, 127, 134, 143, 152, 156, 158, 160, 168, 173, 174, 178, 183, 185, 194, 200, 201], "behavior": [2, 12, 20, 22, 23, 27, 34, 75, 77, 84, 86, 89, 90, 93, 95, 104, 106, 122, 126, 132, 138, 139, 140, 147, 150, 152, 156, 157, 158, 162, 164, 166, 172, 174, 176, 183, 185, 187, 189, 190, 191, 192, 196], "naturalist": [2, 126], "arm": [2, 81, 134, 166, 191, 192], "eneuro": [2, 22, 23, 84, 104, 132], "8": [2, 22, 24, 25, 34, 35, 36, 40, 71, 75, 76, 77, 81, 82, 84, 88, 90, 93, 98, 100, 101, 104, 108, 109, 115, 116, 120, 125, 126, 127, 132, 134, 140, 150, 152, 156, 157, 158, 172, 173, 175, 176, 182, 183, 185, 189, 191, 192, 201], "0007": 2, "21": [2, 25, 84, 93, 97, 111, 120, 134, 138, 141, 148, 152, 185, 189, 191, 192], "mine": 2, "long": [2, 12, 35, 70, 72, 88, 124, 140, 147, 149, 150, 165, 175, 182, 190, 201], "term": [2, 12, 23, 34, 35, 64, 70, 71, 72, 75, 77, 81, 82, 88, 90, 100, 102, 108, 116, 124, 125, 126, 127, 138, 139, 140, 141, 145, 148, 150, 154, 156, 157, 158, 164, 172, 174, 183, 189, 191, 201], "358": 2, "109199": 2, "1016": [2, 12, 20, 27, 84, 93, 104, 111, 120, 134, 143, 152, 157, 158, 168, 178, 185], "jneumeth": [2, 134, 143], "daili": 3, "guid": [3, 22, 23, 40, 44, 71, 84, 86, 109, 127, 130, 132, 140, 165, 170, 202], "everyon": [4, 12, 76, 86, 189], "onli": [4, 12, 20, 22, 23, 24, 25, 34, 35, 36, 48, 64, 70, 71, 72, 75, 77, 81, 82, 88, 89, 90, 99, 100, 102, 108, 109, 116, 117, 118, 122, 124, 125, 126, 130, 132, 138, 139, 141, 147, 148, 149, 150, 154, 156, 157, 158, 160, 164, 165, 166, 170, 172, 173, 174, 175, 182, 183, 187, 189, 190, 191, 192, 198, 199, 200, 201], "veri": [4, 12, 22, 23, 24, 25, 27, 34, 36, 64, 71, 72, 75, 76, 77, 81, 82, 88, 98, 99, 100, 101, 102, 106, 108, 109, 124, 126, 127, 132, 138, 140, 145, 147, 149, 150, 154, 158, 164, 165, 172, 173, 176, 182, 183, 190, 191, 192, 194, 198, 199, 200, 201], "rich": [4, 35, 36, 157], "mani": [4, 12, 20, 22, 23, 24, 25, 27, 36, 70, 71, 75, 76, 77, 81, 82, 88, 89, 90, 99, 100, 106, 108, 109, 113, 115, 117, 124, 125, 126, 127, 132, 139, 148, 149, 150, 156, 157, 162, 164, 165, 166, 172, 174, 182, 183, 187, 189, 190, 191, 198, 200, 201], "pose": [4, 122, 148, 202], "track": [4, 12, 34, 35, 36, 66, 72, 124, 126, 127, 139, 147, 170, 173, 174, 189], "social": [4, 20, 194, 198], "interact": [4, 22, 45, 47, 48, 64, 71, 118, 132, 141, 148, 152, 154, 162, 170, 176, 191, 192, 198], "mice": [4, 27, 88, 109, 122, 124, 125, 126, 183], "code": [4, 12, 20, 22, 23, 24, 27, 29, 30, 45, 46, 47, 48, 76, 86, 104, 111, 120, 130, 132, 160, 165, 185, 194, 202], "templat": [4, 20, 27, 29], "ann": [4, 35, 57, 120], "kennedi": 4, "loader": 4, "notebook": [4, 12, 22, 23, 27, 45, 47, 48, 64, 70, 71, 88, 102, 109, 115, 116, 117, 118, 125, 126, 127, 132, 164, 165, 166, 175, 189, 192, 198, 200, 201], "visual": [4, 12, 20, 22, 23, 24, 25, 27, 36, 64, 66, 70, 71, 72, 76, 77, 81, 82, 89, 90, 97, 98, 99, 100, 101, 102, 104, 108, 109, 113, 115, 116, 120, 122, 132, 134, 138, 139, 140, 141, 147, 148, 149, 152, 154, 157, 158, 164, 166, 170, 172, 173, 174, 175, 176, 178, 182, 183, 189, 190, 191, 198, 199, 200, 201, 202], "decis": [4, 22, 23, 24, 40, 76, 77, 81, 82, 84, 86, 95, 104, 106, 109, 124, 127, 132, 134, 140, 162, 172, 178, 182, 187, 189, 190, 202], "similar": [4, 20, 22, 24, 25, 34, 35, 36, 64, 66, 70, 75, 76, 82, 88, 89, 100, 101, 108, 115, 116, 117, 120, 122, 124, 125, 127, 130, 132, 140, 148, 150, 156, 157, 158, 164, 165, 166, 172, 173, 182, 190, 191, 192, 200, 201], "eric": [4, 22, 132, 164, 165, 189, 190, 191, 192], "dewitt": [4, 22, 132, 164, 165, 189, 190, 191, 192], "explor": [4, 12, 24, 29, 34, 35, 72, 77, 81, 82, 89, 90, 99, 100, 101, 102, 115, 118, 122, 124, 127, 138, 139, 140, 141, 145, 148, 158, 172, 173, 175, 180, 187, 189, 190, 191, 199, 200], "psychometr": 4, "contain": [4, 11, 12, 22, 23, 24, 25, 27, 29, 34, 36, 48, 75, 81, 82, 88, 90, 97, 98, 99, 100, 108, 118, 122, 124, 125, 126, 127, 132, 148, 160, 165, 175, 190, 191, 192, 198, 200], "collect": [4, 12, 22, 23, 24, 64, 66, 70, 76, 77, 81, 82, 99, 132, 164, 172, 173, 174, 175, 176, 182, 183], "motion": [4, 22, 24, 25, 132, 140, 168, 172], "direct": [4, 23, 24, 25, 29, 34, 35, 70, 71, 75, 76, 77, 81, 90, 93, 99, 115, 116, 120, 124, 127, 138, 139, 149, 156, 157, 158, 165, 166, 172, 175, 191, 198, 199], "perform": [4, 12, 22, 23, 24, 25, 32, 34, 35, 36, 66, 70, 71, 75, 82, 97, 102, 108, 109, 113, 118, 120, 122, 124, 125, 126, 132, 134, 141, 147, 149, 166, 172, 173, 175, 176, 183, 189, 190, 191, 192, 198, 199, 201], "reaction": [4, 168], "variou": [4, 70, 81, 82, 88, 89, 97, 98, 99, 100, 101, 102, 113, 125, 126, 127, 147, 154, 164, 175, 182, 192, 200], "83": [4, 192], "214": [4, 84, 194], "author": [4, 25, 108, 109], "strength": [4, 22, 25, 70, 75, 76, 77, 82, 109, 125, 132, 143, 149, 156, 157, 158, 192, 198, 199, 200], "evid": [4, 12, 22, 24, 25, 76, 82, 99, 109, 118, 132, 134, 141, 145, 149, 157, 158, 164, 172, 173, 174, 182], "coher": [4, 134, 172], "prior": [4, 22, 23, 46, 81, 104, 108, 109, 132, 162, 164, 172, 173, 174, 176, 183], "compar": [4, 20, 22, 24, 34, 35, 36, 70, 75, 77, 81, 82, 89, 90, 95, 97, 98, 99, 102, 106, 108, 109, 115, 116, 117, 118, 122, 124, 125, 126, 132, 138, 139, 140, 141, 147, 149, 158, 164, 165, 172, 173, 175, 176, 182, 183, 190, 191, 192, 198, 201, 202], "predict": [4, 12, 22, 23, 24, 25, 34, 35, 36, 72, 75, 77, 81, 82, 89, 90, 97, 100, 101, 102, 104, 106, 109, 120, 124, 125, 126, 127, 132, 134, 139, 140, 141, 172, 174, 175, 182, 183, 185, 191, 192, 194, 201], "bayesian": [4, 20, 40, 93, 104, 160, 162, 166, 173, 174, 175, 194, 196, 202], "observ": [4, 22, 24, 25, 34, 35, 36, 72, 75, 76, 81, 82, 86, 89, 90, 97, 98, 99, 101, 108, 125, 126, 127, 132, 138, 139, 141, 147, 148, 149, 150, 156, 158, 162, 164, 165, 170, 172, 173, 174, 175, 176, 180, 182, 187, 189, 190, 191, 192, 194, 198, 199], "model": [4, 12, 20, 34, 35, 71, 72, 75, 82, 84, 86, 95, 97, 99, 104, 106, 113, 115, 118, 122, 124, 125, 130, 132, 138, 139, 145, 148, 154, 162, 164, 165, 170, 174, 175, 178, 180, 182, 183, 187, 189, 190, 191, 194, 196, 199, 201, 202], "page": [11, 45, 47, 48, 82, 109, 118], "exampl": [11, 12, 23, 29, 30, 34, 35, 47, 64, 66, 71, 72, 75, 77, 81, 86, 88, 89, 90, 95, 100, 101, 106, 108, 109, 113, 115, 117, 124, 125, 126, 127, 130, 138, 139, 140, 141, 145, 147, 149, 156, 157, 160, 162, 164, 166, 170, 172, 173, 175, 176, 180, 182, 183, 189, 190, 191, 192, 196, 200], "last": [11, 12, 22, 27, 34, 35, 36, 40, 47, 48, 64, 70, 72, 75, 76, 82, 88, 89, 99, 102, 108, 109, 117, 124, 126, 132, 134, 138, 139, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 176, 189, 191, 192, 200, 201], "year": [11, 12, 27, 76, 77, 84, 164, 189], "sens": [11, 12, 22, 24, 25, 36, 72, 76, 88, 89, 100, 101, 117, 122, 127, 132, 139, 141, 164, 165, 170, 175, 182, 190, 192], "like": [11, 12, 22, 23, 24, 25, 27, 34, 35, 40, 66, 71, 75, 76, 77, 81, 82, 86, 88, 89, 90, 91, 97, 98, 102, 106, 108, 109, 117, 118, 120, 122, 124, 125, 126, 127, 130, 132, 139, 140, 141, 147, 149, 150, 156, 157, 162, 164, 165, 166, 170, 172, 173, 174, 175, 182, 183, 187, 189, 190, 191, 192, 198, 199, 201], "brainstorm": [11, 12, 22, 24, 25, 132], "idea": [11, 12, 22, 23, 24, 70, 72, 75, 81, 82, 88, 98, 99, 100, 106, 108, 126, 132, 147, 149, 150, 154, 162, 164, 165, 170, 172, 173, 174, 180, 183, 187, 189, 191, 194, 200], "plan": [12, 166, 180, 182, 185, 189], "explicitli": [12, 24, 25, 81, 82, 88, 95, 126, 130, 160, 162], "encourag": [12, 23, 25, 109, 182, 191], "iter": [12, 34, 35, 36, 64, 66, 102, 124, 126, 127, 176, 183, 189], "natur": [12, 27, 64, 72, 81, 84, 89, 100, 104, 111, 120, 125, 134, 143, 147, 148, 149, 150, 162, 178, 185, 190, 194, 196, 201], "answer": [12, 22, 23, 24, 25, 36, 71, 76, 77, 86, 109, 122, 130, 132, 147, 149, 164, 182, 196, 198, 199, 200, 202], "gradual": [12, 34, 139, 149, 173, 182, 189], "refin": [12, 24], "hypothes": [12, 23, 86, 124, 130, 164, 166, 172, 189], "assign": [12, 34, 35, 36, 81, 88, 90, 97, 100, 101, 102, 108, 125, 126, 127, 166, 196], "pod": [12, 30, 40], "broad": [12, 174, 187, 189, 196, 202], "fmri": [12, 81, 109, 196, 199], "ecog": 12, "theori": [12, 22, 71, 90, 93, 101, 109, 132, 160, 178, 182, 192], "each": [12, 13, 22, 23, 24, 25, 27, 34, 35, 36, 40, 42, 45, 47, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 122, 124, 125, 126, 127, 130, 132, 138, 139, 140, 141, 145, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "split": [12, 22, 24, 34, 35, 36, 90, 102, 109, 125, 126, 127, 132, 190], "alphabet": 12, "goal": [12, 22, 23, 24, 25, 76, 84, 86, 100, 101, 108, 109, 116, 124, 126, 130, 132, 139, 140, 141, 149, 150, 164, 165, 166, 182, 189, 190, 191, 192, 198], "balanc": [12, 86, 89, 90, 101, 154, 164, 190, 191, 192], "expert": [12, 202], "move": [12, 22, 24, 25, 70, 72, 75, 77, 81, 82, 88, 124, 125, 132, 140, 150, 156, 157, 158, 165, 166, 172, 173, 174, 180, 182, 189, 191, 192, 199, 200, 202], "around": [12, 22, 24, 35, 70, 77, 81, 88, 89, 90, 97, 98, 99, 100, 101, 102, 116, 117, 132, 138, 140, 148, 152, 156, 158, 164, 165, 166, 173, 174, 175, 182, 183, 191, 199, 201], "onc": [12, 22, 23, 24, 25, 48, 72, 77, 82, 88, 89, 99, 102, 106, 117, 118, 124, 126, 127, 132, 139, 149, 157, 175, 176, 183, 189, 190, 191, 192, 198, 201, 202], "search": [12, 22, 25, 29, 93, 97, 124, 132, 185, 192, 194, 201], "literatur": [12, 23, 24, 25, 29, 40, 130], "paper": [12, 20, 25, 71, 76, 77, 84, 90, 104, 118, 143, 147, 148, 157, 158, 164, 168, 199], "form": [12, 22, 24, 30, 32, 34, 35, 36, 46, 64, 70, 72, 75, 76, 77, 81, 89, 90, 95, 97, 100, 108, 109, 113, 115, 116, 124, 126, 127, 132, 138, 140, 141, 148, 150, 162, 164, 165, 166, 174, 175, 176, 183, 189, 190, 199, 200, 201], "rest": [12, 66, 76, 77, 82, 88, 89, 90, 100, 101, 102, 117, 147, 149, 158, 198, 200, 202], "try": [12, 22, 25, 27, 34, 35, 48, 70, 71, 72, 75, 76, 81, 82, 88, 90, 97, 98, 99, 101, 108, 109, 117, 118, 124, 125, 126, 127, 132, 138, 139, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 174, 175, 182, 183, 189, 190, 191, 192, 200, 201], "preliminari": [12, 22, 132, 183], "dataset": [12, 22, 24, 29, 82, 86, 90, 97, 98, 100, 108, 109, 117, 118, 122, 124, 125, 126, 132, 141, 166, 175, 176], "2": [12, 20, 23, 24, 32, 40, 42, 48, 84, 86, 93, 95, 102, 104, 106, 113, 122, 134, 143, 152, 178, 185, 187, 194, 196], "dedic": [12, 27], "teach": [12, 34, 46, 106, 174, 180, 196], "strategi": [12, 22, 72, 90, 125, 132, 139, 140, 172, 182, 190, 191, 192, 196, 198], "approach": [12, 22, 23, 24, 25, 34, 75, 82, 97, 98, 99, 100, 102, 106, 109, 122, 126, 127, 130, 132, 141, 156, 157, 160, 162, 164, 165, 166, 175, 176, 182, 183, 187, 189, 191, 194, 196], "step": [12, 24, 25, 34, 35, 36, 64, 66, 70, 71, 72, 76, 81, 82, 88, 89, 90, 97, 102, 108, 109, 115, 116, 117, 118, 124, 126, 127, 130, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 168, 170, 172, 173, 174, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201, 202], "appli": [12, 23, 24, 34, 35, 66, 72, 75, 77, 82, 88, 90, 95, 98, 100, 102, 108, 109, 117, 122, 124, 125, 126, 134, 148, 156, 158, 162, 165, 175, 183, 189, 191, 194, 198, 199, 200, 201, 202], "second": [12, 22, 24, 25, 34, 37, 64, 66, 70, 72, 75, 76, 77, 81, 82, 88, 89, 90, 106, 108, 109, 113, 115, 116, 117, 118, 122, 124, 125, 126, 127, 132, 138, 140, 141, 145, 148, 149, 154, 156, 157, 158, 164, 165, 172, 174, 175, 176, 182, 183, 189, 192, 200, 201], "continu": [12, 22, 46, 64, 66, 72, 75, 77, 82, 88, 89, 90, 95, 102, 132, 140, 141, 148, 157, 162, 164, 170, 172, 174, 176, 180, 189, 192], "analyz": [12, 24, 25, 27, 36, 118, 125, 126, 140, 166, 198, 202], "result": [12, 22, 23, 24, 25, 34, 35, 36, 64, 66, 71, 72, 75, 76, 77, 81, 82, 84, 86, 88, 89, 90, 97, 98, 100, 108, 115, 116, 118, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 156, 158, 165, 166, 172, 174, 175, 182, 183, 189, 190, 191, 192, 198, 200, 202], "least": [12, 25, 46, 70, 72, 82, 98, 99, 101, 102, 108, 124, 127, 140, 158, 164, 175, 182, 199], "testabl": [12, 23], "hypothesi": [12, 23, 24, 25, 64, 88, 95, 99, 126, 127, 201], "swap": [12, 30, 34, 40, 64, 200], "cours": [12, 24, 25, 34, 35, 36, 46, 48, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 106, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 134, 138, 139, 140, 141, 147, 148, 149, 150, 154, 156, 157, 158, 160, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201, 202], "focu": [12, 23, 64, 70, 71, 72, 81, 82, 88, 89, 98, 100, 109, 115, 124, 126, 138, 147, 149, 150, 154, 164, 165, 175, 182, 192, 198, 199, 200, 201, 202], "against": [12, 23, 25, 95, 97, 106, 140, 141, 157, 183, 196, 201], "other": [12, 22, 23, 24, 25, 34, 36, 40, 47, 64, 70, 72, 75, 76, 77, 81, 82, 84, 88, 89, 90, 91, 98, 102, 106, 108, 109, 117, 118, 122, 124, 125, 126, 127, 132, 138, 139, 140, 141, 145, 147, 148, 149, 150, 156, 157, 158, 162, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 187, 189, 190, 191, 192, 194, 196, 198, 199, 200, 201], "megapod": 12, "organ": [12, 27, 34, 36, 64, 66, 88, 108, 120, 134], "lead": [12, 22, 25, 30, 35, 66, 71, 76, 82, 98, 124, 126, 132, 148, 150, 154, 156, 158, 164, 172, 183, 189, 190, 191, 192], "tell": [12, 23, 71, 75, 82, 88, 95, 98, 102, 106, 109, 122, 124, 126, 127, 139, 156, 164, 165, 175, 183, 199], "them": [12, 22, 23, 24, 29, 34, 35, 36, 42, 64, 66, 70, 71, 75, 82, 86, 88, 89, 90, 102, 106, 109, 116, 117, 118, 122, 124, 125, 126, 127, 132, 138, 140, 141, 148, 149, 156, 162, 165, 166, 173, 175, 176, 182, 183, 187, 189, 192, 196, 198, 200, 201, 202], "stori": [12, 182], "low": [12, 34, 75, 88, 101, 109, 113, 117, 118, 126, 134, 147, 149, 158, 164, 165, 168, 172, 173, 175, 182, 183, 189], "kei": [12, 23, 24, 25, 36, 66, 70, 97, 98, 100, 101, 102, 113, 115, 122, 124, 126, 165, 170, 192, 201, 202], "wai": [12, 22, 23, 24, 25, 34, 35, 64, 70, 71, 75, 76, 77, 81, 82, 86, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 106, 108, 113, 115, 117, 122, 124, 125, 126, 127, 130, 132, 134, 139, 140, 141, 147, 148, 149, 150, 156, 162, 164, 165, 166, 175, 183, 190, 191, 192, 194, 196, 198, 199, 201], "meant": [12, 24, 25, 122, 124, 125, 127], "product": [12, 22, 23, 25, 34, 35, 36, 64, 66, 71, 72, 76, 77, 81, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 192, 199, 200, 201], "valu": [12, 22, 23, 24, 25, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 81, 82, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 140, 141, 148, 149, 150, 154, 164, 165, 166, 168, 172, 173, 174, 175, 176, 178, 183, 185, 187, 191, 192, 198, 199, 200, 201], "airtabl": [12, 30, 46], "develop": [12, 22, 23, 29, 88, 98, 101, 109, 116, 124, 125, 130, 132, 138, 140, 141, 145, 148, 149, 154, 156, 160, 166, 175, 176, 189], "conjunct": 12, "varieti": [12, 22, 24, 70, 71, 122, 125, 132, 138], "starter": 12, "just": [12, 20, 22, 23, 25, 36, 40, 70, 71, 72, 75, 77, 81, 82, 88, 89, 90, 97, 98, 99, 101, 102, 106, 108, 109, 115, 117, 124, 125, 126, 127, 132, 138, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201, 202], "keyword": [12, 34, 35, 108, 166], "reus": [12, 66, 91, 173, 182], "extens": [12, 34, 36, 81, 100, 109, 115, 164, 165, 189, 190, 192], "don": [12, 22, 23, 25, 48, 69, 70, 76, 80, 82, 87, 88, 89, 90, 96, 100, 101, 102, 107, 108, 109, 114, 116, 117, 118, 123, 127, 130, 131, 132, 137, 146, 148, 155, 163, 164, 165, 166, 171, 173, 174, 175, 176, 181, 182, 188, 189, 190, 197, 198, 199, 200, 201], "experi": [12, 22, 23, 24, 25, 27, 34, 35, 36, 46, 48, 76, 77, 81, 82, 88, 106, 108, 109, 117, 124, 132, 141, 158, 164, 165, 166, 172, 174, 175, 187, 189, 192, 196], "design": [12, 20, 22, 24, 27, 36, 66, 76, 77, 101, 102, 132, 175], "give": [12, 22, 23, 24, 25, 27, 64, 70, 75, 76, 77, 81, 82, 88, 89, 90, 106, 108, 109, 117, 124, 132, 141, 145, 147, 148, 149, 154, 156, 157, 158, 164, 165, 166, 172, 173, 175, 182, 189, 190, 192, 196, 198, 199], "enough": [12, 22, 23, 64, 88, 97, 101, 108, 124, 132, 165, 172, 182, 192, 199, 201], "structur": [12, 22, 23, 29, 34, 36, 40, 70, 71, 72, 88, 89, 104, 106, 109, 113, 117, 118, 125, 126, 127, 132, 134, 141, 168, 173, 174, 175, 182, 189, 201, 202], "option": [12, 22, 23, 24, 34, 35, 36, 40, 48, 64, 66, 71, 75, 81, 82, 109, 122, 124, 125, 127, 132, 138, 149, 164, 165, 166, 172, 174, 175, 176, 182, 183, 190, 199, 200, 201, 202], "keep": [12, 22, 23, 34, 35, 36, 64, 66, 72, 75, 77, 88, 89, 101, 109, 117, 126, 132, 134, 138, 139, 147, 149, 164, 165, 166, 172, 175, 176, 180, 182, 183, 189, 190], "stick": [12, 23, 190], "Or": [12, 22, 23, 126, 132, 182], "first": [12, 22, 23, 24, 25, 34, 35, 36, 38, 40, 48, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 97, 99, 100, 101, 102, 106, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 130, 132, 138, 139, 140, 141, 145, 147, 148, 149, 150, 154, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 187, 189, 190, 192, 194, 198, 200, 201, 202], "diverg": [12, 156, 158], "test": [12, 22, 34, 35, 36, 64, 75, 81, 82, 86, 90, 95, 102, 108, 109, 115, 124, 125, 126, 132, 141, 143, 150, 166, 175, 182, 183, 189, 191, 192, 201], "flow": [12, 23, 64, 76, 149], "hesit": 12, "skip": [12, 64, 66, 118, 124, 125, 172, 189], "complet": [12, 22, 30, 34, 35, 36, 40, 46, 66, 69, 70, 71, 72, 75, 77, 80, 81, 82, 87, 88, 96, 101, 102, 104, 107, 108, 109, 114, 115, 116, 118, 120, 123, 124, 125, 126, 127, 131, 132, 134, 137, 138, 139, 140, 146, 147, 148, 149, 150, 155, 163, 164, 165, 166, 171, 172, 173, 174, 176, 181, 182, 183, 188, 189, 192, 197, 198, 199, 200, 201, 202], "flexibl": [12, 23, 66, 98, 109, 120, 122, 124, 165, 182], "friendli": [12, 27], "consult": [12, 22, 75, 76, 108, 132, 192, 198], "issu": [12, 24, 25, 34, 36, 77, 138, 164, 175], "help": [12, 22, 23, 34, 35, 36, 42, 43, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 122, 124, 125, 126, 127, 130, 132, 141, 147, 148, 149, 150, 154, 156, 157, 158, 164, 165, 166, 170, 173, 175, 176, 182, 183, 187, 191, 192, 201, 202], "aspect": [12, 22, 23, 34, 35, 36, 64, 66, 75, 86, 88, 98, 124, 127, 132, 140, 152, 175, 191, 192, 201], "approxim": [12, 34, 64, 66, 75, 81, 82, 88, 117, 122, 124, 138, 143, 156, 158, 164, 165, 175, 200], "someth": [12, 22, 23, 24, 25, 64, 75, 76, 77, 88, 90, 91, 108, 109, 125, 126, 132, 148, 154, 164, 165, 166, 174, 189, 190, 202], "sinc": [12, 24, 25, 34, 35, 36, 47, 64, 66, 71, 81, 90, 98, 100, 101, 109, 115, 117, 122, 124, 125, 126, 127, 139, 141, 147, 148, 150, 158, 164, 165, 166, 172, 173, 176, 182, 183, 190, 192, 199, 200, 201], "arriv": [12, 72, 89, 90, 97, 98, 99, 149, 150, 164, 174], "unannounc": 12, "ani": [12, 22, 23, 24, 25, 29, 34, 35, 48, 64, 70, 71, 72, 75, 76, 81, 82, 86, 88, 90, 95, 98, 101, 102, 108, 109, 116, 117, 118, 120, 124, 125, 126, 127, 130, 132, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 175, 182, 183, 189, 190, 191, 199, 200, 201], "busi": [12, 71], "stop": [12, 22, 24, 64, 66, 108, 132, 147, 176, 190], "were": [12, 22, 23, 24, 34, 75, 82, 88, 89, 90, 102, 108, 122, 124, 125, 126, 127, 132, 141, 148, 149, 150, 164, 165, 172, 173, 175, 176, 182, 183, 187, 189, 199, 201, 202], "do": [12, 20, 22, 23, 24, 25, 27, 29, 34, 35, 36, 40, 47, 48, 64, 71, 72, 77, 81, 82, 86, 88, 90, 91, 95, 97, 98, 99, 100, 101, 102, 108, 115, 117, 118, 122, 124, 125, 126, 127, 130, 132, 138, 140, 141, 147, 149, 150, 154, 156, 157, 158, 160, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 194, 196, 198, 199, 200, 201, 202], "resum": 12, "when": [12, 22, 23, 24, 25, 34, 35, 36, 40, 48, 64, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 91, 95, 97, 98, 100, 101, 102, 106, 108, 109, 115, 117, 118, 124, 125, 126, 127, 130, 132, 138, 139, 140, 147, 148, 149, 150, 156, 157, 158, 164, 165, 172, 173, 174, 175, 182, 183, 187, 189, 190, 191, 196, 198, 199, 200, 201, 202], "leav": [12, 70, 89, 99, 126, 148, 156, 164, 172, 182], "sometim": [12, 23, 25, 34, 64, 70, 71, 75, 76, 81, 82, 102, 106, 116, 139, 140, 157, 164, 165, 175, 189, 190, 192, 196, 199, 200], "might": [12, 20, 22, 23, 24, 25, 29, 71, 72, 76, 77, 82, 88, 89, 97, 106, 108, 109, 124, 125, 126, 127, 132, 141, 147, 148, 149, 164, 165, 168, 175, 182, 191, 201], "earlier": [12, 64, 71, 75, 108, 138, 140, 164, 165, 189], "later": [12, 22, 25, 64, 71, 72, 75, 76, 77, 81, 82, 89, 115, 124, 125, 130, 132, 141, 148, 156, 164, 165, 170, 176, 180, 182, 183, 189, 191, 198], "reach": [12, 24, 25, 35, 81, 88, 89, 98, 117, 130, 134, 140, 147, 149, 150, 156, 157, 158, 172, 183], "out": [12, 22, 23, 24, 25, 34, 35, 40, 43, 46, 47, 64, 66, 71, 72, 75, 76, 81, 82, 88, 89, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 124, 125, 126, 127, 132, 138, 139, 141, 147, 148, 149, 150, 154, 156, 158, 160, 164, 165, 166, 172, 174, 175, 176, 180, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201, 202], "extra": [12, 23, 82, 100, 124, 147, 158, 172, 176, 189, 192, 198], "whenev": [12, 66, 109, 126, 150, 182, 189, 192], "post": [12, 40, 72, 75, 88, 90, 91, 120, 141, 148, 149, 150], "channel": [12, 66, 76, 125, 126, 127, 139, 149, 173, 176], "senior": 12, "figur": [12, 22, 23, 24, 25, 180], "field": [12, 20, 22, 23, 88, 89, 90, 104, 106, 108, 125, 126, 127, 132, 156, 158, 160, 165, 192, 196, 201, 202], "typic": [12, 34, 35, 86, 88, 95, 124, 125, 127, 130, 138, 147, 148, 149, 150, 164, 166, 175, 176, 189, 196], "postdoc": 12, "professor": 12, "industri": 12, "navig": [12, 20, 104, 124, 140, 165, 183, 191], "scientif": [12, 22, 23, 24, 25, 64, 84, 88, 120, 132, 178, 183], "process": [12, 22, 23, 24, 25, 27, 29, 34, 36, 66, 71, 76, 77, 81, 82, 84, 86, 88, 89, 93, 99, 101, 102, 104, 108, 111, 120, 125, 126, 127, 130, 132, 134, 148, 149, 154, 156, 158, 166, 168, 170, 172, 173, 174, 175, 180, 182, 189, 201, 202], "won": [12, 82, 109, 124, 126, 138, 165, 166, 191, 200], "often": [12, 22, 23, 24, 25, 34, 36, 71, 75, 81, 82, 86, 88, 90, 98, 100, 101, 102, 106, 117, 122, 124, 125, 127, 130, 132, 140, 149, 156, 158, 164, 165, 166, 170, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 194, 196, 199, 202], "sourc": [12, 29, 32, 36, 81, 82, 101, 140, 148, 165, 175, 183, 201], "guidanc": [12, 130], "perspect": [12, 64, 70, 71, 84, 120, 125, 134, 194], "depend": [12, 22, 23, 25, 32, 34, 36, 66, 72, 77, 81, 82, 86, 88, 89, 95, 97, 98, 99, 100, 101, 102, 108, 109, 118, 124, 125, 130, 132, 134, 139, 140, 141, 145, 147, 148, 149, 156, 157, 158, 164, 165, 166, 172, 173, 174, 183, 189, 198], "slot": [12, 30, 40, 42, 190], "regardless": [12, 90, 125, 126, 140, 164, 189, 191], "whether": [12, 22, 24, 25, 34, 35, 36, 71, 72, 75, 77, 81, 82, 95, 108, 109, 113, 118, 124, 125, 126, 127, 132, 145, 148, 149, 150, 156, 158, 164, 165, 182, 201], "spend": [12, 22, 82, 91, 132, 138, 164, 198], "session": [12, 36, 37, 38, 39, 40, 48, 88, 191, 192], "sort": [12, 36, 88, 100, 108, 115, 116, 117, 118, 124, 127, 134, 148, 176, 198, 202], "yourselv": [12, 175], "letter": [12, 24, 25, 76], "name": [12, 22, 29, 32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "introduct": [12, 23, 100, 138, 139, 185], "30": [12, 25, 40, 72, 75, 76, 77, 82, 93, 97, 98, 99, 100, 108, 109, 118, 124, 126, 127, 139, 141, 147, 148, 150, 157, 164, 189, 191, 192, 200, 201], "min": [12, 22, 24, 34, 35, 36, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "sai": [12, 23, 40, 70, 71, 75, 76, 77, 81, 82, 90, 95, 98, 102, 126, 127, 138, 139, 164, 165, 172, 190, 198, 201], "few": [12, 24, 25, 34, 35, 36, 64, 66, 72, 76, 77, 82, 88, 108, 117, 118, 124, 125, 126, 127, 141, 145, 147, 148, 149, 150, 162, 164, 174, 175, 189, 199, 200], "thing": [12, 22, 70, 72, 82, 98, 106, 127, 130, 132, 138, 140, 149, 157, 165, 168, 170, 175, 176, 190, 192, 199, 200, 201, 202], "about": [12, 23, 24, 25, 34, 36, 48, 64, 66, 71, 72, 77, 81, 82, 86, 88, 89, 90, 95, 98, 99, 101, 106, 108, 113, 116, 117, 122, 124, 125, 126, 127, 130, 138, 139, 140, 141, 145, 147, 148, 149, 150, 154, 156, 157, 158, 162, 164, 165, 166, 170, 172, 173, 174, 175, 180, 182, 183, 187, 189, 190, 191, 192, 194, 196, 198, 199, 200, 202], "area": [12, 20, 27, 34, 36, 66, 70, 72, 75, 81, 82, 86, 89, 90, 122, 124, 125, 126, 127, 134, 148, 149, 150, 172, 187, 189, 192, 199, 202], "curiou": [12, 88, 149, 198], "listen": [12, 37, 38, 39, 76, 77], "carefulli": [12, 23, 138, 189, 198, 202], "brows": 12, "booklet": [12, 22, 23, 30, 132], "skim": 12, "entir": [12, 27, 88, 99, 125, 139, 140, 141, 156, 157, 165, 166, 175, 183, 191, 200], "slide": [12, 30, 72, 125, 147], "doc": [12, 34, 47, 101], "further": [12, 23, 24, 34, 35, 75, 76, 77, 82, 97, 101, 102, 108, 113, 124, 125, 127, 138, 140, 164, 165, 172, 175, 182, 190, 191, 192], "within": [12, 22, 23, 24, 25, 64, 70, 81, 88, 90, 99, 109, 124, 125, 126, 127, 132, 139, 150, 189, 191, 198, 199, 201, 202], "60": [12, 22, 24, 34, 75, 76, 82, 124, 127, 132, 139, 148, 149, 150, 172, 182, 191], "choos": [12, 23, 36, 71, 75, 81, 82, 86, 90, 97, 98, 99, 100, 101, 102, 117, 124, 127, 138, 140, 149, 156, 158, 164, 165, 172, 174, 175, 178, 180, 182, 191, 192, 202], "concret": [12, 22, 124, 126, 132, 139, 198], "either": [12, 24, 27, 34, 35, 36, 72, 75, 82, 88, 89, 90, 95, 99, 102, 139, 149, 150, 156, 157, 165, 172, 173, 182, 191, 198], "directli": [12, 34, 47, 64, 88, 90, 98, 116, 125, 126, 127, 139, 165, 170, 173, 174, 175, 180, 182, 191, 198, 200, 202], "tip": [12, 23, 70, 98, 183, 190], "No": [12, 22, 32, 33, 34, 35, 36, 40, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "after": [12, 22, 23, 24, 34, 35, 40, 48, 64, 66, 69, 70, 71, 72, 80, 81, 82, 87, 88, 89, 90, 96, 97, 98, 100, 101, 106, 107, 114, 115, 116, 117, 120, 123, 124, 126, 127, 131, 132, 137, 138, 139, 141, 146, 147, 148, 149, 150, 155, 157, 158, 163, 165, 171, 172, 174, 176, 181, 182, 188, 189, 190, 191, 192, 197, 198, 199, 200, 201, 202], "feasibl": [12, 99, 124], "next": [12, 24, 34, 40, 64, 66, 70, 71, 72, 75, 76, 81, 82, 86, 88, 89, 90, 91, 100, 101, 102, 108, 109, 115, 116, 117, 118, 122, 124, 125, 126, 127, 139, 140, 141, 147, 148, 149, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 182, 183, 189, 191, 192, 198, 199, 200, 201, 202], "That": [12, 22, 23, 24, 34, 71, 72, 75, 88, 90, 108, 109, 124, 125, 130, 132, 141, 147, 150, 156, 157, 158, 164, 165, 166, 182, 199], "how": [12, 22, 23, 24, 25, 29, 34, 35, 36, 48, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 84, 86, 88, 90, 91, 95, 97, 98, 99, 100, 101, 102, 106, 108, 109, 111, 113, 115, 116, 117, 118, 122, 124, 125, 126, 127, 130, 132, 134, 138, 139, 140, 141, 145, 147, 149, 150, 154, 156, 157, 158, 162, 164, 165, 166, 172, 173, 175, 176, 178, 180, 187, 189, 190, 191, 194, 196, 198, 199, 200, 202], "culmin": [12, 126], "propos": [12, 29, 76, 77, 86, 89, 99, 147], "peek": [12, 64, 140], "ahead": [12, 88, 173], "stai": [12, 23, 71, 82, 89, 122, 138, 139, 140, 156, 158, 173, 182, 183, 191, 192], "tune": [12, 104, 122, 124, 125, 152, 178], "receiv": [12, 23, 36, 66, 89, 125, 147, 148, 149, 156, 165, 182, 187, 189, 190, 191, 192, 198], "arrang": [12, 76, 77, 126], "ideal": [12, 23, 82, 89, 90, 101, 124, 127, 190], "could": [12, 22, 23, 24, 25, 34, 36, 40, 70, 71, 72, 75, 76, 77, 81, 82, 84, 86, 88, 89, 90, 95, 100, 102, 108, 113, 115, 117, 118, 124, 125, 126, 127, 132, 148, 150, 156, 162, 164, 165, 166, 173, 174, 175, 182, 183, 189, 190, 200, 201], "hand": [12, 22, 23, 24, 34, 71, 76, 77, 82, 90, 97, 124, 125, 132, 134, 138, 140, 149, 156, 158, 162, 166, 176, 183, 191, 201], "dirti": 12, "There": [12, 22, 23, 24, 25, 34, 66, 71, 75, 77, 81, 82, 88, 89, 90, 102, 109, 122, 124, 125, 127, 132, 139, 148, 149, 156, 157, 160, 164, 165, 170, 172, 174, 182, 183, 189, 192, 196, 201], "interspers": 12, "among": [12, 35, 36, 90, 157, 178, 190], "even": [12, 25, 34, 36, 64, 70, 71, 72, 76, 77, 81, 88, 89, 90, 97, 106, 108, 109, 122, 124, 125, 126, 134, 138, 139, 140, 148, 149, 150, 157, 158, 162, 165, 166, 172, 173, 175, 182, 183, 189, 190, 191, 192, 194, 198, 200, 201], "especi": [12, 23, 48, 71, 82, 97, 102, 125, 140, 147, 164, 165, 172, 175, 183, 202], "fine": [12, 138], "being": [12, 64, 72, 75, 81, 82, 90, 97, 109, 116, 124, 125, 126, 127, 139, 165, 166, 172, 175, 183], "pai": [12, 76, 77, 149, 182, 190, 191, 192], "attent": [12, 76, 77, 149, 152, 158, 183, 192], "access": [12, 22, 27, 29, 40, 47, 48, 81, 98, 108, 116, 124, 157, 173, 174, 183, 185, 200], "bin": [12, 22, 24, 34, 66, 72, 81, 82, 88, 89, 90, 99, 108, 124, 125, 126, 127, 132, 140, 147, 148, 150, 174, 176, 182], "align": [12, 22, 24, 25, 35, 64, 70, 71, 72, 75, 76, 77, 81, 82, 89, 90, 97, 98, 99, 100, 108, 109, 115, 116, 117, 124, 126, 127, 132, 147, 148, 156, 157, 158, 164, 165, 172, 173, 174, 175, 176, 183, 189, 200, 201], "element": [12, 23, 24, 34, 35, 36, 64, 66, 70, 71, 75, 76, 77, 88, 89, 100, 101, 108, 109, 116, 117, 124, 126, 130, 138, 139, 158, 164, 166, 173, 175, 176, 182, 190, 194, 198, 199, 200, 201], "Be": [12, 22, 23, 70, 81, 88, 132, 201], "lookout": 12, "notic": [12, 22, 23, 24, 25, 34, 64, 75, 82, 106, 109, 124, 126, 132, 139, 140, 141, 147, 148, 150, 156, 158, 183, 189, 191, 192, 200], "unexpect": 12, "dig": [12, 22, 132], "deeper": [12, 22, 64, 106, 116, 124, 125, 132, 149, 158], "must": [12, 23, 71, 76, 82, 88, 89, 90, 102, 116, 118, 124, 139, 164, 165, 172, 173, 182, 183, 190, 191, 192, 200, 201], "open": [12, 23, 29, 40, 42, 47, 99, 108, 109, 124, 125, 126, 127, 139, 149, 156, 173, 175, 192], "mind": [12, 22, 23, 34, 64, 76, 77, 101, 109, 132, 165], "trick": [12, 76, 82, 124, 126, 176], "hardest": [12, 22, 86, 132], "part": [12, 22, 23, 24, 25, 34, 36, 46, 75, 81, 88, 89, 90, 98, 100, 106, 108, 109, 124, 125, 126, 132, 138, 140, 141, 148, 156, 157, 158, 164, 165, 176, 183, 190, 191, 192, 196, 198], "technic": [12, 35, 70, 71, 125, 182, 189], "challeng": [12, 20, 35, 36, 98, 124, 175, 176, 183, 190, 191], "wrestl": 12, "easier": [12, 22, 23, 34, 64, 127, 130, 132, 141, 166, 174, 183], "equal": [12, 24, 34, 64, 70, 71, 72, 75, 76, 77, 81, 82, 89, 90, 97, 98, 109, 115, 116, 118, 126, 140, 147, 156, 164, 165, 172, 174, 176, 182, 183, 189, 190, 198, 199, 200, 201], "network": [12, 20, 32, 34, 35, 36, 40, 76, 77, 82, 84, 86, 95, 104, 111, 113, 122, 134, 143, 145, 149, 150, 154, 157, 185, 194, 198, 200, 201, 202], "simul": [12, 22, 23, 24, 25, 66, 72, 76, 77, 81, 82, 84, 89, 95, 97, 98, 99, 100, 101, 102, 115, 132, 138, 139, 141, 148, 158, 166, 175, 182, 183, 189, 190, 192, 200], "still": [12, 22, 25, 27, 34, 35, 70, 72, 82, 88, 89, 97, 99, 100, 124, 125, 126, 127, 132, 134, 138, 139, 149, 156, 160, 164, 182, 183, 190, 198, 200, 201], "becom": [12, 34, 36, 71, 72, 75, 76, 77, 81, 82, 90, 115, 116, 140, 147, 149, 150, 157, 158, 164, 165, 173, 174, 176, 182, 183, 189, 190, 199, 200, 201], "opposit": [12, 34, 70, 75, 124, 149, 172, 198, 199, 201], "happen": [12, 23, 47, 71, 72, 75, 76, 77, 81, 88, 89, 100, 108, 109, 115, 116, 127, 138, 147, 148, 149, 150, 154, 156, 157, 158, 164, 165, 172, 174, 182, 183, 189, 198, 199, 202], "find": [12, 23, 24, 25, 27, 29, 36, 43, 70, 71, 75, 76, 77, 97, 99, 100, 101, 102, 108, 109, 116, 117, 118, 124, 127, 138, 148, 150, 157, 164, 165, 166, 172, 175, 176, 182, 183, 189, 190, 191, 192, 199, 200, 201], "realiz": [12, 64, 66, 148, 149], "alwai": [12, 23, 24, 25, 34, 35, 70, 71, 72, 75, 77, 82, 88, 90, 97, 98, 99, 100, 106, 124, 126, 138, 139, 148, 149, 150, 156, 157, 158, 162, 164, 165, 173, 182, 190, 191, 192, 201], "bug": 12, "too": [12, 22, 23, 24, 25, 76, 81, 82, 88, 89, 101, 108, 109, 116, 117, 124, 132, 165, 175, 183, 189, 190, 192, 199, 200], "true": [12, 22, 24, 25, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 172, 173, 175, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "train": [12, 22, 23, 102, 108, 118, 120, 122, 124, 125, 126, 130, 132, 141, 143, 147, 149, 150, 189], "simpl": [12, 23, 24, 25, 34, 35, 64, 70, 72, 75, 76, 81, 82, 84, 88, 89, 90, 93, 95, 97, 98, 99, 100, 101, 102, 106, 108, 109, 113, 115, 122, 124, 125, 126, 130, 138, 139, 141, 143, 145, 147, 148, 149, 150, 152, 157, 162, 164, 165, 166, 168, 170, 173, 182, 187, 189, 190, 191, 192, 198, 200, 201, 202], "where": [12, 22, 23, 24, 25, 34, 47, 48, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 100, 101, 102, 108, 109, 113, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 162, 165, 166, 170, 172, 173, 174, 175, 176, 180, 183, 187, 189, 190, 191, 192, 196, 198, 200, 201], "matter": [12, 22, 23, 25, 34, 66, 70, 82, 109, 124, 132, 149, 156, 158, 164, 165, 182, 183, 189, 194, 201], "curv": [12, 22, 24, 75, 76, 82, 88, 100, 104, 108, 109, 124, 125, 132, 147, 148, 150, 158, 165, 173, 174, 176, 183], "doe": [12, 22, 23, 24, 25, 27, 32, 36, 47, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 95, 98, 99, 108, 109, 115, 117, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 189, 190, 191, 192, 196, 198, 199, 200, 201], "rememb": [12, 22, 23, 70, 71, 72, 75, 81, 82, 90, 109, 116, 124, 127, 132, 138, 139, 141, 147, 148, 164, 165, 176, 182, 183, 190, 192, 198, 199, 201], "quick": [12, 90, 111, 165, 199], "survei": [12, 22, 27, 40, 93, 132], "googl": [12, 29, 42, 48, 124, 125, 126, 127, 200], "thought": [12, 22, 34, 71, 75, 91, 125, 127, 130, 132, 162, 165, 176, 189, 190, 194], "past": [12, 77, 108, 115, 120, 141, 173, 174, 175, 176, 182, 192], "origin": [12, 23, 25, 34, 35, 36, 66, 70, 71, 72, 75, 76, 88, 97, 98, 99, 100, 115, 116, 117, 126, 138, 145, 158, 165, 166, 175, 176, 190, 200], "howev": [12, 24, 25, 29, 36, 64, 71, 75, 81, 82, 86, 88, 89, 90, 97, 99, 101, 106, 109, 116, 117, 118, 124, 126, 138, 139, 140, 141, 148, 149, 150, 156, 158, 165, 166, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200], "situat": [12, 70, 75, 98, 100, 109, 125, 164, 165, 172, 182, 183, 189, 192, 199], "relev": [12, 23, 24, 29, 34, 35, 36, 66, 76, 77, 81, 93, 98, 100, 102, 109, 124, 125, 126, 127, 138, 156, 157, 160, 164, 165, 189], "hint": [12, 22, 75, 81, 82, 88, 90, 99, 100, 101, 108, 109, 116, 117, 124, 127, 132, 138, 139, 140, 147, 149, 156, 158, 164, 165, 166, 172, 173, 176, 182, 189, 201], "suggest": [12, 25, 66, 75, 88, 99, 100, 109, 117, 118, 166, 172, 176], "complex": [12, 23, 29, 36, 75, 76, 81, 82, 89, 95, 100, 101, 102, 108, 109, 120, 122, 124, 126, 127, 134, 138, 145, 147, 156, 158, 164, 166, 168, 187, 189, 191, 192, 202], "sever": [12, 24, 34, 35, 46, 66, 70, 71, 75, 81, 88, 97, 102, 106, 109, 113, 124, 125, 145, 149, 150, 154, 156, 158, 165, 176, 183, 189, 192, 202], "wrangl": 12, "simpli": [12, 22, 25, 72, 75, 77, 88, 90, 98, 109, 124, 126, 127, 132, 141, 147, 160, 164, 165, 175, 182, 190, 192, 201], "right": [12, 22, 23, 24, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 90, 97, 99, 101, 102, 108, 109, 124, 125, 126, 127, 132, 138, 139, 140, 149, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "psth": 12, "scatter": [12, 22, 24, 66, 72, 76, 77, 81, 97, 98, 99, 100, 109, 115, 116, 118, 126, 132, 138, 141, 166, 173, 174, 175, 198, 199, 200, 201], "differ": [12, 20, 22, 23, 24, 25, 34, 35, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 95, 97, 98, 99, 101, 102, 106, 108, 115, 116, 124, 125, 126, 127, 130, 132, 138, 139, 140, 141, 148, 150, 156, 158, 160, 164, 166, 172, 173, 174, 175, 176, 183, 190, 191, 192, 194, 198, 199, 200, 201], "across": [12, 20, 22, 24, 25, 27, 64, 71, 72, 76, 81, 86, 88, 89, 90, 97, 101, 109, 115, 116, 120, 124, 125, 126, 127, 132, 134, 149, 150, 164, 165, 166, 172, 175, 176, 182, 189, 191, 192, 196], "most": [12, 20, 23, 27, 34, 72, 75, 76, 77, 81, 82, 86, 88, 90, 97, 98, 99, 101, 109, 117, 120, 122, 124, 125, 126, 127, 130, 147, 156, 164, 165, 172, 175, 180, 182, 187, 189, 190, 191, 192, 200, 201, 202], "those": [12, 22, 23, 24, 25, 34, 70, 75, 81, 82, 86, 97, 106, 109, 113, 124, 125, 126, 127, 130, 132, 138, 139, 140, 149, 150, 156, 157, 164, 165, 172, 175, 176, 182, 190, 192], "pick": [12, 24, 75, 82, 97, 102, 109, 124, 126, 127, 182, 190, 202], "qualiti": [12, 36, 82, 99, 101, 102, 164, 175, 182, 199, 201], "deep": [12, 20, 23, 32, 34, 36, 40, 48, 84, 86, 95, 106, 113, 122, 127, 185, 187, 189, 202], "stage": [12, 22, 130, 132], "popul": [12, 20, 24, 27, 70, 71, 75, 88, 95, 104, 106, 113, 115, 122, 124, 125, 126, 127, 134, 150, 152, 154, 158, 178, 198], "voxel": [12, 20, 109], "encod": [12, 34, 35, 36, 104, 106, 109, 122, 124, 125, 134, 176, 199, 202], "certain": [12, 22, 24, 36, 75, 76, 77, 82, 89, 90, 109, 132, 139, 147, 148, 158, 165, 172, 173, 175, 182, 190, 191, 192, 199], "By": [12, 22, 23, 30, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 70, 71, 72, 75, 76, 81, 82, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 162, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "far": [12, 22, 24, 72, 98, 100, 116, 124, 132, 138, 140, 149, 150, 157, 164, 165, 182, 190], "regress": [12, 22, 24, 95, 99, 101, 102, 106, 113, 124, 126, 127, 132, 141, 196, 198, 199], "pca": [12, 35, 36, 113, 115, 126], "cluster": [12, 34, 35, 88, 118, 126], "binari": [12, 22, 25, 34, 35, 36, 81, 82, 95, 109, 125, 132, 141, 148, 149, 150, 162, 165, 170, 172, 176, 180, 182, 183, 199, 201], "categor": [12, 81, 82, 120, 126], "pipelin": [12, 22, 24, 130, 132, 166], "easi": [12, 23, 75, 76, 115, 124, 165, 190, 198, 199, 201], "switch": [12, 34, 70, 71, 82, 124, 134, 173, 176, 182], "predictor": [12, 141], "scikit": [12, 24, 34, 102, 200, 201], "learn": [12, 22, 23, 24, 25, 30, 34, 35, 36, 40, 47, 48, 64, 66, 70, 71, 75, 76, 81, 82, 86, 88, 89, 90, 93, 95, 97, 98, 99, 100, 101, 102, 104, 106, 108, 111, 113, 115, 116, 117, 118, 122, 124, 126, 127, 130, 132, 134, 138, 139, 141, 143, 145, 147, 148, 149, 150, 154, 156, 157, 158, 160, 162, 164, 165, 166, 170, 172, 173, 174, 175, 178, 180, 182, 183, 185, 187, 196, 198, 199, 200, 201, 202], "reduc": [12, 34, 35, 75, 90, 102, 109, 116, 117, 120, 124, 125, 148, 158, 166, 175, 183, 189], "compon": [12, 22, 23, 24, 25, 29, 34, 36, 40, 70, 71, 75, 95, 98, 113, 118, 124, 125, 132, 134, 138, 140, 164, 165, 166, 173, 192, 201], "kind": [12, 20, 22, 24, 76, 81, 86, 91, 102, 108, 117, 124, 126, 130, 132, 138, 147, 149, 165, 183, 189, 190, 196], "pc": 12, "size": [12, 22, 25, 34, 35, 36, 66, 70, 71, 76, 77, 81, 82, 89, 99, 102, 108, 115, 116, 117, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 172, 173, 176, 182, 189, 190, 198, 200, 201], "averag": [12, 20, 22, 24, 25, 75, 77, 81, 82, 88, 89, 97, 102, 106, 108, 109, 124, 125, 126, 127, 132, 139, 140, 147, 148, 149, 150, 154, 156, 157, 158, 164, 165, 172, 173, 174, 176, 182, 189, 190, 192, 198], "simplest": [12, 25, 89, 140, 147, 148, 149, 150, 156, 190, 192], "complic": [12, 77, 89, 100, 106, 126, 164, 168, 189], "nonlinear": [12, 24, 32, 76, 77, 104, 134, 156, 168, 174, 198, 199, 200, 201], "fail": [12, 22, 23, 34, 36, 88, 108, 109, 124, 125, 126, 127, 132, 175, 176, 198, 199, 200, 201], "choic": [12, 20, 22, 24, 25, 27, 34, 35, 36, 81, 86, 90, 95, 97, 99, 102, 106, 108, 109, 115, 117, 118, 124, 126, 127, 130, 132, 134, 156, 162, 165, 168, 172, 173, 183, 189, 190, 191, 192, 198, 199, 200, 201], "fanci": [12, 75], "tsne": [12, 118, 126], "dead": 12, "end": [12, 22, 24, 25, 34, 35, 36, 40, 46, 64, 66, 70, 71, 72, 75, 76, 81, 82, 89, 90, 97, 98, 99, 100, 101, 102, 106, 108, 109, 115, 116, 117, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 162, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 200, 201, 202], "die": [12, 158], "progress": [12, 34, 76, 104, 124, 126, 127, 140, 149, 189, 191], "greatli": 12, "reason": [12, 46, 71, 76, 77, 81, 86, 89, 97, 100, 113, 124, 125, 147, 148, 149, 150, 156, 165, 166, 173, 182, 191, 192], "hard": [12, 22, 23, 24, 81, 126, 132, 165, 200, 202], "interpret": [12, 22, 23, 24, 36, 81, 106, 109, 118, 120, 124, 125, 126, 132, 139, 170, 172, 174, 175, 183, 198, 201], "function": [12, 20, 23, 25, 27, 64, 86, 104, 106, 120, 122, 134, 145, 170, 180], "black": [12, 34, 64, 66, 76, 77, 125, 140, 148, 149, 150, 157, 164, 168, 173, 174, 176], "box": [12, 23, 66, 70, 72, 81, 102, 149, 173, 182], "paramet": [12, 22, 23, 24, 25, 34, 35, 36, 66, 71, 75, 77, 88, 89, 95, 97, 98, 99, 100, 101, 102, 106, 108, 115, 116, 118, 124, 125, 126, 127, 132, 138, 139, 148, 149, 150, 157, 164, 166, 172, 173, 174, 175, 183, 189, 190, 191, 192, 198, 200, 201], "its": [12, 22, 23, 24, 34, 64, 70, 72, 75, 77, 81, 82, 88, 89, 90, 95, 97, 98, 102, 108, 109, 116, 117, 124, 125, 126, 127, 132, 134, 138, 139, 140, 143, 147, 149, 150, 156, 157, 158, 165, 166, 170, 174, 175, 176, 182, 183, 189, 190, 191, 192, 194, 199], "replac": [12, 34, 35, 36, 77, 81, 102, 117, 124, 126, 127, 149, 156, 183, 189, 190], "sne": [12, 111, 113, 126], "umap": [12, 111], "leiden": 12, "louvain": 12, "tool": [12, 23, 29, 30, 34, 35, 36, 86, 88, 95, 100, 113, 122, 130, 141, 149, 165, 176, 196], "unlik": [12, 34, 47, 82, 89, 108, 109, 118, 140, 164, 165, 182, 191], "noisi": [12, 22, 24, 25, 34, 82, 97, 99, 100, 101, 117, 132, 138, 158, 165, 166, 173, 174, 175, 176, 183, 190], "reduct": [12, 32, 34, 36, 40, 70, 84, 86, 113, 115, 116, 125, 147, 148, 196, 202], "instead": [12, 66, 70, 71, 72, 75, 76, 77, 82, 88, 90, 97, 98, 99, 102, 108, 109, 113, 124, 126, 127, 140, 141, 148, 149, 156, 157, 158, 164, 165, 172, 173, 175, 182, 190, 191, 192, 199, 200, 201, 202], "valid": [12, 24, 76, 93, 95, 97, 98, 99, 100, 101, 106, 125, 127, 187, 189, 201], "simpler": [12, 101, 116, 122, 124, 125], "algorithm": [12, 22, 24, 34, 35, 75, 88, 93, 99, 106, 108, 109, 111, 117, 124, 126, 127, 132, 156, 157, 158, 160, 170, 173, 180, 187, 189, 190, 192, 194], "hdbscan": 12, "tend": [12, 23, 81, 88, 89, 100, 101, 117, 125, 127, 139, 157, 183, 189], "unstabl": [12, 98, 157, 158, 183], "difficult": [12, 46, 48, 82, 101, 113, 126, 127, 148, 183, 201], "configur": 12, "specif": [12, 20, 23, 24, 25, 27, 29, 34, 70, 72, 75, 81, 82, 86, 88, 89, 90, 98, 108, 113, 115, 124, 125, 126, 138, 139, 148, 149, 156, 164, 165, 172, 183, 189, 192, 200, 202], "resembl": [12, 34, 64, 117, 125, 126, 165, 172, 189], "ramp": [12, 168, 183], "launch": [12, 45, 47, 48], "done": [12, 22, 23, 24, 25, 47, 75, 81, 82, 88, 89, 90, 95, 122, 124, 126, 127, 132, 138, 150, 182, 183, 192], "review": [12, 23, 30, 34, 35, 36, 40, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 70, 71, 75, 76, 77, 81, 82, 84, 86, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 108, 109, 113, 115, 116, 117, 118, 124, 125, 126, 127, 130, 134, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 162, 164, 165, 166, 172, 173, 174, 176, 182, 183, 189, 190, 191, 192, 194, 198, 199, 200, 201], "2h": 12, "outro": [12, 36, 40, 95, 106, 113, 122, 145, 154, 180, 196], "yet": [12, 22, 25, 99, 102, 108, 124, 132, 150, 156, 157, 164, 165, 190, 192], "haven": [12, 99, 102, 182], "walk": [12, 23, 126, 130, 138, 139, 141, 172, 175, 178], "four": [12, 35, 64, 70, 77, 130, 138, 158, 191], "translat": [12, 34, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 125, 134, 147, 165], "colab": [12, 22, 24, 48, 124, 125, 126, 127, 132], "readili": 12, "avail": [12, 23, 27, 34, 35, 40, 88, 93, 124, 127, 141, 149, 160, 172, 175, 176, 190, 201], "down": [12, 22, 23, 48, 75, 76, 77, 81, 89, 124, 126, 132, 138, 141, 156, 158, 172, 176, 191, 192], "sentenc": [12, 23], "todai": [12, 22, 24, 70, 71, 75, 82, 84, 86, 95, 97, 100, 106, 109, 113, 124, 130, 132, 136, 138, 145, 154, 162, 164, 170, 172, 173, 174, 176, 180, 183, 196, 198, 199, 200, 201], "5h": 12, "identifi": [12, 20, 22, 23, 34, 35, 36, 66, 70, 102, 125, 127, 132, 141, 145, 147, 150, 154, 157, 183, 189, 190, 191, 192, 201], "context": [12, 34, 71, 75, 89, 98, 134, 148, 164, 165, 172, 176, 202], "acquir": [12, 22, 34, 132, 191, 192], "30min": 12, "promis": 12, "ones": [12, 22, 23, 24, 64, 66, 70, 76, 77, 82, 90, 100, 101, 102, 109, 117, 118, 127, 132, 141, 147, 148, 149, 150, 156, 157, 158, 173, 175, 176, 182, 183, 189, 191, 192, 198], "10min": 12, "report": [12, 66, 82, 102, 120, 124, 125, 126, 127, 175, 190], "whole": [12, 23, 24, 82, 88, 95, 109, 117, 124, 126, 134, 138, 149, 165, 173, 191, 198, 201], "found": [12, 22, 48, 75, 81, 90, 98, 108, 109, 115, 117, 124, 132, 147, 156, 166, 175, 190, 201], "pool": [12, 125, 148, 149], "togeth": [12, 23, 24, 25, 40, 70, 71, 75, 82, 88, 98, 99, 101, 108, 118, 124, 125, 126, 127, 148, 150, 158, 164, 176, 182, 191, 198], "per": [12, 20, 22, 24, 34, 35, 36, 76, 81, 88, 89, 100, 118, 132, 138, 139, 148, 149, 172, 182, 191, 192, 199, 201], "person": [12, 47, 77, 130, 164, 175], "1h": 12, "wa": [12, 20, 22, 23, 24, 25, 27, 34, 36, 64, 71, 76, 77, 81, 82, 88, 89, 90, 98, 99, 100, 101, 108, 109, 118, 122, 124, 125, 126, 127, 132, 139, 147, 149, 150, 164, 165, 166, 175, 176, 182, 189, 190, 201], "common": [12, 22, 72, 75, 81, 82, 88, 90, 102, 104, 106, 109, 117, 122, 124, 132, 138, 145, 148, 149, 164, 165, 166, 189, 191, 192, 196, 199, 200], "share": [12, 29, 34, 36, 40, 66, 88, 90, 109, 125, 126, 148, 164, 165, 174, 178], "connect": [12, 20, 29, 34, 36, 48, 70, 72, 104, 106, 113, 120, 122, 124, 125, 138, 139, 148, 149, 152, 156, 157, 158, 162, 170, 173, 174, 180, 187, 189], "edu": [12, 20, 71, 84, 93, 108, 111, 160, 168, 178, 185, 189, 194], "domain": [12, 34, 35, 36, 172, 173, 174], "vpn": 12, "full": [12, 13, 23, 24, 25, 34, 35, 36, 71, 72, 75, 76, 77, 81, 82, 89, 98, 99, 108, 116, 120, 124, 125, 126, 127, 160, 164, 172, 183, 191, 199, 200, 201], "preprint": [12, 84, 93, 104, 109, 111, 120, 124, 125, 126, 127, 134, 143, 152, 185, 194], "server": [12, 32], "arxiv": [12, 104, 109, 111, 120, 132, 134, 152, 194], "biorxiv": [12, 93, 109, 120, 124, 125, 126, 127, 152, 185], "turn": [12, 34, 70, 72, 76, 77, 81, 82, 98, 100, 106, 109, 124, 125, 126, 127, 141, 147, 148, 156, 158, 174, 175, 183, 191, 192, 199], "someon": [12, 82, 164, 172, 175], "who": [12, 23, 46, 200], "univers": [12, 42, 84, 93, 143, 152, 160, 175, 194], "understood": [12, 124, 138, 139, 147, 158], "section": [12, 22, 23, 46, 93, 132, 202], "block": [12, 64, 76, 106, 122, 125, 126, 139, 145, 154, 164, 198], "3h": 12, "text": [12, 25, 32, 33, 34, 35, 36, 40, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "wrote": [12, 124, 126, 127, 199], "worri": [12, 76, 88, 89, 201], "paragraph": [12, 24, 25], "word": [12, 22, 23, 70, 71, 72, 75, 76, 77, 81, 90, 122, 124, 132, 138, 140, 141, 149, 156, 157, 164, 165, 173, 183, 192, 199], "200": [12, 24, 25, 71, 88, 90, 108, 124, 127, 141, 147, 148, 149, 150, 172, 174, 175, 190, 192, 201], "300": [12, 81, 139, 140, 147, 149, 150, 176], "possibl": [12, 23, 24, 25, 34, 35, 64, 70, 71, 72, 75, 77, 81, 82, 88, 89, 90, 97, 106, 109, 113, 124, 127, 130, 139, 140, 148, 150, 156, 157, 158, 164, 165, 166, 173, 174, 182, 183, 189, 190, 191, 192, 196, 198, 199, 200, 201], "properli": [12, 22, 88, 132, 165], "It": [12, 22, 23, 24, 25, 29, 48, 70, 71, 72, 76, 77, 81, 82, 86, 88, 97, 99, 108, 109, 115, 117, 124, 125, 126, 127, 132, 138, 140, 149, 156, 157, 158, 162, 164, 165, 166, 170, 172, 174, 175, 180, 182, 183, 187, 190, 191, 198, 199, 200, 201], "readi": [12, 22, 23, 82, 88, 90, 132, 140, 149], "submit": 12, "mandatori": 12, "evalu": [12, 22, 34, 35, 36, 66, 75, 81, 82, 86, 90, 97, 101, 102, 124, 130, 132, 138, 141, 165, 166, 190, 191, 192], "overal": [12, 20, 22, 23, 24, 34, 102, 106, 118, 132, 149, 156, 172, 196, 198], "vagu": 12, "would": [12, 22, 23, 24, 25, 27, 34, 64, 70, 71, 75, 76, 77, 81, 82, 88, 90, 91, 99, 100, 102, 108, 109, 117, 124, 125, 127, 130, 132, 139, 141, 148, 150, 156, 164, 165, 166, 172, 173, 174, 175, 182, 183, 190, 191, 192, 198, 199, 201], "take": [12, 22, 23, 25, 32, 34, 35, 36, 47, 64, 71, 75, 76, 81, 82, 88, 89, 90, 97, 98, 102, 108, 109, 115, 117, 118, 124, 125, 126, 127, 130, 132, 138, 139, 140, 141, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201, 202], "let": [12, 22, 24, 25, 29, 34, 35, 36, 64, 70, 71, 72, 75, 76, 77, 81, 82, 88, 90, 97, 98, 99, 100, 102, 108, 109, 117, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 190, 191, 192, 198, 199, 200, 201], "explicit": [12, 22, 23, 102, 132, 148, 157, 164], "One": [12, 35, 66, 70, 76, 82, 89, 90, 99, 100, 101, 102, 109, 117, 124, 125, 126, 127, 140, 145, 156, 157, 160, 165, 173, 175, 190, 191, 201], "best": [12, 22, 23, 24, 25, 34, 75, 77, 86, 88, 91, 95, 97, 98, 100, 101, 102, 109, 122, 124, 127, 130, 132, 140, 141, 147, 148, 149, 156, 157, 158, 160, 174, 182, 189, 190, 191], "earli": [12, 23, 40, 120, 125, 150, 157, 172, 189], "thesi": 12, "confer": [12, 120], "intermedi": [12, 20, 64, 109], "chanc": [12, 22, 40, 81, 82, 132, 141, 150, 164, 182], "venu": 12, "wait": [12, 77, 88, 183], "requir": [12, 20, 22, 23, 24, 32, 34, 35, 36, 40, 48, 64, 71, 75, 81, 88, 90, 117, 120, 124, 125, 132, 156, 165, 175, 182, 183, 190, 191, 192, 199, 201], "branch": [12, 20, 75, 120, 127], "pursu": [12, 23, 29], "knowledg": [12, 23, 34, 70, 71, 82, 88, 108, 113, 116, 127, 139, 140, 162, 164, 165, 166, 172, 180, 199, 202], "again": [12, 22, 35, 72, 75, 77, 81, 82, 88, 89, 95, 98, 99, 101, 102, 109, 113, 124, 126, 127, 132, 139, 141, 150, 157, 165, 175, 182, 190, 191, 192, 198, 199, 201, 202], "necessari": [12, 22, 23, 46, 64, 70, 86, 90, 95, 109, 117, 127, 132, 162, 166], "lack": [12, 22, 23, 34, 132], "oomph": 12, "sound": [12, 81, 82, 109, 166], "check": [12, 22, 23, 24, 34, 35, 36, 40, 43, 47, 66, 69, 70, 71, 75, 80, 82, 87, 88, 89, 96, 99, 107, 108, 109, 114, 115, 116, 123, 125, 126, 131, 132, 137, 141, 146, 147, 148, 149, 155, 156, 157, 158, 163, 165, 166, 171, 172, 175, 181, 182, 183, 188, 189, 191, 197, 198, 201], "facet": [12, 76, 86], "enjoy": 12, "big": [12, 40, 72, 75, 77, 81, 100, 124, 138, 156, 158, 165, 175, 191, 192, 198, 199, 201, 202], "point": [12, 22, 23, 24, 25, 34, 64, 70, 72, 75, 76, 77, 81, 82, 84, 88, 89, 90, 97, 98, 99, 100, 104, 108, 109, 115, 122, 124, 126, 132, 138, 139, 140, 141, 147, 148, 149, 150, 154, 157, 164, 165, 166, 172, 173, 175, 176, 182, 183, 189, 191, 196, 198, 199], "show": [12, 22, 23, 24, 30, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 106, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 154, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 194, 198, 199, 200, 201], "build": [12, 22, 23, 24, 25, 34, 36, 70, 76, 77, 82, 86, 89, 97, 98, 99, 100, 101, 102, 106, 108, 115, 117, 122, 124, 125, 127, 132, 140, 141, 145, 147, 150, 154, 156, 158, 162, 164, 166, 174, 182, 189, 192, 202], "begin": [12, 24, 25, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 124, 125, 126, 127, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 178, 182, 183, 189, 190, 191, 198, 200, 201], "pictur": [12, 70, 88, 125, 158], "With": [12, 72, 75, 76, 81, 100, 115, 145, 147, 158, 164, 165, 172, 173, 189, 192], "abc": 12, "ten": [12, 23, 36, 84, 93, 189], "rule": [12, 23, 72, 82, 84, 93, 97, 122, 124, 138, 140, 150, 158, 162, 165, 168, 174, 189, 190, 191, 192, 198, 201], "close": [12, 23, 34, 40, 75, 76, 77, 81, 82, 88, 97, 106, 108, 124, 125, 126, 127, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 164, 165, 173, 175, 176, 189, 198, 199, 200, 201], "specifi": [12, 22, 23, 24, 34, 35, 36, 64, 66, 72, 81, 82, 88, 89, 97, 115, 116, 124, 125, 126, 127, 132, 138, 156, 173, 175, 182, 189, 192, 198, 199, 200, 201], "refer": [12, 23, 24, 25, 34, 36, 40, 70, 72, 82, 89, 90, 100, 101, 102, 106, 108, 124, 125, 126, 127, 138, 139, 140, 141, 148, 149, 157, 158, 165, 166, 172, 173, 174, 175, 176, 183, 189, 190, 191, 192, 200], "principl": [12, 23, 82, 84, 86, 122, 124, 143, 165, 166, 180, 183, 202], "order": [12, 22, 23, 24, 40, 45, 48, 66, 70, 76, 88, 90, 98, 101, 102, 109, 115, 116, 117, 124, 125, 126, 127, 132, 148, 149, 150, 156, 158, 166, 175, 176, 183, 189, 190, 191, 199, 201, 202], "problem": [12, 22, 23, 24, 71, 75, 77, 81, 82, 86, 89, 90, 93, 97, 98, 100, 102, 108, 109, 124, 125, 132, 141, 145, 148, 154, 162, 164, 165, 172, 174, 176, 178, 183, 187, 189, 190, 191, 196, 200], "solut": [12, 23, 34, 35, 36, 64, 66, 70, 71, 72, 75, 81, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 127, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "break": [12, 40, 71, 75, 76, 77, 89, 138, 191, 192], "At": [12, 66, 72, 109, 124, 140, 149, 154, 157, 164, 165, 182, 189, 190, 191, 192, 201], "style": [12, 25, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 194, 198, 199, 200, 201], "scientist": [12, 100, 164, 165], "writer": [12, 23, 34], "importantli": [12, 22, 72, 86, 102, 106, 108, 125, 130, 132, 139, 140, 148, 162, 164, 187, 202], "previou": [12, 22, 23, 24, 25, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 82, 89, 90, 98, 100, 109, 116, 117, 118, 124, 125, 126, 127, 132, 138, 140, 141, 147, 148, 149, 150, 156, 157, 158, 166, 172, 173, 174, 175, 176, 182, 189, 191, 192, 198, 199, 202], "left": [12, 22, 23, 24, 25, 34, 35, 36, 48, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 90, 97, 101, 102, 108, 109, 124, 125, 126, 127, 132, 138, 139, 140, 149, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 190, 191, 192, 198], "jargon": 12, "without": [12, 22, 23, 34, 36, 64, 70, 81, 98, 102, 108, 116, 124, 127, 132, 134, 140, 164, 166, 173, 175, 182, 183, 192, 198, 201], "defin": [12, 23, 25, 34, 35, 66, 71, 75, 77, 81, 82, 88, 89, 90, 97, 108, 109, 116, 117, 118, 124, 126, 127, 139, 141, 147, 148, 149, 150, 156, 157, 158, 162, 164, 165, 166, 172, 175, 182, 183, 187, 189, 192, 199, 200, 201], "cohes": 12, "copi": [12, 24, 34, 35, 36, 47, 126, 157, 158], "put": [12, 23, 24, 25, 77, 81, 100, 108, 115, 124, 138, 139, 149, 158, 164, 165, 183], "did": [12, 22, 23, 24, 25, 82, 88, 89, 91, 101, 127, 132, 139, 150, 156, 157, 164, 165, 182, 183, 189, 190, 191, 199], "precis": [12, 22, 23, 27, 82, 88, 116, 120, 130, 132, 138, 164, 172, 175, 190, 200], "60min": 12, "mode": [12, 35, 134, 154, 165, 166, 176, 178, 191, 192, 200], "alreadi": [12, 20, 22, 25, 34, 36, 72, 75, 88, 90, 101, 102, 106, 113, 115, 116, 117, 126, 130, 132, 140, 147, 149, 150, 164, 166, 173, 175, 180, 182, 183, 190, 191, 192, 199, 200, 201], "mayb": [12, 22, 23, 24, 25, 76, 82, 109, 132, 182, 199, 200], "match": [12, 22, 36, 64, 71, 75, 81, 82, 88, 89, 109, 124, 125, 126, 127, 132, 139, 148, 164, 166, 174, 176], "mondai": 12, "timeslot": 12, "had": [12, 24, 25, 30, 72, 76, 81, 82, 89, 90, 98, 109, 139, 140, 141, 148, 164, 165, 166, 172, 175, 183, 189], "reflect": [12, 24, 40, 69, 71, 75, 80, 82, 87, 91, 96, 107, 114, 117, 123, 131, 137, 146, 149, 155, 157, 163, 165, 171, 172, 178, 181, 188, 197], "inspir": [12, 37, 38, 39, 71, 89, 97, 108, 125, 194], "unknowingli": 12, "proven": 12, "steer": 12, "toward": [12, 72, 81, 88, 89, 138, 139, 140, 149, 150, 156, 157, 164, 165, 172, 174, 183, 189, 191, 192], "invalid": 12, "cover": [12, 22, 23, 34, 37, 38, 39, 70, 71, 72, 75, 76, 81, 82, 95, 97, 98, 100, 113, 122, 124, 125, 132, 138, 139, 149, 150, 156, 160, 164, 165, 166, 172, 175, 182, 187, 189, 199, 200, 201, 202], "materi": [12, 23, 46, 70, 71, 75, 76, 81, 86, 95, 113, 156, 157, 162, 166, 170, 172, 175, 176, 189, 196, 202], "afraid": [12, 23], "why": [12, 22, 23, 24, 34, 35, 36, 64, 66, 71, 77, 81, 82, 84, 86, 88, 91, 106, 111, 120, 124, 126, 127, 132, 138, 140, 147, 148, 149, 150, 156, 157, 164, 165, 172, 173, 174, 175, 182, 183, 189, 191, 192, 194, 198, 199, 200, 202], "sparsiti": [12, 104, 127], "These": [12, 20, 22, 27, 34, 35, 36, 40, 64, 66, 70, 71, 72, 76, 77, 81, 82, 88, 89, 101, 102, 108, 115, 124, 125, 126, 127, 132, 139, 141, 145, 148, 149, 158, 164, 165, 166, 174, 175, 176, 182, 183, 189, 196, 200, 201, 202], "usual": [12, 22, 24, 25, 29, 40, 86, 108, 117, 124, 132, 147, 156, 176, 189], "spark": 12, "discuss": [12, 22, 29, 40, 70, 71, 75, 76, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 113, 117, 124, 125, 127, 130, 132, 136, 147, 148, 149, 150, 156, 157, 158, 165, 191, 194, 198, 199], "mix": [12, 22, 24, 34, 82, 132, 165, 166], "respond": [12, 71, 75, 77, 82, 108, 124, 125, 147, 149, 156, 172, 192], "stimulu": [12, 24, 77, 81, 82, 98, 106, 108, 109, 122, 124, 125, 126, 127, 152, 158, 175, 189, 196], "increas": [12, 24, 25, 34, 35, 70, 75, 76, 77, 81, 82, 88, 89, 90, 98, 109, 115, 124, 125, 127, 138, 140, 147, 148, 149, 156, 158, 164, 165, 173, 175, 176, 183, 189, 191, 199], "facilit": [12, 23, 143], "arbitrari": [12, 22, 25, 75, 90, 109, 115, 116, 124, 125, 126, 132, 165, 166, 183], "transform": [12, 22, 24, 34, 35, 36, 72, 82, 88, 98, 109, 113, 115, 116, 118, 122, 124, 125, 126, 127, 132, 148, 164, 165, 173, 174, 198, 199, 200, 201], "toi": [12, 24, 25, 72, 90, 124, 130, 183], "pure": [12, 29, 82, 140, 158, 176], "label": [12, 20, 22, 24, 25, 34, 35, 36, 64, 66, 70, 72, 75, 76, 77, 81, 82, 88, 90, 97, 98, 99, 101, 102, 108, 109, 115, 116, 118, 124, 125, 126, 127, 132, 139, 140, 141, 147, 148, 149, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200], "line": [12, 22, 24, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 81, 82, 88, 89, 90, 97, 98, 99, 108, 109, 117, 118, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 156, 157, 172, 174, 175, 176, 182, 183, 189, 191, 201], "combin": [12, 24, 25, 72, 75, 77, 82, 90, 104, 125, 127, 145, 148, 158, 160, 164, 165, 166, 170, 172, 173, 175, 176, 180, 182, 183, 189, 190, 191, 192, 194], "between": [12, 22, 24, 25, 34, 35, 36, 64, 70, 71, 72, 75, 76, 77, 81, 82, 86, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 106, 108, 115, 117, 118, 124, 125, 126, 127, 130, 132, 138, 140, 141, 143, 147, 149, 150, 158, 164, 165, 172, 173, 174, 175, 176, 182, 185, 189, 190, 191, 192, 196, 198, 199, 200, 201], "rather": [12, 22, 24, 34, 36, 64, 88, 90, 117, 124, 126, 127, 132, 139, 149, 165, 172, 175, 182, 183, 189, 191, 196, 198, 200], "input": [12, 22, 23, 24, 25, 34, 35, 36, 66, 70, 71, 72, 77, 82, 88, 90, 97, 98, 99, 100, 101, 102, 104, 108, 109, 115, 122, 124, 125, 126, 127, 132, 134, 138, 143, 145, 152, 154, 157, 158, 172, 174, 175, 182, 199, 200, 201], "effici": [12, 29, 34, 35, 66, 97, 100, 124, 125, 126, 140, 149, 176, 178, 187, 201], "dynam": [12, 22, 23, 29, 34, 40, 66, 75, 76, 77, 81, 82, 86, 89, 95, 104, 106, 120, 132, 139, 140, 141, 145, 147, 148, 150, 152, 154, 157, 158, 162, 164, 168, 170, 173, 176, 178, 180, 187, 189, 191, 199, 200, 201, 202], "fire": [12, 22, 24, 64, 66, 71, 75, 81, 88, 90, 115, 124, 132, 143, 145, 148, 149, 154, 156, 157, 158, 176, 198, 202], "ch": [12, 143, 152], "dayan": [12, 76, 77, 84, 86, 143, 147, 185], "abbott": [12, 76, 77, 86, 143, 147], "theoret": [12, 76, 77, 84, 143, 147, 154, 178, 183, 202], "critic": [12, 23, 71, 81, 158, 164, 190], "assumpt": [12, 22, 81, 82, 89, 98, 109, 125, 132, 149, 164, 166, 189, 190, 200, 201], "impli": [12, 71, 88, 100, 148, 199, 200], "region": [12, 20, 34, 36, 48, 75, 88, 125, 157, 158, 165, 172, 192, 196], "transfer": [12, 76, 134, 145, 147, 156, 157, 158], "basi": [12, 71, 72, 75, 89, 90, 97, 117, 127, 148, 150, 162], "dictionari": [12, 34, 35, 36, 100, 101, 102, 108, 147, 148, 149, 150, 156, 157, 158, 175, 189, 190, 191, 192, 200, 201], "featur": [12, 24, 37, 38, 39, 88, 100, 101, 102, 118, 120, 125, 127, 149, 158, 189], "ensembl": [12, 104, 134], "syllabl": 12, "suffici": [12, 23, 64, 127, 140, 147, 158, 175, 183, 190], "band": [12, 77], "alpha": [12, 34, 35, 36, 64, 66, 70, 71, 72, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 124, 140, 141, 147, 148, 149, 150, 156, 157, 158, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 191, 192, 198, 199, 200, 201], "associ": [12, 25, 35, 81, 82, 115, 148, 190, 192, 198, 199], "gamma": [12, 77, 165, 176, 189, 191, 192], "etc": [12, 20, 23, 25, 27, 34, 36, 46, 47, 70, 72, 82, 86, 89, 100, 102, 108, 147, 154, 156, 157, 164, 166, 187, 189, 196, 199, 200], "cell": [12, 27, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 104, 109, 115, 116, 117, 118, 120, 124, 126, 127, 134, 138, 139, 140, 141, 143, 147, 148, 149, 150, 156, 157, 158, 164, 165, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 198, 199, 200, 201], "1146": [12, 134, 194], "annurev": [12, 134, 194], "26": [12, 40, 77, 158, 164, 175, 191, 192, 201], "041002": 12, "131022": 12, "mcn": 12, "2006": [12, 93, 143, 174, 175, 194], "001": [12, 25, 64, 66, 70, 82, 124, 127, 138, 139, 178, 189, 190, 200, 201], "narrow": [12, 98, 124, 165], "posit": [12, 22, 24, 34, 36, 64, 70, 71, 72, 75, 76, 77, 82, 88, 102, 108, 109, 117, 124, 125, 126, 127, 132, 138, 140, 141, 149, 150, 156, 157, 160, 162, 165, 172, 174, 175, 178, 182, 183, 189, 191, 192], "neg": [12, 34, 66, 70, 72, 75, 76, 77, 81, 82, 88, 89, 90, 98, 104, 108, 109, 115, 117, 124, 125, 126, 127, 138, 140, 141, 149, 150, 156, 158, 164, 165, 166, 172, 174, 175, 189, 191, 201], "actual": [12, 22, 23, 24, 25, 64, 75, 81, 82, 90, 99, 100, 102, 108, 124, 125, 126, 127, 132, 138, 141, 164, 165, 172, 174, 175, 182, 183, 189, 190, 191, 199, 200, 201], "discourag": 12, "month": [12, 22, 132], "toolkit": [12, 22, 132, 202], "otherwis": [12, 22, 47, 64, 71, 82, 88, 102, 109, 118, 124, 127, 132, 148, 149, 150, 164, 165, 174, 182, 190, 191, 198, 199, 201], "implement": [12, 22, 34, 35, 36, 64, 66, 70, 71, 75, 77, 81, 82, 90, 97, 98, 99, 100, 108, 115, 118, 124, 125, 126, 127, 132, 138, 139, 140, 147, 149, 157, 158, 164, 165, 170, 172, 173, 180, 189, 192, 199, 201], "scratch": [12, 36, 147, 202], "exist": [12, 25, 29, 70, 75, 81, 86, 88, 91, 100, 106, 113, 156, 165, 199], "absolut": [12, 66, 70, 72, 90, 102, 109, 116, 127, 164, 165, 172], "ok": [12, 25, 108, 109, 124, 125, 126, 127, 175], "Then": [12, 22, 23, 71, 75, 76, 82, 88, 95, 100, 115, 116, 117, 124, 125, 126, 127, 132, 141, 145, 148, 156, 158, 164, 173, 182, 201, 202], "initi": [12, 22, 35, 36, 64, 66, 70, 77, 81, 82, 89, 99, 102, 108, 109, 115, 118, 124, 125, 126, 127, 132, 134, 139, 140, 147, 148, 149, 150, 158, 164, 166, 173, 174, 175, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "limit": [12, 23, 24, 25, 34, 64, 71, 72, 75, 76, 81, 82, 86, 90, 98, 102, 106, 117, 127, 140, 147, 149, 157, 164, 165, 166, 174, 176, 182, 183, 191, 192, 200, 201], "somebodi": 12, "somedai": 12, "shuffl": [12, 34, 35, 36, 148], "logic": [12, 22, 84, 132, 160, 182, 198], "accident": [12, 201], "peak": [12, 22, 24, 75, 88, 90, 126, 127, 132, 140, 148, 150, 165], "respons": [12, 20, 64, 70, 71, 72, 75, 76, 77, 82, 89, 90, 97, 98, 99, 100, 104, 106, 108, 109, 120, 125, 126, 127, 150, 154, 156, 157, 158, 165, 168, 172, 174, 189, 201], "sequenc": [12, 34, 64, 75, 88, 97, 98, 99, 100, 124, 125, 141, 147, 148, 149, 150, 168, 172, 173, 174, 175, 182, 183, 189, 191, 192], "circular": [12, 115, 127], "obviou": [12, 138, 164, 190], "catch": [12, 164, 172, 180, 183], "experienc": [12, 22, 24, 25, 132, 191, 192], "off": [12, 34, 35, 36, 71, 81, 82, 97, 98, 99, 100, 102, 108, 109, 115, 116, 125, 126, 127, 130, 164, 165, 172, 175, 176, 183, 198, 199, 200, 201], "guard": 12, "calendar": 12, "http": [12, 22, 32, 33, 34, 35, 36, 37, 38, 39, 43, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "compneuro": [12, 46], "io": [12, 22, 43, 46, 84, 88, 90, 108, 109, 111, 120, 124, 125, 126, 127, 132, 175], "daily_schedul": 12, "html": [12, 20, 43, 101, 102, 104, 109, 118, 120, 152, 168, 173, 174, 176, 182, 183, 189, 194, 201], "invit": 12, "screen": [12, 108, 124, 175], "graphic": [12, 23, 81, 82, 101, 134, 156, 157, 166, 178], "told": [12, 75, 141, 166], "taught": [12, 130, 176], "via": [12, 75, 82, 97, 115, 120, 124, 126, 127, 134, 143, 148, 165, 173, 175, 183, 192, 200], "minut": [12, 40, 70, 71, 75, 76, 77, 82, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 139, 140, 141, 148, 156, 157, 164, 165, 172, 173, 174, 199, 201], "greet": 12, "round": [12, 75, 126, 140, 165, 173, 176], "call": [12, 22, 23, 24, 64, 66, 70, 71, 75, 76, 81, 82, 88, 90, 97, 98, 100, 102, 106, 108, 109, 113, 116, 124, 125, 126, 127, 132, 139, 140, 141, 147, 148, 149, 156, 157, 158, 164, 165, 166, 173, 175, 176, 182, 183, 189, 190, 191, 192, 199, 200, 201], "zoom": [12, 40, 117, 139, 154], "themselv": [12, 23, 70, 71, 75, 148], "hi": [12, 90, 97, 106, 108, 145, 165, 189], "jonni": 12, "wiggli": 12, "caterpillar": 12, "am": [12, 40, 134, 201], "phd": 12, "notr": 12, "dame": 12, "pari": 12, "fli": [12, 140], "my": [12, 22, 23, 66, 86, 95, 106, 132, 141, 175], "bike": [12, 75], "ride": 12, "40": [12, 22, 24, 75, 77, 81, 82, 88, 93, 100, 109, 117, 124, 125, 127, 132, 147, 149, 158, 165, 174, 183, 189, 191, 192, 198, 201], "speak": [12, 23, 24, 25, 164, 189, 198], "approx": [12, 34, 77, 90, 98, 108, 109, 156, 198], "wast": [12, 192], "join": [12, 36, 108, 138, 149], "appropri": [12, 20, 22, 23, 24, 108, 132, 164, 172, 183, 190, 201], "breakout": 12, "room": [12, 34, 89, 124], "20": [12, 25, 27, 66, 70, 71, 72, 75, 76, 77, 81, 82, 89, 90, 97, 98, 99, 101, 102, 104, 108, 109, 115, 117, 124, 125, 126, 127, 134, 138, 140, 147, 148, 149, 150, 156, 157, 158, 164, 173, 174, 175, 176, 182, 183, 189, 191, 192, 198, 199, 200, 201], "miss": [12, 22, 23, 36, 46, 81, 82, 88, 89, 91, 97, 102, 108, 109, 124, 127, 130, 132, 148, 175, 182, 189, 190], "anyon": [12, 36], "futur": [12, 23, 24, 25, 64, 66, 70, 71, 77, 120, 126, 141, 148, 164, 175, 176, 182, 187, 189, 191, 192], "perhap": [12, 36, 127, 183, 190, 198], "surpris": [12, 23, 90, 109, 175], "techniqu": [12, 34, 35, 36, 64, 66, 90, 95, 97, 113, 122, 124, 125, 126, 174, 191, 196, 200, 201], "immedi": [12, 22, 24, 77, 132, 182, 189, 191, 192], "current": [12, 23, 25, 32, 34, 66, 71, 75, 76, 77, 82, 89, 111, 122, 124, 127, 134, 143, 148, 149, 156, 157, 158, 172, 173, 174, 175, 176, 178, 182, 183, 185, 189, 190, 191, 192, 198, 199, 201], "subgroup": 12, "separ": [12, 23, 24, 27, 34, 35, 64, 75, 118, 125, 164, 165, 166, 172, 182, 183], "larg": [12, 27, 35, 36, 72, 75, 77, 81, 82, 88, 98, 108, 111, 117, 120, 122, 124, 125, 126, 127, 134, 138, 140, 148, 149, 154, 156, 158, 160, 164, 165, 174, 175, 182, 183, 187, 189, 192], "hour": [12, 40, 70, 71, 108, 109, 124, 126, 138, 147, 149, 156, 157, 164, 165, 173, 174, 189, 201], "00": [12, 40, 90, 109, 111, 124, 141, 147], "rel": [12, 22, 24, 25, 27, 29, 34, 36, 66, 77, 82, 88, 90, 102, 124, 125, 126, 132, 139, 150, 164, 165, 174, 190, 192], "jupyterbook": [12, 22, 132], "cutoff": 12, "mark": [12, 166], "ensur": [12, 22, 23, 34, 66, 75, 81, 89, 97, 98, 99, 100, 108, 124, 126, 127, 130, 132, 149, 199], "powerpoint": 12, "creat": [12, 22, 23, 24, 25, 34, 36, 48, 64, 66, 70, 75, 77, 82, 88, 90, 97, 99, 100, 101, 102, 109, 122, 124, 125, 126, 132, 138, 148, 150, 157, 164, 165, 166, 173, 175, 176, 182, 189, 198, 200, 201], "primarili": [12, 175], "superpod": 12, "conclus": [12, 124, 158], "floor": [12, 72, 98, 126], "seem": [12, 22, 24, 25, 34, 72, 76, 77, 81, 82, 88, 117, 118, 124, 125, 126, 127, 132, 140, 150, 157, 158, 164, 165, 189, 190, 191, 196, 201], "imposs": [12, 22, 23, 24, 36, 109, 132, 165], "elev": 12, "pitch": 12, "poster": 12, "zuckerberg": 12, "secur": 12, "million": [12, 35, 76, 77], "dollar": 12, "fund": 12, "art": [12, 24, 25, 124], "act": [12, 75, 90, 125, 127, 147, 164, 180, 183, 187, 189, 192], "plai": [12, 22, 23, 34, 66, 70, 72, 75, 76, 82, 88, 89, 109, 117, 127, 132, 148, 164, 165, 172, 173, 182, 183, 189, 190], "music": [12, 76, 77], "instrument": [12, 196, 198, 199, 200], "rehears": 12, "doesn": [12, 20, 22, 23, 24, 25, 34, 71, 72, 75, 76, 89, 90, 108, 109, 116, 124, 132, 156, 164, 165, 170, 176, 182, 189, 190, 192, 201], "WILL": 12, "annoi": 12, "tenth": [12, 149], "secret": 12, "prepar": [12, 70, 82, 125, 134, 175], "small": [12, 22, 24, 64, 66, 69, 72, 75, 76, 80, 81, 82, 87, 88, 89, 96, 98, 107, 109, 114, 123, 124, 125, 126, 127, 131, 132, 137, 138, 140, 141, 146, 148, 149, 154, 155, 156, 163, 164, 165, 171, 172, 175, 181, 183, 188, 189, 192, 197, 200], "anecdot": 12, "magic": 12, "engag": [12, 27], "As": [12, 22, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 97, 100, 101, 102, 109, 115, 116, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 149, 150, 156, 158, 164, 165, 166, 172, 173, 174, 175, 183, 189, 191, 192, 199, 200, 201], "passiv": 12, "bore": 12, "grab": 12, "smart": 12, "while": [12, 22, 24, 34, 35, 40, 45, 71, 72, 75, 76, 77, 81, 82, 88, 89, 97, 99, 109, 116, 118, 122, 124, 127, 132, 147, 148, 149, 150, 154, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 182, 183, 189, 190, 191, 192, 196, 198, 200, 201], "main": [12, 22, 23, 24, 25, 27, 64, 66, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 108, 109, 113, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 172, 174, 175, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "anywai": [12, 46], "commun": [12, 23, 29, 46, 90, 127, 130, 134, 145, 160, 194], "bind": 12, "didn": [12, 22, 23, 75, 81, 88, 97, 126, 132], "hear": [12, 76, 77, 113, 139, 140], "furthermor": [12, 192], "clear": [12, 22, 82, 117, 118, 124, 126, 127, 132, 149, 158], "got": [12, 34, 97, 141, 148, 172, 190], "dream": [12, 192], "oppos": [12, 24, 75, 82, 99, 149, 165, 166, 183], "except": [12, 40, 46, 70, 72, 108, 109, 124, 125, 126, 127, 150, 174, 175, 183, 189, 198, 201], "concis": [12, 29, 34], "rambl": 12, "avoid": [12, 22, 23, 34, 36, 64, 66, 90, 124, 126, 127, 132, 138, 165, 166, 189, 190, 191, 192], "skill": [12, 22, 82, 132], "life": [12, 100, 116, 140, 165], "given": [12, 22, 24, 64, 66, 70, 71, 72, 75, 77, 81, 82, 88, 89, 90, 97, 98, 100, 101, 102, 108, 109, 115, 116, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 201], "constraint": [12, 22, 34, 35, 88, 111, 125, 132, 194], "click": [13, 22, 23, 42, 44, 47, 48, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 97, 98, 100, 101, 109, 115, 124, 125, 132, 138, 139, 147, 156, 157, 164, 165, 172, 173, 198], "imag": [13, 27, 34, 35, 66, 72, 82, 98, 109, 113, 117, 118, 120, 122, 124, 125, 126, 127, 170, 175, 196, 198, 202], "browser": [13, 47, 76, 77], "2020": [20, 22, 23, 27, 36, 64, 66, 76, 77, 84, 104, 115, 116, 117, 118, 120, 132, 134, 140, 141, 147, 148, 150, 152, 156, 158, 160, 166, 175, 176, 178, 185, 189], "gambl": 20, "languag": [20, 22, 23, 132, 199], "preprocess": [20, 102, 175], "john": [20, 68, 74, 75, 76, 77, 79, 85, 94, 105, 112, 115, 116, 117, 118, 121, 129, 135, 138, 139, 140, 141, 144, 147, 148, 149, 150, 153, 156, 157, 158, 161, 169, 172, 173, 176, 179, 186, 195, 202], "murrai": [20, 115, 116, 117, 118, 147, 148, 149, 150, 156, 157, 158], "saad": 20, "jbabdi": 20, "barch": 20, "burgess": [20, 84], "harm": 20, "petersen": 20, "schlaggar": 20, "l": [20, 34, 35, 64, 76, 77, 82, 93, 98, 102, 104, 109, 120, 124, 126, 127, 134, 143, 148, 150, 152, 165, 168, 172, 173, 175, 176, 178, 183, 185, 189, 191, 192], "corbetta": 20, "essen": 20, "2013": [20, 84, 104, 127, 134, 152, 160, 194], "connectom": 20, "neuroimag": [20, 29, 81], "80": [20, 71, 75, 127, 147, 149, 189], "169": [20, 143], "189": 20, "05": [20, 34, 35, 36, 64, 66, 70, 72, 75, 82, 90, 99, 104, 117, 125, 126, 127, 134, 140, 147, 148, 150, 158, 164, 166, 172, 173, 176, 182, 183, 192, 200, 201], "033": 20, "complement": 20, "brainwid": [20, 27], "none": [20, 24, 34, 35, 36, 48, 66, 70, 71, 72, 75, 81, 82, 89, 98, 100, 101, 102, 108, 109, 118, 124, 125, 126, 127, 138, 141, 148, 149, 150, 156, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "summer": 20, "recept": [20, 104, 106, 108, 125, 165], "ml": [20, 106, 194], "savi": 20, "hierarchi": [20, 27, 125], "benson": 20, "jamison": 20, "arcaro": 20, "vu": 20, "glasser": 20, "coalson": 20, "2018": [20, 34, 35, 36, 84, 104, 111, 120, 134, 152, 178, 185, 194], "tesla": 20, "descript": [20, 22, 29, 64, 75, 84, 86, 95, 132, 134, 138, 143, 145, 164, 165, 172, 173, 174, 182, 183, 187, 189, 190], "vision": [20, 22, 24, 25, 34, 36, 120, 132], "18": [20, 40, 76, 97, 125, 127, 139, 143, 148, 149, 150, 156, 157, 165, 175, 182, 185, 191], "13": [20, 23, 32, 84, 109, 111, 120, 134, 152, 156, 157, 158, 172, 175, 183, 192], "1167": [20, 127], "michael": [20, 34, 35, 36, 57, 64, 66, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 138, 139, 140, 141, 147, 148, 149, 156, 157, 158, 166, 172, 173, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "waskom": [20, 34, 35, 36, 64, 66, 88, 89, 90, 97, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 138, 139, 140, 141, 147, 148, 149, 156, 157, 158, 166, 172, 173, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "v1": [20, 71, 109, 120, 124, 125, 126, 127, 201], "v2": [20, 201], "v3": 20, "v4": [20, 125], "naselari": 20, "prenger": 20, "gallant": 20, "452": 20, "7185": 20, "352": 20, "355": 20, "1038": [20, 27, 84, 104, 111, 120, 134, 143, 148, 178, 185, 194], "nature06713": 20, "oliv": [20, 27], "reconstruct": [20, 34, 35, 118], "63": [20, 192], "902": 20, "915": 20, "09": [20, 93, 104], "006": [20, 64, 143], "di": [20, 75, 126, 157, 158], "static": [20, 72, 124, 183, 191], "kshitij": [20, 34, 35, 36, 124, 125, 126, 127], "dwivedi": [20, 34, 35, 36, 124, 125, 126, 127], "anim": [20, 72, 77, 81, 82, 106, 109, 124, 127, 141, 164, 172, 180, 182, 187, 189, 196], "clip": [20, 36, 66, 174, 200, 201], "kriegeskort": [20, 120], "mur": [20, 120, 172], "bandettini": [20, 120], "system": [20, 22, 23, 25, 27, 29, 34, 36, 40, 70, 75, 76, 81, 82, 84, 86, 90, 93, 104, 120, 125, 126, 127, 132, 136, 139, 140, 141, 143, 145, 147, 148, 154, 157, 165, 168, 173, 174, 182, 185, 196, 202], "06": [20, 64, 120, 156], "004": [20, 64, 120, 127, 175], "epstein": 20, "afford": [20, 34, 100, 124], "4793": 20, "4798": 20, "1618228114": 20, "pantazi": [20, 120], "oliva": [20, 120, 122, 125], "2014": [20, 34, 35, 36, 76, 77, 104, 111, 120, 143, 152, 160, 178, 194], "resolv": [20, 22, 24, 25, 32, 88, 132], "recognit": [20, 93, 120, 122, 125, 126, 174, 175], "space": [20, 22, 72, 81, 88, 109, 113, 115, 117, 118, 125, 132, 134, 138, 149, 162, 164, 165, 175], "17": [20, 40, 70, 99, 104, 111, 116, 124, 143, 152, 156, 164, 178, 192, 194], "455": [20, 176], "462": 20, "nn": [20, 34, 35, 36, 104, 111, 124, 125, 126, 127, 200], "3635": 20, "url": [20, 22, 27, 32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 194, 195, 196, 197, 198, 199, 200, 201], "csail": 20, "mit": [20, 84, 104, 134, 143, 160, 175, 178, 185, 189, 194], "creator": [22, 23, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 88, 89, 90, 91, 94, 97, 98, 99, 100, 101, 102, 105, 108, 109, 112, 115, 116, 117, 118, 121, 124, 125, 126, 127, 129, 132, 135, 138, 139, 140, 141, 144, 147, 148, 149, 150, 153, 156, 157, 158, 161, 164, 165, 166, 169, 172, 173, 174, 175, 176, 179, 182, 183, 186, 189, 190, 191, 192, 195, 198, 199, 200, 201], "hart": [22, 23, 24, 25, 132], "megan": [22, 23, 24, 25, 132], "peter": [22, 23, 24, 25, 132, 147, 194], "paul": [22, 23, 24, 25, 37, 38, 39, 132], "schrater": [22, 23, 24, 25, 84, 132], "gunnar": [22, 23, 24, 25, 38, 132], "blohm": [22, 23, 24, 25, 38, 84, 132], "tara": [22, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 132], "viegen": [22, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 132], "editor": [22, 23, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 147, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 192, 198, 199, 200, 201], "ella": [22, 23, 30, 56, 61, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 156, 157, 158, 164, 165, 172, 173, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "batti": [22, 23, 30, 56, 61, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 120, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 156, 157, 158, 164, 165, 172, 173, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "w1d2": 22, "eas": [22, 36, 157], "yesterdai": [22, 75, 109, 132, 147, 149, 156, 172, 173, 174, 183], "gain": [22, 23, 24, 25, 46, 72, 81, 89, 100, 115, 122, 132, 138, 140, 156, 157, 158, 164, 165, 173, 174, 175, 192], "bui": [22, 132], "But": [22, 24, 25, 75, 76, 77, 82, 86, 98, 102, 108, 117, 118, 124, 126, 132, 140, 141, 147, 148, 149, 156, 158, 164, 165, 168, 174, 182, 190, 192, 199, 200, 201], "clarifi": [22, 132, 165], "assum": [22, 24, 72, 75, 81, 82, 89, 90, 98, 99, 108, 109, 115, 116, 132, 139, 140, 147, 149, 150, 156, 164, 165, 166, 172, 173, 175, 176, 180, 189, 192, 199, 200], "et": [22, 25, 27, 88, 90, 109, 118, 124, 125, 126, 127, 132, 148, 175], "al": [22, 25, 27, 88, 90, 109, 118, 124, 125, 126, 127, 132, 148, 175], "2019": [22, 23, 25, 27, 71, 84, 88, 90, 93, 104, 109, 120, 124, 125, 126, 127, 132, 134, 152, 168, 178, 194], "frame": [22, 23, 24, 25, 70, 71, 108, 130, 165], "remain": [22, 23, 36, 71, 90, 115, 127, 130, 132, 139, 140, 149, 150, 156, 158, 166, 183, 189, 190], "throughout": [22, 72, 81, 95, 97, 115, 132, 139, 148, 150, 154, 156, 165, 183, 189, 199, 202], "revit": 22, "maxim": [22, 34, 70, 75, 82, 90, 98, 99, 109, 116, 126, 127, 132, 150, 156, 164, 166, 168, 180, 182, 189, 190, 191], "succeed": [22, 127, 132], "tabl": [22, 75, 82, 132, 164, 191, 192], "side": [22, 34, 36, 64, 70, 76, 77, 89, 117, 125, 126, 127, 130, 132, 138, 147, 157, 165, 172, 182, 191, 198], "illus": [22, 130, 132], "introductori": [22, 132], "explain": [22, 23, 24, 25, 70, 71, 82, 88, 89, 90, 97, 98, 106, 115, 116, 120, 126, 127, 132, 139, 145, 148, 152, 157, 164, 165, 168, 172, 174, 182, 185, 192, 200], "roleplai": [22, 130, 132], "showcas": [22, 36, 132], "pitfal": [22, 23, 106, 130, 132], "appreci": [22, 23, 84, 86, 132, 145, 154], "np": [22, 24, 25, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "pyplot": [22, 24, 25, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "plt": [22, 24, 25, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "random": [22, 24, 25, 34, 35, 36, 75, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 124, 126, 127, 132, 139, 141, 147, 148, 149, 150, 156, 158, 164, 165, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 196, 199, 200, 201], "stat": [22, 24, 25, 81, 82, 89, 90, 98, 126, 132, 165, 172, 173, 174, 175, 176], "norm": [22, 24, 25, 34, 35, 70, 72, 81, 82, 98, 108, 125, 132, 157, 162, 164, 172, 173, 174], "poisson": [22, 24, 89, 104, 106, 109, 132, 139, 147, 148, 149, 150], "logist": [22, 24, 104, 106, 108, 126, 132], "sklearn": [22, 24, 34, 35, 36, 102, 106, 109, 117, 118, 126, 132, 200, 201], "linear_model": [22, 24, 109, 132, 200, 201], "logisticregress": [22, 24, 109, 132], "model_select": [22, 24, 102, 109, 132], "cross_val_scor": [22, 24, 109, 132], "titl": [22, 24, 32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "def": [22, 24, 25, 32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "rasterplot": [22, 24, 132], "spike": [22, 24, 27, 34, 36, 75, 77, 81, 86, 95, 100, 104, 106, 109, 132, 134, 145, 149, 154, 156, 168, 196], "timepoint": [22, 24, 82, 108, 132], "trial_spik": [22, 24, 132], "trial_ev": [22, 24, 132], "nonzero": [22, 24, 109, 116, 132, 147, 176], "150": [22, 24, 37, 38, 39, 64, 66, 132, 172, 198, 199, 200, 201], "100": [22, 23, 24, 25, 37, 38, 39, 76, 77, 81, 82, 89, 98, 108, 109, 113, 117, 124, 126, 127, 132, 140, 141, 147, 148, 149, 156, 157, 158, 166, 172, 173, 174, 175, 182, 183, 189, 191, 192, 198, 199, 200, 201], "dt": [22, 24, 25, 64, 66, 75, 76, 77, 89, 108, 132, 138, 139, 147, 148, 149, 150, 156, 158, 176], "eventplot": [22, 24, 88, 132], "linewidth": [22, 24, 66, 70, 71, 75, 81, 82, 98, 99, 100, 108, 115, 116, 127, 132, 138, 141, 165, 166, 173, 174, 175, 176, 182], "ylabel": [22, 24, 25, 34, 35, 36, 64, 66, 70, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 174, 175, 176, 183, 190, 191, 192, 198, 199, 200, 201], "xlabel": [22, 24, 25, 34, 35, 36, 64, 66, 70, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 174, 175, 176, 183, 190, 191, 192, 198, 199, 200, 201], "plotcrossvalaccuraci": [22, 24, 132], "accuraci": [22, 24, 77, 99, 120, 122, 127, 132, 143, 168, 175, 183, 190], "ax": [22, 24, 25, 34, 35, 36, 70, 71, 72, 75, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 108, 109, 117, 124, 125, 126, 127, 132, 138, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "subplot": [22, 24, 25, 34, 35, 36, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 108, 109, 117, 124, 125, 126, 127, 132, 138, 140, 147, 149, 150, 157, 158, 165, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "figsiz": [22, 24, 25, 34, 35, 36, 66, 70, 71, 72, 75, 76, 77, 89, 90, 97, 98, 99, 108, 109, 115, 116, 124, 125, 126, 127, 132, 138, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 190, 191, 192, 198, 199, 200, 201], "boxplot": [22, 24, 102, 109, 132], "vert": [22, 24, 109, 132], "fals": [22, 23, 24, 34, 35, 36, 64, 66, 70, 71, 72, 75, 82, 89, 102, 106, 108, 109, 117, 118, 124, 125, 126, 127, 132, 138, 147, 148, 149, 150, 156, 158, 164, 165, 172, 173, 174, 175, 182, 183, 189, 191, 198, 199, 200, 201], "width": [22, 24, 37, 38, 39, 70, 71, 72, 75, 76, 77, 88, 98, 101, 109, 125, 126, 127, 132, 138, 147, 149, 150, 164, 165, 173, 174, 182, 183, 198, 199, 200, 201], "ytick": [22, 24, 35, 36, 70, 71, 72, 75, 76, 77, 88, 109, 127, 132, 139, 149, 164, 165, 176], "spine": [22, 24, 70, 71, 72, 75, 108, 109, 125, 126, 132, 164, 172, 182], "set_vis": [22, 24, 70, 72, 109, 125, 126, 132, 150, 164, 172], "generatespiketrain": [22, 24, 132], "50": [22, 24, 25, 64, 66, 70, 76, 77, 82, 88, 90, 98, 99, 100, 101, 102, 108, 109, 115, 117, 118, 124, 126, 127, 132, 147, 148, 149, 150, 157, 158, 164, 172, 173, 174, 176, 183, 189, 199, 200, 201], "repetit": [22, 24, 25, 132], "800": [22, 24, 127, 132], "seed": [22, 24, 34, 64, 66, 81, 82, 89, 97, 98, 99, 100, 101, 102, 109, 115, 116, 117, 124, 126, 127, 132, 139, 140, 141, 147, 148, 149, 150, 156, 158, 172, 173, 174, 175, 176, 182, 189, 190, 191, 192, 198, 199, 200, 201], "37": [22, 24, 88, 111, 132, 143, 176, 178, 189, 192], "arang": [22, 24, 34, 35, 36, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 101, 102, 108, 109, 116, 117, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 176, 182, 183, 189, 191, 192], "interv": [22, 24, 66, 71, 72, 75, 77, 81, 86, 89, 90, 97, 98, 100, 101, 102, 132, 147, 148, 149, 150, 174, 176, 189, 194], "velocity_sigma": [22, 24, 132], "std": [22, 24, 64, 82, 99, 127, 132, 140, 141, 147, 166, 172, 183, 199, 201], "dev": [22, 24, 82, 132], "veloc": [22, 24, 25, 75, 132, 178], "profil": [22, 24, 132], "velocity_profil": [22, 24, 132], "pdf": [22, 24, 66, 81, 82, 84, 90, 98, 104, 111, 120, 132, 134, 143, 152, 165, 168, 172, 173, 174, 178, 185, 194], "gaussian": [22, 24, 34, 75, 89, 99, 115, 116, 125, 126, 127, 132, 134, 140, 149, 162, 170, 172, 174, 180, 190, 194], "properti": [22, 23, 24, 64, 71, 75, 81, 82, 86, 99, 117, 124, 125, 126, 127, 132, 139, 140, 145, 148, 152, 154, 156, 162, 164, 165, 172, 173, 174, 198], "rand": [22, 24, 97, 98, 99, 126, 132, 148, 149, 150, 176], "sensit": [22, 24, 75, 82, 118, 125, 132, 148, 150, 165], "fr": [22, 24, 97, 98, 132], "rate": [22, 24, 34, 35, 66, 70, 75, 77, 81, 88, 89, 90, 108, 109, 115, 124, 126, 127, 132, 138, 139, 140, 141, 148, 154, 157, 158, 172, 176, 178, 190, 191, 192], "output": [22, 23, 24, 25, 34, 35, 36, 64, 66, 70, 71, 75, 76, 77, 88, 90, 98, 100, 101, 102, 108, 109, 116, 118, 124, 126, 127, 132, 134, 139, 141, 145, 147, 149, 150, 156, 158, 164, 166, 172, 182, 198, 199, 201], "target_shap": [22, 24, 132], "len": [22, 24, 25, 34, 35, 36, 66, 71, 72, 75, 76, 77, 82, 88, 89, 90, 97, 98, 99, 100, 102, 108, 109, 116, 117, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 157, 158, 166, 172, 173, 174, 175, 176, 182, 183, 190, 191, 192, 198, 199, 200, 201], "repeat": [22, 24, 64, 72, 82, 99, 102, 125, 132, 150, 157, 164, 166, 172, 173, 182, 192], "reshap": [22, 24, 34, 35, 36, 71, 100, 117, 132, 164, 166, 176, 191, 192, 199, 201], "axi": [22, 24, 34, 35, 36, 64, 66, 70, 71, 72, 75, 77, 81, 82, 89, 98, 109, 115, 116, 117, 125, 126, 127, 132, 138, 140, 141, 149, 156, 157, 164, 165, 166, 172, 173, 174, 176, 182, 183, 190, 191, 192, 198, 199, 200, 201], "multipli": [22, 24, 70, 71, 72, 75, 76, 82, 98, 117, 124, 126, 127, 132, 148, 166, 174, 176, 183, 189], "s_gain": [22, 24, 132], "s_move": [22, 24, 132], "arrai": [22, 24, 25, 34, 35, 36, 66, 70, 71, 72, 75, 77, 81, 82, 88, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "top": [22, 24, 34, 36, 47, 48, 70, 71, 72, 75, 76, 77, 88, 95, 97, 100, 108, 109, 115, 116, 117, 118, 124, 126, 132, 138, 140, 141, 150, 157, 172, 191, 192, 199, 200], "baselin": [22, 24, 36, 77, 106, 132, 147, 148, 149], "s_fr": [22, 24, 132], "lower": [22, 24, 25, 34, 35, 36, 66, 70, 81, 82, 89, 98, 100, 101, 109, 113, 115, 125, 127, 132, 147, 157, 158, 164, 165, 172, 175, 176, 182, 183, 190, 191, 192, 199, 202], "correct": [22, 24, 64, 66, 72, 82, 90, 101, 108, 109, 127, 132, 134, 156, 158, 164, 165, 172, 173, 174, 175, 189, 196, 198, 199, 200, 201], "rv": [22, 24, 25, 89, 98, 132, 172, 173, 175, 176, 182], "return": [22, 24, 25, 32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "subsetpercept": [22, 24, 132], "400": [22, 24, 27, 127, 132, 147, 148, 149, 150, 165, 189, 192], "subset": [22, 24, 66, 70, 90, 99, 102, 109, 124, 127, 132, 175, 200], "hwin": [22, 24, 132], "num_mov": [22, 24, 132], "zero": [22, 24, 34, 35, 36, 66, 70, 71, 72, 75, 77, 81, 82, 88, 89, 90, 97, 98, 99, 101, 102, 108, 109, 115, 116, 117, 118, 125, 126, 127, 132, 138, 139, 140, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "ground": [22, 24, 34, 35, 36, 99, 116, 132, 148, 165, 173, 198, 199, 202], "truth": [22, 24, 34, 35, 36, 84, 99, 116, 132, 148, 165, 173, 198, 201], "y_train": [22, 24, 34, 35, 36, 101, 102, 127, 132], "y_test": [22, 24, 34, 35, 36, 101, 102, 127, 132], "m_train": [22, 24, 132], "m_test": [22, 24, 132], "reproduc": [22, 23, 24, 34, 81, 88, 89, 100, 124, 125, 126, 127, 132, 149, 175, 190, 191, 192, 198, 199, 200, 201], "w_idx": [22, 24, 132], "ab": [22, 24, 34, 35, 36, 70, 71, 72, 90, 125, 126, 127, 132, 156, 165, 166, 172, 174, 198, 199, 200], "w_0": [22, 24, 132], "w_1": [22, 24, 115, 132], "max": [22, 23, 24, 34, 35, 36, 64, 66, 70, 71, 72, 76, 77, 81, 82, 88, 89, 90, 97, 98, 100, 101, 102, 108, 109, 115, 124, 125, 127, 132, 138, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "total": [22, 24, 75, 90, 108, 109, 117, 124, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 172, 173, 174, 176, 182, 190, 191, 192, 199], "count": [22, 24, 34, 35, 36, 66, 76, 77, 81, 82, 89, 90, 95, 99, 109, 132, 139, 147, 148, 149, 176, 182, 190], "stationari": [22, 24, 25, 132, 149, 150], "spikes_stat": [22, 24, 132], "sum": [22, 24, 25, 64, 70, 72, 81, 82, 88, 90, 98, 100, 102, 108, 109, 117, 124, 125, 126, 127, 132, 138, 139, 140, 148, 149, 150, 158, 164, 165, 166, 172, 173, 174, 176, 182, 183, 189, 190, 191, 192, 198], "spikes_mov": [22, 24, 132], "train_spikes_stat": [22, 24, 132], "train_spikes_mov": [22, 24, 132], "test_spikes_stat": [22, 24, 132], "test_spikes_mov": [22, 24, 132], "y": [22, 24, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 97, 98, 99, 100, 101, 102, 104, 108, 109, 111, 115, 116, 117, 118, 120, 124, 125, 126, 127, 132, 134, 138, 140, 143, 148, 152, 156, 158, 164, 165, 166, 168, 174, 175, 176, 182, 183, 185, 189, 191, 192, 198, 199, 200, 201], "x_train": [22, 24, 34, 35, 36, 101, 102, 132], "concaten": [22, 24, 36, 88, 108, 125, 126, 127, 132, 172, 198, 199, 200, 201], "x_test": [22, 24, 34, 35, 36, 101, 102, 132, 141], "fit": [22, 23, 24, 25, 34, 40, 66, 71, 76, 82, 86, 95, 97, 98, 99, 101, 102, 106, 113, 118, 120, 122, 124, 125, 126, 127, 132, 154, 162, 164, 191, 196, 198, 199, 201, 202], "population_model": [22, 24, 132], "solver": [22, 24, 109, 132, 138], "liblinear": [22, 24, 132], "random_st": [22, 24, 118, 126, 132, 198, 199, 200, 201], "newton": [22, 24, 132], "cg": [22, 24, 132], "lbfg": [22, 24, 132], "sag": [22, 24, 132], "saga": [22, 24, 109, 132], "coef_": [22, 24, 109, 132, 200, 201], "slope": [22, 24, 34, 75, 88, 97, 98, 99, 100, 124, 132, 140, 148, 156, 157, 158], "intercept_": [22, 24, 132], "intercept": [22, 24, 88, 100, 108, 124, 132, 141, 200, 201], "ground_truth": [22, 24, 132], "getdata": [22, 24, 132], "ipywidget": [22, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 109, 115, 116, 117, 118, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 199, 200, 201], "widget": [22, 30, 40, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 109, 115, 116, 117, 118, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 199, 200, 201], "ipython": [22, 37, 38, 39, 76, 77, 109, 124, 125, 132, 164, 165, 173, 174, 176, 182, 183], "displai": [22, 23, 24, 34, 35, 36, 37, 38, 39, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 109, 115, 116, 117, 118, 124, 125, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 172, 173, 174, 175, 176, 182, 183, 189, 190, 198, 199, 200, 201], "markdown": [22, 24, 34, 37, 38, 39, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 109, 115, 116, 117, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 182, 183, 189, 190, 191, 198, 199, 200, 201], "markdown1": [22, 132], "br": [22, 132], "font": [22, 71, 75, 82, 132], "3pt": [22, 132], "occur": [22, 24, 25, 40, 66, 75, 81, 89, 90, 127, 132, 138, 139, 141, 150, 164, 189, 198, 201], "sit": [22, 24, 25, 90, 132, 141], "window": [22, 24, 25, 108, 132, 139, 149], "suddenli": [22, 24, 25, 132], "wrong": [22, 23, 24, 25, 72, 77, 82, 90, 132, 138, 164, 166, 172, 198, 199], "vice": [22, 24, 25, 34, 75, 77, 126, 132, 157, 158, 165, 189], "versa": [22, 24, 25, 34, 75, 77, 126, 132, 157, 158, 165, 189], "surround": [22, 24, 25, 82, 125, 126, 127, 132, 152, 154], "disambigu": [22, 24, 25, 132], "strong": [22, 23, 24, 25, 66, 82, 109, 117, 132, 147, 149, 156, 164, 190, 194, 201], "vibrat": [22, 24, 25, 132], "indic": [22, 24, 25, 34, 70, 76, 77, 81, 82, 99, 102, 109, 115, 116, 124, 126, 127, 132, 138, 157, 158, 172, 175, 182, 189, 192], "inde": [22, 24, 25, 81, 82, 89, 95, 98, 108, 109, 125, 127, 132, 147, 148, 156], "vestibular": [22, 24, 132], "illusori": [22, 25, 132], "self": [22, 24, 25, 35, 36, 66, 70, 90, 124, 125, 126, 127, 132, 134, 141, 182, 183, 189, 191, 192], "markdown2": [22, 132], "accumul": [22, 24, 25, 76, 81, 124, 132, 134, 166, 172, 191, 192], "case": [22, 23, 24, 25, 34, 40, 48, 64, 66, 70, 71, 72, 75, 81, 82, 88, 90, 97, 98, 100, 106, 108, 109, 118, 124, 125, 126, 127, 132, 138, 147, 148, 149, 156, 158, 164, 165, 170, 172, 174, 175, 182, 183, 189, 190, 191, 192, 198], "pretend": [22, 24, 132, 175, 198], "hold": [22, 24, 25, 90, 100, 124, 125, 127, 132, 148, 201], "condit": [22, 24, 25, 36, 64, 66, 72, 77, 86, 95, 115, 124, 132, 139, 140, 147, 148, 149, 156, 157, 158, 164, 165, 173, 174, 182, 183, 189, 191, 198, 200, 201], "slowli": [22, 24, 132, 182, 183], "acceler": [22, 24, 25, 48, 120, 127, 132], "faster": [22, 24, 36, 81, 108, 118, 126, 132, 138, 158, 166, 172, 174, 182, 199], "correl": [22, 24, 25, 104, 108, 113, 132, 134, 147, 172, 175, 178, 196, 198, 200, 201, 202], "judgement": [22, 24, 132], "out2": [22, 132], "out1": [22, 132], "tab": [22, 23, 132, 183], "set_titl": [22, 25, 34, 35, 36, 71, 75, 90, 109, 125, 126, 127, 132, 150, 166, 172, 173, 182, 183, 189, 198, 199, 201], "25": [22, 36, 40, 64, 70, 72, 77, 81, 82, 88, 90, 101, 102, 104, 108, 109, 116, 117, 124, 126, 132, 138, 141, 143, 148, 152, 156, 158, 164, 165, 173, 174, 176, 183, 190, 191, 192, 198, 199, 200, 201], "write": [22, 24, 25, 36, 45, 47, 48, 64, 70, 71, 72, 76, 77, 82, 89, 90, 97, 98, 108, 109, 115, 116, 124, 125, 126, 127, 132, 138, 140, 141, 147, 148, 149, 156, 157, 164, 166, 172, 175, 176, 182, 189, 190, 191, 192, 198], "remind": [22, 81, 82, 97, 125, 132, 138], "exact": [22, 24, 70, 72, 75, 77, 81, 86, 98, 101, 102, 118, 125, 127, 132, 139, 156, 165], "clearli": [22, 23, 24, 25, 88, 132, 140, 149, 175, 191], "lost": [22, 23, 102, 132, 175], "guarante": [22, 109, 132, 156, 172, 176, 178, 200], "everyth": [22, 29, 82, 88, 100, 108, 132, 164, 165, 175, 201], "address": [22, 23, 24, 25, 34, 36, 76, 86, 88, 95, 108, 127, 132, 154, 175, 182, 201], "comparison": [22, 23, 25, 34, 82, 95, 120, 122, 132, 174, 176, 199, 201], "essenti": [22, 23, 24, 25, 64, 70, 75, 81, 82, 101, 102, 124, 125, 127, 132, 145, 147, 156, 164, 165, 183, 194], "interfac": [22, 23, 88, 108, 113, 132, 134, 168, 174, 175, 180], "phenomena": [22, 23, 24, 25, 81, 88, 109, 132, 143, 150, 154, 158, 173, 189, 192], "mechanist": [22, 25, 29, 132, 145, 182, 202], "investig": [22, 25, 36, 77, 88, 113, 126, 132, 140, 147, 149, 150, 156, 157, 158, 175, 183, 189, 192], "recap": [22, 23, 70, 71, 72, 75, 76, 77, 81, 82, 97, 98, 100, 101, 109, 115, 124, 125, 132, 138, 139, 147, 156, 157, 164, 165, 172, 198], "unclear": [22, 132], "meaning": [22, 132, 182], "chosen": [22, 75, 77, 82, 124, 132, 156, 157, 166, 182, 189, 190, 191, 192, 202], "prevent": [22, 23, 132, 149, 189], "deepli": [22, 23, 132], "behind": [22, 72, 113, 124, 127, 132, 140, 164, 166, 172, 190, 202], "BUT": [22, 71, 132, 198], "anywher": [22, 70, 125, 132, 191, 192], "revisit": [22, 82, 98, 130, 132, 165], "frequent": [22, 25, 75, 89, 132, 196], "necess": [22, 132], "feel": [22, 24, 25, 34, 76, 77, 81, 115, 126, 132, 162, 164, 174, 182, 191], "bad": [22, 23, 24, 82, 93, 124, 125, 127, 132, 141, 165, 174, 185, 191], "nest": [22, 82, 109], "known": [22, 24, 25, 36, 70, 76, 77, 81, 82, 88, 90, 97, 100, 108, 130, 132, 138, 139, 140, 141, 149, 150, 172, 174, 175, 183, 189, 191, 192], "examin": [22, 24, 25, 72, 75, 81, 82, 86, 116, 127, 132, 138, 147, 156, 157, 158, 165, 173, 175, 183, 199, 200, 201], "attempt": [22, 25, 109, 132, 166, 189, 192, 199], "perceptu": [22, 25, 132, 134], "markdown21": [22, 132], "4d": [22, 24, 125, 132, 176], "integ": [22, 24, 34, 35, 36, 64, 71, 89, 95, 108, 126, 132, 140, 141], "2d": [22, 24, 36, 70, 71, 72, 108, 109, 116, 117, 124, 126, 132, 157, 166, 173, 176, 182, 191], "markdown22": [22, 132], "dimens": [22, 24, 34, 71, 75, 88, 89, 100, 101, 108, 113, 115, 117, 124, 125, 126, 127, 132, 134, 140, 141, 156, 157, 165, 174, 175, 176], "simultan": [22, 24, 27, 81, 104, 124, 130, 132, 134, 139, 148, 192, 196, 198, 199, 201], "third": [22, 24, 35, 39, 100, 117, 132, 138, 145, 156, 158], "ms": [22, 24, 66, 75, 76, 77, 88, 108, 132, 147, 148, 149, 150, 156, 157, 158], "fourth": [22, 24, 132, 157], "perfect": [22, 24, 25, 76, 132, 160, 182, 198, 199, 201], "closer": [22, 24, 82, 89, 97, 100, 116, 117, 125, 126, 132, 140, 165, 189], "mi": [22, 24, 132, 175], "markdown23": [22, 132], "blue": [22, 24, 64, 70, 75, 76, 77, 82, 100, 115, 116, 117, 124, 125, 132, 138, 140, 150, 156, 157, 164, 165, 172, 173, 183, 189], "produc": [22, 23, 24, 34, 35, 66, 86, 89, 90, 97, 98, 99, 100, 102, 108, 109, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 158, 164, 165, 172, 176, 183, 189, 191, 196, 199], "flat": [22, 24, 82, 132, 147, 165], "orang": [22, 24, 71, 75, 82, 88, 98, 132, 140, 150, 157, 158, 172, 173, 174, 175, 189], "green": [22, 24, 70, 71, 76, 77, 81, 125, 132, 164, 165, 173, 175, 183, 189, 192], "bell": [22, 24, 34, 132, 150, 189], "correspond": [22, 24, 25, 34, 35, 64, 70, 71, 72, 75, 81, 82, 88, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 120, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 183, 190, 191, 192, 198, 199, 201], "consider": [22, 23, 24, 102, 132, 196], "nois": [22, 24, 25, 34, 75, 82, 97, 99, 100, 101, 102, 104, 108, 109, 118, 124, 127, 132, 141, 149, 150, 152, 156, 158, 166, 172, 173, 174, 175, 182, 198, 201], "exactli": [22, 24, 64, 72, 76, 77, 81, 89, 90, 108, 124, 125, 126, 132, 139, 140, 156, 158, 160, 164, 165, 175, 183, 189, 201], "singl": [22, 24, 34, 35, 36, 64, 66, 70, 72, 75, 76, 81, 82, 89, 90, 97, 98, 100, 104, 106, 108, 115, 117, 122, 124, 125, 126, 127, 132, 134, 138, 143, 147, 149, 150, 152, 157, 164, 165, 166, 172, 173, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "markdown24": [22, 132], "abov": [22, 24, 36, 46, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 100, 101, 102, 109, 115, 116, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 172, 174, 175, 176, 182, 183, 189, 190, 191, 192, 196, 198, 199, 200, 201], "distinguish": [22, 24, 34, 81, 117, 118, 127, 132, 194], "ey": [22, 24, 108, 117, 132, 134, 138, 176, 198, 199, 200, 201], "ball": [22, 24, 132, 165], "seen": [22, 24, 66, 70, 72, 75, 76, 88, 89, 90, 99, 101, 102, 108, 109, 116, 117, 126, 127, 132, 139, 141, 147, 148, 149, 156, 157, 158, 162, 164, 165, 166, 173, 182, 183, 187, 189, 190, 191, 196, 201], "extract": [22, 24, 64, 86, 88, 108, 118, 126, 127, 132, 134, 198, 199, 200, 201], "move_no": [22, 24, 132], "legend": [22, 23, 24, 25, 34, 64, 66, 70, 72, 75, 76, 77, 81, 82, 88, 97, 98, 99, 100, 101, 108, 115, 116, 126, 127, 132, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 200, 201], "thorough": [22, 132], "week": [22, 40, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "exhaust": [22, 132, 201], "emit": [22, 82, 90, 108, 132, 173], "altern": [22, 25, 34, 36, 70, 75, 81, 95, 108, 117, 126, 127, 132, 139, 141, 176, 191, 196, 199, 200, 201], "math": [22, 23, 71, 81, 89, 113, 124, 132, 141, 148, 156, 166, 172, 175, 182, 183], "v": [22, 25, 34, 35, 36, 64, 66, 70, 71, 72, 75, 77, 82, 89, 93, 104, 126, 132, 134, 138, 139, 143, 147, 148, 149, 150, 152, 164, 173, 174, 178, 182, 183, 185, 189, 191, 192, 200, 201], "threshold": [22, 64, 66, 75, 76, 89, 117, 132, 138, 143, 147, 148, 149, 150, 156, 157, 158], "\u03b8": [22, 132], "filter": [22, 25, 81, 108, 126, 127, 132, 147, 149], "mechan": [22, 23, 24, 36, 64, 86, 89, 90, 132, 152, 154, 176, 182, 183, 199, 201], "somehow": [22, 24, 132], "classic": [22, 24, 71, 82, 99, 117, 124, 126, 127, 132, 165, 172, 174, 189, 191, 201], "classif": [22, 24, 34, 106, 109, 125, 127, 132], "raw": [22, 24, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "pre": [22, 24, 64, 72, 76, 88, 89, 90, 108, 125, 132, 138, 139, 145, 147, 148, 149, 157, 164, 165, 166, 173, 202], "10m": [22, 24, 132], "sub": [22, 34, 75, 132, 190], "perceiv": [22, 24, 36, 81, 109, 132], "classifi": [22, 24, 86, 126, 127, 132, 202], "render": [22, 32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "allow": [22, 23, 24, 25, 46, 64, 70, 72, 77, 81, 82, 86, 88, 95, 97, 99, 100, 102, 106, 108, 109, 116, 122, 124, 125, 127, 132, 147, 149, 157, 162, 164, 165, 166, 170, 172, 173, 174, 182, 187, 189, 192, 196, 200, 201], "constant": [22, 25, 64, 70, 75, 76, 77, 88, 89, 90, 100, 102, 108, 127, 132, 139, 147, 148, 149, 150, 156, 158, 164, 165, 166, 172, 174, 183, 189, 198], "over": [22, 24, 25, 64, 66, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 124, 125, 126, 127, 132, 138, 139, 140, 147, 148, 149, 150, 156, 158, 164, 165, 166, 170, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 194, 198, 199, 200, 201, 202], "omit": [22, 132, 189], "describ": [22, 23, 64, 70, 71, 76, 77, 81, 82, 86, 88, 89, 98, 99, 115, 116, 124, 127, 132, 138, 139, 140, 147, 148, 149, 150, 156, 157, 158, 162, 164, 165, 166, 170, 172, 173, 175, 180, 182, 189, 190, 191, 198], "measur": [22, 23, 34, 70, 75, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 116, 132, 139, 141, 143, 147, 158, 164, 165, 172, 175, 176, 182, 189, 198, 199, 200, 201, 202], "latent": [22, 95, 117, 132, 170, 172, 173, 174, 176, 182, 183, 190], "abstract": [22, 24, 72, 76, 104, 120, 124, 125, 126, 127, 132, 147, 168, 178, 192, 200], "instanti": [22, 124, 132, 174], "util": [22, 86, 132, 149, 162, 180, 182, 192], "uncertainti": [22, 90, 95, 98, 99, 132, 162, 165, 173, 174, 182, 185], "cost": [22, 35, 88, 90, 97, 98, 106, 124, 132, 182, 190, 191, 192, 201], "salienc": [22, 132, 175], "plant": [22, 132], "intuit": [22, 23, 71, 72, 75, 76, 77, 81, 82, 86, 89, 109, 115, 116, 117, 124, 126, 132, 138, 140, 141, 147, 148, 158, 160, 162, 164, 165, 166, 170, 173, 174, 175, 176, 182, 183, 189, 196, 200], "inventori": [22, 132], "anymor": [22, 132, 156], "link": [22, 24, 29, 40, 42, 48, 70, 102, 109, 127, 132, 134, 147, 149, 158, 165, 166, 196], "Not": [22, 23, 90, 132, 141, 149, 160, 192, 194, 201], "latex": [22, 132], "relationship": [22, 23, 24, 25, 36, 70, 72, 76, 77, 82, 88, 98, 100, 109, 115, 126, 132, 139, 141, 147, 148, 149, 158, 164, 165, 174, 198, 199, 200], "amplitud": [22, 25, 72, 75, 132, 148, 149, 158], "div": [22, 132], "center": [22, 34, 35, 36, 70, 71, 72, 75, 81, 82, 109, 116, 120, 125, 126, 127, 132, 140, 149, 157, 158, 164, 165, 166, 172, 173, 175, 182], "em": [22, 132, 168], "frequenc": [22, 25, 66, 75, 76, 77, 125, 126, 127, 132, 147, 149, 152, 156, 157, 158, 173], "deviat": [22, 25, 34, 75, 77, 81, 82, 98, 126, 127, 132, 140, 141, 147, 149, 158, 165, 166, 172, 173, 174], "sup": [22, 132], "stand": [22, 25, 89, 132, 166, 176], "\u03c3": [22, 132, 165], "drive": [22, 24, 27, 47, 75, 89, 93, 132, 147, 149, 158, 165, 175, 196], "strongest": [22, 24, 127, 132, 164], "decid": [22, 23, 24, 25, 101, 109, 124, 132, 165, 172, 175, 182, 190, 191], "period": [22, 23, 24, 36, 64, 76, 77, 88, 90, 132, 139, 147, 149, 158, 189, 190], "ratio": [22, 24, 25, 35, 75, 88, 115, 132, 148, 149, 150, 164, 174, 175, 200, 201], "higher": [22, 24, 25, 75, 89, 90, 100, 101, 115, 117, 120, 124, 125, 132, 134, 147, 149, 150, 164, 165, 172, 182, 183, 191, 201], "came": [22, 24, 25, 76, 132], "focuss": [22, 23, 24, 130, 132], "hyp": [22, 24, 132], "vs": [22, 23, 24, 25, 34, 71, 97, 98, 109, 118, 127, 132, 140, 141, 147, 148, 150, 157, 158, 164, 165, 166, 174, 175, 182, 190, 196, 198, 200, 202], "slower": [22, 24, 132, 147, 157, 172, 174, 190], "simplic": [22, 24, 84, 98, 100, 108, 115, 118, 132, 141, 150, 183, 190, 192, 201], "accum": [22, 24, 132], "win": [22, 24, 29, 76, 132], "fast": [22, 24, 75, 124, 132, 152, 157, 175, 182, 183, 189, 191], "slow": [22, 24, 75, 108, 132, 176, 189], "denot": [22, 24, 64, 71, 77, 117, 124, 126, 127, 132, 149, 150, 156, 165, 173, 174, 175, 183, 190], "argument": [22, 24, 34, 35, 36, 64, 66, 88, 89, 97, 108, 124, 125, 126, 127, 132, 156, 158, 166, 174, 191, 196, 200, 201], "outcom": [22, 23, 24, 25, 76, 81, 82, 109, 132, 139, 164, 172, 183, 191, 192, 198, 199, 200, 201], "consist": [22, 23, 70, 71, 72, 77, 81, 100, 117, 122, 124, 125, 132, 138, 139, 149, 157, 172, 175, 178, 192, 198], "consecut": [22, 88, 132], "influenc": [22, 23, 25, 89, 97, 102, 108, 109, 132, 147, 150, 156, 164, 165, 189, 190, 196, 200], "express": [22, 23, 35, 36, 64, 71, 75, 82, 90, 97, 100, 108, 109, 115, 116, 117, 126, 132, 138, 139, 150, 156, 157, 158, 174, 175, 176, 183, 189, 190, 191, 192], "z": [22, 25, 34, 35, 36, 70, 72, 75, 81, 109, 120, 124, 125, 127, 132, 148, 165, 174, 175, 185, 201], "captur": [22, 34, 35, 70, 75, 88, 89, 95, 100, 101, 104, 116, 117, 120, 126, 127, 132, 147, 150, 165, 199, 200, 201], "justifi": [22, 132], "loop": [22, 23, 35, 66, 72, 77, 89, 97, 99, 100, 101, 102, 109, 120, 124, 126, 127, 132, 139, 140, 147, 166, 172, 174, 182, 191, 192, 198, 199, 201], "clariti": [22, 23, 132, 196], "OR": [22, 71, 132, 139, 164], "kord": [22, 23, 39, 84, 88, 89, 90, 91, 93, 104, 120, 132, 160, 166, 194, 198, 199, 200, 201], "kp": [22, 23, 132], "pr": [22, 23, 82, 132, 172], "0352": [22, 23, 84, 132], "19": [22, 23, 40, 77, 84, 104, 132, 156, 175, 191, 192], "nbdt": [22, 132], "scholasticahq": [22, 132], "com": [22, 30, 32, 33, 34, 35, 36, 37, 38, 39, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "articl": [22, 29, 34, 84, 104, 111, 120, 125, 132, 134, 152, 172, 178, 185], "16723": [22, 132], "mk": [22, 132], "osf": [22, 23, 84, 88, 90, 108, 109, 124, 125, 126, 127, 132, 175], "w56vt": [22, 84, 132], "jean": [23, 24], "lauren": [23, 24], "dive": [23, 35, 64, 71, 82, 86, 108, 124, 156, 158, 165, 166, 172, 202], "satisfact": 23, "mathemat": [23, 24, 25, 29, 64, 70, 75, 76, 77, 81, 84, 88, 93, 100, 106, 124, 138, 140, 143, 145, 147, 149, 156, 162, 165, 166, 172, 173, 174, 175, 182, 194, 198, 200], "empow": 23, "chose": [23, 25, 81, 109], "physic": [23, 76, 77, 88, 89, 134, 149, 170, 182], "repres": [23, 25, 34, 66, 70, 71, 75, 76, 77, 81, 82, 88, 90, 113, 115, 116, 117, 122, 124, 125, 126, 127, 134, 138, 148, 149, 150, 156, 157, 158, 162, 164, 165, 166, 173, 175, 176, 182, 189, 190, 192, 198, 199, 200, 201], "ingredi": [23, 130], "granular": [23, 97], "scale": [23, 25, 27, 34, 71, 75, 81, 88, 89, 90, 109, 111, 122, 124, 127, 134, 139, 140, 154, 157, 158, 165, 166, 172, 173, 174, 175, 176, 183, 198], "span": [23, 34, 35, 71, 157, 176, 202], "wider": [23, 101, 124, 125, 140, 165], "behaviour": [23, 32, 81, 106, 109, 166, 194], "lumpabl": 23, "solv": [23, 34, 70, 75, 76, 77, 82, 98, 99, 100, 108, 124, 125, 126, 127, 138, 141, 147, 156, 157, 158, 174, 175, 182, 187, 189, 191, 192], "analyt": [23, 34, 76, 77, 81, 97, 98, 99, 100, 108, 130, 140, 156, 164, 165, 172, 175, 189], "numer": [23, 34, 35, 64, 70, 76, 81, 82, 86, 89, 97, 98, 100, 102, 108, 118, 138, 147, 150, 164, 166, 176, 183, 190], "spatial": [23, 120, 125, 126, 127, 134, 147, 191], "resolut": [23, 25, 125, 126, 127, 176], "regard": [23, 25, 106], "state": [23, 24, 25, 36, 66, 70, 77, 82, 89, 124, 134, 138, 149, 150, 154, 157, 158, 162, 170, 172, 173, 175, 176, 180, 187, 189, 190, 191, 192, 198, 199, 201, 202], "els": [23, 24, 34, 35, 36, 66, 71, 72, 75, 76, 81, 82, 88, 89, 90, 99, 108, 109, 124, 125, 126, 127, 147, 148, 149, 150, 156, 157, 158, 164, 165, 172, 173, 174, 175, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "sake": [23, 166], "dl": [23, 124, 176, 194], "cool": [23, 29, 124, 140, 141, 164, 201], "Being": 23, "w1d1": [23, 30, 40, 145], "meaningfulli": 23, "constrain": [23, 35, 90, 127, 138], "add": [23, 25, 34, 35, 42, 64, 66, 70, 71, 75, 76, 77, 81, 82, 88, 89, 100, 101, 102, 108, 109, 124, 125, 126, 138, 140, 141, 147, 149, 150, 156, 157, 158, 164, 172, 173, 174, 175, 183, 190, 192], "needless": 23, "care": [23, 34, 81, 102, 109, 124, 126, 164, 165, 189, 196, 201], "highlight": [23, 25, 75, 81, 106, 192, 194], "outlin": [23, 77, 97, 126, 199, 200, 201], "draw": [23, 36, 64, 70, 71, 76, 81, 90, 97, 99, 100, 109, 124, 126, 127, 140, 147, 149, 166, 180, 182, 190], "diagram": [23, 102, 124, 139, 201], "sketch": 23, "formal": [23, 70, 75, 88, 126, 127, 164, 165, 180, 182, 187, 189, 191], "thu": [23, 40, 70, 75, 82, 86, 89, 90, 100, 101, 102, 109, 124, 125, 126, 127, 147, 149, 150, 156, 165, 166, 172, 176, 182, 183, 189, 191, 192], "huge": [23, 154, 174, 192], "broken": 23, "portenti": 23, "hypothet": [23, 90], "arrow": [23, 70, 71, 72, 138, 157, 198, 199, 200, 201], "intern": [23, 35, 36, 66, 108, 113, 120, 122, 125, 126, 178, 183, 192], "place": [23, 71, 77, 81, 86, 108, 164, 165, 182, 183, 190, 191, 192], "explan": [23, 70, 71, 72, 75, 76, 77, 81, 82, 84, 88, 89, 97, 98, 115, 116, 117, 118, 125, 127, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 172, 173, 174, 182, 183, 189, 190, 198, 199], "rough": [23, 82], "forget": [23, 69, 80, 82, 87, 96, 107, 108, 109, 114, 117, 118, 123, 131, 137, 146, 148, 155, 163, 166, 171, 174, 181, 183, 188, 197, 201], "recurs": [23, 172, 173, 174, 176, 189], "insid": [23, 64, 66, 81, 88, 124, 158], "icon": [23, 182], "unit": [23, 24, 25, 35, 36, 64, 70, 71, 81, 88, 89, 90, 98, 108, 115, 122, 124, 125, 126, 138, 141, 147, 148, 149, 172, 174, 182, 189, 190], "easiest": [23, 86, 164, 201], "ad": [23, 35, 36, 70, 75, 82, 88, 89, 98, 100, 108, 109, 124, 126, 138, 140, 141, 158, 165, 172, 174, 176, 183, 192, 198, 200], "accomplish": [23, 101, 201], "surprisingli": [23, 192], "remov": [23, 34, 35, 64, 66, 70, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 124, 126, 127, 138, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 166, 172, 174, 175, 183, 190, 191, 192, 198, 199, 200, 201], "insight": [23, 25, 34, 77, 86, 113, 125, 145, 164], "isn": [23, 71, 97, 127, 165, 182, 190], "stabil": [23, 75, 98, 138, 139, 154, 157, 176, 183, 189], "equilibrium": [23, 76, 77, 140, 141, 158, 174], "asymptot": [23, 191], "isol": [23, 34, 64, 134, 138, 165], "mistak": [23, 30, 173, 175], "debug": [23, 64, 166], "Is": [23, 75, 76, 77, 82, 88, 97, 108, 109, 118, 126, 148, 149, 189], "wore": 23, "nice": [23, 75, 76, 81, 125, 127, 165, 190, 198, 200], "useless": 23, "distract": 23, "reader": 23, "alreali": 23, "achiev": [23, 86, 89, 125, 138, 147, 149, 172, 176, 191, 192], "determ": 23, "handi": [23, 64, 100, 183], "improv": [23, 34, 35, 36, 64, 66, 77, 82, 89, 120, 124, 125, 164, 174, 189, 192, 199], "finish": [23, 36, 40, 82, 90, 97, 98, 99, 100, 101, 102, 108, 116, 149, 150, 156, 157, 172, 189, 199], "phenomenon": [23, 86, 88, 101, 130, 149, 172], "criterion": [23, 34, 35, 36, 99, 172], "satisfi": [23, 70, 90, 97, 115, 201], "criteria": [23, 90, 138, 201], "parametr": 23, "elimin": 23, "met": [23, 200], "board": 23, "endless": 23, "benchmark": [23, 117, 143, 180, 194], "neglect": 23, "warrant": 23, "cannot": [23, 71, 75, 76, 77, 88, 139, 165, 166, 173, 174, 182, 183, 189, 190], "ultim": [23, 70, 86, 130, 166], "qualit": [23, 35, 77, 98, 100, 108, 125, 138, 147, 148, 182, 199], "upfront": 23, "amount": [23, 35, 71, 75, 82, 88, 89, 102, 117, 127, 139, 141, 149, 150, 158, 164, 165, 172, 174, 175, 182, 183, 189, 198, 201], "w1d3": [23, 106, 122, 124, 196], "breadth": 23, "bic": 23, "aic": 23, "fair": 23, "respect": [23, 34, 72, 75, 77, 81, 82, 89, 90, 97, 98, 102, 108, 117, 124, 125, 126, 127, 138, 149, 150, 156, 157, 158, 165, 173, 175, 182, 192], "subsumpt": 23, "uncov": [23, 36, 97, 126, 202], "falsifi": 23, "demonstr": [23, 24, 25, 70, 72, 124, 130, 158, 192], "appar": [23, 34, 117], "alon": [23, 175], "leverl": 23, "avenu": 23, "experiment": [23, 25, 27, 77, 86, 89, 95, 127, 149, 166, 172, 175, 178, 189, 194, 199, 201], "target": [23, 34, 36, 72, 108, 109, 118, 124, 127, 134, 165, 180, 183, 189, 191], "messag": [23, 36, 82, 88, 189], "experimentalist": [23, 149, 166], "analog": [23, 174, 199], "famou": [23, 76, 191], "worth": [23, 125, 175, 178, 182], "1000": [23, 25, 75, 76, 77, 81, 82, 88, 89, 98, 102, 113, 115, 116, 126, 127, 139, 140, 147, 148, 149, 150, 156, 165, 166, 176, 190, 191, 192, 199], "parallel": [23, 27, 71, 82, 138, 189], "convinc": [23, 140, 141], "AND": [23, 71], "impact": [23, 77, 104, 148, 154, 173, 175, 190, 192, 201], "accept": [23, 34, 35, 36, 71, 82, 99, 156, 157, 158, 183], "peer": [23, 30], "frget": 23, "spell": 23, "unreason": 23, "claim": [23, 172], "reject": [23, 99, 154, 201], "expeiment": 23, "mesi": 23, "rightfulli": 23, "cleanli": 23, "comment": [23, 36, 66, 82, 88, 89, 90, 108, 117, 118, 139, 154, 166, 182, 190, 191, 192], "stereotyp": 23, "piec": [23, 34, 108, 127, 165], "condens": [23, 100, 175], "To": [23, 24, 25, 34, 36, 47, 72, 75, 76, 77, 81, 82, 88, 89, 90, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 126, 127, 130, 138, 139, 140, 141, 147, 149, 150, 156, 158, 164, 165, 166, 172, 174, 175, 178, 182, 183, 189, 192, 198, 200], "summari": [23, 175], "summar": [23, 24, 25, 66, 71, 82, 102, 115, 138, 164, 173], "articul": [23, 24, 25], "tri": [23, 24, 25, 64, 97, 98, 109, 138, 141, 148, 164, 174, 191], "overview": [23, 24, 25, 115, 116, 117, 118, 138, 156, 194], "conclud": [23, 24, 25], "briefli": [23, 24, 25, 72, 113, 139, 175, 176], "argu": [23, 24, 25, 196], "plausibl": [23, 24, 25, 36, 76, 77, 104, 122, 202], "instruct": [23, 34, 35, 36, 82, 97, 126, 182], "guidelin": [23, 24, 25, 30], "effect": [23, 34, 35, 36, 66, 75, 77, 81, 82, 84, 89, 90, 95, 98, 100, 104, 111, 124, 125, 149, 152, 156, 165, 166, 172, 173, 175, 189, 190, 192, 194, 196, 198, 199, 200, 201], "mensh": 23, "schedul": [23, 189], "schemat": [23, 109, 198], "convei": [23, 72], "necessarili": [23, 72, 101, 157, 165, 189], "upload": 23, "repositori": [23, 29, 120], "github": [23, 36, 43, 93, 109, 111, 118, 120, 124, 138, 175], "forc": [23, 35, 46, 109, 124, 165, 182, 198, 199], "succinctli": [23, 100], "commit": [23, 182], "purpos": [23, 24, 25, 64, 71, 72, 75, 77, 82, 89, 97, 102, 108, 109, 124, 127, 141, 147, 166, 175], "biol": [23, 76, 77], "e1005619": 23, "1005619": 23, "disclaim": [24, 25, 71], "procedur": [24, 25, 93, 97, 99, 101, 109, 127, 148, 162, 201], "pip": [24, 25, 32, 35, 48, 75, 175, 201], "tqdm": 24, "quiet": [24, 25, 32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "matric": [24, 34, 70, 72, 95, 100, 101, 109, 117, 124, 126, 127, 138, 141, 173, 175, 183, 198, 199, 200, 201], "301": 24, "36": [24, 64, 90, 108, 134, 192], "7575": 24, "975": 24, "m_r": 24, "m_p": 24, "mathbb": [24, 71, 90, 101, 116, 147, 164, 165, 175, 189, 190, 198], "c_": [24, 25, 89, 108, 125, 201], "cdot": [24, 25, 70, 71, 75, 77, 81, 109, 115, 124, 126, 127, 148, 150, 156, 158, 165, 173, 176], "w1d4": [24, 196], "glm": [24, 86, 95, 106, 109, 122], "whiteboard": [24, 25], "convert": [24, 34, 35, 36, 90, 124, 125, 126, 127, 147, 148, 149, 172, 174, 176], "belong": [24, 88, 127], "half": [24, 35, 77, 99, 125, 138, 140, 183], "halfwin": 24, "a_r": 24, "cross": [24, 34, 35, 36, 66, 77, 89, 93, 97, 98, 99, 100, 101, 106, 108, 126, 127, 138, 147, 148, 156, 172, 173], "getdesignmatrix": 24, "arg": [24, 25, 34, 35, 36, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 189, 190, 191, 192, 198, 199, 200, 201], "ndarrai": [24, 34, 35, 36, 70, 71, 72, 75, 81, 82, 88, 90, 97, 98, 99, 100, 101, 102, 118, 124, 126, 127, 138, 139, 140, 147, 164, 174, 175, 183, 189, 190, 191, 192, 198, 199, 200, 201], "three": [24, 34, 36, 64, 76, 77, 82, 86, 88, 90, 97, 108, 109, 122, 124, 126, 127, 154, 156, 157, 158, 165, 173, 175, 176, 182, 189, 200, 201], "length": [24, 35, 36, 70, 71, 72, 75, 88, 100, 109, 115, 124, 139, 141, 148, 149, 172, 173, 176, 182, 183, 198, 201], "float": [24, 34, 35, 36, 64, 66, 72, 81, 82, 88, 89, 97, 98, 99, 109, 115, 116, 117, 118, 124, 125, 126, 127, 138, 140, 141, 147, 150, 156, 165, 166, 172, 173, 176, 182, 183, 189, 190, 191, 192, 199, 200, 201], "extent": [24, 36, 70, 98, 117, 166], "1d": [24, 70, 71, 88, 89, 97, 98, 100, 108, 109, 124, 126, 127, 156, 158, 172, 173, 174, 183], "movstim": 24, "win_idx": 24, "desmat": 24, "mov": [24, 25], "76": [24, 149, 192], "33475": 24, "77": [24, 76, 90, 192], "53275": 24, "78": [24, 134, 164, 194], "61975": 24, "calcul": [24, 34, 35, 36, 71, 72, 76, 77, 81, 82, 88, 97, 98, 99, 100, 101, 102, 115, 124, 126, 138, 139, 140, 147, 148, 149, 150, 157, 158, 165, 172, 173, 174, 176, 182, 183, 189, 190, 191, 199, 200, 201], "correctli": [24, 35, 82, 100, 172, 182, 183, 198, 201], "saw": [24, 34, 36, 70, 71, 72, 75, 77, 88, 89, 102, 109, 116, 117, 124, 126, 139, 147, 149, 156, 158, 164, 165, 166, 173, 174, 189, 190, 199, 201], "cv": [24, 109, 147, 149], "dot": [24, 25, 64, 66, 71, 76, 77, 81, 89, 90, 101, 102, 108, 109, 115, 116, 138, 139, 140, 141, 149, 165, 166, 172, 198, 199, 200, 201], "graph": [24, 77, 101, 118, 127, 134, 139, 176, 183, 198, 199, 201], "56": [24, 134, 156, 192], "72": [24, 27, 90, 134, 152, 157, 158, 192], "65": [24, 71, 84, 127, 149, 150, 158, 164, 165, 172, 192], "median": [24, 99, 165, 166, 199], "accord": [24, 71, 75, 81, 86, 88, 98, 99, 100, 102, 115, 126, 150, 172, 174, 176, 182, 183, 189, 191, 198], "magnitud": [24, 109, 127, 138, 140, 150, 174, 183, 199], "ignor": [24, 36, 82, 100, 108, 109, 118, 126, 157, 158, 164, 165, 166, 175, 196], "maximum": [24, 34, 35, 36, 72, 75, 81, 88, 97, 99, 100, 101, 102, 104, 106, 108, 109, 116, 125, 126, 127, 149, 150, 156, 162, 164, 165, 182, 183, 189, 190, 191, 192], "discrimin": [24, 117, 122, 124, 125], "classifymotionfromspik": 24, "750": [24, 102, 149], "int": [24, 25, 34, 35, 36, 64, 66, 71, 72, 75, 81, 82, 88, 89, 99, 109, 117, 118, 124, 126, 127, 141, 147, 148, 149, 150, 156, 158, 172, 173, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "regular": [24, 64, 89, 106, 124, 147, 149, 162, 183, 192, 200], "intend": [24, 174, 199], "ye": [24, 25, 70, 89, 141, 147, 148, 150, 165, 182], "somewhat": [24, 82, 175], "contrast": [24, 75, 82, 100, 118, 173, 176, 180, 192, 202], "quit": [24, 97, 101, 108, 124, 126, 165, 166, 190, 192, 201], "presenc": [24, 156, 182, 183, 201], "And": [24, 25, 64, 70, 72, 75, 84, 108, 138, 147, 149, 165, 172, 174, 190, 198], "runanalysi": 24, "050": 24, "class_set": 24, "empti": [24, 72, 81, 108, 147, 173, 182], "halfwin_no": 24, "lty": 24, "leg_hw": 24, "classes_no": 24, "leg_class": 24, "color": [24, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 88, 89, 97, 98, 99, 100, 108, 109, 115, 116, 118, 125, 126, 127, 138, 140, 141, 147, 148, 149, 150, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 192, 198, 199, 200, 201, 202], "purpl": [24, 71], "motions_no": 24, "cond_acc": 24, "m_acc": 24, "store": [24, 29, 34, 35, 36, 82, 88, 89, 109, 117, 118, 124, 126, 127, 139, 141, 147, 172, 182, 189, 199], "simplifi": [24, 64, 75, 77, 82, 89, 98, 101, 145, 150, 176], "plotaccuraci": 24, "accuarci": 24, "xlim": [24, 34, 35, 36, 70, 71, 72, 75, 76, 77, 81, 88, 89, 90, 98, 99, 117, 124, 127, 139, 140, 148, 149, 150, 158, 164, 175, 176, 191, 192, 200, 201], "ylim": [24, 34, 35, 36, 70, 71, 72, 75, 76, 77, 81, 88, 89, 90, 98, 99, 116, 117, 124, 127, 140, 147, 148, 149, 150, 156, 158, 164, 175, 176, 190, 191, 192], "proport": [24, 25, 82, 97, 109, 117, 140, 148, 164, 165, 172, 173, 175, 198, 200, 201], "xtick": [24, 35, 36, 66, 70, 71, 72, 75, 108, 109, 116, 127, 141, 164, 190], "tick": [24, 34, 117, 118, 126, 189, 198, 199], "loc": [24, 70, 71, 72, 75, 77, 100, 108, 126, 140, 147, 148, 149, 150, 156, 157, 158, 165, 172, 173, 174, 182, 183, 191, 192], "job": [24, 77, 108, 124, 141, 172, 191, 198, 200], "dash": [24, 76, 77, 147, 148, 149, 156, 165, 166, 172, 173, 183], "wors": [24, 77, 126, 165, 183, 199], "longer": [24, 35, 71, 89, 138, 149, 150, 165, 182, 183, 189, 190, 192], "harder": [24, 27, 76, 127, 172, 182, 183, 194, 200], "clearer": [24, 66, 81], "judgment": [24, 25, 120, 122, 168], "sensor": [24, 174, 175], "notion": [24, 75, 109, 154, 164], "Of": [24, 82, 149, 164, 199], "contribut": [24, 64, 75, 89, 91, 98, 100, 178, 191, 194], "On": [24, 30, 34, 77, 82, 84, 95, 102, 109, 118, 149, 164, 172, 183, 189, 190, 202], "adjac": [24, 25, 75, 88, 141, 148, 176], "unknown": [24, 25, 75, 77, 97, 164, 165, 190], "effort": [24, 97, 175, 182], "cumul": [24, 75, 88, 117, 139, 140, 172, 189, 191], "instantan": [24, 148, 150, 182, 191], "world": [24, 34, 35, 70, 76, 82, 98, 125, 140, 162, 164, 165, 170, 172, 174, 180, 182, 187, 189, 191, 194, 200, 202], "scenario": [24, 34, 64, 90, 100, 150, 164, 183, 189, 190], "causal": [24, 40, 88, 106, 134, 145, 154, 194, 196, 202], "paraphras": [24, 25], "built": [24, 25, 29, 89, 124, 125, 126, 127, 138, 140, 147, 154, 182, 187, 189, 202], "extrem": [24, 25, 34, 72, 81, 82, 97, 108, 116, 150, 164, 182, 189, 190], "artifici": [24, 25, 34, 84, 120, 122, 141, 149, 150, 166, 187, 189], "hopefulli": [24, 25, 34, 36, 64, 70, 81, 82, 86, 125, 126, 139, 140, 199], "hit": [24, 25, 147, 165, 191], "roadblock": [24, 25], "somewher": [24, 25, 108, 174, 182], "optim": [24, 34, 35, 36, 40, 75, 81, 86, 98, 99, 100, 101, 102, 106, 109, 117, 120, 122, 125, 126, 127, 134, 156, 157, 158, 162, 164, 165, 166, 170, 173, 176, 178, 180, 187, 189, 190, 191, 192, 202], "neuroscientist": [24, 81, 84, 113, 122, 156, 176], "weight": [24, 35, 36, 70, 71, 72, 77, 81, 90, 100, 101, 102, 108, 109, 116, 118, 124, 126, 145, 149, 156, 164, 165, 166, 174, 189, 198, 199, 200, 201], "role": [24, 34, 82, 104, 109, 115, 134, 148, 156, 183, 189, 194], "demo": [25, 130, 162, 166], "theta": [25, 34, 35, 36, 70, 75, 82, 97, 98, 99, 100, 101, 102, 108, 109, 115, 125, 126, 127, 147, 156, 157, 158, 175, 176, 182, 198, 199, 200, 201], "mathbf": [25, 70, 71, 72, 82, 97, 98, 99, 100, 108, 116, 124, 126, 127, 138, 139, 141], "sigma": [25, 34, 64, 66, 75, 81, 82, 98, 101, 102, 109, 115, 116, 125, 126, 127, 140, 141, 147, 165, 166, 172, 173, 174, 175, 198, 200, 201], "drift": [25, 76, 77, 141, 168, 183], "diffus": [25, 76, 77, 141, 149, 168, 173], "establish": [25, 141], "framework": [25, 72, 82, 104, 106, 108, 109, 120, 141, 145, 162, 187, 189, 192, 199], "frac": [25, 35, 64, 70, 75, 76, 77, 81, 82, 89, 90, 97, 98, 100, 102, 108, 109, 115, 116, 117, 124, 126, 127, 138, 140, 147, 148, 149, 150, 156, 164, 165, 172, 174, 175, 176, 182, 183, 190, 200], "de": [25, 27, 90, 148, 157, 158, 178], "leakag": [25, 89], "instal": [25, 48, 79], "panda": [25, 174], "dark_background": 25, "vestibular_sign": 25, "sig": [25, 140, 141, 147, 148, 149, 156, 158], "scalar": [25, 70, 71, 72, 75, 81, 82, 89, 100, 101, 102, 108, 109, 115, 116, 117, 124, 126, 127, 138, 139, 140, 141, 164, 165, 166, 172, 174, 183, 201], "sd": [25, 108], "white": [25, 34, 88, 98, 108, 117, 125, 149, 174], "1m": 25, "linspac": [25, 34, 35, 36, 64, 66, 71, 81, 82, 88, 90, 97, 98, 100, 108, 109, 124, 125, 126, 127, 141, 147, 150, 156, 157, 158, 165, 166, 172, 173, 174, 176, 182, 183, 191, 192, 198, 199, 200, 201], "14": [25, 70, 77, 82, 88, 104, 108, 120, 124, 140, 143, 148, 149, 156, 157, 183, 189, 192], "1001": 25, "exp": [25, 75, 76, 77, 81, 82, 88, 98, 108, 109, 125, 126, 127, 138, 150, 156, 157, 158, 165, 166, 172, 174, 176, 198, 199, 200, 201], "diff": [25, 75, 88, 89, 90, 139, 147, 149, 176], "u": [25, 34, 35, 36, 64, 70, 72, 75, 81, 104, 115, 116, 120, 124, 149, 156, 157, 158, 160, 164, 165, 174, 183, 191, 192, 194], "leaki": [25, 64, 89, 90, 134, 145, 148, 202], "append": [25, 34, 35, 36, 76, 77, 88, 89, 100, 102, 109, 124, 126, 127, 139, 147, 148, 149, 150, 156, 157, 158, 172, 173, 176, 182, 183, 201], "thr": [25, 149], "run_model": 25, "selfmot": 25, "aris": [25, 71, 126, 147, 148, 154, 158, 166, 200], "thrshold": 25, "fool": [25, 189], "conceptu": 25, "behav": [25, 89, 138, 140, 149, 165, 174, 176, 189, 191, 201], "alter": [25, 71, 90, 156, 189], "regim": [25, 124, 143, 147, 149, 152, 158], "itertool": [25, 71], "automat": [25, 34, 66, 120, 124, 127, 178], "generat": 25, "param": [25, 35, 138, 141, 166, 174, 175, 182, 191, 192], "map": [25, 29, 34, 35, 36, 71, 75, 109, 138, 139, 148, 157, 172, 173, 189, 191, 192], "zip": [25, 34, 35, 36, 70, 72, 90, 97, 98, 109, 125, 126, 150, 164, 175, 176], "temp": 25, "hypothsi": 25, "pd": [25, 174], "df": [25, 75, 156, 157, 158, 174], "datafram": [25, 174], "column": [25, 34, 64, 71, 75, 82, 100, 101, 102, 108, 115, 116, 117, 124, 125, 126, 127, 164, 166, 200], "multi": [25, 126, 134, 152, 165, 189], "panel": [25, 48, 76, 77, 109], "layout": [25, 35, 75, 76, 77, 81, 82, 147, 148, 149, 150, 164, 165, 173, 174, 176, 182], "constrained_layout": 25, "absent": 25, "present": [25, 27, 34, 36, 40, 82, 100, 108, 120, 122, 124, 125, 126, 139, 156, 166, 175, 189, 198], "mov_": 25, "uniqu": [25, 70, 76, 77, 90, 108, 124, 126, 127, 139], "thr_": 25, "sig_": 25, "thr_n": 25, "c_n": [25, 70], "subdf0": 25, "groupbi": 25, "subdf1": 25, "im0": [25, 198], "im1": [25, 198], "4f": [25, 34, 35, 36, 82, 127, 141, 156, 189], "set_ylim": [25, 71, 72, 90, 127, 140, 150, 158, 164, 165, 172, 173, 174, 176, 182], "set_xlim": [25, 71, 72, 90, 127, 150, 164, 165, 174, 176, 182], "450": 25, "set_xlabel": [25, 75, 81, 82, 90, 108, 124, 125, 126, 127, 138, 150, 157, 158, 164, 165, 166, 172, 173, 174, 182, 183, 189, 198, 200, 201], "set_ylabel": [25, 70, 75, 81, 82, 90, 108, 124, 125, 126, 127, 138, 150, 157, 158, 164, 165, 166, 172, 173, 174, 176, 182, 183, 189, 198, 199, 200, 201], "set_facecolor": [25, 166], "grei": [25, 66, 71, 76, 77, 164, 165, 166, 173, 175], "redund": 25, "sensibl": [25, 140], "0004": 25, "d0": 25, "d1": 25, "detect": [25, 175], "59": 25, "roughli": [25, 108, 118, 165, 189, 199], "likelihood": [25, 81, 93, 95, 97, 99, 100, 101, 102, 104, 106, 108, 109, 126, 127, 162, 165, 170, 172, 173, 174, 176, 191], "201": 25, "monoton": [25, 75, 82, 88, 98, 127, 138, 149, 156, 176], "satur": [25, 124, 156], "push": [25, 138, 147, 149], "larger": [25, 72, 75, 76, 77, 81, 108, 109, 115, 116, 122, 124, 125, 127, 138, 139, 140, 141, 164, 165, 183, 189, 190, 196, 199, 200, 201], "linearli": [25, 70, 77, 140, 148, 198], "error": [25, 34, 35, 36, 48, 71, 88, 90, 93, 98, 99, 100, 102, 108, 109, 117, 124, 134, 141, 156, 157, 158, 165, 172, 174, 175, 178, 183, 191, 192, 201], "construct": [25, 34, 88, 89, 90, 106, 108, 124, 126, 127, 140, 141, 166], "under": [25, 34, 35, 48, 71, 75, 102, 126, 127, 147, 148, 149, 150, 157, 158, 165, 168, 173, 182, 183, 189], "occurr": [25, 139, 150], "variat": [25, 77, 88, 89, 116, 139, 140, 147, 189], "probabilist": [25, 81, 82, 104, 139, 164, 175, 194], "dokka": 25, "head": [25, 70, 71, 140, 183, 190], "39": [27, 71, 149, 191, 192], "neuropixel": [27, 88, 109], "700": [27, 125], "mous": [27, 109, 113, 124, 125, 126, 127, 134, 165, 183], "superior": [27, 175], "colliculu": 27, "offer": [27, 29, 86, 109], "pathwai": [27, 134], "scott": [27, 101, 104], "linderman": [27, 134], "lfp": [27, 199], "waveform": 27, "zatka": 27, "haa": 27, "carandini": 27, "harri": [27, 134], "action": [27, 66, 86, 101, 145, 147, 150, 160, 164, 165, 166, 170, 176, 178, 180, 182, 187, 189, 191, 192, 202], "576": 27, "7786": 27, "266": 27, "273": 27, "s41586": [27, 185], "019": [27, 120, 134, 185], "1787": 27, "neurostar": 27, "org": [27, 46, 70, 76, 77, 84, 93, 102, 104, 109, 111, 118, 120, 124, 125, 126, 127, 134, 152, 160, 178, 185, 194, 201], "14539": 27, "000": [27, 34, 64, 117, 118, 124, 125, 126, 127, 156, 166, 199], "grate": [27, 122, 124, 125, 126, 127], "whisk": 27, "snif": 27, "tast": [27, 66, 88], "orient": [27, 34, 36, 81, 82, 100, 122, 124, 125, 127, 157, 165, 200], "reddi": 27, "multidimension": [27, 100], "364": 27, "6437": 27, "eaav7893": 27, "1126": [27, 84, 134, 143, 152, 178, 185], "aav7893": 27, "michaelo": [27, 120], "tsyboulski": [27, 120], "lindo": [27, 120], "184": [27, 120], "2767": [27, 120], "2778": [27, 120], "03": [27, 77, 82, 93, 104, 120, 126, 143, 152, 158, 165, 178], "042": [27, 120, 156], "beginn": [27, 34, 66, 160], "adapt": [27, 36, 93, 104, 124, 134, 178, 192], "novel": [27, 81, 82], "vip": 27, "sst": 27, "focus": [27, 70, 71, 82, 88, 102, 130, 147, 160, 194], "caveat": [27, 122], "unpublish": 27, "dataload": 27, "sdk": 27, "marina": 27, "garret": 27, "iryna": 27, "yavorska": 27, "doug": 27, "ollerenshaw": 27, "vri": 27, "lecoq": 27, "buic": [27, 134], "groblewski": 27, "ocker": [27, 134], "koch": [27, 54, 168], "138": 27, "151": 27, "s41593": [27, 111, 120, 185], "0550": 27, "siegl": 27, "jia": 27, "durand": 27, "gale": 27, "bennett": [27, 84], "graddi": 27, "592": [27, 152], "7852": 27, "86": [27, 192], "92": [27, 143, 150, 176], "020": [27, 120], "03171": 27, "feulner": 29, "clopath": 29, "biomodel": 29, "biolog": [29, 36, 40, 72, 76, 77, 89, 120, 122, 125, 134, 143, 145, 147, 148, 149, 150, 154, 156, 189, 201, 202], "biomed": [29, 134, 194, 198], "host": [29, 37, 38, 39, 76, 77], "vast": 29, "pharmaceut": 29, "modeldb": 29, "locat": [29, 34, 36, 81, 82, 90, 98, 149, 156, 166, 174, 175, 176, 180, 182, 183, 191, 192], "retriev": [29, 34, 35, 36, 84, 147, 148, 149, 150, 156, 158], "entri": [29, 82, 88, 90, 108, 173, 200], "citat": 29, "publish": [29, 76, 77, 194], "collabor": [29, 37, 38, 39, 47, 82], "crcn": 29, "websit": [29, 46, 125], "marketplac": 29, "forum": [29, 120], "eegbas": 29, "storag": [29, 64, 89], "manag": [29, 150], "eeg": [29, 77, 81, 173, 174, 196, 199], "metadata": 29, "document": [29, 71, 109, 118, 124, 125, 126, 127, 165, 168], "electrophysiolog": [29, 147, 156], "incf": 29, "endors": 29, "nitrc": 29, "collaboratori": 29, "award": 29, "web": [29, 93, 189], "comprehens": [29, 64], "ever": [29, 48, 88, 89, 90, 91, 130, 150, 165, 175, 189, 190], "expand": [29, 34, 35, 88, 124, 145], "scope": 29, "neuroinformat": 29, "figshar": 29, "openli": 29, "neurovault": 29, "public": [29, 108, 130, 194], "unthreshold": 29, "parcel": 29, "atlas": 29, "mri": [29, 120], "pet": 29, "knowledgespac": 29, "global": [29, 77, 118, 165, 173, 182, 183, 189], "driven": [29, 75, 89, 134, 143, 147, 149, 150, 156, 202], "encyclopedia": 29, "staff": 30, "cma": 30, "quiz": 30, "old": [30, 97, 106, 141], "conduct": [30, 46, 76, 77, 81, 104, 134, 143, 147, 148, 164], "updat": [30, 40, 64, 66, 72, 75, 82, 89, 116, 124, 126, 127, 138, 140, 147, 148, 149, 150, 156, 157, 158, 162, 164, 172, 173, 174, 175, 176, 180, 182, 189, 191, 198, 200, 201], "shrezdsthwplj4rpi": 30, "manual": [30, 82, 127], "racial": 30, "equiti": 30, "bilibili": 30, "program": [30, 34, 36, 178, 183, 189], "nicola": [30, 154], "toolbox": [30, 75, 81, 93, 120], "instructor": 30, "deck": 30, "bonu": [32, 36, 88, 113, 122, 141, 145, 157, 165, 170], "autoencod": [32, 113], "pip3": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "vibecheck": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "datatop": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "datatopscontentreviewcontain": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "content_review": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "notebook_sect": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "str": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "prompt": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "pmyvdlilci": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "api": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "east": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "amazonaw": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "klab": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "neuromatch_cn": [32, 33, 34, 35, 36, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "user_kei": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "y1x3mpx5": [32, 33, 34, 35, 36, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "feedback_prefix": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "bonus_autoencoders_intro": 32, "31merror": 32, "account": [32, 48, 76, 81, 82, 95, 102, 108, 140, 141, 150, 152, 164, 165, 168, 174, 175, 183], "packag": [32, 34, 64, 89, 124, 175], "conflict": [32, 101], "jupyt": [32, 109, 118, 138], "client": 32, "incompat": 32, "0m": 32, "31m": 32, "_video": [32, 33, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 130, 131, 136, 137, 145, 146, 154, 155, 162, 163, 170, 171, 180, 181, 187, 188, 196, 197], "bonus_autoencoders_outro": 33, "marco": [34, 35, 36, 64, 66], "brigham": [34, 35, 36, 64, 66], "ccnss": [34, 35, 36, 64, 66], "itzel": [34, 35, 36, 174, 182], "olivo": [34, 35, 36, 174, 182], "karen": [34, 35, 36], "schroeder": [34, 35, 36], "karolina": [34, 35, 36, 64, 66, 138, 139, 166, 182, 183], "stosio": [34, 35, 36, 64, 66, 138, 139, 166, 182, 183], "spiro": [34, 35, 36, 64, 66, 75, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 192, 198, 199, 200, 201], "chavli": [34, 35, 36, 64, 66, 75, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 192, 198, 199, 200, 201], "robust": [34, 35, 36, 84, 118], "famili": [34, 71, 88, 165], "auxiliari": [34, 174], "primari": [34, 82, 124, 126, 134], "compress": [34, 35, 36, 113], "throw": 34, "awai": [34, 36, 72, 82, 89, 139, 140, 149, 164, 165, 175, 183, 191, 200], "fictiti": 34, "cognit": [34, 35, 36, 84, 93, 104, 111, 120, 140, 143, 152, 175], "bundl": 34, "elabor": 34, "guess": [34, 81, 82, 99, 108, 141, 150, 156, 165, 172, 174, 175, 189, 191], "occlud": [34, 36], "recov": [34, 36, 71, 82, 149, 158, 166, 174, 176, 183, 190, 199, 201], "handwritten": [34, 117], "digit": [34, 35, 75, 98, 117, 118, 124, 126, 127, 141], "bottleneck": [34, 35, 36], "layer": [34, 35, 36, 108, 109, 122, 124, 143], "enforc": [34, 124, 127], "fewer": [34, 102, 117, 124, 125, 172, 201], "enabl": [34, 35, 48, 66, 70, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 109, 115, 116, 117, 124, 127, 138, 139, 140, 147, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 182, 183, 189, 190, 198, 199, 200, 201], "roadmap": 34, "architectur": [34, 36, 122, 124, 125, 126, 192], "extend": [34, 36, 72, 75, 76, 77, 100, 108, 124, 149, 154, 156, 157, 164, 165, 172, 183, 202], "acquaint": 34, "princip": [34, 113, 117, 118, 138], "non": [34, 35, 36, 71, 77, 81, 88, 89, 90, 109, 113, 116, 118, 122, 124, 125, 126, 138, 140, 147, 148, 149, 154, 156, 165, 174, 183, 194], "factor": [34, 72, 75, 76, 77, 88, 89, 90, 98, 111, 127, 134, 138, 148, 165, 174, 191, 192], "hidden": [34, 35, 40, 66, 81, 82, 88, 104, 109, 124, 126, 127, 134, 162, 166, 170, 174, 175, 176, 180, 182, 187, 189, 200, 202], "inspect": [34, 35, 36, 48, 72, 100, 157, 182, 183, 200], "bonus_autoencoders_t1": 34, "torch": [34, 35, 36, 124, 125, 126, 127], "fetch_openml": [34, 35, 36, 117, 118], "log": [34, 35, 36, 48, 64, 66, 69, 71, 72, 75, 76, 77, 80, 81, 82, 87, 88, 89, 90, 93, 96, 97, 98, 99, 100, 101, 102, 107, 108, 109, 114, 115, 116, 117, 118, 123, 124, 125, 126, 127, 131, 132, 137, 138, 139, 140, 141, 146, 147, 148, 149, 150, 155, 156, 157, 158, 163, 164, 165, 171, 172, 173, 174, 175, 176, 181, 182, 183, 188, 189, 190, 191, 192, 197, 198, 199, 200, 201], "getlogg": [34, 35, 36, 64, 66, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "font_manag": [34, 35, 36, 64, 66, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "disabl": [34, 35, 36, 64, 66, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "config": [34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "inlinebackend": [34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "figure_format": [34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "retina": [34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "githubusercont": [34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "neuromatchacademi": [34, 35, 36, 43, 46, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "nma2020": [34, 35, 36, 166, 172, 173, 176], "mplstyle": [34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "fig_w": [34, 66, 75], "fig_h": [34, 66, 75], "rcparam": [34, 66, 71, 72, 75, 82], "downloadmnist": [34, 35, 36], "tensor": [34, 35, 36, 124, 125, 126, 127, 134, 176], "60000": [34, 35, 36], "28": [34, 35, 36, 93, 117, 120, 125, 126, 127, 172, 178, 201], "10000": [34, 35, 36, 66, 72, 88, 139, 140, 148, 182, 199, 200, 201], "mnist_784": [34, 35, 36, 117, 118], "return_x_i": [34, 35, 36], "as_fram": [34, 35, 36, 117, 118], "trunk": [34, 35, 36], "n_train": [34, 35, 36, 124, 126, 127], "n_test": [34, 35, 36, 127], "train_idx": [34, 35, 36], "test_idx": [34, 35, 36], "from_numpi": [34, 35, 36, 125, 126, 127], "astyp": [34, 35, 36, 72, 125, 126, 127, 147, 149, 150, 165, 182], "float32": [34, 35, 36, 88, 124, 125, 126, 127], "init_weights_kaiming_uniform": [34, 35, 36], "pytorch": [34, 35, 36, 122, 127], "kaim": [34, 35, 36], "uniform": [34, 35, 36, 64, 75, 82, 90, 97, 98, 99, 100, 101, 102, 117, 165, 175, 182, 189, 191, 192], "modul": [34, 35, 36, 37, 38, 39, 48, 66, 88, 102, 108, 115, 116, 117, 118, 124, 125, 126, 127, 141, 147, 148, 149, 150, 152, 156, 157, 158, 173, 199, 202], "noth": [34, 35, 36, 66, 76, 81, 82, 115, 116, 117, 118, 124, 126, 127, 138, 149, 165, 183, 198, 199, 200, 201], "isinst": [34, 35, 36], "init": [34, 35, 36, 124, 127, 156, 157, 158, 183], "kaiming_uniform_": [34, 35, 36], "init_weights_kaiming_norm": [34, 35, 36], "kaiming_normal_": [34, 35, 36], "get_layer_weight": [34, 35, 36], "learnabl": [34, 35, 36], "item": [34, 35, 36, 88, 108, 109, 124, 126, 127, 150, 156, 176, 182], "detach": [34, 35, 36, 125, 126, 127], "eval_ms": [34, 35, 36], "y_pred": [34, 35, 36, 109, 127], "y_true": [34, 35, 36, 99], "squar": [34, 35, 36, 64, 70, 71, 81, 98, 99, 101, 102, 108, 115, 116, 118, 124, 127, 148, 164, 165, 175, 192], "mse": [34, 35, 36, 98, 99, 101, 102, 124, 127, 165, 175, 183], "no_grad": [34, 35, 36], "mseloss": [34, 35, 36, 124, 127], "eval_bc": [34, 35, 36], "entropi": [34, 35, 36, 126, 127], "bce": [34, 35, 36], "bceloss": [34, 35, 36, 126], "plot_weights_ab": 34, "encoder_w_a": 34, "encoder_w_b": 34, "decoder_w_a": 34, "decoder_w_b": 34, "label_a": 34, "label_b": 34, "bins_encod": 34, "bins_decod": 34, "row": [34, 35, 36, 64, 66, 71, 75, 82, 88, 100, 108, 117, 118, 124, 125, 126, 127, 140, 148, 149, 150, 164, 166, 173, 176, 182, 192, 200], "histogram": [34, 81, 82, 88, 89, 98, 140, 141, 147, 148, 150, 174, 182], "checkpoint": [34, 36], "string": [34, 35, 36, 108, 109, 126, 138, 166, 182, 189], "num": [34, 64, 191, 192], "32": [34, 35, 36, 66, 88, 90, 120, 157, 191, 192, 201], "221": [34, 149], "hist": [34, 66, 81, 82, 88, 90, 98, 99, 139, 140, 141, 147, 152, 174, 182], "flatten": [34, 100, 126, 127, 164, 173, 176, 198, 199, 200, 201], "222": [34, 158], "223": [34, 149], "224": [34, 149, 158], "tight_layout": [34, 35, 36, 66, 100, 108, 109, 117, 124, 126, 127, 147, 149, 150, 157, 158, 174, 182, 183, 189, 199, 200], "plot_row": [34, 35, 36], "show_n": [34, 35, 36], "image_shap": [34, 35, 36], "randomli": [34, 35, 36, 81, 82, 99, 108, 117, 124, 127, 140, 141, 173, 176, 189, 190, 191, 192, 196, 198], "tupl": [34, 35, 36, 88, 109, 126, 127, 138, 166, 201], "items_idx": [34, 35, 36], "enumer": [34, 35, 36, 66, 70, 71, 76, 97, 98, 99, 102, 108, 125, 126, 127, 138, 140, 141, 172, 175, 176, 182, 190, 192, 199, 200, 201], "ndim": [34, 35, 36, 100, 101, 102, 125, 191, 192], "expand_dim": [34, 35, 36, 198, 199], "image_idx": [34, 35, 36], "imshow": [34, 35, 36, 66, 70, 82, 98, 109, 117, 124, 125, 126, 127, 166, 175, 189, 191, 192, 198, 199, 200, 201], "cmap": [34, 35, 36, 66, 70, 72, 75, 98, 100, 108, 117, 118, 124, 125, 126, 127, 138, 164, 165, 191, 192, 198, 199, 200, 201], "grai": [34, 35, 36, 125, 157, 158, 174, 183, 192], "vmin": [34, 35, 36, 70, 72, 98, 117, 124, 125, 126, 127, 164, 198, 199, 200, 201], "vmax": [34, 35, 36, 70, 72, 98, 117, 124, 125, 126, 127, 164, 198, 199, 200, 201], "xy_lim": [34, 35, 36], "minimum": [34, 35, 36, 70, 75, 81, 88, 97, 108, 109, 124, 147, 156, 164, 165, 183], "x_min": [34, 35, 36], "x_max": [34, 35, 36], "finfo": [34, 35, 36, 166], "ep": [34, 35, 36, 166, 199, 200], "plot_gen": [34, 35, 36], "decoder_fn": [34, 35, 36], "n_row": [34, 35, 36], "16": [34, 35, 36, 64, 71, 75, 77, 81, 82, 100, 108, 120, 124, 127, 138, 140, 148, 149, 156, 164, 175, 176, 182, 190, 191, 192, 194, 199], "grid": [34, 35, 36, 66, 70, 71, 72, 75, 82, 97, 100, 109, 125, 126, 127, 138, 140, 147, 157, 191, 192], "coordin": [34, 35, 36, 42, 66, 70, 71, 81, 138, 157, 158, 165, 175], "dx": [34, 35, 36, 71, 75, 77, 138, 156, 157, 158, 165], "canva": [34, 35, 36], "get_cmap": [34, 35, 36, 98, 100, 176], "latent_i": [34, 35, 36], "latent_x": [34, 35, 36], "dtype": [34, 35, 36, 88, 109, 124, 125, 126, 127, 138, 173, 176, 182], "x_decod": [34, 35, 36], "plot_lat": [34, 35, 36], "500": [34, 35, 36, 66, 81, 102, 127, 134, 139, 140, 141, 143, 147, 149, 172, 174, 191, 192], "fontdict": [34, 35, 36], "xy_label": [34, 35, 36], "bold": [34, 35, 36, 81, 95, 149, 150, 158, 198, 199, 200, 201], "tab10": [34, 35, 36, 118, 176], "my_x": [34, 35, 36], "my_i": [34, 35, 36], "horizontalalign": [34, 35, 36, 72, 149, 157, 158], "verticalalign": [34, 35, 36, 72, 149, 157, 158], "z_1": [34, 35, 36, 126], "z_2": [34, 35, 36, 126], "plot_latent_gen": [34, 35, 36], "horizont": [34, 35, 36, 71, 75, 77, 81, 82, 88, 109, 115, 125, 141, 156], "lsit": 34, "fig": [34, 35, 36, 70, 71, 72, 75, 76, 77, 81, 82, 89, 90, 97, 98, 99, 100, 101, 109, 115, 116, 117, 124, 125, 126, 127, 138, 140, 141, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "suptitl": [34, 35, 36, 71, 81, 82, 124, 125, 126, 127, 138, 183, 198, 199, 200, 201], "add_subplot": [34, 35, 36, 70, 75, 115, 116, 166, 174], "121": [34, 35, 36, 97, 98, 99, 100, 104, 117, 127, 147, 149, 158, 176], "122": [34, 35, 36, 117, 127, 147, 149, 150, 158, 176], "plot_latent_ab": [34, 36], "x1": [34, 36, 75, 100, 138, 141], "x2": [34, 36, 100, 138, 141], "selected_idx": [34, 35, 36], "title_a": [34, 36], "title_b": [34, 36], "index": [34, 36, 82, 88, 90, 108, 116, 117, 125, 126, 127, 141, 176, 192, 198, 199, 200, 201], "s2": [34, 35, 36], "boolean": [34, 35, 36, 108, 117, 124, 125, 126, 127, 138, 147, 148, 149, 150, 156, 158, 175, 189, 190], "3d": [34, 36, 70, 71, 72, 75, 100, 118, 176], "spheric": [34, 36], "phi": [34, 35, 36, 124, 125, 126, 127], "runsgd": [34, 35, 36], "net": [34, 35, 36, 106, 120, 124, 126, 127, 172], "input_train": [34, 35, 36], "input_test": [34, 35, 36], "n_epoch": [34, 35, 36, 124, 126, 127], "batch_siz": [34, 35, 36, 126], "verbos": [34, 35, 36, 172, 201], "stochast": [34, 35, 36, 64, 95, 104, 126, 139, 147, 174, 175, 182, 183, 189, 190, 202], "gradient": [34, 35, 36, 82, 120, 125, 126, 127, 140], "descent": [34, 35, 36, 82, 101, 126, 127], "adam": [34, 35, 36, 134], "opoch": [34, 35, 36], "minibatch": [34, 35, 36, 126], "mini": [34, 35, 36, 124, 126], "batch": [34, 35, 36, 120, 124, 126, 127, 173, 175], "loss_fn": [34, 35, 36, 124, 126, 127], "elif": [34, 35, 36, 71, 72, 75, 84, 93, 104, 108, 109, 124, 125, 126, 127, 134, 139, 147, 148, 149, 150, 152, 165, 172, 175, 182, 183, 191, 192], "sgd": [34, 35, 36, 126, 127], "placehold": [34, 35, 36, 124, 126, 127], "track_loss": [34, 35, 36, 126], "epoch": [34, 35, 36, 124, 126, 127, 176], "shuffle_idx": [34, 35, 36], "permut": [34, 35, 36], "output_train": [34, 35, 36], "zero_grad": [34, 35, 36, 124, 126, 127], "backward": [34, 35, 36, 75, 124, 126, 127, 175, 189], "loss_epoch": [34, 35, 36], "loss_train": [34, 35, 36], "output_test": [34, 35, 36], "loss_test": [34, 35, 36, 127], "loss_ms": [34, 35, 36], "nmse": [34, 35, 36], "loss_bc": [34, 35, 36], "ceil": [34, 35, 36, 71, 98, 176], "x_rang": [34, 35, 36, 90], "c0": [34, 35, 36, 64, 66, 82, 100, 189], "_intro_video": [34, 86, 95, 166], "_autoencoders_video": 34, "introduc": [34, 35, 36, 64, 72, 75, 76, 77, 82, 90, 106, 109, 113, 122, 130, 138, 139, 145, 147, 148, 149, 150, 154, 156, 157, 162, 164, 165, 172, 175, 176, 182, 192, 196, 198, 200, 201], "decompress": [34, 35, 36], "character": [34, 104, 156, 157, 182], "trigger": [34, 104, 106, 108], "backpropag": [34, 120, 124], "adjust": [34, 35, 36, 64, 66, 70, 72, 81, 88, 109, 138, 174, 182, 189, 201], "unseen": [34, 36, 109, 127], "fulli": [34, 35, 36, 70, 71, 82, 100, 104, 122, 125, 158, 164, 182, 192, 199], "aan": 34, "due": [34, 35, 46, 66, 70, 76, 88, 89, 124, 126, 134, 145, 148, 149, 158, 166, 175, 189, 190, 199, 201], "stretch": [34, 138], "28x28": [34, 117], "pixel": [34, 36, 113, 117, 125, 126, 127, 175], "grayscal": [34, 117, 125, 126], "uncom": [34, 35, 36, 71, 82, 125, 141, 191], "255": [34, 35, 36, 117, 127], "rescal": [34, 139, 175], "favor": [34, 172], "input_s": [34, 35, 36], "prod": [34, 35, 36, 126, 127], "test_selected_idx": [34, 35, 36], "train_selected_idx": [34, 35, 36], "bottom": [34, 36, 42, 70, 71, 72, 75, 76, 77, 82, 117, 125, 126, 138, 149, 150, 157, 158, 164, 165, 172, 182, 183, 191, 192, 198, 199, 202], "w1d5": [34, 126, 196], "overlaid": 34, "overlai": [34, 70, 175, 176], "pca1": 34, "pca2": 34, "Their": [34, 198], "usag": [34, 149, 199], "straightforward": [34, 141, 149], "shown": [34, 66, 75, 82, 108, 124, 125, 139, 147, 150, 158, 172, 182, 183, 189, 198, 199], "truncat": [34, 117, 118, 165], "svd": [34, 198, 199, 200, 201], "truncatedsvd": 34, "n_compon": [34, 118, 126, 173, 176], "svd_latent_train": 34, "svd_latent_test": 34, "svd_reconstruction_train": 34, "inverse_transform": 34, "svd_reconstruction_test": 34, "obtain": [34, 36, 64, 75, 81, 88, 97, 100, 108, 109, 124, 147, 148, 149, 156, 158, 165, 175, 182, 183, 189, 191, 192, 198, 200, 201], "todo": [34, 35, 64, 66, 70, 72, 75, 77, 81, 82, 88, 97, 98, 99, 100, 101, 102, 109, 115, 116, 117, 118, 125, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 172, 175, 189, 190, 191, 192, 198, 199, 200, 201], "rais": [34, 35, 36, 64, 66, 70, 72, 75, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "notimplementederror": [34, 35, 36, 64, 66, 70, 72, 75, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "make_design_matrix": [34, 100, 101, 102, 108], "pca_latent_test": 34, "to_remov": [34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "xkcd": [34, 64, 66, 70, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 166, 172, 173, 174, 175, 176, 182, 189, 190, 191, 192, 198, 199, 201], "_visualize_pca_latent_space_exercis": 34, "similarli": [34, 36, 71, 75, 126, 149, 150, 158, 164, 173, 183], "recogniz": 34, "components_": 34, "colormap": [34, 138, 166], "sign": [34, 48, 71, 75, 108, 116, 125, 141, 156, 158, 172, 174], "thick": [34, 156], "thin": 34, "indistinguish": [34, 191], "confus": [34, 109, 149, 165, 175], "pca_compon": 34, "pca_output_test": 34, "shallow": [34, 35, 120, 124], "oop": [34, 36], "w3d4": [34, 36, 122, 145], "equival": [34, 64, 71, 75, 81, 88, 90, 108, 124, 164, 165, 166, 172], "deepnetrelu": [34, 124, 127], "sequenti": [34, 35, 36, 134, 191], "n_input": [34, 124, 127], "n_hidden": [34, 124, 127], "n_output": 34, "hyper": 34, "nielsen": [34, 120], "excel": [34, 116, 125], "ian": 34, "goodfellow": 34, "yoshua": 34, "bengio": [34, 120], "aaron": 34, "courvil": 34, "coverag": 34, "momentum": [34, 120, 124, 126, 127], "decai": [34, 72, 77, 88, 138, 139, 140, 149, 150, 156, 157, 158, 183, 189], "smith": [34, 178], "rectifi": [34, 124, 125, 156], "encoding_dim": 34, "sigmoid": [34, 35, 36, 75, 124, 126, 156, 157, 198, 199, 200, 201], "compat": 34, "Such": [34, 36, 75, 86, 125, 126, 138, 140, 149, 154, 158], "finit": [34, 75, 81, 88, 99, 149, 183], "addition": [34, 115, 125, 127, 141, 148, 165, 198], "greater": [34, 72, 81, 124, 164, 189], "input_shap": 34, "encoding_s": [34, 35, 36], "insert": [34, 66, 82, 89, 90, 118, 139, 140, 141, 166, 172, 173, 176, 183, 198, 199, 200, 201], "in_featur": 34, "784": [34, 35, 36, 117], "out_featur": 34, "bia": [34, 36, 82, 97, 98, 99, 100, 102, 108, 109, 124, 125, 126, 127], "_design_ann_autoencoder_exercis": 34, "illustr": [34, 36, 72, 75, 76, 77, 90, 95, 97, 101, 116, 125, 127, 147, 149, 160, 172, 191], "hat": [34, 82, 97, 98, 99, 100, 101, 102, 108, 109, 116, 117, 165, 174, 175, 183, 201], "64": [34, 35, 64, 90, 125, 126, 134, 178, 191, 192], "middl": [34, 36, 76, 77, 90, 125, 157, 164, 165, 192], "priorit": [34, 185], "penal": 34, "gentl": 34, "quadrat": [34, 97], "rise": [34, 82, 89, 90, 148, 156, 182, 189], "dramat": [34, 158], "dark": [34, 82, 165], "wherea": [34, 109, 125, 126, 141, 149, 150, 158, 175], "verifi": [34, 36, 48, 90, 156, 158], "subtl": [34, 124, 182], "converg": [34, 82, 109, 124, 140, 148, 156, 157, 158, 174, 183, 189], "retrain": [34, 102, 109], "accentu": 34, "opt": [34, 75, 156, 157, 158, 183], "prelu": [34, 35, 36], "wiggl": 34, "latent_test": [34, 35, 36], "wise": [34, 70, 88, 166, 176, 182, 198, 199, 200, 201], "capac": [34, 35], "oper": [34, 35, 71, 124, 125, 126, 127, 147, 166, 182, 191, 194], "successfulli": [34, 35, 149, 176], "despit": [34, 46, 72, 165, 172, 175, 190, 198], "charact": 34, "advantag": [34, 35, 82, 102, 125, 192], "pattern": [34, 35, 71, 76, 89, 93, 95, 100, 101, 109, 120, 124, 134, 141, 145, 147, 149, 150, 152, 164, 172, 174, 175, 180, 189, 190, 198], "richer": [34, 138, 200], "tackl": [34, 70, 106, 176, 191], "_wrapup_video": [34, 35, 36], "default": [34, 64, 71, 72, 81, 82, 88, 109, 124, 125, 126, 127, 147, 149, 156, 157, 158, 174, 175, 191, 192], "rng": [34, 64, 82], "manual_se": [34, 124, 126, 127], "afterward": [34, 64, 166, 189], "success": [34, 97, 176, 182, 189], "rai": 34, "recal": [34, 81, 82, 90, 98, 100, 109, 115, 117, 125, 127, 158, 172, 175, 183, 189, 190, 191, 192, 198, 200], "sqrt": [34, 35, 36, 64, 70, 81, 98, 115, 116, 117, 126, 138, 147, 148, 149, 156, 158, 164, 165, 172, 173, 174, 183], "fan_in": 34, "increment": [34, 64, 66, 147, 148, 149, 150, 157, 158], "central": [34, 81, 143, 165, 196], "theorem": [34, 77, 81, 148, 172, 178], "clt": 34, "independ": [34, 75, 82, 89, 97, 98, 99, 100, 102, 109, 111, 125, 139, 140, 148, 149, 164, 165, 166, 172, 173, 175, 176], "inter": [34, 86, 89, 90, 139, 147, 148, 149, 189], "collaps": [34, 35, 88], "unchang": [34, 75, 115, 127, 164], "bias": [34, 82, 102, 124, 126, 127, 172, 196], "torch_se": 34, "reset": [34, 36, 64, 66, 77, 89, 147, 148, 149, 150, 189], "encoder_w_init": 34, "encoder_b_init": 34, "decoder_w_init": 34, "decoder_b_init": 34, "encoder_w_train": 34, "encoder_b_train": 34, "decoder_w_train": 34, "decoder_b_train": 34, "popular": [34, 89, 109, 140, 190], "mathcal": [34, 64, 66, 75, 77, 81, 82, 98, 102, 109, 115, 127, 165, 172, 173, 174, 175, 198], "fan": 34, "_in": 34, "mu": [34, 66, 81, 82, 98, 126, 139, 140, 147, 149, 165, 166, 172, 173, 174, 175, 190], "backprop": 34, "feedforward": [34, 150, 156, 178], "delv": [34, 70, 72, 75, 76, 106], "surpass": 34, "imagenet": [34, 125], "_choosing_weight_initialization_bonus_exercis": 34, "proce": [34, 36, 189], "sk": 34, "furthest": 34, "apart": [34, 127, 165], "shift": [34, 72, 75, 98, 120, 125, 126, 127, 139, 141, 156, 158, 165, 174, 189], "nmf_latent_test": 34, "nmf_compon": 34, "nmf_output_test": 34, "sphere": [35, 36], "geometri": [35, 115, 116, 134], "degre": [35, 36, 70, 81, 82, 100, 101, 102, 115, 124, 125, 126, 127, 140, 141, 143, 148, 165], "freedom": 35, "plotli": 35, "bonus_autoencoders_t2": 35, "graph_object": 35, "print_parameter_count": 35, "params_n": 35, "layer_idx": 35, "params_layer_n": 35, "ntotal": 35, "sampl": [35, 36, 66, 75, 82, 89, 90, 97, 98, 99, 100, 101, 102, 117, 118, 124, 125, 126, 127, 140, 141, 148, 150, 156, 157, 158, 165, 166, 172, 173, 174, 176, 190, 191, 192, 194, 201], "loss": [35, 36, 71, 120, 126, 164], "to_s2": [35, 36], "pi": [35, 36, 64, 71, 75, 77, 81, 82, 98, 102, 115, 116, 117, 125, 126, 127, 138, 165, 172, 174, 175, 183, 189, 190, 198, 199, 200, 201], "speric": [35, 36], "arcco": [35, 36, 116, 117], "arctan2": [35, 36], "to_u3": [35, 36], "sin": [35, 36, 64, 71, 75, 77, 125, 126, 127, 174, 183, 198, 199, 200, 201], "co": [35, 36, 70, 71, 75, 77, 108, 125, 126, 127, 198, 199, 200, 201], "varphi": [35, 36], "plot_latent_3d": 35, "show_text": 35, "marker": [35, 64, 66, 76, 77, 108, 109, 172, 174, 175, 176, 191, 192], "margin": [35, 71, 109, 115, 173, 176, 178], "scene": [35, 120, 124, 125, 127], "xaxi": [35, 70, 71, 164, 182, 189, 198, 199], "showspik": 35, "z1": 35, "yaxi": [35, 70, 71, 108, 164, 174, 198, 199], "z2": 35, "zaxi": 35, "z3": 35, "t10": 35, "idx": [35, 36, 88, 127, 147, 165, 166, 182, 192, 199, 200, 201], "trace": [35, 64, 75, 89, 172, 175, 189], "scatter3d": 35, "textfont": 35, "hovermod": 35, "hoverinfo": 35, "opac": 35, "normalizelay": 35, "l2": [35, 36, 106, 109, 127], "inherit": [35, 36, 165], "__init__": [35, 36, 66, 70, 124, 125, 126, 127, 182, 183, 189, 191, 192], "super": [35, 36, 124, 125, 126, 127, 183, 189, 194], "dim": [35, 36, 126, 127, 175], "_extensions_video": 35, "leverag": [35, 48, 191, 201], "capabl": [35, 36, 81, 90, 124, 126, 140, 190], "layerwis": 35, "depthwis": 35, "392": 35, "aim": [35, 84, 97, 127, 190], "trainabl": 35, "doubl": [35, 66, 77, 88, 101, 174], "halv": 35, "667k": 35, "333k": 35, "diminish": [35, 150, 189], "2x": [35, 75, 97], "3x": 35, "particularli": [35, 82, 106, 124, 125, 165, 182], "drove": 35, "revolut": 35, "n_l": 35, "fill": [35, 36, 40, 46, 64, 66, 70, 72, 81, 82, 88, 89, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 126, 127, 138, 147, 148, 150, 156, 164, 166, 172, 174, 175, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "_build_deeper_autoencoder_exercis": 35, "128": [35, 36, 199], "skew": [35, 150, 165], "lean": 35, "recogn": [35, 126], "spread": [35, 81, 99, 115, 140, 165], "z_3": 35, "indefinit": [35, 75], "eventu": [35, 72, 90, 138, 148, 156, 157, 172, 173, 183, 190], "divid": [35, 64, 70, 75, 77, 102, 124, 141, 147, 148, 149, 157, 164, 172, 183, 198, 199, 201], "l_2": 35, "longmapsto": 35, "s_1": [35, 173], "s_3": 35, "_2": [35, 70, 72, 124, 138, 141], "radiu": 35, "custom": [35, 127, 201], "_deep_autoencoder_with_latent_spherical_space_exercis": 35, "arctan": 35, "angl": [35, 70, 71, 115, 124, 125, 126, 127, 157, 158], "un": [35, 90, 173], "unfold": 35, "deal": [35, 64, 66, 76, 77, 95, 97, 98, 164, 165], "sophist": [35, 124, 190, 198, 200, 201], "8m": [35, 108], "equip": [36, 150], "encount": [36, 70, 71, 72, 75, 81, 100, 130, 154, 162, 164, 176], "evolv": [36, 66, 72, 130, 138, 140, 141, 150, 156, 157, 158, 173, 175, 183, 189], "bonus_autoencoders_t3": 36, "os": [36, 108, 109, 124, 125, 126, 127, 158, 175], "ndimag": [36, 127], "s_2": 36, "out_train": 36, "out_test": [36, 127], "different_output": 36, "batches_out": 36, "batch_idx": 36, "image_occlus": 36, "quadrant": [36, 77, 116, 117], "image_rot": 36, "deg": [36, 140, 148], "my_deg": 36, "prefilt": 36, "autoencoderclass": 36, "activatino": 36, "enc1": 36, "enc1_f": 36, "enc2": 36, "enc2_f": 36, "enc3": 36, "enc3_f": 36, "dec1": 36, "dec1_f": 36, "dec2": 36, "dec2_f": 36, "dec3": 36, "dec3_f": 36, "pass": [36, 70, 75, 108, 109, 124, 126, 127, 147, 149, 156, 157, 158, 175, 176, 182, 183, 192, 198, 201], "save_checkpoint": 36, "filenam": [36, 125, 127], "save": [36, 47, 89, 100, 108, 118, 124, 126, 127, 176, 189, 192], "model_state_dict": 36, "state_dict": [36, 189], "optimizer_state_dict": 36, "pt": [36, 126, 140], "load_checkpoint": 36, "local": [36, 42, 47, 75, 77, 82, 88, 89, 104, 108, 118, 124, 125, 126, 127, 134, 152, 157, 158, 190], "file": [36, 108, 143], "path": [36, 108, 109, 124, 125, 126, 127, 175, 194], "isfil": [36, 108, 109, 124, 125, 126, 127, 175], "wget": 36, "reset_checkpoint": 36, "load_state_dict": 36, "_applications_video": 36, "test_subset_idx": 36, "onto": [36, 71, 113, 117, 126, 127, 132, 139, 189, 190], "lengthi": 36, "ident": [36, 71, 75, 82, 117, 127, 149, 150, 158, 166, 172, 173, 175, 189], "filename_path": 36, "eval": [36, 75, 109, 116, 117, 158], "repo": 36, "3rd": 36, "bellow": 36, "root": [36, 70, 75, 98, 148, 156, 157, 158, 202], "mpbrigham": 36, "colaboratori": 36, "master": [36, 64, 70, 185, 194, 198, 199, 200, 201], "ae_6h_prelu_bce_adam_25e_32b": 36, "_s2": 36, "abil": [36, 82, 90, 108, 122, 125, 173, 191, 192, 199], "invari": [36, 90, 125, 183, 194], "latent_test_ref": 36, "clean": [36, 64, 115, 175, 189], "noise_factor": 36, "input_train_noisi": 36, "input_test_noisi": 36, "output_test_noisi": 36, "latent_test_noisi": 36, "signific": [36, 117, 199, 201], "regener": 36, "denois": 36, "caus": [36, 71, 84, 109, 145, 149, 154, 165, 166, 174, 183, 189, 194, 198, 200, 201], "compos": [36, 82, 88, 90, 156, 157, 189], "characterist": [36, 88], "partial": [36, 98, 117, 124, 182], "input_train_mask": 36, "input_test_mask": 36, "output_test_mask": 36, "latent_test_mask": 36, "arguabl": [36, 95], "input_train_rot": 36, "90": [36, 70, 76, 82, 115, 117, 125, 126, 152, 174, 190, 192, 198, 199], "input_test_rot": 36, "output_test_rot": 36, "latent_test_rot": 36, "melt": 36, "my_input_train": 36, "my_input_test": 36, "my_y_test": 36, "my_latent_test": 36, "occupi": [36, 125, 126, 127], "Will": [36, 127, 148, 149, 156], "evenli": [36, 71, 90, 190, 199], "intersect": [36, 156, 157, 158], "cond_a": 36, "cond_b": 36, "missing_a": 36, "missing_b": 36, "47335": 36, "7885": 36, "_removing_the_most_dominant_class_exercis": 36, "asia": 36, "supposedli": 36, "revers": [36, 70, 75, 115, 147, 148, 149, 150, 172, 175], "shuffle_image_idx": 36, "unshuffl": 36, "input_shuffl": 36, "shuffle_rev_image_idx": 36, "empty_lik": 36, "pos_idx": 36, "po": [36, 125, 172], "input_train_shuffl": 36, "input_test_shuffl": 36, "input_train_shuffle_noisi": 36, "input_test_shuffle_noisi": 36, "confirm": [36, 198], "latent_test_shuffle_noisi": 36, "output_test_shuffle_noisi": 36, "hoorai": [36, 141, 150], "hope": [36, 99, 182, 190], "embed": [36, 37, 38, 39, 118, 126, 175], "imprint": 36, "coin": [36, 140, 141, 190], "daniel": 36, "kahneman": 36, "psycholog": [36, 120, 134, 164, 187, 189], "replic": [36, 64, 125], "middlebrook": [37, 38, 39], "panelist": [37, 38, 39], "adrienn": 37, "fairhal": 37, "bing": [37, 138, 139, 140, 141], "kanaka": 37, "rajan": 37, "audio": [37, 38, 39, 76, 77, 82], "ifram": [37, 38, 39], "src": [37, 38, 39], "braininspir": [37, 38, 39], "casto": [37, 38, 39], "player": [37, 38, 39], "563932": 37, "height": [37, 38, 39, 66, 75, 125, 126, 127, 164, 165], "athena": [38, 178, 183], "akrami": 38, "demba": 38, "ba": 38, "kunlin": 38, "wei": [38, 93, 157, 158], "560014": 38, "yael": 39, "niv": [39, 185], "konrad": [39, 88, 89, 90, 91, 166, 198, 199, 200, 201], "sam": 39, "gershman": 39, "tim": 39, "behren": 39, "569670": 39, "sun": [40, 53, 60, 61, 120], "ceremoni": 40, "utc": [40, 42], "pm": [40, 64, 172], "mon": 40, "tue": 40, "wed": 40, "fri": 40, "15": [40, 64, 66, 70, 71, 72, 75, 82, 88, 90, 97, 98, 99, 101, 104, 108, 109, 117, 118, 120, 126, 127, 134, 138, 139, 140, 141, 149, 150, 156, 157, 164, 165, 168, 173, 176, 189, 190, 192, 198, 199, 200, 201], "22": [40, 82, 93, 104, 120, 138, 148, 164, 172, 189, 191, 192, 198], "24": [40, 76, 88, 99, 100, 104, 108, 127, 143, 152, 178, 189, 191, 201], "reinforc": [40, 86, 95, 122, 162, 170, 180, 185, 187, 189, 190, 191, 202], "graduat": 40, "45": [40, 70, 75, 76, 77, 82, 89, 90, 91, 97, 108, 115, 116, 125, 126, 138, 139, 140, 141, 149, 156, 157, 172, 183, 190, 192, 199, 200], "ii": [40, 75, 77, 149, 157, 158, 192], "asynchron": [40, 202], "synchron": [40, 145], "info": [40, 77, 148, 182], "mentor": 40, "farewel": 40, "certiic": 40, "cour": 40, "goodby": 40, "impos": [40, 183], "quarter": [40, 189], "overlap": [40, 118, 126, 165, 190, 194], "late": [40, 125, 160], "attend": 40, "live": [40, 140, 176], "tbd": 40, "zone": 42, "tz": 43, "environ": [45, 47, 48, 64, 70, 81, 82, 109, 118, 122, 182, 189, 190, 191, 192], "portal": 46, "violat": 46, "precours": [46, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 86], "exempt": 46, "shrubhlgswj8dua7": 46, "shrlp9uktpr5o9u28": 46, "particip": [46, 81, 82, 95, 166], "certif": 46, "assist": [46, 106], "circumst": [46, 88, 198], "beyond": [46, 72, 76, 100, 101, 175, 192], "ill": 46, "electr": [46, 88, 89, 149, 168], "blackout": 46, "request": [46, 88, 90, 108, 109, 124, 125, 126, 127, 175], "grant": [46, 48, 124], "portion": [46, 81, 192, 201], "drop": [46, 48, 75, 98, 102, 116, 148, 149, 182, 189], "elig": 46, "button": [47, 48, 88, 182], "overwrit": 47, "git": 47, "ipynb": 47, "china": 48, "substitut": [48, 70, 71, 72, 98, 172, 199], "regist": [48, 166], "asococi": 48, "workaround": 48, "user": [48, 127, 175], "phone": 48, "gpu": [48, 124], "internet": 48, "sidebar": 48, "enter": [48, 88, 117, 141, 191], "credenti": 48, "kernel": [48, 125, 126, 127, 147, 149, 150], "restart": 48, "newli": [48, 99], "NOT": [48, 71, 166, 182], "comp": [48, 70, 72, 202], "menu": [48, 75, 127], "artwork": [49, 50, 83, 133, 142, 151], "daniela": [49, 50, 83], "buchwald": [49, 50, 83], "arvind": [51, 61, 75, 76, 77, 147, 148, 149, 150, 156, 157, 158], "kumar": [51, 56, 61, 75, 76, 77, 134, 147, 148, 149, 150, 156, 157, 158], "caption": [51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62], "ashish": [51, 58, 62], "sahoo": [51, 58, 62], "kushaan": [51, 58, 62], "gupta": [51, 58, 62, 168], "cynthia": 51, "castillo": [51, 174, 182], "shuze": [51, 53, 55, 56, 57, 58, 59, 60, 61, 62], "liu": [51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 198, 199, 200, 201], "8zxfvwxw": [51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82], "w0d0_t1": 51, "jen": 52, "kremkow": 52, "jiaxin": [52, 55, 59], "tu": [52, 55, 59], "pooya": [52, 56, 57, 70, 71, 81, 82], "pakarian": [52, 56, 57, 70, 71, 81, 82], "maryam": [52, 88, 89, 90, 147, 148, 149, 156, 157, 158], "ansari": 52, "antoni": 52, "puthusseri": 52, "w0d0_t10": 52, "emanuela": 53, "santini": 53, "ethan": [53, 54, 58, 81, 82, 139, 147], "cheng": [53, 54, 58, 81, 82, 139, 147, 189, 190, 191, 192], "anoop": [53, 54, 58, 62, 70, 71, 81, 82, 164, 165, 189, 190, 191, 192], "kulkarni": [53, 54, 58, 62, 70, 71, 81, 82, 104, 164, 165, 189, 190, 191, 192], "manisha": [53, 54, 55, 59, 61], "sinha": [53, 54, 55, 59, 61], "andrew": [53, 60, 61], "carolina": [53, 57, 58], "shimabukuro": [53, 58], "yihe": 53, "lu": 53, "w0d0_t11": 53, "christof": 54, "lili": [54, 189, 190, 191, 192], "ghinwa": [54, 60], "el": [54, 60, 64, 66], "masri": [54, 60], "w0d0_t12": 54, "jenni": 55, "zahra": [55, 60, 164, 165], "arjmandi": [55, 60, 164, 165], "lui": [55, 56, 59, 60, 61, 62], "alvarez": [55, 56, 59, 60, 61, 62], "tong": 55, "liang": 55, "w0d0_t2": 55, "swapnil": [56, 76, 77], "jeremi": [56, 57], "forest": [56, 57], "aditya": 56, "yang": [56, 58, 62], "lin": [56, 58, 62], "w0d0_t3": 56, "churchland": [57, 84, 134], "chaoqun": 57, "yin": 57, "alex": [57, 97, 98, 99, 100, 101, 102, 115, 116, 117, 118], "kostiuk": 57, "luka": 57, "oesch": 57, "ryan": 57, "ashlei": 57, "chen": [57, 134, 168], "joao": 57, "couto": 57, "oluwatomisin": [57, 62], "faniyan": [57, 62], "sirisha": [57, 59, 76], "sripada": [57, 59, 76], "shimabuku": 57, "w0d0_t4": 57, "thoma": [58, 134], "tago": 58, "w0d0_t5": 58, "gaut": 59, "einevol": 59, "richard": [59, 115, 116, 117, 118, 120, 138, 139, 140, 141, 145, 147, 148, 149, 150, 156, 157, 158, 160], "gao": [59, 115, 116, 117, 118, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 168], "zhanao": [59, 60], "fu": [59, 60], "w0d0_t6": 59, "nihan": 60, "alp": 60, "natali": [60, 81, 82, 115, 116, 117, 118], "schaworonkow": [60, 81, 82, 115, 116, 117, 118], "w0d0_t7": 60, "pedro": 61, "vald": 61, "sosa": 61, "benjamin": [61, 104, 108, 109, 198, 199, 200, 201], "becker": 61, "carlo": [61, 82], "lopez": 61, "liangyou": 61, "zhang": [61, 120], "w0d0_t8": 61, "yeka": 62, "apont": 62, "matt": [62, 75, 88, 89, 90, 91, 115, 116, 117, 118, 166, 172, 173, 175, 176, 182, 183, 189, 190, 191, 192], "mccann": [62, 75, 76, 77], "w0d0_t9": 62, "fun": [64, 108, 140, 157, 189], "sneak": 64, "workhors": 64, "unlock": 64, "couldn": 64, "evolut": [64, 66, 72, 120, 156, 157, 165], "w0d1_t1": 64, "_python_basics_and_the_lif_model_video": 64, "tau_m": [64, 76, 77, 147, 148, 149, 150], "e_": [64, 149, 150], "quad": [64, 66, 77, 89, 90, 97, 98, 99, 100, 108, 109, 115, 116, 117, 147, 148, 149, 156, 158, 190], "leq": [64, 109], "v_": [64, 66, 82, 89, 147, 189], "th": [64, 66, 76, 90, 100, 108, 116, 117, 124, 126, 147, 149, 150, 172], "leak": [64, 77, 147, 148, 149, 150, 158], "resist": [64, 76, 77, 89, 147], "voltag": [64, 66, 75, 76, 77, 89, 143, 147, 148, 149, 150, 173, 201], "v_m": [64, 66, 89], "conveni": [64, 70, 82, 89, 98, 117, 139, 150, 172, 175, 182], "charg": [64, 89, 147], "ordinari": [64, 75, 101, 102, 108, 138, 149], "_nano_recap_of_comments_and_strings_video": 64, "modifi": [64, 115, 124, 126, 127, 140, 147, 150, 182, 201], "t_max": [64, 66, 174], "150e": [64, 66], "1e": [64, 66, 88, 124, 127, 150, 156, 157, 158, 173, 199, 200], "tau": [64, 66, 75, 147, 156, 174], "20e": [64, 66], "60e": [64, 66], "milivolt": [64, 66], "vr": [64, 66], "70e": [64, 66], "vth": [64, 66], "50e": [64, 66], "100e6": [64, 66], "ohm": [64, 66, 149], "i_mean": [64, 66, 75, 147], "25e": [64, 66], "amper": [64, 66], "02": [64, 66, 75, 77, 109, 126, 134, 139, 140, 141, 147, 148, 149, 152, 156, 157, 158, 164, 165, 173, 176], "07": [64, 109, 120, 152, 166, 176, 178], "100000000": 64, "5e": [64, 108, 127], "_defining_parameters_ecercis": 64, "notat": [64, 72, 81, 82, 138, 158, 165, 166, 174, 175, 183, 198, 201], "goe": [64, 75, 76, 81, 115, 125, 138, 139, 147, 150, 156, 158, 164, 165, 172, 173, 191, 192], "sinusoid": [64, 77, 183], "i_": [64, 75, 76, 77, 89, 147, 149, 150, 156, 158], "01": [64, 66, 75, 76, 77, 82, 84, 88, 89, 97, 99, 104, 109, 125, 126, 127, 134, 139, 140, 143, 147, 156, 157, 158, 164, 165, 166, 173, 174, 175, 182, 183, 190, 198, 199, 200, 201], "009": [64, 84, 134, 178, 201], "delta": [64, 77, 140, 147, 149, 157, 158, 165, 172, 173, 174, 192], "syntax": [64, 124, 156], "sine": [64, 127], "dagger": 64, "969463130731183e": 64, "877641290737885e": 64, "9694631307311837e": 64, "5000000000000007e": 64, "0305368692688176e": 64, "2235870926211617e": 64, "223587092621159e": 64, "0305368692688186e": 64, "_simulating_an_input_current_ecercis": 64, "3f": [64, 124, 127, 138, 139, 141, 147, 148, 149, 150, 156, 157, 158, 175, 199, 200, 201], "decim": 64, "4e": 64, "exponenti": [64, 75, 76, 77, 86, 88, 89, 90, 98, 108, 138, 148, 149, 150, 156, 165, 174, 176, 189], "14159265e": 64, "314": 64, "1416e": 64, "step_end": [64, 66], "5000e": 64, "9695e": 64, "002": [64, 66, 104, 120, 124, 127, 176], "8776e": 64, "003": [64, 134, 175, 185], "005": [64, 88, 111, 143, 152, 164, 175], "0305e": 64, "007": [64, 66, 76, 77, 143], "2236e": 64, "_printing_pretty_numbers_ecercis": 64, "_for_loops_and_discrete_time_integration_video": 64, "indent": [64, 75, 173, 174], "formul": [64, 95, 117, 141, 176], "stepsiz": [64, 81, 82, 157], "_nano_recap_of_discrete_time_integration_video": 64, "qquad": [64, 76, 77, 149, 156, 157, 158], "manipul": [64, 76, 77, 89, 172, 173, 174, 182, 189], "euler": [64, 75, 86, 147, 149, 150, 156, 157, 158], "e_l": [64, 76, 77, 147, 149, 150], "reorgan": 64, "eq": [64, 149, 158, 183, 198], "v0": 64, "8750e": 64, "6828e": 64, "4548e": 64, "2381e": 64, "0778e": 64, "9989e": 64, "9974e": 64, "0414e": 64, "0832e": 64, "0775e": 64, "_simulating_membrane_potential_exercis": 64, "_intro_to_plotting_video": 64, "_nano_recap_of_plotting_video": 64, "024": [64, 150], "ko": [64, 156, 157, 158], "curent": 64, "_plotting_current_exercis": 64, "t_": [64, 66, 75, 76, 77, 138, 147, 149, 150, 176, 201], "nearest": [64, 126], "smaller": [64, 72, 75, 77, 90, 109, 115, 124, 125, 126, 127, 141, 147, 148, 149, 150, 157, 158, 189], "_plotting_membrane_potential_exercis": 64, "xi": [64, 147, 156, 176], "sim": [64, 81, 89, 98, 115, 140, 156, 172, 173, 174, 175, 189, 198, 201], "pseudo": [64, 82, 99], "random_num": [64, 81], "_adding_randomness_exercis": 64, "_lists_": 64, "_ensemble_statistics_video": 64, "_nano_recap_of_ensemble_statistics_": 64, "_lists_video": 64, "impress": [64, 109], "autocovari": [64, 147], "v_n": [64, 66], "langl": 64, "rangl": 64, "sum_": [64, 66, 70, 82, 90, 97, 98, 100, 109, 116, 117, 124, 125, 126, 127, 148, 150, 164, 172, 175, 176, 183, 189, 198], "command": [64, 124], "symbol": [64, 75, 100], "beta": [64, 82, 89, 109, 165, 201], "tex": 64, "markup": 64, "intiati": 64, "transpar": 64, "_storing_simulations_in_lists_exercis": 64, "v_mean": [64, 66], "markers": [64, 75, 101, 127, 140, 174, 182], "_plotting_sample_mean_exercis": 64, "equiv": [64, 109, 156, 164, 183], "var": [64, 82, 101, 109, 115, 117, 126, 140, 148, 164, 173, 174, 176, 183, 201], "v_var": 64, "49": [64, 192], "81": [64, 82, 134, 164], "v_var_n": 64, "v_std": 64, "c7": 64, "_plotting_sample_standard_deviation_exercis": 64, "_using_numpy_video": 64, "significantli": [64, 125], "narr": [64, 66], "_nano_recap_of_using_numpy_video": 64, "t_rang": [64, 66], "endpoint": [64, 165, 198, 199, 200, 201], "_rewriting_with_numpy_exercis": 64, "i_step": 64, "_using_enumerate_and_indexing_exercis": 64, "_aggregation_video": 64, "_nano_recap_of_aggregation_video": 64, "transpos": [64, 100, 173, 198, 200, 201], "_using_2d_arrays_exercis": 64, "_plotting_sample_mean_and_standard_deviation_exercis": 64, "_overview_video": 64, "repeatedli": [66, 72, 190, 192], "elsewher": [66, 165], "w0d2_t1": 66, "creation": [66, 71, 72, 75, 76, 77, 81, 82], "plot_al": 66, "spikes_mean": 66, "membran": [66, 75, 77, 89, 90, 134, 143, 147, 148, 150, 173], "ax1": [66, 75, 89, 98, 99, 115, 116, 124, 127, 150, 157, 158, 173, 175, 182, 183, 189, 190, 191], "c1": [66, 82, 88, 97, 99, 100, 189], "auto": [66, 98, 117, 118, 124, 126, 127, 134, 141, 164, 166, 175, 191, 192, 201], "sharex": [66, 108, 109, 157, 158, 164, 165, 183], "ones_lik": [66, 108, 141, 165, 199, 200], "hz": [66, 75, 76, 77, 138, 148, 149, 150, 176], "_histograms_video": 66, "t_k": [66, 77, 149], "m_j": 66, "fall": [66, 70, 72, 88, 90, 99, 108, 124, 125, 126, 127, 145, 182], "nbin": 66, "histtyp": [66, 88, 98], "stepfil": [66, 88, 98], "appear": [66, 70, 72, 88, 108, 109, 117, 118, 124, 125, 126, 127, 148, 175, 189, 191, 192, 199], "patch": [66, 70, 125, 126, 127, 164, 173, 176, 201], "edg": [66, 88, 89, 90, 125, 127, 190, 191, 198], "_nano_recap_of_histograms_video": 66, "_plotting_a_histogram_exercis": 66, "_dictionaries_": 66, "_introducing_spikes_video": 66, "geq": [66, 108, 147, 189], "_nano_recap_of_dictionaries_video": 66, "spike_tim": [66, 76, 77, 89, 90, 147], "sharei": [66, 108, 109, 126, 157, 158, 164, 165, 183], "1st": [66, 138, 149, 182], "my_data_left": 66, "my_data_right": 66, "spikes_n": 66, "vm": 66, "_adding_spiking_to_the_lif_neuron_exercis": 66, "_boolean_indexes_video": 66, "itself": [66, 70, 72, 75, 76, 88, 109, 124, 141, 150, 162, 165, 175, 191], "_nano_recap_of_boolean_indexes_video": 66, "v_rest": 66, "__main__": [66, 72, 88, 102, 115, 116, 117, 118, 126, 141, 147, 148, 149, 150, 156, 157, 158, 173], "v_thr": 66, "_using_boolean_indexing_exercis": 66, "v_reset": [66, 76, 77, 147, 148, 149, 150], "_making_a_binary_raster_plot_exercis": 66, "_refractory_period_video": 66, "millisecond": [66, 89, 150], "synapt": [66, 72, 75, 104, 125, 145, 147, 148, 152, 156, 158], "2nd": [66, 71, 76, 77, 138, 182, 190], "biophys": [66, 143, 152, 157, 158], "_nano_recap_of_refractory_period_video": 66, "ref": [66, 147], "lambda": [66, 71, 72, 77, 81, 89, 108, 140, 141, 148, 156, 173, 176], "clamp": [66, 75, 147, 180, 189, 198, 201], "t_ref": 66, "last_spik": 66, "_investigating_refractory_periods_exercis": 66, "random_ref_period": 66, "syn": [66, 148, 149], "_": [66, 70, 71, 72, 75, 76, 77, 81, 82, 89, 90, 97, 98, 101, 115, 116, 117, 124, 127, 138, 139, 147, 148, 149, 150, 156, 158, 166, 172, 174, 175, 176, 182, 183, 189, 192, 198, 199, 200, 201], "_random_refractory_period_interactive_demo": 66, "_functions_video": 66, "_nano_recap_of_functions_video": 66, "spike_clamp": 66, "ode_step": 66, "discret": [66, 77, 82, 88, 90, 134, 138, 140, 147, 148, 149, 150, 156, 157, 158, 165, 166, 168, 172, 173, 174, 175, 183], "delta_spik": 66, "_rewriting_code_with_functions_exercis": 66, "_classes_video": 66, "reliabl": [66, 108, 148, 149, 164, 182], "unimport": 66, "attribut": [66, 88, 124, 125, 126, 127, 164, 189], "_nano_recap_of_classes_video": 66, "lifneuron": 66, "spike_and_clamp": 66, "t_ref_mu": 66, "t_ref_sigma": 66, "histori": [66, 72, 82, 104, 139, 141, 145, 149, 172, 175, 182, 192], "ran": [66, 172, 192], "_making_a_lif_class_exercis": 66, "_last_concepts_": 66, "_recap_video": 66, "butler": [68, 74, 75, 76, 77, 79, 85, 94, 105, 112, 121, 129, 135, 138, 139, 140, 141, 144, 153, 161, 169, 172, 173, 176, 179, 186, 195, 202], "w0d3_daysummari": 68, "_slide": [68, 74, 79], "patient": [69, 70, 72, 80, 87, 96, 107, 114, 123, 131, 137, 146, 155, 163, 171, 174, 181, 188, 197], "delai": [69, 80, 87, 88, 96, 107, 114, 123, 131, 137, 141, 146, 148, 155, 163, 171, 181, 188, 189, 191, 197], "redirect": [69, 80, 87, 96, 107, 114, 123, 131, 137, 146, 155, 163, 171, 181, 188, 197], "keith": [70, 71, 77, 81, 82, 172], "antwerp": [70, 71, 81, 82, 172], "siddharth": [70, 71, 115, 116, 117, 118, 156, 157, 158], "suresh": [70, 71, 115, 116, 117, 118, 156, 157, 158], "geometr": [70, 71, 100, 116], "w0d3_t1": 70, "fix": [70, 71, 81, 82, 90, 97, 98, 99, 100, 127, 147, 148, 149, 154, 157, 165, 173, 174, 175, 182, 183, 189, 190, 198, 199, 200, 202], "fancyarrowpatch": 70, "mpl_toolkit": [70, 71, 75, 108, 198, 201], "mplot3d": [70, 71, 75], "proj3d": 70, "visualize_vector": 70, "v_unit": 70, "aesthet": 70, "set_color": [70, 71, 72, 75, 109, 150], "set_posit": [70, 71, 72, 75, 182], "zorder": [70, 72, 108, 126, 127, 140, 148, 149, 150, 156, 158, 165, 175, 182], "v_arr": 70, "648fff": [70, 72], "length_includes_head": [70, 71, 72, 138, 198, 199, 200, 201], "v_unit_arr": 70, "dc267f": [70, 72], "leg": [70, 72], "tild": [70, 102, 124, 126, 127, 166], "handlelength": [70, 72, 157, 158], "fontsiz": [70, 71, 72, 75, 109, 140, 148, 149, 150, 156, 157, 173, 176, 182, 183, 198, 200], "upper": [70, 75, 77, 81, 88, 90, 108, 126, 127, 165, 172, 173, 174, 182, 183, 192, 198], "handl": [70, 72, 84, 89, 99, 102, 120, 176, 191, 192, 201], "legendhandl": [70, 72], "get_facecolor": [70, 72], "arrow3d": 70, "xs": [70, 88], "ys": [70, 88], "zs": 70, "kwarg": [70, 71, 89, 147, 148, 149, 150, 156, 157, 158], "_verts3d": 70, "xs3d": 70, "ys3d": 70, "zs3d": 70, "proj_transform": 70, "do_3d_project": 70, "_why_do_we_care_about_linear_algebra_video": 70, "_vector_definition_": 70, "_properties_video": 70, "bmatrix": [70, 71, 72, 100, 109, 124, 126, 127, 158, 173, 175, 198, 200], "_i": [70, 72, 82, 97, 100, 109, 116, 126, 148, 157, 158, 166], "x_1": [70, 71, 81, 82, 90, 98, 100, 115, 138, 140, 141, 198], "x_2": [70, 71, 81, 82, 90, 100, 115, 138, 141, 198], "x_3": [70, 71, 82, 90, 198], "normalize_vector": 70, "input_vector": 70, "n_dim": 70, "linalg": [70, 71, 72, 82, 100, 101, 102, 108, 116, 117, 138, 139, 141, 158, 175, 198, 199, 200, 201], "vector_length": 70, "normalized_vector": 70, "_normalizing_vectors_exercis": 70, "_linear_combinations_of_vectors_video": 70, "180": [70, 115, 125, 126, 127, 147], "_1": [70, 72, 124, 138, 141, 172, 175, 200], "vdot": [70, 100, 126, 127], "_n": [70, 100], "stack": [70, 100, 101, 102, 115, 125, 126, 139, 173, 176, 191, 198], "tail": [70, 71, 190], "essenc": [70, 101, 165], "parallelogram": 70, "4th": [70, 71], "vertex": 70, "c_1": [70, 72], "c_2": [70, 72], "fraction": [70, 72, 88, 117, 127, 139, 148, 149, 174, 182, 200, 201], "slider": [70, 72, 75, 81, 82, 88, 89, 90, 97, 115, 116, 117, 138, 157, 164, 172, 173, 174, 182, 183, 189, 200], "releas": [70, 72, 149], "coupl": [70, 72, 77, 82, 90, 149, 156, 157, 158, 165], "desir": [70, 72, 81, 115, 116, 165, 172, 180, 192, 201], "plot_arrow": [70, 72], "a_times_x": [70, 72], "b_times_i": [70, 72], "set_aspect": [70, 71, 72, 124, 126, 127, 166, 174, 183, 198, 199, 200, 201], "xticklabel": [70, 72, 108, 164], "yticklabel": [70, 72, 164], "z_arr": [70, 72], "x_orig": [70, 72], "y_orig": [70, 72], "ax_arr": [70, 72], "by_arr": [70, 72], "bbox_to_anchor": [70, 72, 75, 126, 172, 173], "get_color": [70, 72], "floatslid": [70, 72, 76, 77, 81, 88, 97, 98, 115, 138, 147, 149, 150, 156, 157, 158, 164, 165, 172, 173, 174, 175, 182, 183, 189, 190], "plot_linear_combin": [70, 72], "shorter": [70, 77, 88, 89, 90, 139, 183, 199], "_linear_combinations_of_vectors_interactive_demo": 70, "35": [70, 71, 88, 89, 90, 100, 101, 109, 115, 118, 120, 126, 140, 148, 149, 157, 164, 165, 173, 192], "_span_and_linear_independence_video": 70, "rm": [70, 147, 148, 149, 150, 156, 158, 173, 174, 175, 182], "written": [70, 72, 76, 77, 81, 82, 100, 124, 125, 138, 139, 140, 141, 156, 157, 166, 174, 189, 199], "111": [70, 75, 84, 120, 158, 166, 174, 191], "mutation_scal": 70, "lw": [70, 71, 88, 109, 147, 149, 150, 156, 158, 173, 174], "arrowstyl": [70, 138], "add_artist": 70, "785ef0": 70, "ffb000": 70, "zlim": 70, "zlabel": [70, 75, 100], "o\u011ful": 70, "yurdakul": 70, "www": [70, 76, 77, 93, 111, 120, 124, 125, 126, 127, 134, 160, 178, 201], "geogebra": 70, "hherq78z": 70, "plane": [70, 71, 75, 100, 154, 156], "_determing_dependence_discuss": 70, "_basis_vectors_video": 70, "tradit": 70, "applic": [70, 76, 77, 99, 106, 111, 122, 125, 130, 134, 141, 143, 157, 158, 172, 173, 174, 175, 180, 194, 198, 201], "unwieldi": 70, "though": [70, 71, 72, 88, 89, 90, 97, 101, 102, 109, 124, 127, 139, 149, 150, 162, 165, 172, 175, 182, 183, 189, 190, 199], "unusu": [70, 108], "tightli": 70, "subspac": 70, "r3": 70, "xx": [70, 98, 100, 108, 125, 126, 127, 141, 165], "yy": [70, 98, 100, 125, 126, 127, 141, 165], "meshgrid": [70, 71, 75, 125, 126, 127, 138, 157, 158, 164], "plot_surfac": [70, 75, 100], "invert_xaxi": 70, "lie": [70, 71, 72, 140, 157], "_figuring_out_a_basis_discuss": 70, "hr": [70, 109, 124, 164], "_the_dot_product_video": 70, "retin": [70, 71, 72, 100, 104, 120], "synaps": [70, 134, 145, 148, 198], "dot_prod": 70, "r_1": [70, 71, 124], "r_2": [70, 71, 124], "circuit": [70, 104, 125, 149, 150, 152], "w_1r_1": 70, "w_2r_2": 70, "heatmap": [70, 82, 108, 124, 127, 191, 192, 198, 199, 200], "combo": 70, "highest": [70, 82, 90, 100, 127, 164, 165, 190], "postsynapt": [70, 143, 147, 148, 149], "minim": [70, 71, 82, 97, 98, 99, 100, 108, 117, 124, 126, 127, 166, 182, 183], "x_vec": 70, "y_vec": 70, "n_pixel": 70, "coord1": 70, "coord2": 70, "circle_mask": 70, "coord_i": 70, "coord_j": 70, "mask": [70, 175], "plot_heatmap": 70, "masked_x": 70, "masked_i": 70, "outer": 70, "im": [70, 82, 98, 125, 127, 189, 191, 192, 198, 199, 200, 201], "bwr": [70, 125, 127], "cbar": [70, 82, 124, 126, 127, 166, 198, 199], "colorbar": [70, 72, 75, 82, 98, 108, 117, 118, 124, 125, 126, 127, 166, 189, 191, 192, 198, 199, 200, 201], "set_label": [70, 166], "rotat": [70, 71, 72, 76, 77, 82, 115, 126, 157, 158, 165, 174, 198, 199], "270": 70, "labelpad": [70, 138, 139, 174, 198, 199], "set_label_coord": [70, 182], "fr_arr": 70, "40b0a6": 70, "we_arr": 70, "frameon": [70, 150, 165], "description_width": [70, 164], "neuron1_fir": 70, "neuron2_fir": 70, "firing_r": 70, "maximi": 70, "mimim": 70, "perpendicular": 70, "grow": [70, 71, 76, 122, 138, 140, 156, 158], "bigger": [70, 76, 109, 124, 138, 147, 150, 182, 199], "_lgn_firing_interactive_demo": 70, "_the_geometry_of_the_dot_product_video": 70, "largest": [70, 77, 100, 190, 198, 201], "smallest": [70, 75, 100], "axiom": 70, "cd": 70, "mostli": [70, 82, 108, 109, 126, 130, 138, 149, 175, 194, 198, 200], "p_3": [70, 81], "c_o": 70, "c_1x": 70, "c_2x": 70, "c_3x": 70, "c_0": 70, "c_3": 70, "obei": [70, 139], "prove": [70, 101, 172], "law": [70, 149], "cosin": [70, 127], "formula": [70, 71, 75, 77, 81, 82, 90, 102, 126, 127, 140, 148, 165, 172, 198], "subtract": [70, 75, 115, 116, 117, 124, 126], "aderogba": [71, 75], "bayo": [71, 75], "openedx": 71, "sea": [71, 178], "gwu": 71, "gw": 71, "engcomp4": 71, "plot_linear_transform": 71, "licens": 71, "bsd": 71, "claus": 71, "lorena": 71, "barba": 71, "tingyu": 71, "IS": 71, "BY": 71, "THE": 71, "copyright": 71, "holder": 71, "contributor": 71, "AS": 71, "warranti": 71, "TO": [71, 117, 118, 124, 126, 127, 173], "OF": [71, 76, 77], "merchant": 71, "FOR": 71, "IN": 71, "NO": 71, "shall": [71, 100, 158], "BE": 71, "liabl": 71, "indirect": [71, 165], "incident": 71, "exemplari": 71, "consequenti": 71, "damag": 71, "procur": 71, "servic": 71, "profit": 71, "interrupt": [71, 175], "ON": [71, 108], "liabil": 71, "contract": 71, "strict": 71, "tort": 71, "neglig": 71, "IF": 71, "advis": 71, "SUCH": 71, "w0d3_t2": 71, "inv": [71, 72, 100, 101, 102, 108, 175], "eig": [71, 72, 138, 139, 156, 158], "ticker": [71, 189], "get_backend": 71, "rc": 71, "axes3d": [71, 75], "cycl": [71, 138, 176], "_int_backend": 71, "gtk3agg": 71, "gtk3cairo": 71, "macosx": 71, "nbagg": 71, "qt4agg": 71, "qt4cairo": 71, "qt5agg": 71, "qt5cairo": 71, "tkagg": 71, "tkcairo": 71, "webagg": 71, "wx": 71, "wxagg": 71, "wxcairo": 71, "_backend": 71, "backend": [71, 75], "shrink": [71, 109, 174, 198, 199], "fig_scal": 71, "808080": 71, "gold": [71, 84, 97, 164, 199], "cab18c": 71, "lightblu": 71, "0096d6": 71, "008367": 71, "red": [71, 75, 77, 81, 82, 89, 98, 115, 116, 117, 138, 149, 150, 156, 157, 164, 165, 172, 173, 174, 182, 183, 192], "e31937": 71, "darkblu": 71, "004065": 71, "pink": [71, 124, 127], "yellow": [71, 75, 77, 174, 192], "brown": [71, 104, 134, 148, 160, 194], "ef7b9d": 71, "fbd349": 71, "ffa500": 71, "a35cff": 71, "731d1d": 71, "quiver_param": 71, "xy": [71, 157, 158, 164, 165], "scale_unit": [71, 157, 158], "grid_param": 71, "set_rc": 71, "func": [71, 157, 158], "wrapper": [71, 199, 200, 201], "serif": 71, "dpi": 71, "axisbelow": 71, "titles": [71, 75], "plot_vector": 71, "assert": [71, 164, 165, 172, 173, 198, 199, 200, 201], "zeros_lik": [71, 81, 82, 138, 139, 140, 141, 156, 165, 166, 172, 175, 190], "tile": [71, 125, 166, 173, 176, 191, 192], "nvector": 71, "ntail": 71, "xlimit": [71, 117], "ylimit": 71, "hstack": [71, 82, 100, 101, 102, 176], "quiver": [71, 157, 158, 191, 192], "finer": [71, 72], "get_xtick": [71, 189], "get_ytick": 71, "dy": [71, 75, 77], "multipleloc": 71, "set_major_loc": [71, 108, 189], "hide": [71, 72], "plot_transformation_help": 71, "unit_vector": 71, "unit_circl": 71, "helper": [71, 82, 88, 98, 99, 108, 115, 138, 140, 147, 156, 173, 191, 198], "2x2": [71, 138, 158, 164], "bool": [71, 172, 173], "circl": [71, 77, 157, 158], "grid_rang": 71, "x_": [71, 77, 97, 99, 100, 101, 108, 138, 140, 141, 176, 198, 199, 200, 201], "y_": [71, 77, 97, 99, 101, 176, 201], "color_cycl": 71, "vector_": 71, "41": [71, 120, 192], "vstack": [71, 139, 141], "circle_tran": 71, "set_linewidth": [71, 109, 189], "axis1": 71, "axis2": 71, "plot_eig_vec_transform": 71, "vec_nam": 71, "vec": [71, 72, 158, 198, 199, 200, 201], "prop_cycl": [71, 72], "by_kei": [71, 72], "i_vec": 71, "head_width": [71, 138, 198, 199, 200, 201], "facecolor": [71, 75, 99, 157, 158, 164, 173, 176, 183], "edgecolor": [71, 75, 174], "transformed_vec": 71, "matmul": [71, 116, 117], "_systems_of_equations_video": 71, "3x_1": 71, "2x_2": 71, "y_1": [71, 77, 98, 124, 165], "7x_1": 71, "2x_3": 71, "y_2": [71, 124, 165], "y_3": 71, "appeal": 71, "cast": 71, "lgn": [71, 72], "dictat": [71, 139, 147, 165], "g_": [71, 149, 150, 174, 183, 189], "p_1": [71, 77, 81, 127], "p_2": [71, 81, 127], "3r_2": 71, "2r_1": 71, "_p": [71, 124], "g_p": 71, "q": [71, 143, 165, 175, 183, 190], "invert": [71, 82, 109, 200], "g_q": 71, "_understanding_neural_transformations_exercis": 71, "_linear_transformations_video": 71, "enact": 71, "manner": [71, 106, 147, 149], "straight": [71, 77, 117], "flip": [71, 116, 117, 140, 141, 190], "bar": [71, 75, 82, 100, 101, 102, 116, 125, 126, 139, 148, 149, 150, 164, 174, 183, 190], "_creating_matrices_for_transformations_exercis": 71, "_rank_": 71, "_null_space_video": 71, "li": [71, 72, 100, 108, 120, 147, 148, 149, 150, 156, 157, 158, 176], "aren": [71, 124, 164, 165, 190], "intrins": [71, 117, 178], "squish": 71, "pair": [71, 98, 106, 111, 118, 124, 126, 127, 138, 141, 148, 150, 157, 158, 164, 165, 189, 191, 192, 198, 201], "lose": [71, 116, 164], "_neural_coding_discuss": 71, "_eigenstuff_video": 71, "infinit": [71, 81, 109, 124, 164, 165, 183], "jog": 71, "expans": 71, "vertic": [71, 75, 77, 82, 89, 117, 125, 126, 127], "neither": [71, 140, 165], "_identifying_transformations_from_eigenvectors_discuss": 71, "_matrix_multiplication_video": 71, "pen": [71, 164], "wr": 71, "matrix1": 71, "matrix2": 71, "_computation_corner_exercis": 71, "interconnect": [72, 198], "explod": [72, 156, 174, 183], "w0d3_bonu": 72, "plot_circuit_respons": 72, "cs": [72, 185], "textz": 72, "tracker_text": 72, "transax": [72, 127], "eigval": 72, "eigvec": 72, "lc1": 72, "lc2": 72, "cm": [72, 124, 125, 126, 127, 138, 164, 166], "coolwarm": [72, 100, 108, 198, 199, 200, 201], "a_1": [72, 198, 201], "a_2": 72, "scalarmapp": 72, "get_eigval_specified_matrix": 72, "target_eig": 72, "unless": [72, 165], "distinct": [72, 118, 165, 176, 183], "diag": [72, 176], "bc": 72, "squeez": [72, 108, 109, 125, 127, 176], "_a_neural_circuit_video": 72, "subscript": [72, 98, 149], "a_": [72, 138, 150, 157, 158, 176, 182, 183, 189, 190, 191, 198], "w_": [72, 77, 127, 157, 158, 174], "chop": 72, "weird": [72, 182], "faithfulli": 72, "symmetr": [72, 81, 89, 115, 116, 126, 165, 172], "mess": [72, 201], "luckili": [72, 75, 100, 102, 165, 200], "concern": [72, 75, 98, 148, 150], "quantiti": [72, 81, 124, 126, 127, 149, 150, 165, 187, 189], "unsurprisingli": 72, "embrac": 72, "tomorrow": [72, 140, 164], "w2d2": [72, 76, 145, 154], "circuit_implement": 72, "_0": [72, 138, 175, 198, 200], "a0": 72, "i_t": [72, 198], "u0": [72, 149], "_implementing_the_circuit_exercis": 72, "infin": [72, 76, 165, 174, 183], "incred": 72, "115": [72, 75, 120, 178], "31": [72, 120, 148, 190, 191, 192, 201], "a_i": [72, 157, 158, 176], "ia_0": 72, "a_0": [72, 198, 199, 200, 201], "_looking_at_activity_along_an_eigenvector_video": 72, "rewrit": [72, 108, 117, 156, 157, 158, 172], "subsitut": 72, "subsequ": [72, 126], "plot_system": 72, "activit": 72, "jump": [72, 127, 138, 173, 191, 199], "_changing_the_eigenvalue_interactive_demo": 72, "_understanding_general_dynamics_using_eigenstuff_video": 72, "lambda_1": 72, "lambda_2": 72, "a0_1": 72, "a0_2": 72, "eigenvalue1": 72, "eigenvalue2": 72, "lag": [72, 108, 148, 200, 201], "update_rang": 72, "drawn": [72, 81, 82, 98, 124, 127, 140, 172, 173, 174, 183, 190], "increasingli": [72, 81, 125, 202], "domin": [72, 88, 148, 149, 165], "_changing_both_eigenvalues_interactive_demo": 72, "until": [72, 89, 102, 125, 140, 149, 172, 174, 175, 189, 191], "proof": [72, 120, 191], "sustain": 72, "_t": [72, 174, 175, 182, 183, 198, 200, 201], "takeawai": [72, 199, 201], "whose": [72, 75, 81, 90, 116, 124, 126, 127, 140, 149, 174, 191], "w0d4_daysummari": 74, "tessi": [75, 76], "tom": [75, 76], "matthew": [75, 76, 77, 138, 139, 140, 141, 147, 148, 149, 150, 189, 190, 191, 192], "rusti": 75, "w0d4_t1": 75, "sp": [75, 81, 82, 147, 149], "rendr": 75, "my_layout": [75, 76, 77, 147, 148, 149, 150], "my_fonts": 75, "my_param": 75, "labels": [75, 182, 198, 199], "move_sympyplot_to_ax": 75, "process_seri": 75, "plot_funct": [75, 109, 174], "show_deriv": 75, "show_integr": 75, "2t": [75, 172], "parabol": 75, "diff_f": 75, "p1": [75, 172, 173], "line_color": 75, "int_f": 75, "plot_alpha_func": 75, "df_dt": 75, "au": 75, "plot_charge_transf": 75, "psp": [75, 149], "numerical_integr": 75, "_why_do_we_care_about_calculus_video": 75, "_a_geometrical_interpretation_of_differentiation_and_integration_video": 75, "eigenfunct": 75, "contin": [75, 165], "slight": [75, 82, 190, 191], "distanc": [75, 81, 118, 165, 182], "travel": [75, 81], "vehicl": 75, "decreas": [75, 76, 77, 88, 89, 90, 109, 115, 116, 117, 127, 138, 147, 149, 150, 158, 176, 182], "different": 75, "5t": 75, "4t": 75, "function_opt": 75, "dropdown": [75, 127, 138, 165], "checkbox": [75, 149, 164, 173, 174], "on_value_chang": 75, "eigenvector": [75, 117, 139], "imagin": [75, 81, 82, 100, 109, 115, 127, 149, 150, 165, 172, 173, 174, 190, 192, 198, 201], "_geometrical_understanding_interactive_demo": 75, "_differentiation_video": 75, "trusti": 75, "friend": 75, "wikipedia": 75, "site": [75, 182], "nt": [75, 108], "me": 75, "3t": 75, "du": [75, 149], "dv": [75, 76, 77, 89, 147, 148, 149, 150], "u_t": 75, "v_t": [75, 183], "du_dt": 75, "dv_dt": 75, "_derivative_of_the_postsynaptic_potential_alpha_function_exercis": 75, "dr": [75, 106, 149, 156, 157, 158, 175, 189], "da": [75, 176], "expon": [75, 90], "4a": [75, 141], "3e": 75, "_chain_rule_math_exercis": 75, "hood": 75, "fd": 75, "rightarrow": [75, 77, 98, 109, 126, 139, 150, 157, 158, 173], "accur": [75, 77, 101, 113, 127, 134, 138, 141, 148, 164, 166, 174, 175, 182, 183, 200], "numerical_derivative_demo": 75, "tx": 75, "sine_fun": 75, "diffrenti": 75, "cos_fun": 75, "n_tx": 75, "n_sine_fun": 75, "sine_diff": 75, "ncol": [75, 89, 90, 97, 98, 99, 108, 173, 174, 175, 190, 191, 192], "fancybox": 75, "_numerical_differentiation_of_the_sine_function_interactive_demo": 75, "34": [75, 77, 120, 172, 178, 199], "inject": [75, 147, 148, 149, 156, 158, 198, 201], "dc": [75, 108, 149], "eta": [75, 140, 141, 147, 156, 175, 201], "visit": [75, 81], "timestep": [75, 77, 89, 138, 139, 175, 183, 189, 198, 199, 200, 201], "compute_rate_and_gain": 75, "current_timestep": 75, "plot_rate_and_gain": 75, "i_1": [75, 148], "rate_1": 75, "i_2": [75, 148], "rate_2": 75, "input_rang": 75, "output_rang": 75, "ital": 75, "bbox": [75, 173], "pad": [75, 108, 125, 126, 127, 164, 198, 200, 201], "leftward": [75, 172], "steep": 75, "steeper": [75, 158], "therefor": [75, 81, 88, 97, 99, 108, 122, 124, 125, 126, 127, 139, 148, 149, 150, 156, 157, 158, 164, 165, 166, 183, 191, 192, 200], "_calculating_the_transfer_function_and_gain_of_a_neuron_interactive_demo": 75, "44": [75, 178], "_functions_of_multiple_variables_video": 75, "inhibitori": [75, 77, 90, 152, 154, 158], "derriv": 75, "multivari": [75, 100, 116, 117, 124, 201], "2xy": 75, "2y": 75, "curvi": 75, "f2d_string": 75, "plot_partial_deriv": 75, "f2d": 75, "f2d_dx": 75, "f2d_dy": 75, "plot3d": 75, "p2": 75, "p3": 75, "jacobian": [75, 157], "_visualize_partial_derivatives_interactive_demo": 75, "_numerical_integration_video": 75, "wish": [75, 97, 100, 149, 172, 201], "rectangl": [75, 176], "approcah": 75, "cut": [75, 81], "stripe": 75, "downsid": 75, "underestim": 75, "overestim": 75, "riemann_sum_demo": 75, "step_siz": [75, 81], "min_val": [75, 176], "max_val": [75, 176], "ftn": 75, "int_ftn": 75, "r_tx": 75, "fun_valu": 75, "r_sum": 75, "cumsum": [75, 117, 139, 140, 165, 172, 176, 183], "lebesgu": 75, "rung": 75, "kutta": 75, "_riemann_sum_vs_analytical_integral_with_changing_step_size_interactive_demo": 75, "68": [75, 88, 149, 164], "incom": [75, 89, 149, 174], "elicit": [75, 149, 150], "tau_": [75, 77, 147, 149, 150, 156, 157, 158], "t_sp": [75, 148, 149, 150], "rectangle_area": 75, "_calculating_charge_transfer_with_excitatory_input_exercis": 75, "_filtering_operations_video": 75, "consequ": [75, 149, 164, 165, 174, 175, 183], "akin": 75, "shock": 75, "absorb": 75, "noise_sign": 75, "wave": 75, "x1_diff": 75, "x1_integr": 75, "sec": [75, 147, 148], "0x7f78d4df0b50": 75, "amplifi": [75, 154], "suppress": [75, 147, 152, 154], "smooth": [75, 88, 90, 100, 126, 127, 138, 189], "easili": [75, 82, 97, 100, 122, 124, 126, 164, 173, 175, 190], "took": [75, 164, 166, 174, 190, 191], "tradeoff": [75, 102, 109, 190], "trough": 75, "smoothen": [75, 147], "enhanc": 75, "inhibit": [75, 77, 86, 148, 149, 154, 157], "sigmoid_funct": 75, "exc_input": 75, "inh_input": 75, "exc_a": 75, "exc_theta": 75, "inh_a": 75, "inh_theta": 75, "jj": 75, "lg_txt": 75, "ax2": [75, 89, 98, 99, 115, 116, 124, 127, 150, 157, 158, 173, 174, 175, 182, 189, 190, 191], "ax3": [75, 115, 116, 190], "surf": 75, "rstride": 75, "cstride": 75, "viridi": 75, "set_zlabel": 75, "expectedli": 75, "downward": 75, "tediou": [75, 108, 138], "plot_2d_neuron_transfer_funct": 75, "rate_d": 75, "rate_di": 75, "surf1": 75, "exc": [75, 89, 149, 158], "inh": [75, 89, 149], "view_init": 75, "xde": 75, "yde": 75, "surf2": 75, "wrt": 75, "xdi": 75, "ydi": 75, "surf3": 75, "notch": 75, "ridg": [75, 109], "driv": 75, "_numerical_partial_derivatives_bonus_discuss": 75, "rebecca": 76, "bradi": 76, "gate": 76, "blood": 76, "nobel": 76, "prize": 76, "hodgkin": [76, 134], "huxlei": [76, 134], "axon": [76, 143], "paradox": [76, 152, 158], "mc": [76, 77], "escher": 76, "paint": 76, "motiv": [76, 77, 88, 106, 202], "raster": [76, 77, 148, 150, 176], "breakdown": 76, "w0d4_t2": 76, "ipd": [76, 77], "gridspec": [76, 77, 164, 183], "plot_dpdt": 76, "birth": [76, 77, 201], "gs": [76, 77, 115, 116, 164, 183], "dpdt": 76, "fucntion": 76, "plot_v_no_input": 76, "v_rang": 76, "dvdt": 76, "hline": [76, 77, 82, 165], "linestyl": [76, 77, 89, 108, 109, 150, 165, 172, 173, 174, 183, 191, 192], "vline": [76, 77, 89, 97, 98, 165, 182], "mv": [76, 77, 147, 148, 149, 150], "95": [76, 99, 134, 140, 143, 148, 166, 182, 183], "plot_if": [76, 77], "height_ratio": [76, 77, 189], "na": [76, 77, 200], "plot_dvdt": 76, "85": [76, 152, 176, 183, 192], "g_l": [76, 147, 148, 149], "exact_integrate_and_fir": 76, "v_exact": 76, "t_isi": [76, 77], "v_th": [76, 77, 147, 148, 149, 150], "_why_do_we_care_about_differential_equations_video": 76, "_population_differential_equation_video": 76, "dp": [76, 77, 176], "_interpretating_the_behavior_of_a_linear_population_equation_discuss": 76, "obscur": 76, "p_0": [76, 77], "declin": 76, "asid": [76, 126], "mathematician": [76, 77], "taunt": 76, "3p": 76, "generaliz": 76, "countri": 76, "transit": [76, 82, 138, 154, 173, 175, 176, 183, 189, 191, 192], "450px": [76, 77, 147, 149], "pop_widget": [76, 77], "stabl": [76, 77, 102, 138, 152, 157, 158, 183, 201], "_parameter_change_interactive_demo": 76, "simplif": [76, 89], "pronounc": 76, "growth": [76, 77, 88, 138], "extern": [76, 77, 106, 127, 147, 148, 149, 150, 152, 157, 158], "weather": 76, "predat": [76, 127], "prei": [76, 174], "_the_leaky_integrate_and_fire_model_video": 76, "loui": [76, 147], "\u00e9douard": [76, 147], "lapicqu": [76, 77, 143, 147], "1907": [76, 77, 143, 147], "subthreshold": [76, 147], "r_mi": [76, 77], "r_m": [76, 77, 89], "minu": [76, 108, 126, 127, 165], "_effect_of_membrane_potential_interactive_demo": 76, "91": [76, 100, 117], "61": [76, 127, 152, 191, 192], "v_reset_widget": 76, "75mv": 76, "_initial_condition_vreset_interactive_demo": 76, "biolig": 76, "_the_impact_of_input_interactive_demo": 76, "t_rest": 76, "_adding_firing_to_the_lif_video": 76, "plateau": 76, "isi": [76, 86, 89, 149], "\ud835\udc46\ud835\udc5d\ud835\udc56\ud835\udc58\ud835\udc52": 76, "discontinu": [76, 77], "eleg": [76, 77, 106], "electrophysiologist": [76, 77], "refractori": [76, 88, 147, 148, 149, 150, 198], "_input_on_spikes_interactive_demo": 76, "38": [76, 88, 147, 149, 164], "exectur": 76, "fi": 76, "i_rang": 76, "spike_r": [76, 149], "weak": [76, 82, 156, 165, 172, 190], "_summary_video": [76, 77, 82, 198, 199, 201], "lotka": [76, 77], "1920": [76, 77], "rhythmic": [76, 77], "inorgan": [76, 77], "410": [76, 77], "415": [76, 77, 152], "brunel": [76, 77, 143, 152, 154], "rossum": [76, 77, 143], "frog": [76, 77, 143], "cybern": [76, 77], "dec": [76, 77], "97": [76, 77, 99, 104, 134, 143], "337": [76, 77, 134, 143], "1007": [76, 77, 84, 104, 134, 143, 178, 194], "s00422": [76, 77, 134, 143], "0190": [76, 77, 143], "epub": [76, 77], "oct": [76, 77], "pmid": [76, 77], "17968583": [76, 77], "2001": [76, 77, 86, 120, 134, 178], "strogatz": [76, 77], "chao": [76, 77, 152], "chemistri": [76, 77], "westview": [76, 77], "press": [76, 77, 84, 88, 93, 104, 120, 134, 143, 152, 160, 178, 185, 189, 194], "lindsai": [76, 77, 120, 152], "bloomsburi": [76, 77], "2004": [76, 77, 93, 104, 108, 143, 149], "sync": [76, 77, 173, 174], "emerg": [76, 77, 84, 120, 134, 148, 191, 196], "penguin": [76, 77], "uk": [76, 77, 93, 104, 120, 160], "joi": [76, 77], "quantamagazin": [76, 77], "tag": [76, 77, 172, 173, 183], "quanta": [76, 77], "magazin": [76, 77], "harvei": [77, 104], "mccone": 77, "70": [77, 117, 164, 189], "odd": [77, 81, 125, 126, 173], "mysteri": 77, "w0d4_t3": 77, "plot_slop": 77, "og": 77, "plot_stepeul": 77, "bo": [77, 147, 148, 150, 156, 157], "t_1": [77, 138, 174], "e_1": 77, "visualize_population_approx": 77, "e_k": 77, "plot_reri": 77, "r_e": [77, 149, 156], "r_i": [77, 126, 158], "plot_reri_simpl": 77, "plot_reri_matrix": 77, "null_r": 77, "null_ri": 77, "_intro_to_numerical_methods_for_differential_equations_video": 77, "leonhard": 77, "1707": 77, "1783": 77, "t_0": [77, 138, 139], "y_0": [77, 175], "_slope_of_a_line_interactive_demo": 77, "p_0e": 77, "pretti": [77, 89, 95, 99, 115, 117, 141, 166, 198, 199, 201], "rearrang": [77, 115, 183], "henc": [77, 81, 82, 150, 172, 198], "_euler_error_of_single_step_interactive_demo": 77, "_taking_more_steps_video": 77, "segment": [77, 97], "t_2": [77, 138], "t_3": 77, "t_4": 77, "times1": 77, "_step_step_step_exercis": 77, "_leaky_integrate_and_fire_video": 77, "v_k": 77, "euler_integrate_and_fir": 77, "esitm": 77, "_lif_and_euler_exercis": 77, "_systems_of_differential_equations_video": 77, "grip": 77, "regul": [77, 178, 199], "dr_e": [77, 149, 158], "ee": [77, 157, 158], "ei": [77, 157, 158], "tau_i": [77, 157, 158], "dr_i": [77, 158], "ie": [77, 108, 149, 156, 157, 158, 183, 201], "excitatori": [77, 89, 90, 152, 154, 158], "timescal": [77, 134, 138, 150, 156, 157, 158, 174, 198, 199, 200, 201], "120": [77, 108, 127, 150], "100m": 77, "120m": 77, "01m": 77, "r_": [77, 89, 148, 156, 189, 190], "euler_simple_linear_system": 77, "_euler_on_a_simple_system_exercis": 77, "_simple_euler_solution_to_the_wilson_cowan_model_discuss": 77, "orbit": 77, "prefer": [77, 91, 102, 109, 127, 189, 190], "benefit": [77, 82, 182, 192, 201], "_discuss_the_plots_discuss": 77, "57": [77, 84, 157, 158, 192], "re_": 77, "re_k": 77, "ri_k": 77, "ri_": 77, "re_0": 77, "ri_0": 77, "willson": 77, "euler_linear_system_matrix": 77, "w_ee": 77, "n_er": 77, "dre": [77, 156, 157, 158], "n_ir": 77, "dri": [77, 157, 158], "w_ei": 77, "w_ie": 77, "w_ii": 77, "uncontrol": 77, "spiral": 77, "_oscillations_discuss": 77, "62": [77, 152, 191, 192], "maintain": [77, 89, 140, 175, 183], "_small_change_changes_everything_interactive_demo": 77, "k_1": 77, "y_k": 77, "k_2": 77, "k_3": 77, "k_4": 77, "tk_3": 77, "2k_2": 77, "2k_3": 77, "p_": [77, 82, 166, 172, 173, 176, 182], "rk4": 77, "t_fine": 77, "prk4": 77, "k1": [77, 117], "k2": [77, 117], "k3": 77, "k4": 77, "ro": [77, 81, 150, 157], "entre": 77, "constitut": [77, 196], "essai": [77, 84], "dowl": 77, "florencia": 77, "assaneo": 77, "omega": 77, "x_k": [77, 140, 141], "x_0": [77, 108, 138, 140, 141, 198], "plot_stuart_landa": 77, "width_ratio": [77, 108, 183], "euler_stuart_landau": 77, "lamba": 77, "doell": 77, "perfectli": [77, 126, 182], "lamda": 77, "_oscillator_bonus_interactive_demo": 77, "4hz": 77, "freq": 77, "flash": 77, "50hz": 77, "_stuart_landau_system_bonus_interactive_demo": 77, "e3001234": 77, "pbio": 77, "3001234": 77, "gadget": 79, "w0d5_daysummari": 79, "ulrik": [81, 82], "beierholm": [81, 82], "hyosub": [81, 82, 164, 165], "kim": [81, 82, 134, 164, 165], "previous": [81, 82, 90, 99, 108, 109, 118, 149, 158, 180, 182, 192], "w0d5_t1": 81, "hbox": [81, 82, 164, 165, 173, 174, 176], "vbox": [81, 82, 164, 165, 173, 174, 176], "interact_manu": [81, 82, 190], "plot_random_sampl": 81, "figtitl": [81, 82, 138], "datax": 81, "datai": 81, "plot_random_walk": 81, "plot_hist": [81, 82], "num_bin": [81, 82], "my_plot_singl": 81, "px": [81, 82, 164], "c2": [81, 82, 88, 189], "plot_gaussian_samples_tru": [81, 82], "xspace": [81, 82], "num_sampl": [81, 82, 172], "densiti": [81, 82, 98, 138, 165, 166, 174], "_stochastic_world_video": 81, "bound": [81, 82, 90, 140, 150, 156, 175], "generate_random_sampl": 81, "num_point": [81, 82, 173], "uniformli": [81, 90, 100, 138, 139, 148, 149, 150, 176, 182], "_create_randomness_exercis": 81, "although": [81, 108, 139, 140, 149], "smoothli": [81, 88, 90], "gen_and_plot_random_sampl": 81, "selectionslid": 81, "_random_sample_generation_from_uniform_distribution_interactive_demo": 81, "_random_walk_video": 81, "rat": [81, 82, 134, 172], "generate_random_walk": 81, "enclos": 81, "num_step": 81, "random_x_step": 81, "random_y_step": 81, "restrict": [81, 88, 124, 148, 164, 165, 183], "_modeling_a_random_walk_exercis": 81, "arena": 81, "intslid": [81, 82, 89, 90, 109, 157, 173, 174, 175, 189, 190, 200], "gen_and_plot_random_walk": 81, "_varying_parameters_of_a_random_walk_interactive_demo": 81, "nevertheless": 81, "preview": [81, 82], "_binomial_distribution_video": 81, "bernoulli": [81, 109, 126, 141, 201], "thankfulli": 81, "maze": [81, 82, 191], "food": [81, 82, 127, 140, 182, 189], "mutual": [81, 165, 182], "exclus": [81, 182, 198], "binom": 81, "coeffici": [81, 100, 109, 115, 124, 126, 127, 141, 147, 148, 165, 175, 198, 199, 200, 201], "mass": [81, 164], "sum_k": [81, 149], "n_sampl": [81, 82, 97, 98, 99, 100, 101, 102, 109, 118], "visualis": 81, "left_turn_samples_1000": 81, "_binomial_distribution_sampling_discuss": 81, "p_4": 81, "sum_i": [81, 82, 90, 102, 109, 164, 166, 176], "p_i": [81, 82, 90, 127, 150], "multinomi": 81, "markov": [81, 134, 170, 174, 175, 176, 180, 182, 187, 189], "chain": [81, 97, 124, 150, 158, 173, 175, 176], "_poisson_distribution_video": 81, "encapsul": [81, 82], "sampled_spike_count": 81, "_poisson_distribution_sampling_exercis": 81, "asymmetr": [81, 165], "lambda_valu": 81, "gen_and_plot_possion_sampl": 81, "decent": [81, 175], "obvious": [81, 82, 148, 192], "_varying_parameters_of_poisson_distribution_interactive_demo": 81, "typo": [81, 82], "vido": 81, "mu_1": [81, 165], "sigma_1": [81, 115, 165], "mu_2": [81, 165], "sigma_2": [81, 115, 165], "_continuous_distributions_video": 81, "ourselv": [81, 82, 109, 124, 138, 140, 183, 200], "000120141": 81, "believ": [81, 97, 109, 141, 165], "int_": [81, 166, 175], "int_a": 81, "infti": [81, 109, 140, 141, 165, 183, 189], "permit": [81, 165], "my_gaussian": [81, 82, 166], "x_point": [81, 82, 166], "normalis": [81, 82], "_gaussian_distribution_exercis": 81, "standard_dev": 81, "gen_and_plot_normal_sampl": 81, "distriut": 81, "everywher": [81, 95, 165, 196, 198], "_sampling_from_a_gaussian_distribution_interactive_demo": 81, "gotten": [81, 141], "textbook": [81, 174], "summaris": 82, "maximis": 82, "w0d5_t2": 82, "default_rng": 82, "plot_likelihood": 82, "mean_val": 82, "variance_v": 82, "va": [82, 109, 164, 198, 199], "set_xtick": [82, 117, 124, 125, 126, 127, 164, 173, 176, 182, 191, 192, 198, 199, 201], "set_ytick": [82, 117, 124, 125, 126, 127, 164, 165, 173, 174, 182, 191, 192], "set_xticklabel": [82, 115, 164, 176, 189, 191, 192, 198, 199, 201], "set_yticklabel": [82, 127, 164, 173, 174, 182, 191, 192], "posterior_plot": 82, "posterior_pointwis": 82, "auditori": 82, "plot_classical_vs_bayesian_norm": 82, "mu_class": 82, "var_class": 82, "mu_bay": 82, "var_bay": 82, "_basic_probability_video": 82, "marginalis": 82, "cap": 82, "summat": [82, 149], "b0": 82, "db": [82, 174], "hubel": [82, 125], "wiesel": [82, 125], "1959": 82, "fiction": 82, "inact": 82, "h_": [82, 125, 126, 175], "h_0": [82, 201], "v_0": 82, "\ud835\udc43": 82, "percent": [82, 189, 200], "horizon": [82, 182, 183, 191], "\ud835\udc4e": 82, "\ud835\udc4f": 82, "075": 82, "lastli": [82, 196], "latter": 82, "calculut": 82, "h0": 82, "phew": 82, "_probability_example_main_exercis": 82, "_markov_chains_video": 82, "memoryless": 82, "freeli": [82, 93, 175], "bright": 82, "state_i": 82, "state_": 82, "determinist": [82, 90, 139, 147, 174, 182, 189, 192], "tt": 82, "jth": 82, "transition_matrix": [82, 183], "p0": [82, 172, 173], "matrix_pow": 82, "p4": 82, "4311": 82, "43": [82, 97, 120, 134, 192], "spent": [82, 139, 140], "implicit": 82, "ergod": 82, "p_random": 82, "p_average_time_sp": 82, "4473": 82, "4211": 82, "1316": 82, "44736842": 82, "42105263": 82, "13157895": 82, "_markov_chains_exercis": 82, "satiat": 82, "tire": 82, "mont": 82, "_statistical_inference_and_likelihood_video": 82, "x_i": [82, 90, 97, 98, 100, 109, 115, 116, 166, 176], "unbias": [82, 196], "x_n": [82, 90, 98], "prod_": [82, 98, 172], "emphas": [82, 147, 164], "logarithm": [82, 90, 98, 127], "compute_likelihood_norm": 82, "standard_dev_v": 82, "p_data": 82, "true_mean": 82, "true_standard_dev": 82, "guess_mean": 82, "guess_standard_dev": 82, "92904": 82, "81398544145": 82, "meaningless": 82, "ry": 82, "initialis": 82, "gvien": 82, "idxmean": 82, "idxvar": 82, "_computing_likelihood_exercis": 82, "_maximum_likelihood_video": 82, "implicitli": [82, 95], "underset": [82, 98, 127, 190], "operatornam": [82, 98, 101, 190], "argmax": [82, 98, 109, 127, 165, 166, 176, 182, 190, 191, 192], "gave": 82, "bunch": [82, 139, 165, 172], "val": [82, 102, 109], "plotfnc": 82, "loglikelihood": [82, 166], "greatest": [82, 182], "liklihood": 82, "_maximum_likelihood_inference_interactive_demo": 82, "machin": [82, 93, 101, 104, 106, 109, 113, 117, 120, 124, 125, 127, 134, 141, 174, 175, 178, 190, 192, 196, 200, 202], "minimis": 82, "optimis": 82, "hundr": [82, 88, 124, 189], "negloglik": 82, "bnd": 82, "optimal_paramet": 82, "280354769720607": 82, "1481863138460082": 82, "280": 82, "148": 82, "_maximum_likelihood_estimation_exercis": 82, "9547432925098045": 82, "9870331586690259": 82, "theseparamet": 82, "mle": [82, 108, 164], "wiki": 82, "_analytical_solution_exercis": 82, "_bayesian_inference_with_gaussian_distribution_video": 82, "denomin": [82, 102, 199, 200], "classic_vs_bayesian_norm": 82, "mean_class": 82, "mean_bay": 82, "ndata": 82, "random_num_gener": 82, "xsupp": 82, "compris": [82, 124, 125, 126, 127], "regularis": 82, "benefici": [82, 90, 175], "_bayesian_inference_with_gaussian_distribution_discuss": 82, "_conjugate_priors_video": 82, "binomi": [82, 104, 182], "instanc": [82, 102, 118, 124, 140, 147, 150, 158, 173, 175, 176, 189, 190, 192], "mathrm": [82, 89, 98, 100, 101, 102, 108, 147, 150, 156, 158], "priorl": 82, "priorr": 82, "numl": 82, "numr": 82, "betapdf": 82, "betaprior": 82, "datapoint": [82, 109], "stabilis": 82, "fluctuat": [82, 143, 147, 149, 150, 158], "willing": 82, "peaki": 82, "conid": 82, "badli": 82, "brief": [82, 109, 158, 199, 202], "belief": [82, 162, 174, 190, 191], "compel": 82, "_conjugate_priors_interactive_demo": 82, "skeleton": [82, 124], "pointwis": [82, 166], "predefin": 82, "compute_posterior_pointwis": 82, "localization_simul": 82, "mu_auditori": 82, "sigma_auditori": 82, "mu_visu": 82, "sigma_visu": 82, "devot": 82, "_finding_the_posterior_computationally_bonus_exercis": 82, "frequentist": 82, "paradigm": [82, 189], "aka": [82, 86, 108, 127, 189, 191], "hous": 82, "unreli": [82, 165, 174], "sprinkler": 82, "water": 82, "grass": 82, "rain": 82, "wet": 82, "999": [82, 104, 134, 143, 175], "99": [82, 124, 126, 127, 164, 165, 176, 192, 199], "home": [82, 189], "eqnarrai": [82, 138, 147, 149, 150, 165, 166, 175, 176, 183], "pw1r1s1": 82, "pw1r1s0": 82, "pw1r0s1": 82, "pw1r0s0": 82, "ps": [82, 164], "7522": 82, "neighbour": 82, "_bayes_net_bonus_exercis": 82, "stuctur": 82, "_causality_in_the_brain_bonus_discuss": 82, "bassett": 84, "zurn": 84, "566": 84, "578": [84, 152], "s41583": [84, 120], "018": [84, 111, 120, 134, 185, 194], "0038": 84, "postprint": [84, 104, 111, 120, 134, 143, 152, 178, 185, 194], "europepmc": [84, 104, 111, 120, 134, 152, 178, 185], "pmc6466618": 84, "hacker": 84, "2003": [84, 93, 143, 152, 160], "philosoph": 84, "foundat": [84, 113, 140, 162, 170, 175, 182, 194, 202], "wilei": 84, "blackwel": 84, "1998": [84, 143, 174, 175], "occam": [84, 93], "razor": [84, 93], "philosophi": 84, "pp": [84, 120, 134, 194], "195": [84, 134], "clarendon": 84, "oxford": [84, 160], "chandrasekhar": 84, "chicago": 84, "chater": 84, "oaksford": 84, "1999": [84, 104], "ration": 84, "trend": [84, 93, 115, 138, 182], "s1364": 84, "6613": 84, "98": [84, 109, 134, 152, 178, 189, 192], "01273": 84, "sejnowski": [84, 152], "1990": 84, "343": 84, "382": [84, 143, 152], "2307": 84, "2214198": 84, "cnl": 84, "salk": 84, "20represent": 84, "20and": 84, "20neural": 84, "20comput": 84, "201990": 84, "3325": 84, "1988": [84, 148], "242": 84, "4879": 84, "741": 84, "745": [84, 175], "3055294": 84, "cichi": [84, 120], "kaiser": 84, "305": 84, "317": 84, "tic": [84, 93], "2005": [84, 104, 143, 172, 185], "feldman": 84, "interdisciplinari": 84, "330": 84, "340": [84, 134], "1002": 84, "wc": 84, "1406": 84, "pmc5125387": 84, "gillett": 84, "cambridg": [84, 93, 143, 152, 160, 194], "goldstein": [84, 120], "e40018": 84, "7554": [84, 93, 104, 134, 152], "40018": 84, "jona": [84, 194], "microprocessor": 84, "e1005268": 84, "1005268": 84, "josephson": 84, "ed": [84, 104, 160], "1996": [84, 134, 143, 152, 160], "abduct": 84, "infer": [84, 88, 93, 97, 98, 99, 100, 101, 102, 104, 117, 118, 122, 134, 157, 160, 162, 164, 170, 172, 174, 175, 176, 180, 182, 187, 194, 198, 202], "technolog": 84, "kaplan": 84, "2011": [84, 104, 160, 168], "synthes": [84, 174], "183": [84, 152, 194], "339": [84, 134, 143], "373": 84, "s11229": 84, "011": [84, 93, 104, 120], "9970": 84, "31219": 84, "3vy69": 84, "lee": 84, "criss": 84, "devez": 84, "donkin": 84, "etz": 84, "leit": 84, "vandekerckhov": 84, "141": 84, "153": [84, 178], "31234": 84, "dmfhk": 84, "lombrozo": 84, "1093": 84, "oxfordhb": 84, "9780199734689": 84, "013": 84, "0014": 84, "marr": 84, "poggio": 84, "1976": [84, 178], "circuitri": 84, "intellig": [84, 120, 187, 189], "laboratori": 84, "memo": 84, "massachusett": 84, "institut": 84, "357": 84, "dspace": [84, 194], "1721": [84, 194], "5782": 84, "parker": 84, "metasci": 84, "vol": [84, 93, 160, 183, 194], "s11016": 84, "9567": 84, "pearl": [84, 194, 196], "mackenzi": [84, 194], "russel": 84, "1917": 84, "mystic": 84, "5962": 84, "bhl": 84, "19230": 84, "archiv": 84, "download": [84, 88, 108, 109, 124, 125, 126, 127, 175], "mysticismlogicot00russiala": 84, "mysticismlogicot00russiala_bw": 84, "simon": 84, "1969": 84, "ma": [84, 93, 160, 178, 183], "trappenberg": 84, "oup": 84, "collin": [84, 93, 134], "e49547": [84, 93], "49547": [84, 93], "w1d1_daysummari": 85, "_day_summari": [85, 94, 105, 112, 121, 129, 135, 144, 179, 186], "meta": [86, 185], "remaind": [86, 130], "compactli": 86, "quantifi": [86, 90, 99, 117, 124, 126, 140, 147, 164, 172, 182, 183, 198, 199, 201], "bay": [86, 106, 160, 162, 170, 172, 180], "quest": 86, "opportun": [86, 130], "t1": [86, 95, 106, 165], "t3": 86, "w1d1_intro": 86, "w1d1_outro": 87, "_outro_video": [87, 96, 166], "laport": [88, 89, 90, 91], "byron": [88, 89, 90, 91, 97, 98, 99, 100, 111, 113, 172, 175, 189, 190, 191, 192], "galbraith": [88, 89, 90, 91, 97, 98, 99, 100, 172, 175, 189, 190, 191, 192], "dalin": [88, 89, 90], "guo": [88, 89, 90], "aishwarya": [88, 89, 90], "balwani": [88, 89, 90], "madineh": [88, 89, 90, 98, 124, 125, 126, 127, 198, 199, 200, 201], "sarvestani": [88, 89, 90, 98, 124, 125, 126, 127, 198, 199, 200, 201], "vaziri": [88, 89, 90, 147, 148, 149, 156, 157, 158], "pashkam": [88, 89, 90, 147, 148, 149, 156, 157, 158], "gagana": [88, 89, 90, 91, 115, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 189, 190, 192, 198, 199, 200, 201], "acknowledg": [88, 90, 97, 108, 109, 175, 176], "flavor": [88, 89, 90, 109], "w1d1_t1": 88, "script": [88, 166], "corner": [88, 192, 199], "keyboard": 88, "shortcut": [88, 130, 192], "cmd": 88, "mac": 88, "ctrl": 88, "bracket": 88, "inlin": [88, 89, 90, 108, 109, 125, 126, 132, 165, 166, 183], "plot_isi": 88, "single_neuron_isi": 88, "axvlin": [88, 89, 97, 98, 99, 126, 150, 157, 165, 166, 183, 192], "durat": [88, 108, 138, 139, 140, 147, 148, 149, 150, 156, 157, 158, 174, 176], "sy5xt": [88, 90], "status_cod": [88, 90, 108, 109, 124, 125, 126, 127, 175], "bytesio": [88, 90, 175], "allow_pickl": [88, 90, 175], "_what_models_video": [88, 138], "probe": [88, 109], "implant": 88, "electrod": [88, 89], "nearbi": 88, "preced": [88, 108, 166, 172, 189], "incomplet": [88, 166, 172, 173], "partli": 88, "undocu": 88, "unfamiliar": 88, "734": 88, "sep": [88, 90], "826": 88, "321": [88, 150], "9723": 88, "i_neuron": 88, "i_print": 88, "slice": [88, 198, 199, 200, 201], "8149": 88, "822467": 88, "9646": 88, "1436": 88, "8709": 88, "0698667": 88, "1536334": 88, "2403667": 88, "7072": 88, "799": 88, "n_neuron": [88, 109, 124, 125, 126, 127, 198, 199, 200, 201], "total_spikes_per_neuron": 88, "spike_times_i": 88, "five": [88, 99, 150, 173, 175], "2818": 88, "3953": [88, 134], "646": 88, "1115": [88, 134], "_exploring_the_dataset_video": 88, "loud": [88, 165, 166], "percentag": [88, 141, 190], "mean_spike_count": 88, "frac_below_mean": 88, "major": [88, 138, 182, 191, 192], "exception": 88, "median_spike_count": 88, "limegreen": [88, 174, 175], "50th": 88, "percentil": [88, 99, 124, 127], "interquartil": 88, "_comparing_mean_and_median_neurons_exercis": 88, "restrict_spike_tim": 88, "inner": 88, "interval_spike_tim": 88, "interval_mask": 88, "t_interv": 88, "original_count": 88, "interval_count": 88, "frac_interval_spik": 88, "33": [88, 104, 120, 138, 157, 192, 201], "ptp": 88, "spike_times_flat": 88, "experiment_dur": 88, "interval_dur": 88, "frac_interval_tim": 88, "neuron_idx": [88, 90, 198, 199, 200, 201], "51": [88, 134, 165, 182, 192, 201], "5th": 88, "_visualizing_activity_video": 88, "energi": [88, 89, 90, 178], "cellular": 88, "machineri": 88, "metabol": 88, "longest": 88, "interspik": [88, 90, 147, 150], "compute_single_neuron_isi": 88, "single_neuron_spik": 88, "283": [88, 90, 178], "predomin": 88, "rapidli": [88, 89, 108, 149, 158, 174, 183, 192], "absenc": [88, 140], "agre": [88, 126, 141], "_isis_and_their_distributions_exercis": 88, "_isi_distribution_video": 88, "maxima": [88, 190], "x0": [88, 100, 108, 138, 139, 140, 141, 156, 158], "parameter": [88, 98, 124, 156, 182], "offset": [88, 100, 108, 165, 172, 173, 182, 200, 201], "y0": [88, 138], "single_neuron_idx": 88, "c4": 88, "exp_scal": 88, "20000": [88, 108, 189, 201], "250": [88, 102, 117, 140, 147, 200], "exp_rat": 88, "exp_x0": 88, "inv_scal": 88, "3e2": 88, "inv_x0": 88, "lin_slop": 88, "1e5": 88, "6e5": 88, "lin_y0": 88, "4e4": 88, "fit_plot": 88, "2000": [88, 89, 99, 111, 118, 143, 152, 178, 194, 199, 201], "func_param": 88, "fill_between": [88, 89, 90, 165, 172, 174, 182, 183, 199, 200, 201], "_isi_functions_explorer_interactive_demo_and_discuss": 88, "_fitting_models_by_hand_video": 88, "_reflecting_on_what_models_discuss": 88, "poke": 88, "realist": [89, 147, 156, 183, 189, 191], "w1d1_t2": 89, "ax_arg": 89, "duplic": 89, "shade": [89, 90], "drawstyl": [89, 90], "heurist": [89, 106], "ymin": [89, 97, 98, 173], "ymax": [89, 90, 97, 98, 173, 176], "yscale": 89, "autoscal": 89, "tight": [89, 196], "plot_neuron_stat": 89, "n_bin": [89, 90, 125, 127], "xmax": [89, 98], "_how_models_video": 89, "discharg": [89, 152], "preserv": [89, 90, 98], "presynapt": [89, 149], "ge": [89, 149, 150], "suitabl": [89, 90, 97], "lif_neuron": 89, "alia": 89, "n_step": [89, 189, 190], "precomput": [89, 109, 118, 175], "_compute_dvm_exercis": 89, "_lif_neuron": 89, "floatlogslid": [89, 175, 190], "plot_lif_neuron": 89, "fairli": [89, 118, 149, 165, 183, 201], "_linear_if_neuron_interactive_demo_and_discuss": 89, "_linear_if_models_video": 89, "empir": [89, 99, 102, 104, 139, 165, 176], "upon": [89, 126, 174, 180, 189, 190, 192, 198, 202], "tendenc": [89, 140, 201], "steadi": [89, 149, 150, 156, 157, 158], "lambda_": [89, 176], "lif_neuron_inh": 89, "exc_rat": [89, 149], "inh_rat": [89, 149], "_compute_dvm_with_inhibitory_signals_exercis": 89, "_lif_neuron_inh": 89, "_lif_and_inhibition_neuron_interactive_demo_and_discuss": 89, "_lif_and_inhibition_video": 89, "_reflecting_on_how_models_discuss": 89, "c_m": [89, 147], "capacit": [89, 147], "ion": [89, 139, 149, 173], "revert": 89, "insul": 89, "capacitor": 89, "resistor": 89, "millivolt": 89, "megaohm": 89, "w1d1_t3": 90, "plot_pmf": 90, "isi_rang": 90, "pmf_": 90, "steinmetz_spik": 90, "_why_models_video": 90, "consum": [90, 149], "deplet": 90, "replenish": 90, "downstream": [90, 134, 148], "shannon": 90, "h_b": 90, "log_b": [90, 176], "nat": 90, "subdivid": 90, "concentr": [90, 198], "undefin": 90, "log2": [90, 199], "nan": [90, 127, 147, 192], "convent": [90, 126, 175], "exclud": [90, 102], "2f": [90, 97, 98, 99, 100, 124, 127, 138, 140, 141, 147, 148, 164, 182, 183, 190, 199, 200, 201], "_optimization_and_information_exercis": 90, "log_2": 90, "likewis": [90, 139], "taller": 90, "certainti": [90, 182, 189], "h_2": 90, "_entropy_of_different_distributions_video": 90, "nervou": 90, "budget": 90, "expenditur": 90, "mean_isi": 90, "025": [90, 104, 127, 150], "mean_idx": 90, "searchsort": 90, "pmf_singl": 90, "pmf_uniform": 90, "pmf_exp": 90, "dist": 90, "_probabilities_from_histogram_video": 90, "n_i": 90, "nolimits_": 90, "taken": [90, 124, 126, 148, 156, 175, 182, 183, 187, 190, 191, 192], "pmf_from_count": 90, "_probability_mass_function_exercis": 90, "_calculating_entropy_from_pmf_video": 90, "_pmf_from_count": 90, "_entropi": 90, "steinmetz_pmf": 90, "_entropy_of_neurons_interactive_demo": 90, "_reflecting_on_why_models_discuss": 90, "_summary_of_model_types_video": 90, "congratul": [90, 147, 149, 157, 166, 189], "discov": [90, 120, 125, 127, 138, 175, 182], "closest": [90, 106, 126, 166], "exhibit": [90, 157], "1948": 90, "claud": 90, "began": 90, "composit": [90, 134], "subdivis": 90, "i_b": 90, "unsurpris": 90, "w1d1_t4": 91, "favorit": [91, 106, 115], "_model_discussions_discuss": 91, "palminteri": 93, "wyart": 93, "koechlin": 93, "falsif": 93, "425": 93, "433": 93, "1101": [93, 120, 124, 125, 126, 127, 152, 185], "079798": 93, "bishop": [93, 174, 175], "nasrabadi": 93, "738": 93, "york": [93, 160, 175, 194], "springer": [93, 160, 194], "microsoft": 93, "en": 93, "cmbishop": 93, "mackai": [93, 160], "itprnn": [93, 160], "arlot": 93, "celiss": 93, "79": 93, "1214": 93, "ss054": 93, "acerbi": 93, "lacerbi": 93, "boyd": [93, 100, 108, 183], "vandenbergh": [93, 100, 108], "convex": [93, 97, 98, 106, 108, 124, 176], "stanford": [93, 108, 189], "cvxbook": 93, "motor": [93, 134, 166, 178, 180], "101": [93, 134, 173, 176], "655": 93, "664": 93, "90545": 93, "w1d2_daysummari": 94, "confront": 95, "systemat": [95, 130, 134, 141, 148, 199], "bread": 95, "butter": 95, "zoo": 95, "embodi": [95, 166], "assess": [95, 99, 102, 113, 120, 143], "t2": [95, 106], "w1d2_intro": 95, "w1d2_outro": 96, "pierr": [97, 98, 99, 100, 101, 102, 108, 109], "\u00e9tienn": [97, 98, 99, 100, 101, 102], "fiquet": [97, 98, 99, 100, 101, 102, 108, 109], "anqi": [97, 98, 99, 100, 101, 102, 106], "wu": [97, 98, 99, 100, 101, 102, 168, 182, 183], "hyafil": [97, 98, 99, 100, 101, 102], "lina": [97, 98, 99, 100, 101, 102], "teichmann": [97, 98, 99, 100, 101, 102], "saeed": [97, 99, 100, 164, 165, 166, 182, 183], "salehi": [97, 99, 100, 164, 165, 166, 182, 183], "patrick": [97, 98, 99, 100, 101, 102], "mineault": [97, 98, 99, 100, 101, 102], "bootstrap": [97, 98, 100, 101, 102], "confid": [97, 98, 100, 101, 102, 173, 174, 182, 194], "polynomi": [97, 98, 99, 101, 102], "trade": [97, 98, 99, 100, 102, 120, 172, 175, 191], "thank": [97, 100, 108], "eero": 97, "simoncelli": [97, 104, 134], "mathtool": 97, "w1d2_t1": 97, "plot_observed_vs_predict": 97, "y_hat": [97, 99, 100, 101, 102], "theta_hat": [97, 98, 99, 100, 101, 102], "residu": [97, 100, 101, 102, 120, 124], "_mean_squared_error_video": 97, "ls": [97, 147, 149, 150, 157, 165, 166, 172, 182, 183], "suppos": [97, 176, 183, 200, 201], "explanatori": 97, "corrupt": [97, 108, 109, 117, 124, 125, 126, 127, 175], "epsilon_": 97, "synthet": [97, 99, 141, 166], "luxuri": [97, 99], "psuedorandom": [97, 98, 99, 100], "randn": [97, 98, 99, 100, 101, 102, 147, 148, 149, 156, 158, 174, 183, 198], "52": [97, 192], "_compute_mse_exercis": 97, "lowest": [97, 102], "plot_data_estim": 97, "ineffici": 97, "_mse_explorer_interactive_demo_discuss": 97, "landscap": [97, 120, 124, 138], "textrm": [97, 98, 108, 109, 164, 165, 172], "theta_hat_grid": 97, "best_error": 97, "argmin": [97, 126, 165, 166, 183], "theta_": [97, 157, 158], "candid": [97, 172, 175, 182, 192], "solve_normal_eqn": [97, 99], "_solve_for_the_optimal_estimator_exercis": 97, "y_i": [97, 98, 99, 100, 102, 109], "2x_i": [97, 99], "waskomli": 98, "incorpor": [98, 100, 102, 124, 126, 127, 134, 139, 141, 149, 165, 173, 190, 192], "w1d2_t2": 98, "plot_density_imag": 98, "xmin": 98, "wistia": [98, 164], "_maximum_likelihood_estimation_video": 98, "treat": [98, 122, 126, 127, 156, 201], "nuisanc": 98, "epsilon": [98, 100, 156, 172, 191, 192, 198, 199, 200, 201], "plot_normal_dist": 98, "_gaussian_distribution_explorer_interactive_demo_and_discuss": 98, "invok": [98, 99, 100, 109, 124, 127, 198, 199], "get_ylim": [98, 99, 127, 173, 174, 176], "inher": [98, 175], "11344443599846923": 98, "_likelihood_function_exercis": 98, "joint": [98, 115, 116, 149, 164, 165, 176], "y_n": 98, "arithmet": 98, "underflow": 98, "circumv": 98, "routin": [98, 100, 154, 192], "likelihhood": 98, "remark": [98, 117], "theta_hat_ml": 98, "gaug": 99, "w1d2_t3": 99, "plot_original_and_resampl": 99, "get_xlim": [99, 127, 176], "_confidence_intervals_and_bootstrapping_video": 99, "bradlei": 99, "efron": 99, "epsilon_i": 99, "resample_with_replac": 99, "sample_idx": 99, "_resample_dataset_with_replacement_exercis": 99, "thata_hat": 99, "bootstrap_estim": 99, "123": [99, 178], "27550888": 99, "17317819": 99, "18198819": 99, "25329255": 99, "20714664": 99, "_bootsrap_estimates_exercis": 99, "get_legend_handles_label": 99, "set_alpha": 99, "uncertain": 99, "ci": 99, "reassur": 99, "ag": 99, "trevor": 99, "hasti": [99, 101, 172], "w1d2_t4": 100, "evaluate_fit": 100, "order_list": [100, 102], "mse_list": 100, "plot_fitted_polynomi": 100, "x_grid": 100, "max_ord": [100, 101, 102], "x_design": [100, 101, 102], "univari": 100, "regressor": [100, 108, 200, 201], "theta_0": 100, "theta_1": 100, "theta_2": 100, "theta_d": 100, "x_d": 100, "boldsymbol": [100, 108], "paramt": 100, "ol": 100, "_multiple_linear_regression_and_polynomial_regression_video": 100, "ganglion": [100, 104, 120], "light": [100, 124, 126, 166, 175, 192], "1234": 100, "n_regressor": [100, 101, 102], "ordinary_least_squar": [100, 101, 102], "13861386": 100, "09395731": 100, "16370742": 100, "_ordinary_least_squares_estimator_exercis": 100, "mgrid": [100, 165], "50j": 100, "y_hat_grid": 100, "theta_3": 100, "theta_4": 100, "output_nois": 100, "input_nois": 100, "ldot": [100, 124, 126, 127], "_m": 100, "broadcast": [100, 101, 102], "design_matrix": [100, 101, 102], "51194917": 100, "35259945": 100, "solve_poly_reg": [100, 101, 102], "this_theta": [100, 101, 102], "lapack": 100, "stephen": [100, 108, 134, 183], "lieven": [100, 108], "w1d2_t5": 101, "plot_mse_poly_fit": 101, "mse_train": 101, "mse_test": 101, "held": [101, 102, 124], "_bias_variance_tradeoff_video": 101, "n_train_sampl": [101, 102], "n_test_sampl": [101, 102], "overli": [101, 194], "underfit": [101, 102], "overfit": [101, 102, 106, 124, 127, 141], "fortmann": 101, "roe": 101, "biasvari": 101, "metric": [101, 118, 126, 194, 198], "t4": 101, "port": 101, "evaluate_poly_reg": [101, 102], "evalute_poly_reg": 101, "compute_ms": 101, "_compute_train_vs_test_error_exercis": 101, "strike": 101, "modern": 101, "recent": [101, 108, 145, 149, 191, 201], "tibshirani": 101, "friedman": [101, 198, 199, 200, 201], "_proof_bias_variance_for_mse_bonus_exercis": 101, "w1d2_t6": 102, "kfold": 102, "plot_cross_validate_ms": 102, "mse_al": 102, "k_fold": 102, "n_split": 102, "plot_aic": 102, "aic_list": 102, "_crossvalidation_video": 102, "commonli": [102, 109, 124, 126, 127, 140, 165], "hasn": [102, 109, 190], "reassign": 102, "fold": [102, 109, 120], "divis": [102, 126], "sacrif": 102, "preciou": 102, "consensu": 102, "former": 102, "cross_valid": 102, "wrongli": 102, "kfold_iter": 102, "i_split": 102, "train_indic": 102, "val_indic": 102, "x_cv_train": 102, "y_cv_train": 102, "x_cv_val": 102, "y_cv_val": 102, "mse_this_split": 102, "_implement_cross_validation_exercis": 102, "strive": 102, "2k": 102, "plug": [102, 109, 124, 156, 164, 183], "cancel": [102, 148, 172], "sse": 102, "this_aic": 102, "_compute_aic_bonus_exercis": 102, "gerwinn": 104, "bethg": [104, 120], "mack": [104, 108, 109], "seeger": 104, "neurip": 104, "cc": [104, 120, 148, 168], "hash": [104, 120, 168], "46ba9f2a6976570b0353203ec4474217": 104, "glaser": 104, "farhoodi": [104, 124, 125, 126, 127, 182, 183], "supervis": [104, 108, 109, 120], "neurobiolog": [104, 111, 143, 185], "175": 104, "126": [104, 127], "137": 104, "pneurobio": 104, "pmc8454059": 104, "chowdhuri": 104, "perich": 104, "0506": 104, "hardcastl": 104, "maheswaranathan": [104, 120], "ganguli": [104, 120, 134], "giocomo": 104, "multiplex": 104, "heterogen": 104, "medial": 104, "entorhin": 104, "94": 104, "375": 104, "387": [104, 127], "latim": [104, 168], "riek": 104, "pillow": [104, 108, 134, 168], "e47012": 104, "47012": 104, "bues": 104, "cunningham": [104, 111, 134], "yu": [104, 111, 113, 134], "shenoi": [104, 134], "sahani": [104, 134], "nip": [104, 120, 168], "7143d7fbadfa4693b9eec507d9d37443": 104, "kastner": 104, "baccu": [104, 120], "multilay": [104, 120], "e1006291": 104, "1006291": 104, "mccullagh": 104, "nelder": 104, "1989": [104, 172, 189, 191], "chapman": [104, 160], "hall": [104, 160], "london": 104, "mcfarland": 104, "cui": 104, "butt": 104, "e1003143": 104, "1003143": 104, "paninski": [104, 120, 134, 143, 152], "cascad": 104, "243": 104, "0954": 104, "898x": 104, "panzeri": 104, "piasini": 104, "latham": 104, "fellin": 104, "crack": 104, "intervent": [104, 194, 199, 201], "93": [104, 134], "491": [104, 160, 194], "507": 104, "036": 104, "park": [104, 106], "covari": [104, 106, 115, 117, 120, 148, 174, 175, 183, 200, 201], "6395ebd0f4b478145ecfbaf939454fa4": 104, "e1002219": 104, "1002219": 104, "meister": 104, "huk": [104, 168, 172], "pariet": 104, "sensorimotor": [104, 111], "1395": 104, "1403": 104, "3800": 104, "pmc4176983": 104, "uzzel": [104, 108], "chichilniski": [104, 108, 134], "47": [104, 192], "11003": 104, "11013": 104, "jneurosci": [104, 120, 143, 148, 152, 178], "3305": 104, "shlen": [104, 111, 134], "sher": [104, 120, 134], "litk": [104, 120, 134], "spatio": [104, 120, 134], "454": [104, 134], "7207": [104, 134], "995": [104, 134], "nature07140": [104, 134], "pmc2684455": [104, 134], "b55ec28c52d5f6205684a473a2193564": 104, "1404": [104, 111], "schwartz": 104, "327": 104, "338": 104, "gazzaniga": 104, "iii": 104, "stevenson": 104, "obi": [104, 111], "sach": 104, "reimer": 104, "englitz": 104, "e1002775": 104, "1002775": 104, "truccolo": 104, "eden": [104, 160, 194], "fellow": 104, "donoghu": [104, 168], "extrins": [104, 117], "1074": 104, "1089": [104, 127, 178], "00697": 104, "vidn": 104, "ahmadian": [104, 152], "s10827": 104, "0376": 104, "pmc3560841": 104, "weber": 104, "repertoir": [104, 145], "3260": 104, "3289": 104, "1162": [104, 120, 152], "neco_a_01021": 104, "1602": 104, "07389": 104, "zhao": 104, "iyengar": 104, "nonconverg": 104, "1231": 104, "1244": 104, "neco": 104, "982": 104, "w1d3_daysummari": 105, "folk": 106, "unifi": [106, 143, 152, 174, 175], "swiss": 106, "armi": 106, "knife": 106, "intent": 106, "spot": [106, 141, 198], "protect": 106, "l1": [106, 109, 127], "reverend": 106, "christina": 106, "savin": [106, 175], "canon": [106, 189], "she": [106, 145, 149, 154], "qu": 106, "prof": 106, "georgia": 106, "tech": 106, "mem": [106, 149], "cat": [106, 125, 180, 183], "he": [106, 113, 120, 141, 145, 154, 164], "danger": [106, 165, 182, 183, 192], "touch": [106, 124], "readout": [106, 148], "w1d3_intro": 106, "_day_intro": 106, "w1d3_outro": 107, "_day_outro": 107, "etienn": [108, 109], "ari": [108, 109, 198, 199, 200, 201], "jakob": [108, 109], "david": [108, 109, 160], "valeriani": [108, 109], "alish": [108, 109], "dipani": [108, 109], "ej": 108, "permiss": 108, "jonathan": 108, "w1d3_t1": 108, "loadmat": 108, "plot_stim_and_spik": 108, "stim": [108, 175], "intens": 108, "ax_stim": 108, "ax_spik": 108, "nrow": [108, 189, 191, 192], "plot_glm_matric": 108, "boundarynorm": 108, "axes_grid1": [108, 198, 201], "make_axes_locat": [108, 198, 201], "skinni": 108, "ax_x": [108, 164, 165], "ax_i": [108, 164, 165], "gridspec_kw": [108, 189], "imx": 108, "pcolormesh": 108, "setp": 108, "visibl": [108, 149, 157, 160], "divx": 108, "caxx": 108, "append_ax": [108, 198, 201], "cbarx": 108, "cax": [108, 124, 125, 127, 198, 201], "set_tick": 108, "set_ticklabel": 108, "imi": 108, "magma": 108, "invert_yaxi": [108, 166], "divi": 108, "caxi": 108, "cbari": 108, "plot_spike_filt": 108, "kw": 108, "gca": [108, 125, 126, 127, 176, 198, 199, 200], "axhlin": [108, 109, 147, 149, 166, 189], "plot_spikes_with_predict": 108, "predicted_spik": 108, "t0": 108, "stem": [108, 109, 189], "set_zord": [108, 127], "setdefault": 108, "yhat": 108, "maxnloc": 108, "hashlib": [108, 109, 124, 125, 126, 127, 175], "fname": [108, 109, 124, 125, 126, 127, 175], "rgcdata": 108, "mat": [108, 109], "mzuj": 108, "expected_md5": [108, 109, 124, 125, 126, 127, 175], "1b2977453020bce5319f2608c94d38d0": 108, "connectionerror": [108, 109, 124, 125, 126, 127, 175], "md5": [108, 109, 124, 125, 126, 127, 175], "hexdigest": [108, 109, 124, 125, 126, 127, 175], "wb": [108, 109, 124, 125, 126, 127, 175], "fid": [108, 109, 124, 125, 126, 127, 175], "_linear_gaussian_model_video": 108, "lumin": [108, 125], "rgc": 108, "flicker": 108, "120hz": 108, "144051": 108, "spcount": 108, "dtstim": 108, "dt_stim": 108, "cellnum": 108, "keep_timepoint": 108, "ij": [108, 116, 125, 126, 127, 148, 173, 176, 198], "onset": 108, "padded_stim": 108, "_create_design_matrix_exercis": 108, "augment": 108, "column_stack": [108, 115, 116], "lg": 108, "theta_lg": 108, "predict_spike_counts_lg": 108, "predicted_count": 108, "_predict_counts_with_linear_gaussian_model_exercis": 108, "bump": [108, 165], "troublingli": 108, "failur": [108, 200], "subcas": 108, "sta": 108, "statement": [108, 182, 198, 201], "_bonus_challenge_act": 108, "_generalized_linear_model_video": 108, "unfortun": [108, 164, 201], "stuck": [108, 190], "chord": 108, "4g": 108, "566e": 108, "88846e": 108, "tol": 108, "bear": 108, "emphasi": 108, "moment": [108, 134, 139, 149, 189, 192], "start_point": 108, "mew": 108, "lnp": 108, "mid": [108, 156, 166, 173, 198, 200], "sum_t": [108, 182], "y_t": [108, 175, 176, 201], "x_t": [108, 173, 176, 198, 199], "lambda_t": 108, "neg_log_lik_lnp": 108, "loglik": 108, "log_lik": 108, "fit_lnp": 108, "minmiz": 108, "theta_lnp": 108, "_fitting_the_poisson_glm_exercis": 108, "broadli": [108, 187, 189], "predict_spike_counts_lnp": 108, "cach": [108, 192], "_predict_spike_counts_exercis": 108, "_predict_spike_counts_bonu": 108, "oftentim": 109, "awak": [109, 122], "asleep": 109, "car": 109, "bu": 109, "choi": 109, "hyperparamet": [109, 124, 189, 200, 201], "w1d3_t2": 109, "plot_weight": [109, 125, 127], "atleast_1d": 109, "set_mark": 109, "c3": 109, "callabl": 109, "plot_model_select": 109, "c_valu": 109, "set_xscal": 109, "best_c": 109, "1g": 109, "plot_non_zero_coef": 109, "non_zero_l1": 109, "n_voxel": 109, "r9gh8": 109, "w1d4_steinmetz_data": 109, "npz": [109, 124, 125, 126, 127, 175], "d19716354fed0981267456b80db07ea8": 109, "load_steinmetz_data": 109, "data_fnam": [109, 175], "dobj": [109, 124, 125, 126, 127, 175], "_logistic_regression_video": 109, "coinflip": 109, "squash": [109, 126, 198], "Its": [109, 126, 165], "_implement_the_sigmoid_function_exercis": 109, "wheel": 109, "gabor": [109, 125, 126, 127], "kordinglab": 109, "png": 109, "nogo": 109, "n_trial": [109, 148, 176, 189, 190, 199, 200, 201], "0s": [109, 117, 198], "1s": [109, 117, 198], "276": 109, "691": 109, "n_featur": [109, 118], "log_reg": 109, "rerun": [109, 118, 127], "trust": [109, 118], "unabl": [109, 118, 158, 200], "nbviewer": [109, 118], "nbsp": [109, 118], "logisticregressionifittedlogisticregress": 109, "27": [109, 120, 156, 172, 192, 201], "score": [109, 116, 117, 118, 120, 124, 125, 127], "compute_accuraci": 109, "train_accuraci": 109, "_classifier_accuracy_video": 109, "idiosyncrat": 109, "justcv": 109, "tini": [109, 172], "_regularization_video": [109, 127], "priori": 109, "idiosyncraci": 109, "53": [109, 111, 192, 201], "beta2": 109, "theta_i": [109, 157, 158], "unregular": 109, "log_reg_l2": 109, "log_c_step": 109, "penalized_model": 109, "log_c": 109, "max_it": [109, 200, 201], "5000": [109, 139, 140, 189, 198, 199, 200, 201], "plot_observ": [109, 200, 201], "frac1": 109, "lasso": [109, 201], "log_reg_l1": 109, "ugli": [109, 185], "warn": [109, 127, 164, 165, 182, 189], "spars": [109, 118, 152, 198, 199, 200, 201], "unpack": 109, "dens": 109, "m_spars": 109, "text_kw": 109, "iter_part": 109, "1f": [109, 115, 116, 140, 141, 147, 150, 156, 158], "fmt": 109, "count_non_zero_coef": 109, "non_zero_coef": 109, "coef": 109, "non_zero": 109, "logspac": [109, 172], "_effect_of_l1_on_sparsity_exercis": 109, "sparser": [109, 127], "thalamu": 109, "carri": [109, 116, 124, 189], "scheme": [109, 126, 138, 147, 150], "acc": 109, "_model_selection_exercis": 109, "poorli": [109, 118, 124, 201], "risk": [109, 120, 164, 190, 192], "ny_i": 109, "fresh": [109, 174], "proper": [109, 158, 202], "1708": 109, "00909": 109, "1100": 111, "hyvarinen": 111, "oja": 111, "411": 111, "430": [111, 152], "s0893": 111, "6080": 111, "00026": 111, "cse": 111, "msu": 111, "cse902": 111, "s03": 111, "icasurvei": 111, "gilli": 111, "nonneg": 111, "1401": 111, "5226": 111, "coenen": 111, "pearc": 111, "wattenberg": [111, 118], "viega": 111, "johnson": [111, 134], "distil": [111, 118, 120], "23915": [111, 120], "00002": 111, "1500": 111, "1509": 111, "3776": 111, "pmc4433019": 111, "golub": [111, 134], "chase": [111, 165], "batista": 111, "dissect": [111, 120], "opinion": [111, 143, 185], "58": [111, 191], "conb": [111, 143, 185], "sadtler": 111, "ryu": [111, 134], "tyler": 111, "kabara": 111, "reassoci": 111, "607": 111, "0095": 111, "pmc5876156": 111, "512": 111, "7515": 111, "423": 111, "426": 111, "nature13665": 111, "pmc4393644": 111, "w1d4_daysummari": 112, "orthonorm": [113, 116, 117], "constantli": [113, 156, 183], "w1d4_intro": 113, "_intro": [113, 122], "w1d4_outro": 114, "_outro": 114, "cayco": [115, 116, 117, 118], "gajic": [115, 116, 117, 118], "roozbeh": [115, 116, 117, 118, 124, 125, 126, 127, 182, 183], "farhoudi": [115, 116, 117, 118], "kraus": [115, 116, 117, 118, 138, 139, 140, 141, 147, 148, 149, 150, 166, 172, 173, 175, 176, 182, 183, 189, 190, 191, 192], "w1d4_t1": 115, "plot_data": [115, 116], "bivari": [115, 116, 201], "add_gridspec": [115, 116], "markerfacecolor": [115, 116], "markeredgewidth": [115, 116, 148, 149, 150], "corr": [115, 116, 148, 164, 165, 198, 199, 200, 201], "corrcoef": [115, 116, 126, 198, 199, 200, 201], "plot_basis_vector": [115, 116], "plot_data_new_basi": [115, 116], "ascend": [115, 116], "_geometric_view_of_data_video": 115, "mu_i": [115, 148, 165], "sigma_i": [115, 148, 165], "rho": [115, 164, 165, 183], "cov": [115, 116, 126, 148, 164, 174, 175, 183, 201], "bf": [115, 116, 117, 138, 183], "pmatrix": [115, 173], "diagon": [115, 126, 164, 165, 172, 176], "_multivariate_data_video": 115, "get_data": [115, 116, 124, 127], "cov_matrix": [115, 116, 117], "multivariate_norm": [115, 116, 165, 175, 198, 199, 200, 201], "indices_for_sort": [115, 116], "argsort": [115, 116, 117, 127], "calculate_cov_matrix": [115, 116], "var_1": [115, 116], "var_2": [115, 116], "corr_coef": [115, 116, 126], "variance_1": [115, 116], "variance_2": [115, 116], "_draw_samples_from_a_distribution_exercis": 115, "cloud": 115, "_calculate_cov_matrix": 115, "visualize_correlated_data": 115, "_correlation_effect_on_data_interactive_demo_and_discuss": 115, "_orthonormal_bases_video": 115, "u_1": [115, 165], "u_2": [115, 165], "w_2": 115, "orthogon": [115, 116, 117], "define_orthonormal_basi": [115, 116], "orthonom": 115, "_find_an_orthonormal_basis_exercis": 115, "_change_of_basis_video": 115, "change_of_basi": [115, 116, 117], "_change_to_orthonormal_basis_exercis": 115, "uncorrel": [115, 116, 150, 201], "tan": 115, "unequ": 115, "_play_with_basis_vectors_interactive_demo_and_discuss": 115, "mixtur": [115, 149, 189], "decorrel": [115, 148], "beautifulli": [116, 194], "w1d4_t2": 116, "plot_eigenvalu": [116, 117], "scree": 116, "sort_evals_descend": [116, 117], "evector": [116, 117], "_pca_video": 116, "sigma_": [116, 147, 148, 156, 164, 165, 166, 174], "x_j": 116, "n_": 116, "_j": 116, "get_sample_cov_matrix": [116, 117], "sample_cov_matrix": 116, "99315313": 116, "82347589": 116, "01281397": 116, "_calculate_the_covariance_matrix_exercis": 116, "eigh": [116, 117], "descend": [116, 124], "_eigenvectors_of_the_covariance_matrix_exercis": 116, "_pca_implementation_exercis": 116, "_exploration_of_the_correlation_coefficient_interactive_demo_and_discuss": 116, "_properties_of_pca_bonus_video": 116, "w1d4_t3": 117, "plot_variance_explain": 117, "variance_explain": 117, "plot_mnist_reconstruct": 117, "x_reconstruct": 117, "keep_dim": 117, "tick_param": [117, 174, 176, 182, 198, 199], "labelbottom": 117, "clim": [117, 118], "plot_mnist_sampl": 117, "plot_mnist_weight": 117, "seismic": 117, "add_nois": 117, "frac_noisy_pixel": 117, "x_noisi": 117, "n_noise_ix": 117, "noise_ix": 117, "_pca_for_dimensionality_reduction_video": 117, "unravel": 117, "nine": 117, "parser": [117, 118], "elbow": 117, "_scree_plot_of_mnist_exercis": 117, "lambda_i": [117, 176], "get_variance_explain": 117, "csum": 117, "_plot_the_explained_variance_exercis": 117, "_data_reconstruction_video": 117, "reconstruct_data": 117, "x_mean": 117, "_data_reconstruction_exercis": 117, "_reconstruct_the_data_matrix_using_different_numbers_of_pcs_interactive_demo_and_discuss": 117, "100th": 117, "500th": 117, "700th": 117, "_visualization_of_the_weights_exercis": 117, "inflat": 117, "implic": [117, 149], "salt": 117, "pepper": 117, "score_noisi": 117, "evectors_noisi": 117, "evals_noisi": 117, "variance_explained_noisi": 117, "_add_noise_to_the_data_bonus_exercis": 117, "x_noisy_mean": 117, "projx_noisi": 117, "_denoising_bonus_exercis": 117, "w1d4_t4": 118, "visualize_compon": 118, "component1": 118, "component2": 118, "categori": [118, 125, 126, 145], "_pca_applications_video": 118, "reload": 118, "x_all": 118, "labels_al": 118, "pca_model": 118, "pcaifittedpca": 118, "_base": 118, "_pca": 118, "x_new": 118, "_visualization_of_mnist_in_2d_using_pca_exercis": 118, "_pca_visualization_discuss": 118, "_nonlinear_methods_video": 118, "manifold": [118, 126], "tsne_model": 118, "fit_transform": [118, 126], "_t_sne": 118, "csr": 118, "csc": 118, "coo": 118, "barnes_hut": 118, "emb": 118, "_apply_tsne_on_mnist_exercis": 118, "explore_perplex": 118, "perp": 118, "redefin": 118, "_run_tsne_with_different_perplexities_exercis": 118, "_tsne_visualization_discuss": 118, "openreview": 120, "id": [120, 148, 150, 175], "bjjsrmfcz": 120, "lillicrap": 120, "beaudoin": 120, "bogacz": 120, "christensen": 120, "1761": 120, "1770": 120, "0520": 120, "ncbi": [120, 134, 178], "nlm": [120, 134, 178], "nih": [120, 134, 178], "gov": [120, 134, 178], "pmc": [120, 134, 178], "pmc7115933": 120, "convolut": [120, 122], "2031": 120, "jocn_a_01544": 120, "07092": 120, "dnn": 120, "khosla": [120, 173, 176], "torralba": 120, "hierarch": [120, 125], "srep27755": 120, "hasson": 120, "nastas": 120, "evolutionari": 120, "105": [120, 134], "416": 120, "434": 120, "heuer": 120, "gulban": 120, "bazin": 120, "osoianu": 120, "valabregu": 120, "santin": 120, "toro": 120, "neocort": [120, 143, 147, 149], "phylogenet": 120, "primat": [120, 125, 134], "speci": [120, 172], "291": 120, "04": [120, 152, 168, 200, 201], "zhou": 120, "lapedriza": 120, "detector": 120, "cnn": 120, "iclr": 120, "san": 120, "diego": 120, "ca": 120, "usa": 120, "1412": 120, "6856": 120, "bau": 120, "ieee": [120, 134, 178], "transact": [120, 134, 178], "2131": 120, "2145": 120, "1109": [120, 134, 178], "tpami": 120, "2858759": 120, "stringer": [120, 124, 125, 126, 127], "e15": 120, "679324": 120, "merel": 120, "brackbil": 120, "heitman": 120, "recurr": [120, 134, 158], "toulon": 120, "franc": 120, "hkei22jeg": 120, "cadena": 120, "denfield": 120, "walker": [120, 191], "gati": 120, "tolia": 120, "ecker": 120, "macaqu": 120, "e1006897": 120, "1006897": 120, "mcintosh": 120, "nayebi": 120, "a1d33d0dfec820b41b54430b50e96b5c": 120, "sinz": 120, "cobo": 120, "muhammad": 120, "froudaraki": 120, "fahei": 120, "incept": 120, "2060": 120, "2065": 120, "0517": 120, "guclu": 120, "gerven": 120, "stream": [120, 170, 175, 190], "10005": 120, "10014": 120, "5023": 120, "khaligh": 120, "razavi": 120, "unsupervis": [120, 134, 148, 150], "IT": [120, 125], "e1003915": 120, "1003915": 120, "mohsenzadeh": [120, 126], "mullin": 120, "lahner": 120, "peripheri": 120, "s41598": 120, "61409": 120, "yamin": 120, "hong": 120, "cadieu": 120, "solomon": 120, "seibert": 120, "dicarlo": 120, "8619": 120, "8624": 120, "1403112111": 120, "pmc4060707": 120, "goh": 120, "e6": 120, "00006": 120, "ren": 120, "770": 120, "778": 120, "ieeexplor": 120, "stamp": 120, "jsp": 120, "arnumb": 120, "7780459": 120, "ioff": 120, "szegedi": 120, "448": [120, 148], "456": [120, 176], "pmlr": 120, "mlr": 120, "v37": 120, "ioffe15": 120, "xu": [120, 178], "taylor": 120, "studer": 120, "a41b3bb3e6b050b6c9067c67f663b915": 120, "neuralnetworksanddeeplearn": 120, "chap4": 120, "olah": 120, "conv": [120, 125, 126, 127, 191, 192], "modular": 120, "colah": 120, "jozwik": 120, "storr": 120, "outperform": 120, "1726": [120, 152], "fpsyg": 120, "01726": 120, "dougla": 120, "1148": 120, "1160": 120, "0210": 120, "pmc6706072": 120, "kietzmann": 120, "spoerer": 120, "s\u00f6rensen": 120, "hauk": 120, "116": [120, 127, 134, 143], "21854": 120, "21863": 120, "1905544116": 120, "kubiliu": 120, "schrimpf": 120, "kar": 120, "rajalingham": 120, "majaj": 120, "nips2019": 120, "santoro": 120, "marri": 120, "akerman": 120, "hinton": 120, "335": 120, "346": 120, "0277": 120, "ora": 120, "ox": 120, "ac": 120, "uuid": 120, "862189c1": 120, "0088": 120, "4f78": 120, "b17a": 120, "2748c2019209": 120, "download_fil": 120, "safe_filenam": 120, "lillicrap_v6_2020": 120, "file_format": 120, "type_of_work": 120, "nili": 120, "wingfield": 120, "walther": 120, "su": 120, "marslen": 120, "e1003553": 120, "1003553": 120, "issa": 120, "407007": 120, "mehrer": 120, "charest": 120, "e1008215": 120, "1008215": 120, "inferior": 120, "2044": 120, "2064": 120, "jocn_a_01755": 120, "ubn": 120, "ru": 120, "nl": 120, "bitstream": [120, 194], "2066": 120, "237374": 120, "tang": 120, "lotter": 120, "moerman": 120, "pared": 120, "caro": 120, "kreiman": 120, "8835": 120, "8840": 120, "1719397115": 120, "chamber": 120, "seethapathi": 120, "saluja": 120, "loeb": 120, "pierc": 120, "bogen": 120, "infant": [120, 122, 201], "neuromotor": 120, "rehabilit": 120, "2431": 120, "2442": 120, "tnsre": 120, "3029121": 120, "pmc8011647": 120, "w1d5_daysummari": 121, "aud": [122, 125], "propag": [122, 124, 145, 173, 175], "taskonomi": 122, "reward": [122, 185, 187, 191, 192], "w1d5_intro": 122, "w1d5_outro": 123, "_outro_video1": 123, "_outro_video2": 123, "jorg": [124, 125, 126, 127], "menendez": [124, 125, 126, 127], "carsen": [124, 125, 126, 127], "thrive": 124, "w1d5_t1": 124, "mpl": [124, 125, 126, 127, 166], "plot_data_matrix": [124, 127], "plot_train_loss": 124, "train_loss": [124, 127], "load_data": [124, 126, 127], "data_nam": [124, 125, 126, 127], "bin_width": [124, 126, 127], "679324v2": [124, 125, 126, 127], "calcium": [124, 125, 126, 127, 149, 176], "smoother": [124, 126, 127, 147, 175], "resp": [124, 126, 127], "n_stimuli": [124, 125, 126, 127], "mention": [124, 125, 126, 127, 147, 148, 149, 175, 176], "360": [124, 126, 127], "stimuli_bin": [124, 126, 127], "resp_bin": [124, 126, 127], "resp_tensor": [124, 126, 127], "stimuli_tensor": [124, 125, 126, 127], "unsqueez": [124, 125, 126, 127], "singleton": [124, 126, 127, 176], "n_stim": [124, 127], "train_data": [124, 126, 127], "train_label": [124, 126, 127], "radian": [124, 125, 126, 127], "istim": [124, 127], "ori": [124, 125, 126, 127], "w3d4_stringer_oribinned1": [124, 126, 127], "683xc": [124, 126, 127], "436599dfd8ebe6019f066c38aed20580": [124, 126, 127], "_decoding_from_neural_data_video": 124, "front": 124, "photon": 124, "thousand": [124, 189], "24000": 124, "circ": [124, 127], "resp_al": [124, 127], "stimuli_al": [124, 127], "ineuron": [124, 126, 127], "stimuli_train": [124, 127], "resp_train": [124, 125, 127], "stimuli_test": [124, 127], "resp_test": [124, 125, 127], "ishuffl": [124, 126, 127], "randperm": [124, 126, 127], "itrain": [124, 127], "itest": [124, 127], "entail": 124, "r_n": 124, "infrastructur": 124, "deepnet": 124, "declar": [124, 125], "in_lay": [124, 127], "out_lay": [124, 127], "sent": [124, 191], "parent": [124, 127], "_nonlinear_activation_functions_video": 124, "relu": [124, 125, 126, 127, 156], "sole": 124, "tanh": [124, 156], "rectif": 124, "ctifi": 124, "inear": 124, "nit": 124, "nonsens": 124, "139": 124, "_nonlinear_activations_exercis": 124, "_loss_functions_and_gradient_descent_video": 124, "nowher": 124, "shortli": [124, 125, 150, 189], "y_p": 124, "42949": 124, "dw": [124, 150], "accordingli": [124, 127, 140, 149, 158], "realiti": 124, "rocki": 124, "gif": [124, 125], "blob": 124, "grad_desc": 124, "lr": [124, 126, 127], "blank": 124, "learning_r": [124, 126, 127], "12219": [124, 127], "759": [124, 127], "1672": [124, 127], "731": [124, 127], "548": [124, 127], "097": [124, 127], "235": [124, 127], "619": [124, 127], "144": [124, 127, 166], "_gradient_descent_in_pytorch_exercis": 124, "monkei": [124, 172, 176], "xor": [124, 182], "drastic": [124, 183], "neat": 124, "truli": [124, 141, 191], "said": [124, 125, 139], "prone": 124, "rescu": 124, "grad": 124, "leftarrow": [124, 189, 190, 191, 201], "minima": [124, 166, 190], "odot": [124, 166], "prime": 124, "hadamard": [124, 166], "elementwis": [124, 173], "infeas": [124, 176, 201], "bypass": 124, "demand": 124, "subsampl": [124, 200], "induc": [124, 149, 150, 199], "whatev": 124, "suffic": 124, "w1d5_t2": 125, "show_stimulu": [125, 126], "img": [125, 126, 175], "conv_channel": [125, 127], "wmax": [125, 127], "cb_ax": 125, "add_ax": [125, 127, 164, 165], "plot_example_activ": 125, "load_data_split": [125, 127], "imaging": [125, 126, 127], "repsons": [125, 127], "resp_train_tensor": [125, 127], "resp_test_tensor": [125, 127], "out_channel": [125, 126, 127], "wide_gaussian": [125, 126, 127], "center_surround": [125, 126, 127], "lam": [125, 126, 127, 138, 139, 140, 141], "newaxi": [125, 126, 127, 141, 176, 191, 192], "sf": [125, 126, 127], "640": [125, 126, 127], "480": [125, 126, 127], "deg2rad": [125, 126, 127], "wpix": [125, 126, 127], "hpix": [125, 126, 127], "xcent": [125, 126, 127], "ycent": [125, 126, 127], "xxc": [125, 126, 127], "yyc": [125, 126, 127], "icirc": [125, 126, 127], "w3d4_stringer_oribinned6_split": [125, 127], "p3aeb": [125, 127], "b3f7245c6221234a676b71a1f43c3bb5": [125, 127], "slid": 125, "k_x": 125, "k_y": 125, "miro": 125, "medium": 125, "5bwzuqaqffp5f3wkyq6wjg": 125, "_2d_convolutions_video": 125, "revolution": 125, "alexnet": 125, "depict": 125, "downsampl": 125, "attach": [125, 126, 127, 174], "proxim": 125, "stride": [125, 127], "convolutionallay": 125, "conv2d": [125, 126, 127], "barrel": 125, "whisker": 125, "unsolv": 125, "advent": 125, "790": 125, "1okwhewf5kctipafib4xaa": 125, "counterpart": [125, 192], "substanti": [125, 158, 166, 175, 176, 182], "versu": [125, 141, 173, 174, 176, 198], "n_col": [125, 126], "0f": [125, 126, 127], "c_in": [125, 126, 127, 148], "c_out": [125, 126, 127], "kernel_s": [125, 126, 127], "predesign": 125, "example_filt": [125, 127], "48": [125, 126, 147, 201], "convout": 125, "in_channel": 125, "convlay": [125, 127], "h_in": [125, 126], "w_in": [125, 126, 127], "_2d_convolution_in_pytorch_exercis": 125, "_output_and_weight_shapes_conv_layer_discuss": 125, "vocabulari": 125, "teas": 125, "wherebi": [125, 126], "union": 125, "firstli": [125, 126], "mammalian": [125, 126], "mammal": 125, "secondli": [125, 126], "_visualizing_convolutional_filter_weights_bonus_exercis": 125, "emploi": 125, "hook": [125, 126], "_complex_cell_bonus_discuss": 125, "yalda": 126, "shed": 126, "rsa": 126, "w1d5_t3": 126, "zscore": 126, "plot_corr_matrix": 126, "plot_multiple_rdm": 126, "rdm_dict": 126, "resp_dict": 126, "plot_rdm_rdm_correl": 126, "rdm_sim": 126, "nwith": [126, 158], "plot_rdm_row": 126, "ori_list": 126, "rdm_ori": 126, "ori_plot": 126, "iori": 126, "nto": 126, "tilt": 126, "maxpool2d": 126, "fc": 126, "convolv": [126, 191, 192], "kpool": 126, "10d": 126, "0005": 126, "cf": 126, "appendix": [126, 175, 198], "minibatch_data": 126, "minibatch_label": 126, "2e": [126, 147], "get_hidden_act": 126, "layer_label": 126, "hidden_act": 126, "module_label": 126, "_modul": 126, "argwher": [126, 198], "register_forward_hook": 126, "children": 126, "pred": [126, 175], "_deep_convolutional_network_for_orientation_discrimination_video": 126, "conceiv": 126, "courtesi": 126, "10e": 126, "17e": 126, "32e": 126, "27e": 126, "15e": 126, "resp_v1": 126, "resp_model": 126, "aggreg": 126, "_quantitative_comparisons_of_cnns_and_neural_activity_video": 126, "zz": [126, 165], "zresp": 126, "_compute_rdms_exercis": 126, "_solution_discussion_video": 126, "m_": [126, 172, 173, 174, 175, 182], "ss": 126, "overcount": 126, "moreov": [126, 145, 154, 183], "correlate_rdm": 126, "rdm1": 126, "rdm2": 126, "ioffdiag": 126, "triu_indic": 126, "rdm1_offdiag": 126, "rdm2_offdiag": 126, "rdm_model": 126, "rdm_v1": 126, "pop": 126, "_correlate_rdms_exercis": 126, "55": [126, 147, 148, 149, 150, 164, 165, 192], "plot_resp_lowd": 126, "resp_lowd": 126, "twilight": 126, "_vizualizing_reduced_dimensionality_representations_discuss": 126, "fourier": 126, "convfc": [126, 127], "lfloor": 126, "rfloor": 126, "convpoolfc": 126, "neighbor": [126, 189], "leftrightarrow": [126, 198], "gd": [126, 127], "gather": [126, 139, 182], "z_i": 126, "z_n": 126, "ddot": 126, "w1d5_t4_bonu": 127, "plot_decoded_result": 127, "test_loss": 127, "test_label": 127, "predicted_test_label": 127, "n_class": 127, "class_bin": 127, "visualize_weight": 127, "w_in_sort": 127, "w_out": 127, "visualize_hidden_unit": 127, "plot_tun": 127, "respi_train": 127, "respi_test": 127, "neuron_index": 127, "plot_predict": 127, "plot_training_curv": 127, "identitylin": 127, "lim": [127, 198, 199, 200], "minval": 127, "maxval": 127, "equal_lim": 127, "stimulus_class": 127, "accomod": 127, "regularized_mse_loss": 127, "l2_penalti": 127, "l1_penalti": 127, "scala": 127, "penalti": [127, 165], "cuda": 127, "is_avail": 127, "runtim": 127, "hardwar": 127, "opim": 127, "obstacl": [127, 191], "23589": 127, "gaussian_filter1d": 127, "resp_smooth": 127, "preferred_orient": 127, "resort": 127, "isort": 127, "_visualizing_weights_exercis": 127, "b_in": 127, "_interpreting_weights_discuss": 127, "weren": 127, "axtick": 127, "troubl": 127, "_delving_into_error_problems_discuss": 127, "359": [127, 134], "2b": [127, 139, 174], "3b": 127, "p_c": 127, "softmax": 127, "logsoftmax": 127, "l_i": 127, "deepnetsoftmax": 127, "logprob": 127, "logp": 127, "nllloss": 127, "test_data": 127, "n_iter": [127, 183], "decode_orient": 127, "train_binned_label": 127, "test_binned_label": 127, "out_label": 127, "frac_correct": 127, "252": 127, "600": 127, "259": [127, 138], "265": 127, "861": 127, "_a_new_loss_function_exercis": 127, "regularized_loss": 127, "227": 127, "477": 127, "167": [127, 139], "412": 127, "142": 127, "370": 127, "361": 127, "875": 127, "_add_regularization_to_training_exercis": 127, "_convolutional_encoding_model_video": 127, "grating_stimuli": 127, "neuronsto": 127, "_number_of_units_and_weights_discuss": 127, "custom_loss": 127, "param_group": 127, "conv1d": 127, "normal_": 127, "8895": 127, "8836": 127, "0868": 127, "0772": 127, "4668": 127, "4840": 127, "2341": 127, "1072": 127, "1456": 127, "0767": 127, "0685": 127, "140": 127, "0661": 127, "1068": 127, "160": [127, 192], "0650": 127, "1059": 127, "0644": 127, "1054": 127, "0639": 127, "1050": [127, 178], "_add_linear_layer_exercis": 127, "ineur": 127, "w2d1_daysummari": 129, "kick": 130, "accompani": 130, "regret": [130, 190], "forgot": 130, "w2d1_intro": 130, "w2d1_outro": 131, "revis": [132, 166, 175, 176], "w2d1_t1": 132, "_introduction_to_tutorial_video": 132, "_asking_a_question_video": 132, "_asking_your_own_question_discuss": 132, "_literature_review_and_background_knowledge_video": 132, "_literature_review_discuss": 132, "_submit_your_feedback_video": 132, "_determine_your_basic_ingredients_discuss": 132, "_formulating_your_hypothesis_video": 132, "_formulating_your_hypothesis_discuss": 132, "2002": [132, 152, 168], "03211v1": 132, "ekaterina": [133, 142, 151], "morozova": [133, 142, 151], "costa": 134, "aham": 134, "1501": [134, 194], "1510": 134, "1813476116": 134, "billeh": 134, "cai": 134, "gratii": 134, "iyer": 134, "gouwen": 134, "arkhipov": 134, "106": [134, 178], "388": 134, "403": [134, 178], "040": 134, "botvinick": [134, 185], "brodi": 134, "6128": 134, "1233912": 134, "kutz": 134, "258": 134, "010": [134, 189], "gilson": 134, "burkitt": 134, "grayden": 134, "hemmen": 134, "plastic": [134, 145], "strengthen": [134, 150], "cybernet": [134, 143], "102": [134, 168, 173, 178], "0319": 134, "aravkin": 134, "autoregress": [134, 201], "siam": 134, "2335": 134, "2358": 134, "1137": 134, "20m1338058": 134, "1905": 134, "08389": 134, "1952": [134, 143], "nerv": [134, 143], "117": [134, 143], "544": [134, 178], "1113": [134, 143], "jphysiol": [134, 143], "sp004764": [134, 143], "hu": 134, "cain": 134, "mihala": 134, "shea": [134, 148], "motif": [134, 150, 152], "062312": 134, "1103": [134, 194], "physrev": 134, "izhikevich": [134, 143], "burst": [134, 176], "blei": 134, "1610": 134, "08466": 134, "mant": 134, "sussillo": 134, "newsom": [134, 172], "prefront": [134, 185], "503": 134, "7474": 134, "nature12742": 134, "pmc4121670": 134, "morrison": 134, "curto": 134, "combinatori": 134, "241": 134, "277": [134, 178], "academ": [134, 160], "b978": 134, "814066": 134, "00008": 134, "1804": 134, "01487": 134, "litwin": 134, "doiron": [134, 148], "microcircuit": 134, "e1004458": 134, "1004458": 134, "josi\u0107": [134, 148], "e1005583": 134, "1005583": 134, "seung": 134, "13339": 134, "13344": 134, "usher": 134, "mcclelland": [134, 189], "compet": [134, 150], "108": [134, 191], "550": 134, "1037": 134, "0033": 134, "295x": 134, "s41467": 134, "10772": 134, "kaufman": 134, "foster": 134, "nuyujukian": 134, "487": 134, "7405": 134, "nature11129": 134, "pmc3393826": 134, "gilja": 134, "pandarinath": 134, "blabe": 134, "simer": 134, "sarma": 134, "henderson": 134, "prosthesi": 134, "medicin": 134, "1142": 134, "1145": [134, 194], "nm": 134, "pmc4805425": 134, "kao": 134, "ncomms8759": 134, "935": 134, "945": 134, "tbme": 134, "2582691": 134, "nonhuman": 134, "66": [134, 192], "jproc": 134, "2586967": 134, "pmc7970827": 134, "albit": 134, "sanabria": 134, "saab": 134, "jarosiewicz": 134, "tablet": 134, "paralysi": 134, "e0204566": 134, "pone": [134, 168], "0204566": 134, "jozefowicz": 134, "staviski": 134, "805": 134, "815": 134, "s41592": 134, "0109": 134, "pmc6380887": 134, "soric": 134, "willett": 134, "intracort": 134, "e18554": 134, "18554": 134, "santhanam": 134, "afshar": 134, "prosthes": 134, "1315": 134, "1330": 134, "00097": 134, "annual": [134, 194], "062111": 134, "150509": 134, "visuomotor": 134, "null": [134, 201], "208": [134, 152], "023": 134, "murphi": [134, 152], "rezaii": 134, "avansino": 134, "dorsal": 134, "speech": 134, "e46015": 134, "46015": 134, "trautmann": 134, "lahiri": 134, "103": 134, "292": [134, 175], "308": 134, "vya": 134, "1177": 134, "1186": 134, "249": 134, "092619": 134, "094115": 134, "pmc7402639": 134, "329": 134, "deo": 134, "hochberg": 134, "knob": 134, "premotor": 134, "bodi": 134, "181": 134, "396": 134, "409": 134, "043": 134, "william": [134, 189, 190, 191, 192], "discoveri": [134, 194], "demix": 134, "1099": 134, "015": 134, "nips2008": 134, "w2d2_daysummari": 135, "w2d2_intro": 136, "w2d2_outro": 137, "wen": [138, 139, 140, 141], "alic": [138, 140], "schwarz": [138, 140], "norma": [138, 139, 140, 141], "kuhn": [138, 139, 140, 141, 143, 149], "w2d2_t1": 138, "solve_ivp": 138, "plot_trajectori": 138, "initial_condit": 138, "portrait": [138, 157], "figtitlt": 138, "t_span": 138, "t_eval": 138, "dense_output": 138, "timecolor": 138, "ah1": [138, 140], "ah2": [138, 140], "ah3": 138, "set_size_inch": 138, "bx": 138, "subplots_adjust": 138, "wspace": 138, "plot_streamplot": 138, "x1dot": 138, "x2dot": 138, "log1p": 138, "sca": 138, "streamplot": 138, "cividi": 138, "arrows": 138, "eigenvector1": [138, 139], "eigenvector2": [138, 139], "plot_specific_example_stream_plot": 138, "a_opt": 138, "eigstr": 138, "y_label": [138, 165], "righthand": 138, "hspace": [138, 150], "_linear_dynamical_systems_video": [138, 175], "serv": [138, 139, 140], "govern": [138, 139, 140, 156, 192], "t_i": [138, 176], "sudden": 138, "1b": 138, "integrate_exponenti": 138, "xdot": 138, "_forward_euler_integration_exercis": 138, "\u03b1": [138, 165, 190], "readout_format": [138, 189], "plot_euler_integr": 138, "clunki": 138, "ish": 138, "choppier": 138, "erron": 138, "dip": 138, "lesson": [138, 170, 174, 180, 182], "artifact": [138, 166], "toler": [138, 156, 158], "choppi": 138, "creep": 138, "_forward_euler_integration_interactive_demo_discuss": 138, "imaginari": 138, "oscil": [138, 152, 154, 157, 173, 174, 182, 183], "hertz": 138, "0001": [138, 156, 189], "_oscillatory_dynamics_interactive_demo_discuss": 138, "_multidimensional_dynamics_video": 138, "bigg": [138, 157, 165], "1c": 138, "\ud835\udc651": 138, "\ud835\udc652": 138, "a00": 138, "a01": 138, "a10": 138, "a11": 138, "xdot1": 138, "xdot2": 138, "_sample_trajectories_in_2_dimensions_exercis": 138, "asarrai": [138, 164, 173, 182, 200], "a_option_1": 138, "a_option_2": 138, "a_option_3": 138, "a_option_4": 138, "_varying_a_interactive_demo_discuss": 138, "x0_option_1": 138, "x0_option_2": 138, "x0_option_3": 138, "radii": 138, "ellipt": 138, "_varying_initial_conditions_interactive_demo_discuss": 138, "fortun": [138, 175, 183], "1_0": 138, "2_0": 138, "shrunk": 138, "conjug": 138, "saddl": [138, 158], "hors": 138, "rider": 138, "_interpreting_eigenvalues_and_eigenvectors_discuss": 138, "elli": 139, "stradquist": 139, "markovian": [139, 182, 189], "w2d2_t2": 139, "plot_switch_simul": 139, "plot_interswitch_interval_histogram": 139, "inter_switch_interv": 139, "plot_state_prob": 139, "prob": [139, 164, 173, 176, 182], "_markov_process_video": 139, "mu_": [139, 148, 165, 172, 173, 174], "c2o": 139, "o2c": 139, "req": [139, 147, 148, 157, 164, 165, 173, 202], "ion_channel_open": 139, "switch_tim": 139, "uniti": 139, "myrand": 139, "random_sampl": 139, "2a": [139, 174], "_computing_intervals_between_switches_exercis": 139, "return_count": 139, "undergon": 139, "adopt": 139, "plot_inter_switch_interv": 139, "_varying_transition_probability_values_and_t_interactive_demo_and_discuss": 139, "_k": 139, "x_kp1": 139, "plu": [139, 140, 164, 172, 201], "simulate_prob_prop": 139, "latest": [139, 174], "_probability_propagation_exercis": 139, "settl": [139, 140, 158, 190], "relax": 139, "_continuous_vs_discrete_time_fromulation_video": 139, "eigendecomposit": 139, "988": 139, "98058068": 139, "19611614": 139, "70710678": 139, "whichev": 139, "transient": [139, 149, 158], "83333333": 139, "16666667": 139, "06150861e": 139, "_finding_a_stable_state_discuss": 139, "biraj": [140, 141], "pandei": [140, 141], "face": [140, 165, 175, 190, 201], "w2d2_t3": 140, "plot_random_walk_sim": 140, "nsim": 140, "3a": 140, "plot_mean_var_by_timestep": 140, "plot_ddm": 140, "xinfti": [140, 141], "var_comparison_plot": 140, "plot_dynam": [140, 182], "_ecoli_and_random_walks_video": 140, "gander": 140, "wander": 140, "aimlessli": 140, "bacterium": 140, "odor": 140, "substrat": [140, 185], "seek": [140, 182, 191], "dog": 140, "blindfold": 140, "flail": 140, "brownian": 140, "terminolog": 140, "microscop": 140, "protein": 140, "mintag": 140, "this_step": 140, "random_walk_simul": 140, "nxt": 140, "random_walk_simulator_funct": 140, "_random_walk_simulation_exercis": 140, "bacteria": 140, "2500": 140, "sig2": 140, "mytitl": [140, 141], "sharpli": 140, "_random_walk_and_variance_exercis": 140, "plot_gaussian": [140, 165], "_influence_of_parameter_choice_interactive_demo_and_discuss": 140, "_combining_deterministic_and_stochastic_processes_video": 140, "ddm": [140, 141], "hang": [140, 165], "imperfectli": 140, "land": [140, 191, 192], "simulate_ddm": 140, "standard_norm": [140, 141], "_driftdiffusion_model_exercis": 140, "stimul": [140, 149, 156, 196], "_driftdiffusion_simulation_observations_discuss": 140, "_balance_of_variances_video": 140, "pull": [140, 165, 175, 190], "restor": 140, "ddm_eq_var": 140, "hack": 140, "sweep": 140, "empirical_vari": 140, "analytical_vari": 140, "87": [140, 178], "_computing_the_variances_empirically_exercis": 140, "interplai": [140, 149, 165], "w2d2_t4": 141, "plot_residual_histogram": 141, "stdev": 141, "plot_training_fit": 141, "4b": 141, "build_time_delay_matric": 141, "xprime": 141, "roll": 141, "ar_predict": 141, "ar_model": 141, "error_r": 141, "mismatch": [141, 175], "count_nonzero": 141, "_autoregressive_models_video": 141, "bird": [141, 178], "reformul": 141, "rnk": 141, "lstsq": 141, "rcond": 141, "lam_hat": 141, "_residuals_of_the_autoregressive_model_exercis": 141, "_monkey_at_a_typewriter_video": 141, "alpha_0": 141, "alpha_1": 141, "alpha_2": 141, "alpha_3": 141, "alpha_": [141, 158], "jot": 141, "monkey_at_typewrit": 141, "1010101010101010101010101010101010101010101010101": 141, "100100100100100100100100100100100100100": 141, "char": 141, "char2arrai": 141, "_understanding_autoregressive_parameters_discuss": 141, "notori": 141, "terribl": 141, "yr": 141, "laptop": 141, "jab": 141, "10010101001101000111001010110001100101000101101001010010101010001101101001101000011110100011011010010011001101000011101001110000011111011101000011110000111101001010101000111100000011111000001010100110101001011010010100101101000110010001100011100011100011100010110010111000101": 141, "test_monkei": 141, "00100101100001101001100111100101011100101011101001010101000010110101001010100011110": 141, "randint": 141, "unpredict": 141, "jitter": 141, "_fitting_ar_models_exercis": 141, "x1_test": 141, "x2_test": 141, "err": 141, "rr": 141, "test_error": 141, "sweet": 141, "6th": 141, "gerstner": [143, 152], "kistler": [143, 152], "naud": [143, 145, 147, 148, 149, 150, 152], "katz": 143, "giant": 143, "loligo": 143, "424": 143, "sp004716": 143, "fitzhugh": 143, "nagumo": 143, "scholarpedia": 143, "1349": 143, "4249": 143, "1955": 143, "bulletin": 143, "257": 143, "278": [143, 175], "bf02477753": 143, "hakim": 143, "richardson": 143, "149": 143, "155": 143, "326": [143, 150], "5951": 143, "379": 143, "380": 143, "1181936": 143, "infosci": 143, "epfl": [143, 152], "142067": 143, "naud09": 143, "jolivet": 143, "kobayashi": 143, "rauch": 143, "shinomoto": 143, "417": [143, 152], "118680": 143, "jolivet08": 143, "lewi": 143, "959": 143, "976": 143, "00190": 143, "larkum": 143, "nevian": 143, "sandler": 143, "polski": 143, "schiller": 143, "tuft": 143, "dendrit": [143, 145], "pyramid": 143, "325": [143, 150], "5941": 143, "756": [143, 178], "760": 143, "1171958": 143, "poirazi": [143, 145], "brannon": 143, "mel": 143, "989": [143, 175], "s0896": 143, "6273": 143, "00149": 143, "aertsen": [143, 148, 149], "rotter": [143, 149], "2345": 143, "2356": 143, "3349": 143, "markram": 143, "tsodyk": [143, 152], "redistribut": 143, "efficaci": [143, 147, 149], "6594": 143, "807": 143, "810": 143, "382807a0": 143, "5323": 143, "5328": 143, "steven": 143, "1995": [143, 160, 178, 183], "depress": [143, 150], "795": 143, "802": [143, 148], "0896": 143, "90223": 143, "nelson": [143, 185], "tame": 143, "beast": 143, "1178": 143, "1183": 143, "81453": 143, "bi": [143, 148, 165], "poo": 143, "modif": [143, 150], "cultur": 143, "hippocamp": [143, 185], "10464": 143, "10472": 143, "song": 143, "competit": [143, 185], "hebbian": 143, "919": 143, "926": 143, "78829": 143, "w2d3_daysummari": 144, "upi": 145, "bhalla": 145, "irregular": [145, 148, 149, 152], "synchroni": 145, "yiota": 145, "morpholog": 145, "w3d5": [145, 154], "dysfunct": [145, 178], "w2d3_intro": 145, "w2d3_outro": 146, "qinglong": [147, 148, 149, 150, 156, 157, 158], "gu": [147, 148, 149, 150, 156, 157, 158], "songtin": [147, 148, 149, 150, 156, 157, 158], "lorenzo": [147, 148, 149, 150, 156, 157, 158], "fontolan": [147, 148, 149, 150, 156, 157, 158], "w2d3_t1": 147, "plot_volt_trac": [147, 149], "par": [147, 148, 149, 150, 156, 157, 158], "trajetori": [147, 149], "volt": [147, 149], "range_t": [147, 148, 149, 150, 156, 157, 158], "sp_num": [147, 149, 150], "nicer": [147, 149], "npotenti": 147, "plot_gwn": 147, "i_gwn": [147, 148, 149], "pa": [147, 148, 149], "my_hist": 147, "isi1": 147, "isi2": 147, "cv1": 147, "cv2": 147, "sigma1": [147, 165], "sigma2": [147, 165], "my_bin": [147, 148], "_lif_model_video": 147, "laurenc": 147, "eqn": 147, "mimick": [147, 148], "exceed": 147, "default_par": [147, 148, 149, 157, 158], "simulation_tim": 147, "time_step": [147, 156, 157, 158], "new_param": 147, "ns": [147, 148, 149], "v_init": [147, 148, 149, 150], "tref": [147, 148, 149, 150], "000e": 147, "997e": 147, "998e": 147, "999e": 147, "run_lif": [147, 148], "iinj": [147, 148, 149], "puls": 147, "rec_v": [147, 148, 149, 150], "rec_sp": 147, "lt": [147, 148, 149, 150, 156, 157, 158, 183], "rec_spik": [147, 148, 149, 150], "tr": [147, 148, 149, 150], "counter": [147, 148], "_lif_model_exercis": 147, "_response_lif_model_video": 147, "cosmet": 147, "rheobas": 147, "i_dc": 147, "diff_dc": 147, "210": 147, "_parameter_exploration_of_dc_input_amplitude_interactive_demo_and_discuss": 147, "vivo": [147, 149, 189, 201], "mimic": 147, "my_gwn": [147, 148, 149], "myse": [147, 148, 149, 150, 156, 158], "amplitut": [147, 148, 149, 150, 156, 158], "mu_gwn": 147, "diff_gwn_to_lif": 147, "_gaussian_white_noise_interactive_demo_and_discuss": 147, "clock": [147, 148], "_analyzing_gwn_effects_on_spiking_discuss": 147, "textbf": 147, "clocklik": 147, "diff_std_affect_fi": 147, "spk_count": 147, "spk_count_dc": 147, "v_dc": 147, "rec_sp_dc": 147, "_f_i_explorer_interactive_demo_and_discuss": 147, "isi_cv_lif": 147, "spike_train": [147, 148, 150], "sig_gwn1": 147, "sig_gwn2": 147, "i_gwn1": 147, "sp1": [147, 148], "i_gwn2": 147, "sp2": [147, 148], "_compute_cv_isi_exercis": 147, "cv_isi": [147, 149], "FOr": 147, "_spike_irregularity_interactive_demo_and_discuss": 147, "shot": [147, 148], "my_ou": [147, 156, 158], "i_ou": [147, 156, 158], "tau_ou": [147, 156, 158], "sig_ou": [147, 156, 158], "mu_ou": 147, "190": 147, "220": 147, "lif_with_": 147, "regularli": [147, 149], "kept": [147, 175], "_lif_explorer_with_ou_input_bonus_interactive_demo_and_discuss": 147, "_extension_to_integrate_and_fire_bonus_video": 147, "lif": [148, 156], "w2d3_t2": 148, "example_plot_mycc": 148, "50000": 148, "r12": 148, "i1gl": 148, "i2gl": 148, "correlate_input": 148, "my_cc": 148, "my_raster_poisson": 148, "ffunction": 148, "exce": [148, 150, 158], "rater": 148, "plot_c_r_lif": 148, "mycolor": [148, 157, 158], "mylabel": [148, 157, 158], "polyfit": 148, "c_rang": 148, "v_l": [148, 149, 150], "mebran": [148, 149, 150], "lif_output_cc": 148, "bin_siz": 148, "coe": 148, "sp_rate": 148, "i_trial": 148, "sp1_count": 148, "sp2_count": 148, "poisson_gener": [148, 149, 150], "coincid": 148, "uni": 148, "direction": 148, "gap": 148, "junction": 148, "stronger": [148, 150, 201], "forthcom": 148, "impair": 148, "_input_and_output_correlations_video": 148, "unconnect": 148, "i_i": [148, 158], "xi_i": 148, "xi_c": 148, "le": 148, "le1": 148, "whute": 148, "xi_1": 148, "xi_2": 148, "i_j": 148, "pearson": [148, 199], "rodger": 148, "nicewand": 148, "rij": 148, "rxy": 148, "tip1": 148, "a1": 148, "a2": 148, "a3": 148, "b1": 148, "b2": 148, "b3": 148, "tip2": 148, "tip3": 148, "var_i": 148, "var_j": 148, "_compute_the_correlation_exercis": 148, "\ud835\udc36\ud835\udc49isi": 148, "pre_spike_train": [148, 149, 150], "ith": [148, 149, 150], "u_rand": [148, 149, 150], "poisson_train": [148, 149, 150], "generate_corr_poisson": 148, "poi_rat": 148, "mother_r": 148, "mother_spike_train": 148, "sp_mother": 148, "l_sp_mother": 148, "sp_mother_id": 148, "l_sp_corr": 148, "corr_coeff_pair": 148, "r_12": 148, "diff_trial": 148, "simu": 148, "197": 148, "_measure_the_correlation_between_spike_trains_exercis": 148, "aforement": [148, 149], "gwn_mean": 148, "gwn_std": 148, "80000": 148, "starttim": [148, 150], "perf_count": [148, 150], "r12_ss": 148, "sp_ss": 148, "endtim": [148, 150], "timecost": [148, 150], "8000": 148, "09865053105657921": 148, "ic": 148, "_input_output_correlation_discuss": 148, "r12_l": 148, "r12_sl": 148, "sp_l": 148, "sp_sl": 148, "la": [148, 178], "rocha": 148, "rey": 148, "aug": 148, "7155": 148, "_gwn_and_the_correlation_transfer_function_discuss": 148, "campbel": 148, "unphysiolog": 148, "ou": [148, 156, 158], "806": 148, "nature06028": 148, "bujan": 148, "af": 148, "evok": 148, "neocortex": 148, "8611": 148, "4536": 148, "ti": 148, "_correlations_and_network_activity_discuss": 148, "correlogram": 148, "response_of_ensemble_of_neurons_to_time_varying_input_bonus_video": 148, "chemic": 149, "neurotransmitt": 149, "cleft": 149, "permeabl": 149, "partner": 149, "undergo": [149, 150, 189], "w2d3_t3": 149, "my_illus_lifsyn": 149, "v_fmp": 149, "illustart": 149, "fmp": 149, "alongsid": 149, "pot": 149, "my_illus_std": 149, "tau_d": 149, "tau_f": 149, "plot_out": 149, "constantr": 149, "ot": 149, "t_simu": 149, "isi_num": 149, "1e3": 149, "dynamic_syn": 149, "g_bar": 149, "tau_syn": 149, "spt": [149, 150], "gwn": 149, "poissonian": 149, "_static_and_dynamic_synapses_video": 149, "depolar": 149, "hyperpolar": 149, "dg_": 149, "g_e": [149, 150], "g_i": [149, 150, 158], "e_i": 149, "inj": 149, "bombard": 149, "run_lif_cond": 149, "i_inj": 149, "pre_spike_train_ex": [149, 150], "pre_spike_train_in": 149, "gi": 149, "ge_bar": [149, 150], "gi_bar": 149, "vi": 149, "tau_syn_": [149, 150], "tau_syn_i": 149, "pre_spike_train_ex_tot": 149, "pre_spike_train_in_tot": 149, "cv_": 149, "descriptor": 149, "_measure_the_mean_free_membrane_potential_exercis": 149, "ei_isi_regular": 149, "lip": [149, 168], "211": [149, 150, 157, 158], "fontweight": [149, 150, 158], "spk": 149, "fashion": 149, "_lif_explorer_interactive_demo_and_discuss": 149, "_excitatory_inhibitory_balance_discuss": 149, "vesicl": 149, "termin": [149, 189], "influx": 149, "du_e": 149, "u_": 149, "u_0": 149, "5mm": [149, 150], "dg_e": 149, "_e": [149, 157, 158], "spiketim": 149, "ur": 149, "gg": 149, "incur": [149, 191, 192], "phenomenolog": [149, 150], "kinet": 149, "dg": [149, 158], "uncheck": 149, "my_std_diff_r": 149, "_std_explorer_with_input_rate_interactive_demo_and_discuss": 149, "her": [149, 201], "10th": 149, "input_r": 149, "g_1": 149, "g_2": 149, "st": 149, "facilitatori": 149, "delet": [149, 175], "recoveri": [149, 166], "_stf_explorer_with_input_rate_interactive_demo_and_discuss": 149, "therebi": [149, 192], "imping": 149, "run_lif_cond_stp": 149, "u0_": 149, "tau_d_": 149, "tau_f_": 149, "u0i": 149, "tau_di": 149, "tau_fi": 149, "u0_i": 149, "tau_d_i": 149, "tau_f_i": 149, "ne": 149, "ni": 149, "ue": 149, "ge_tot": 149, "ui": 149, "ri": [149, 157, 158], "gi_tot": 149, "tau_ratio": 149, "lif_stp": 149, "t_plot_rang": 149, "400m": 149, "onward": 149, "_lif_with_stp_bonus_interactive_demo": 149, "w2d3_t4_bonu": 150, "my_raster_plot": 150, "raster_plot": 150, "my_example_p": 150, "ltp": 150, "rastert": 150, "color_set": 150, "cyan": 150, "212": [150, 157, 158], "mystdp_plot": 150, "a_plu": 150, "a_minu": 150, "tau_stdp": 150, "time_diff": 150, "biphas": 150, "default_pars_stdp": 150, "ltd": 150, "_stdp_video": 150, "weaken": 150, "latenc": 150, "delta_w": 150, "pre_spik": 150, "post_spik": 150, "_compute_stdp_changes_exercis": 150, "dm": 150, "displaystyl": [150, 156], "sp_or_not": 150, "generate_p": 150, "_compute_dp_exercis": 150, "foral": 150, "run_lif_cond_stdp": 150, "ge_init": 150, "ge_bar_upd": 150, "id_temp": 150, "epsp": 150, "322": 150, "323": 150, "324": 150, "_analyzing_synaptic_strength_discuss": 150, "depotenti": 150, "example_lif_stdp": 150, "inputr": 150, "tsim": 150, "120000": 150, "intputr": 150, "014": 150, "gbar_norm": 150, "620px": 150, "sample_tim": 150, "my_visual_stdp_distribut": 150, "g_di": 150, "049": [150, 178], "15hz": 150, "escap": 150, "_lif_and_stdp_interactive_demo_and_discuss": 150, "example_lif_stdp_corrinput": 150, "i_pr": 150, "figtemp": 150, "iput": 150, "get_text": [150, 182], "legend_handl": 150, "g_dis_cc": 150, "g_dis_dp": 150, "unaffect": [150, 201], "unstructur": 150, "_lif_plasticity_correlated_inputs_interactive_demo_and_discuss": 150, "loooong": 150, "neuronaldynam": 152, "ch4": 152, "cowan": [152, 154], "1972": [152, 157, 158], "s0006": [152, 157, 158], "3495": [152, 157, 158], "86068": [152, 157, 158], "635": 152, "648": 152, "ozeki": 152, "finn": 152, "schaffer": 152, "ferster": 152, "028": 152, "sanzeni": 152, "akitak": 152, "goldbach": 152, "leedi": 152, "widespread": 152, "e54875": 152, "54875": 152, "skagg": 152, "mcnaughton": 152, "1997": [152, 185], "interneuron": 152, "4388": 152, "04382": 152, "rubin": [152, 160, 194, 198], "1994": 152, "2037": 152, "neco_a_00472": 152, "pmc4026108": 152, "1202": 152, "6670": 152, "cerebr": 152, "109": 152, "3373": 152, "3391": 152, "031": [152, 168], "1908": 152, "10101": 152, "hennequin": 152, "lengyel": 152, "attractor": [152, 154, 158], "846": 152, "860": [152, 185], "017": 152, "875534": 152, "hooser": 152, "402": 152, "026": [152, 175], "vreeswijk": 152, "sompolinski": 152, "274": 152, "5293": 152, "1724": 152, "1023": 152, "1008925309027": 152, "01095": 152, "w2d4_daysummari": 153, "_daysummari": [153, 161, 169, 175, 195], "juliana": 154, "georgieva": 154, "ken": 154, "expos": [154, 202], "amplif": 154, "supra": 154, "w2d3": 154, "manifest": 154, "oscillatori": [154, 157, 158, 175], "w2d4_intro": 154, "w2d4_outro": 155, "julijana": [156, 157, 158], "gjorgjieva": [156, 157, 158], "mainli": 156, "signatur": [156, 175, 192], "diseas": [156, 178], "epilepsi": 156, "parkinson": 156, "homogen": 156, "w2d4_t1": 156, "plot_fi": 156, "plot_dr_r": 156, "drdt": 156, "x_fp": [156, 157, 158], "plot_dfdt": 156, "dfdt": 156, "_dynamic_networks_video": 156, "feed": 156, "ext": [156, 157, 158], "default_pars_singl": 156, "i_ext": 156, "r_init": 156, "t_sim": [156, 157, 158], "new_para": [156, 157, 158], "my_func": 156, "hyperbol": 156, "tangent": [156, 157], "_implement_fi_curve_exercis": 156, "interactive_plot_fi": 156, "expecxt": 156, "_parameter_exploration_of_fi_curve_interactive_demo_and_discuss": 156, "simulate_singl": 156, "ana": 156, "myplot_e_diffi_difftau": 156, "r_ana": 156, "_parameter_exploration_of_single_population_dynamics_interactive_demo_and_discuss": 156, "unbound": 156, "_finite_activities_discuss": 156, "_finding_fixed_points_video": 156, "deduc": 156, "compute_drdt": 156, "other_par": [156, 157, 158], "unus": 156, "_visualization_of_the_fixed_points_exercis": 156, "my_fp_singl": 156, "r_guess": 156, "check_fp_singl": 156, "fp": [156, 158], "my_fp_find": 156, "r_guess_vector": 156, "my_wcr": [156, 158], "mytol": [156, 158], "correct_fp": 156, "student_exercis": 156, "_numerical_calculation_of_fixed_points_exercis": 156, "plot_intersection_singl": 156, "r_init_vector": 156, "_fixed_points_inputs_interactive_demo_and_discuss": 156, "plot_single_diffeinit": 156, "vicin": [156, 158], "leftmost": 156, "rightmost": 156, "_dynamics_initial_value_interactive_demo_and_discuss": 156, "04153669901331739": 156, "4471192240898344": 156, "8997171538560865": 156, "_stable_vs_unstable_fixed_points_discuss": 156, "_inhibitory_populations_discuss": 156, "_stability_of_fixed_points_bonus_video": 156, "perturb": [156, 158, 196, 199, 200, 201], "wf": 156, "dfdx": [156, 157, 158], "eig_singl": 156, "r_fp": 156, "eig_fp": 156, "point1": [156, 157, 158], "583": 156, "point2": 156, "447": 156, "498": 156, "point3": 156, "900": 156, "626": 156, "_compute_eigenvalues_bonus_exercis": 156, "ornstein": [156, 158], "uhlenbeck": [156, 158], "uhlenback": 156, "becam": 157, "w2d4_t2": 157, "plot_fi_invers": [157, 158], "f_inv": [157, 158], "plot_fi_ei": [157, 158], "fi_exc": [157, 158], "fi_inh": [157, 158], "my_test_plot": [157, 158], "re1": [157, 158], "ri1": [157, 158], "re2": [157, 158], "ri2": [157, 158], "plot_nullclin": [157, 158], "exc_null_r": [157, 158], "exc_null_ri": [157, 158], "inh_null_r": [157, 158], "inh_null_ri": [157, 158], "my_plot_nullclin": [157, 158], "96": [157, 158, 182], "get_e_nullclin": [157, 158], "get_i_nullclin": [157, 158], "my_plot_vector": [157, 158], "my_n_skip": [157, 158], "myscal": [157, 158], "ei_grid": [157, 158], "dredt": [157, 158], "dridt": [157, 158], "eideriv": [157, 158], "n_skip": [157, 158], "my_plot_trajectori": [157, 158], "x_init": [157, 158], "re_init": [157, 158], "ri_init": [157, 158], "re_tj": [157, 158], "ri_tj": [157, 158], "simulate_wc": [157, 158], "e_grid": [157, 158], "trjectori": [157, 158], "plot_complete_analysi": [157, 158], "nfor": [157, 158], "nlow": [157, 158], "nhigh": [157, 158], "plot_fp": [157, 158], "wee": 157, "wie": [157, 158], "wii": [157, 158], "i_ext_": [157, 158], "i_ext_i": [157, 158], "_phase_analysis_video": 157, "subtyp": 157, "f_e": [157, 158], "f_i": [157, 158], "ae": 157, "ai": 157, "_plot_fi_exercis": 157, "_numerical_integration_of_we_model_exercis": 157, "plot_ei_diffiniti": 157, "_population_trajectories_with_different_initial_values_interactive_demo_and_discuss": 157, "_nullclines_and_vector_fields_video": 157, "n_t": [157, 190], "plot_activity_phas": 157, "r1": [157, 189], "r2": [157, 189], "_time_plane_to_phase_plane_interactive_demo_and_discuss": 157, "1mm": [157, 158], "shere": 157, "ln": [157, 158], "f_invers": [157, 158], "finvers": [157, 158], "_compute_the_nullclines_we_exercis": 157, "travers": 157, "_compute_the_vector_field_exercis": 157, "_analyzing_the_vector_field_discuss": 157, "w2d4_t3_bonu": 158, "_fixed_points_and_stability_video": 158, "my_fp": 158, "check_fp": 158, "x_fp_1": 158, "x_fp_2": 158, "x_fp_3": 158, "_find_the_fixed_points_of_we_exercis": 158, "attract": 158, "yield": 158, "get_eig_jacobian": 158, "eig_1": 158, "eig_2": 158, "eig_3": 158, "62338386": 158, "13110957j": 158, "05720798": 158, "87266898": 158, "95956219": 158, "42197413": 158, "_compute_the_jacobian_exercis": 158, "pitchfork": 158, "bifurc": 158, "plot_nullcline_diffwe": 158, "clip_on": 158, "_effect_of_wee_interactive_demo_and_discuss": 158, "time_constant_effect": 158, "ei_grid_": 158, "ei_grid_i": 158, "_limit_cycle_and_oscillations_interactive_demo": 158, "subpopul": 158, "alpha_i": 158, "noninhibit": 158, "get_dgd": 158, "dgde": 158, "dgdre": 158, "dgdre1": 158, "dgdre2": 158, "dgdre3": 158, "fp1": 158, "fp2": 158, "fp3": 158, "x_fp_lc": 158, "dgdre_lc": 158, "fp_lc": 158, "650": 158, "519": [158, 201], "706": 158, "837": 158, "_compute_dgdre_exercis": 158, "iff": 158, "det": 158, "fw": 158, "isn_i_perturb": 158, "indirectli": [158, 173], "iext": 158, "_nullclines_of_isn_and_nonisn_interactive_demo_and_discuss": 158, "20201": 158, "20202": 158, "se": [158, 201], "outlast": 158, "my_inject": 158, "t_start": 158, "t_lag": 158, "n_start": 158, "n_lag": 158, "i_puls": 158, "l_puls": 158, "wc_with_puls": 158, "2022": [158, 160, 194], "retain": [158, 201], "_persistent_activity_interactive_demo_and_discuss": 158, "treatment": [160, 194, 196, 200, 201], "goldreich": 160, "cn": 160, "nyu": 160, "malab": 160, "bayesianbook": 160, "gelman": 160, "carlin": 160, "stern": 160, "crc": 160, "mcelreath": 160, "rethink": 160, "stan": 160, "stuff": 160, "downei": 160, "reilli": 160, "media": 160, "inc": 160, "kruschk": 160, "jag": 160, "knill": 160, "propel": 160, "welchman": 160, "trommershaus": 160, "landi": 160, "cue": [160, 189], "kass": [160, 194], "w3d1_daysummari": 161, "fish": [162, 165, 170, 172, 173, 180], "astrocat": [162, 170, 180, 183], "rl": [162, 187, 189], "w3d1_intro": 162, "w3d1_outro": 163, "xaq": [164, 165, 172, 173, 174, 175, 182, 183], "pitkow": [164, 165, 172, 173, 174, 175, 182, 183], "w3d1_t1": 164, "fsolv": 164, "namedtupl": [164, 173, 174, 176, 183], "gridspeclayout": 164, "togglebutton": [164, 182], "interactive_output": [164, 165], "clear_output": [164, 165], "filterwarn": [164, 165], "plot_joint_prob": 164, "marginal_i": 164, "marginal_x": 164, "joint_prob": 164, "rect_histx": 164, "rect_histi": 164, "rect_x_cmap": 164, "rect_y_cmap": 164, "matshow": 164, "barh": 164, "ind": 164, "tick_bottom": 164, "tick_left": 164, "silver": [164, 185], "plot_prior_likelihood_posterior": 164, "small_width": 164, "left_spac": 164, "added_spac": 164, "rect_prior": 164, "rect_likelihood": 164, "rect_posterior": 164, "ax_prior": 164, "ax_likelihood": 164, "ax_posterior": 164, "rect_colormap": 164, "tick_right": 164, "set_ticks_posit": 164, "plot_prior_likelihood": 164, "p_a_s1": 164, "p_a_s0": 164, "small_pad": 164, "prior_colormap": 164, "posterior_colormap": 164, "plot_util": 164, "rect_util": 164, "rect_expect": 164, "ax_util": 164, "ax_expect": 164, "plot_prior_likelihood_util": 164, "expected_colormap": 164, "compute_margin": 164, "py": 164, "cor": 164, "p11": 164, "p01": 164, "p10": 164, "p00": 164, "compute_cor_rang": 164, "cmax": 164, "cmin": 164, "_introduction_to_bayesian_statistics_and_decisions_video": 164, "_gone_fishin_video": 164, "losss": 164, "_utility_video": 164, "submarin": 164, "sunburn": 164, "afternoon": 164, "dock": 164, "weigh": [164, 165, 189], "correspondingli": [164, 175], "ps_widget": 164, "make_utility_plot": 164, "outweigh": 164, "_exploring_the_decision_interactive_demo_and_discuss": 164, "_utility_demo_discussion_video": 164, "_likelihood_video": 164, "fisher": 164, "_guessing_the_location_of_the_fish_discuss": 164, "knew": [164, 172], "_correlation_and_marginalization_video": [164, 165], "golden": 164, "cor_widget": 164, "\u03c1": [164, 165, 183], "px_widget": 164, "py_widget": 164, "make_corr_plot": 164, "_covarying_probability_distributions_discuss": 164, "journei": 164, "irrelev": [164, 182], "njoint": 164, "n1": 164, "n2": 164, "n3": 164, "_computing_marginal_probabilities_math_exercis": 164, "caught": [164, 173, 182], "nprior": 164, "nlikelihood": 164, "_computing_marginal_likelihood_math_exercis": 164, "_posterior_beliefs_video": [164, 165], "propto": [164, 165, 166, 173], "intract": 164, "whfere": 164, "bother": 164, "unnorm": 164, "_calculating_a_posterior_probability_math_exercis": 164, "compute_posterior": 164, "p_m": 164, "_computing_posteriors_exercis": 164, "incorrect": [164, 172], "exert": 164, "p_a_s1_widget": 164, "370px": 164, "p_a_s0_widget": 164, "observed_widget": 164, "button_styl": [164, 182], "flex": [164, 165], "widget_ui": [164, 165], "widget_out": [164, 165], "clue": 164, "_what_affects_the_posterior_interactive_demo_and_discuss": 164, "_posterior_beliefs_exercises_discussion_video": 164, "_bayesian_decisions_video": [164, 165], "econom": [164, 178, 187, 189], "ecolog": 164, "300px": 164, "indiffer": 164, "uninform": 164, "_probabilities_vs_utilities_interactive_demo_and_discuss": 164, "_bayesian_decisions_demo_discussion_video": 164, "rho_": [164, 165], "w3d1_t2": 165, "gamma_distribut": 165, "affine2d": 165, "plot_mixture_prior": 165, "gaussian1": 165, "gaussian2": 165, "plot_loss": 165, "mse_loss": 165, "abs_loss": 165, "zero_one_loss": 165, "ax_gau": 165, "ax_error": 165, "gaussian_mixtur": 165, "mu1": [165, 172], "mu2": 165, "deepskyblu": 165, "aquamarin": 165, "plot_utility_mixture_dist": 165, "mu_g": 165, "sigma_g": 165, "mu_loc": 165, "mu_dist": 165, "plot_utility_row": 165, "mu_post": 165, "sigma_post": 165, "product_guassian": 165, "sigma_mix": 165, "mu_mix1": 165, "mu_mix2": 165, "gaus_mix1": 165, "gaus_mix2": 165, "plot_bayes_utility_row": 165, "plot_bayes_row": 165, "plot_mvn2d": 165, "cov12": 165, "mvn2d": 165, "contourf": 165, "plot_margin": 165, "c_x": 165, "c_y": 165, "p_x": 165, "p_y": 165, "mu_x_i": 165, "mu_y_x": 165, "sigma_x_i": 165, "sigma_y_x": 165, "p_x_y": 165, "p_y_x": 165, "p_c_y": 165, "p_c_x": 165, "rect_z": 165, "rect_x": 165, "rect_i": 165, "ax_z": 165, "set_axis_off": 165, "plot_bay": 165, "plot_inform": 165, "mu3": 165, "sigma3": 165, "satellit": 165, "plot_information_glob": 165, "reverse_product": 165, "plot_loss_utility_gaussian": 165, "loss_f": 165, "mu_tru": 165, "plot_loss_util": 165, "plot_loss_utility_mixtur": 165, "calc_mean_mode_median": 165, "calc_loss_func": 165, "calc_expected_loss": 165, "min_expected_loss": 165, "dashdot": 165, "plot_loss_utility_bay": 165, "plot_simple_utility_gaussian": 165, "mu_c": 165, "sigma_c": 165, "plot_utility_gaussian": 165, "plot_utility_mixtur": 165, "mu_m1": 165, "mu_m2": 165, "sigma_m1": 165, "sigma_m2": 165, "plot_utility_uniform": 165, "plot_utility_gamma": 165, "gamma_pdf": 165, "max_util": 165, "plot_bayes_loss_utility_gaussian": 165, "plot_bayes_loss_util": 165, "plot_bayes_loss_utility_uniform": 165, "plot_bayes_loss_utility_gamma": 165, "plot_bayes_loss_utility_mixtur": 165, "expected_loss": 165, "global_loss_plot_switch": 165, "loss_plot_switch": 165, "what_to_plot": 165, "loss_f_opt": 165, "mu_slid": 165, "\u00b5_estim": 165, "continuous_upd": [165, 200], "sigma_slid": 165, "\u03c3_estim": 165, "mu_true_slid": 165, "\u00b5_true": 165, "mu1_slid": 165, "\u00b5_est_p": 165, "mu2_slid": 165, "\u00b5_est_q": 165, "sigma1_slid": 165, "\u03c3_est_p": 165, "sigma2_slid": 165, "\u03c3_est_q": 165, "factor_slid": 165, "\u03c0": 165, "global_plot_prior_switch": 165, "plot_prior_switch": 165, "\u00b5_prior": 165, "\u00b5_likelihood": 165, "\u03c3_prior": 165, "\u03c3_likelihood": 165, "alpha_slid": 165, "\u03b1_prior": 165, "beta_slid": 165, "\u03b2_prior": 165, "offset_slid": 165, "gaus_label": 165, "justify_cont": 165, "gamma_label": 165, "mu_m1_slid": 165, "\u00b5_mix_p": 165, "mu_m2_slid": 165, "\u00b5_mix_q": 165, "sigma_m1_slid": 165, "\u03c3_mix_p": 165, "sigma_m2_slid": 165, "\u03c3_mix_q": 165, "global_plot_bayes_loss_utility_switch": 165, "plot_bayes_loss_utility_switch": 165, "empty_label": 165, "\u03bc": 165, "\u03b2": 165, "mvn": 165, "dstack": 165, "j_1": 165, "j_2": 165, "j_3": 165, "mu_prod": 165, "sigma_prod": 165, "calc": [165, 166], "cdf": 165, "_introduction_video": [165, 173, 175, 176, 189], "astronaut": 165, "jetpack": [165, 180, 183], "thumb": 165, "jet": [165, 183], "pack": [165, 183], "earth": [165, 183], "glimps": 165, "_astrocat_video": 165, "send": 165, "remot": 165, "tenni": 165, "_the_gaussian_distribution_video": 165, "ormal": 165, "clarif": 165, "\u00b5": 165, "_exploring_gaussian_parameters_interactive_demo_and_discuss": 165, "mu_3": 165, "sigma_3": 165, "_multiplying_gaussians_video": 165, "\u00b5_1": 165, "\u00b5_2": 165, "\u03c3_1": 165, "\u03c3_2": 165, "distro_1_label": 165, "distro_2_label": 165, "_multiplying_gaussians_interactive_demo_and_discuss": 165, "multimod": 165, "_mixtures_of_gaussians_video": 165, "\u00b5_p": 165, "\u00b5_q": 165, "\u03c3_p": 165, "\u03c3_q": 165, "mixture_label": 165, "_exploring_gaussian_mixtures_interactive_demo_and_discuss": 165, "_utility_loss_estimators_video": 165, "modal": 165, "_exploring_loss_with_different_distributions_interactive_demo_and_discuss": 165, "safe": [165, 190], "eu": 165, "mu_g_slid": 165, "\u00b5_gain": 165, "mu_c_slid": 165, "\u00b5_cost": 165, "sigma_g_slid": 165, "\u03c3_gain": 165, "sigma_c_slid": 165, "\u03c3_cost": 165, "distro_label": 165, "gain_label": 165, "loss_label": 165, "neutral": 165, "_complicated_cat_costs_interactive_demo_and_discuss": 165, "mu_x": 165, "sigma_x": 165, "anticorrel": 165, "\u00b5_x": 165, "\u00b5_y": 165, "\u03c3_x": 165, "\u03c3_y": 165, "corr_slid": 165, "distro1_label": 165, "distro2_label": 165, "corr_label": 165, "ther": 165, "_covarying_2d_gaussian_interactive_demo_and_discuss": 165, "c_x_slider": 165, "cx": 165, "c_y_slid": 165, "cy": 165, "condition": [165, 175], "_marginalization_and_information_interactive_demo_and_discuss": 165, "2_": [165, 173], "secton": 165, "guassian": 165, "erlang": 165, "chi": 165, "bizarr": 165, "driac": 165, "_prior_exploration_interactive_demo_and_discuss": 165, "cauchi": 165, "unimod": 165, "_standard_loss_functions_with_various_priors_interactive_demo_and_discuss": 165, "dist_label": 165, "\u00b51_c": 165, "\u00b52_c": 165, "loc_label": 165, "mu_dist_slid": 165, "mu_loc_slid": 165, "heavili": [165, 174, 189], "_complicated_cat_costs_with_various_priors_interactive_demo_and_discuss": 165, "vincent": 166, "valton": 166, "jess": [166, 172, 173, 175, 176], "livezei": [166, 172, 173, 175, 176], "outdat": 166, "w3d1_t3_bonu": 166, "plot_myarrai": 166, "plot_my_bayes_model": 166, "ex": 166, "alpha_tri": 166, "nll": 166, "i_tri": 166, "p_independ": 166, "ix": 166, "plot_simulated_behavior": 166, "true_stim": 166, "moments_myfunc": 166, "cdf_function": 166, "noisili": 166, "puppet": 166, "curtain": 166, "speaker": 166, "distant": 166, "hypothetical_stim": 166, "compute_likelihood_arrai": 166, "stim_arrai": 166, "likelihood_arrai": 166, "_auditory_likelihood_exercis": 166, "_prior_array_video": 166, "peakier": 166, "calculate_prior_arrai": 166, "p_indep": 166, "prior_mean_common": 166, "prior_sigma_common": 166, "prior_mean_indep": 166, "prior_sigma_indep": 166, "indep": 166, "prior_common": 166, "prior_indep": 166, "prior_mix": 166, "prior_arrai": 166, "fcn": 166, "_implement_prior_array_exercis": 166, "_posterior_array_video": 166, "calculate_posterior_arrai": 166, "posterior_arrai": 166, "keepdim": [166, 173], "_calculate_posterior_exercis": 166, "_binary_decision_matrix_video": 166, "unobserv": [166, 173, 176, 200, 201], "scan": [166, 175], "x_column": 166, "calculate_binary_decision_arrai": 166, "binary_decision_arrai": 166, "docstr": [166, 182], "_calculate_estimated_response_exercis": 166, "_input_array_video": 166, "generate_input_arrai": 166, "input_arrai": 166, "_generate_input_array_exercis": 166, "_marginalization_video": 166, "snippet": 166, "my_margin": 166, "marginalization_arrai": 166, "_implement_marginalization_matrix_exercis": 166, "gone": 166, "x_stim": 166, "x_hat": [166, 201], "prior_mean": [166, 174], "prior_sigma1": 166, "prior_sigma2": 166, "prior1": 166, "prior2": 166, "prior_combin": 166, "i_stim": 166, "likelihood_mean": 166, "likelihood_sigma": 166, "_loglikelihood_video": 166, "my_bayes_model_ms": 166, "recomput": [166, 190], "trial_ll": 166, "marginal_nonzero": 166, "neg_ll": 166, "_fitting_a_model_to_generated_data_exercis": 166, "went": [166, 191, 192], "katahira": 168, "suzuki": 168, "okanoya": 168, "okada": 168, "birdsong": 168, "e24516": 168, "0024516": 168, "hmm": [168, 170, 174, 175, 182], "serruya": 168, "shaikhouni": 168, "bienenstock": 168, "cursor": 168, "169779d3852b32ce8b1a1724dbf5217d": 168, "kf": [168, 175, 183], "mormann": 168, "malmaud": 168, "huth": 168, "rangel": 168, "pressur": 168, "437": 168, "449": 168, "2139": 168, "ssrn": 168, "1901533": 168, "zoltowski": 168, "yate": 168, "1249": 168, "1258": 168, "demystifi": 168, "vannevar": 168, "ec": 168, "uw": 168, "techsit": 168, "uweetr": 168, "0002": 168, "w3d2_daysummari": 169, "recreat": [170, 189], "plenti": 170, "pervas": 170, "fluoresc": 170, "w3d2_intro": 170, "w3d2_outro": 171, "yicheng": [172, 173, 176], "fei": [172, 173, 176], "melvin": 172, "selim": 172, "atai": 172, "posterior": [172, 173, 174, 175, 180, 182, 183], "w3d2_t1": 172, "erf": 172, "plot_accuracy_vs_stoptim": 172, "stop_time_list": 172, "accuracy_analytical_list": 172, "accuracy_list": 172, "stop_time_list_plot": 172, "sigma_st_max": 172, "stop_tim": 172, "ins": 172, "inset_ax": 172, "mu_st": 172, "sigma_st": 172, "lbl": [172, 173], "crimson": [172, 173, 174, 182], "solid": [172, 202], "domain0": 172, "simulate_and_plot_sprt_fixedtim": 172, "evidence_history_list": 172, "ttotal_evid": 172, "tdecis": 172, "evidence_histori": 172, "mvec": 172, "simulate_sprt_fixedtim": 172, "maxlen_evid": 172, "simulate_and_plot_sprt_fixedthreshold": 172, "threshold_from_errorr": 172, "ttime": 172, "taccumul": 172, "simulate_sprt_threshold": 172, "simulate_and_plot_accuracy_vs_threshold": 172, "threshold_list": 172, "alpha_list": 172, "decision_spe": 172, "simulate_accuracy_vs_threshold": 172, "amin": 172, "amax": 172, "_overview_of_tutorials_video": 172, "identi": 172, "iid": 172, "l_t": [172, 183], "m_t": [172, 173, 174, 175, 183], "tp": 172, "delta_t": 172, "l_": 172, "epsilon_t": [172, 198, 200, 201], "_sequential_probability_ratio_test_video": 172, "m_i": 172, "rewritten": [172, 175], "bt": 172, "log_likelihood_ratio": 172, "logpdf": 172, "llvec": 172, "true_dist": 172, "mu_po": 172, "mu_neg": 172, "p_po": 172, "p_neg": 172, "ll_ratio_vec": 172, "total_evid": 172, "825211": 172, "033974": 172, "121418": 172, "978989": 172, "699630": 172, "214701": 172, "773329": 172, "727977": 172, "286441": 172, "611457": 172, "_simulating_an_sprt_model_exercis": 172, "_trajectories_under_the_fixed_time_stop": 172, "rule_interactive_demo_and_discuss": 172, "_section_1_exercises_discussion_video": [172, 173], "_speed_vs_accuracy_tradeoff_video": 172, "buri": 172, "simulate_accuracy_vs_stoptim": 172, "no_numer": 172, "stop_list_list": 172, "flag": [172, 175], "decisions_list": 172, "tracker": [172, 175], "accuracies_analyt": 172, "i_stop_tim": 172, "sigma_sum_gaussian": 172, "s_t": [172, 173, 174, 175, 182, 183, 189, 191], "snr": [172, 174], "_speed_vs_accuracy_tradeoff_exercis": 172, "inset": 172, "_speed_vs_accuracy_tradeoff_interactive_demo_and_discuss": 172, "_section_2_exercises_discussion_video": 172, "kinematogram": 172, "britten": 172, "movshon": 172, "rightward": 172, "shadlen": 172, "pamela": 172, "reinagl": 172, "youtu": [172, 175, 176], "odxcytn": 172, "0o": 172, "learnt": 172, "_fixed_threshold_on_confidence_bonus_video": 172, "variant": [172, 174], "th_1": 172, "th_0": 172, "th_": 172, "pl": 172, "mul": 172, "has_enough_data": 172, "data_histori": 172, "current_evid": 172, "ll_ratio": 172, "chunk": 172, "log10_alpha": 172, "log10": 172, "817230": 172, "976558": 172, "69": 172, "838498": 172, "963583": 172, "759059": 172, "318346": 172, "022035": 172, "062368": 172, "378682": 172, "943438": 172, "_simulating_the_ddm_with_fixed_confidence_thresholds_bonus_exercis": 172, "_ddm_with_fixed_confidence_threshold_bonus_interactive_demo": 172, "ant": 172, "bee": 172, "rodent": 172, "incentiv": 172, "suppli": 172, "decision_speed_list": 172, "decision_time_list": 172, "decision_list": 172, "decision_tim": 172, "decision_length": 172, "decision_accuraci": 172, "_speed_vs_accuracy_tradeoff_revisited_bonus_exercis": 172, "_speed_vs_accuracy_with_a_threshold_rule_bonus_interactive_demo": 172, "meenakshi": [173, 176], "sleep": [173, 200], "wake": 173, "emiss": [173, 176], "w3d2_t2": 173, "linear_sum_assign": [173, 176], "plot_hmm1": 173, "flag_m": [173, 174], "hmmlearn": 173, "nstep": [173, 189], "aspect_ratio": 173, "states_forplot": 173, "twinx": [173, 174, 182], "maroon": 173, "fill_betweenx": [173, 174], "plot_marginal_seq": 173, "predictive_prob": 173, "switch_prob": 173, "prob_neg": 173, "p_vec": 173, "prob_po": 173, "boxstyl": 173, "wheat": 173, "plot_evidence_vs_noevid": 173, "posterior_matrix": 173, "nsampl": 173, "posterior_mean": [173, 174], "plot_forward_infer": 173, "states_inf": 173, "posterior_prob": 173, "flag_d": 173, "flag_pr": 173, "flag_lik": 173, "flag_post": 173, "gaussianhmm": 173, "states_interpol": 173, "borderaxespad": 173, "bar_scal": 173, "dodgerblu": [173, 174], "wholli": 173, "s_": [173, 174, 175, 183, 189, 191], "d_": 173, "p_t": [173, 175], "_binary_hmm_with_gaussian_measurements_video": 173, "noise_level": 173, "create_hmm": 173, "transmat_": 173, "gaussianhmm1d": [173, 176], "startprob": [173, 176], "startprob_vec": 173, "transmat": [173, 176], "transmat_mat": 173, "means_vec": 173, "vars_vec": 173, "transition_vector": 173, "09355908": 173, "58552915": 173, "93502804": 173, "98819072": 173, "32506947": 173, "_simulating_binary_hmm_with_gaussian_measurements_exercis": 173, "plot_samples_widget": 173, "log10_noise_level": 173, "_binary_hmm_interactive_demo_and_discuss": 173, "_forgetting_in_a_changing_world_video": 173, "s_0": [173, 175], "simulate_prediction_onli": 173, "prob_switch": 173, "entropy_list": 173, "_forgetting_in_a_changing_world_interactive_demo_and_discuss": 173, "_section_2_exercise_discussion_video": 173, "_forward_inference_in_an_hmm_video": 173, "markov_forward": 173, "one_step_upd": 173, "compute_likelihood": 173, "simulate_forward_infer": 173, "rv0": 173, "rv1": 173, "predictive_state1": 173, "posterior_state1": 173, "hte": 173, "condtion": 173, "posterior_tm1": 173, "posterior_t": 173, "_forward_inference_of_hmm_exercis": 173, "log_10_noise_level": 173, "plot_forward_inference_widget": 173, "_forward_inference_of_hmm_interactive_demo": 173, "_section_3_exercise_discussion_video": 173, "rowei": [174, 175], "ghahramani": [174, 175], "mission": [174, 183], "w3d2_t3": 174, "visualize_astrocat": 174, "plot_measur": [174, 182], "y1": 174, "y2": 174, "y3": 174, "y4": 174, "y5": 174, "y6": 174, "process_nois": 174, "measurement_nois": 174, "todays_prior": 174, "info_prior": 174, "info_likelihood": 174, "info_posterior": 174, "prior_weight": 174, "likelihood_weight": 174, "posterior_cov": 174, "todays_posterior": 174, "predicted_estim": [174, 183], "predicted_covari": [174, 183], "innovation_estim": [174, 183], "innovation_covari": [174, 183], "updated_mean": [174, 183], "updated_cov": [174, 183], "paintmyfilt": 174, "initial_guess": 174, "cov_": 174, "filter_s_": 174, "filter_cov_": 174, "process_noise_std": 174, "measurement_noise_std": 174, "smin": 174, "smax": 174, "pscale": 174, "lightgrai": 174, "_astrocat_through_time_video": 174, "_quantifying_astrocat_dynamics_video": 174, "ds_": [174, 175], "w_t": [174, 175, 183], "sigma_p": 174, "actuat": 174, "propuls": 174, "tau_min": 174, "tau_max": 174, "process_noise_min": 174, "process_noise_max": 174, "measurement_noise_min": 174, "measurement_noise_max": 174, "unit_process_nois": 174, "unit_measurement_nois": 174, "s0": 174, "_simulating_astrocats_movements_exercis": 174, "_playing_with_astrocat_movement_interactive_demo_and_discuss": 174, "_exercise_1": 174, "1_discussion_video": 174, "_measuring_astrocats_movements_video": 174, "sigma_measur": 174, "read_collar": 174, "_reading_measurements_from_astrocats_collar_exercis": 174, "_comparing_true_states_to_measured_states_video": 174, "catastroph": 174, "sbound": 174, "_compare_true_states_to_measured_states_exercis": 174, "2_discussion_video": 174, "_the_kalman_filter_video": 174, "15ex": [174, 182, 183], "flag_": 174, "flag_s_": 174, "flag_err_": 174, "stochastic_system": 174, "timelin": [174, 182, 183], "process_noise_cov": 174, "measurement_noise_cov": 174, "prior_cov": 174, "captured_prior": 174, "captured_likelihood": 174, "captured_posterior": 174, "onfilt": 174, "show_pdf": 174, "pdf_likelihood": 174, "pdf_post": 174, "pdf_prior": 174, "_the_kalman_filter_in_action_interactive_demo": 174, "_interactive_demo_2": 174, "_implementing_a_kalman_filter_video": 174, "recip": 174, "broaden": 174, "sigma_w": 174, "sigma_m": 174, "textit": 174, "congrat": 174, "partwai": 174, "_implement_your_own_kalman_filter_exercis": 174, "_exercise_2": 174, "_compare_states_estimates_and_measurements_video": 174, "errorbar": 174, "yerr": 174, "mfc": 174, "mec": 174, "axhist": 174, "pdf_g": 174, "_compare_states_estimates_and_measurements_interactive_demo": 174, "_how_long_does_it_take_to_find_astrocat_video": 174, "hone": 174, "decibel": 174, "equilibr": 174, "snrdb": 174, "pcov": 174, "equilibrium_posterior_var": 174, "equilibrium_process_var": 174, "labelcolor": 174, "set_major_formatt": 174, "funcformatt": 174, "format_func": 174, "nprocess": 174, "_how_long_does_it_take_to_find_astrocat_interactive_demo": 174, "3_discussion_video": 174, "carolin": 175, "haimerl": 175, "cristina": 175, "w3d2_t4_bonu": 175, "sy": 175, "set_printopt": [175, 190], "plot_kalman": 175, "plot_gaze_data": 175, "plot_kf_stat": 175, "mu_0": 175, "n_dim_stat": 175, "initial_state_mean": [175, 183], "w2d3_mit_eyetracking_2009": 175, "jfk8w": 175, "20c7bc4a6f61f49450997e381cf5e0dd": 175, "load_eyetracking_data": 175, "imread": 175, "jpg": 175, "6f_51l3i5aq": 175, "2swh639ygeg": 175, "hs_": 175, "eta_t": 175, "sigma_0": 175, "tractabl": 175, "apolog": 175, "timecours": 175, "n_dim_ob": 175, "sample_ld": 175, "n_timestep": 175, "ob": 175, "286": 175, "527": 175, "_sampling_from_a_linear_dynamical_system_exercis": 175, "explore_dynam": 175, "_adjusting_system_dynamics_interactive_demo": 175, "vbozov9qmoi": 175, "_kalman_filtering_video": 175, "m_1": 175, "sigma_t": 175, "mathsf": 175, "newest": 175, "k_t": 175, "k_th": 175, "hdz_": 175, "kalman_filt": 175, "mu_pr": 175, "sigma_pr": 175, "filtered_state_mean": 175, "filtered_state_covari": 175, "_implement_kalman_filtering_exercis": 175, "m7ouxmvwhgi": 175, "_fitting_eye_gaze_data_video": 175, "devic": 175, "calibr": 175, "ambient": 175, "eyetrack": 175, "databas": 175, "judd": 175, "fixat": 175, "subject_id": 175, "image_id": 175, "plot_subject_trac": 175, "_tracking_eye_gaze_interactive_demo": 175, "influenti": 175, "texttt": 175, "transition_matric": 175, "transition_covari": [175, 183], "observation_matric": 175, "observation_covari": [175, 183], "initial_state_covari": [175, 183], "kalmanfilt": [175, 183], "em_var": 175, "016": 175, "219": 175, "389": 175, "774": 175, "596": 175, "magenta": 175, "triangl": 175, "plot_smoothed_trac": 175, "nonetheless": 175, "kf_state": 175, "kf_data": 175, "environment": [175, 178, 192], "mitig": 175, "arbitrarili": 175, "cb": 175, "4ar2myz1nm": 175, "_kalman_smoothing_and_the_em_algorithm_bonus_video": 175, "j_t": 175, "z_t": 175, "kalman_smooth": 175, "mu_hat": 175, "sigma_hat": 175, "smoothed_state_mean": 175, "smoothed_state_covari": 175, "_implement_kalman_smoothing_bonus_exercis": 175, "963": 175, "087": 175, "dz": 175, "kl": 175, "s_ts_": 175, "j_": [175, 183, 198], "q_0": 175, "s_0s_0": 175, "s_ts_t": 175, "ny_ty_t": 175, "sean": 176, "escola": 176, "w3d2_t5_bonu": 176, "plot_spike_train": 176, "hot": 176, "trial_t": 176, "rect": 176, "add_patch": 176, "tmp": 176, "plot_ll": 176, "plot_lls_ecl": 176, "plot_epoch": 176, "save_v": 176, "minll": 176, "maxll": 176, "inf": 176, "bs": 176, "lls_for_plot": 176, "eclls_for_plot": 176, "ecll": 176, "framealpha": 176, "plot_learnt_vs_tru": 176, "l_true": 176, "a_tru": 176, "run_em": 176, "psi": 176, "flot": 176, "e_step": 176, "print_everi": 176, "psi_new": 176, "a_new": 176, "l_new": 176, "m_step": 176, "interpol": [176, 191, 192], "extrapol": 176, "b_min": 176, "b_max": 176, "b_lim": 176, "num_plot_v": 176, "logpmf": 176, "diff_ll": 176, "ceqxn0ouafo": 176, "wb8mf5chmyi": 176, "_hmm_for_poisson_spiking_neurons_video": 176, "thalam": 176, "relai": 176, "tonic": 176, "rapid": 176, "receptor": 176, "molecular": 176, "n_frozen_tri": 176, "max_firing_r": 176, "max_transition_r": 176, "expens": 176, "ts": 176, "craft": 176, "42": [176, 178, 182, 192, 198, 199, 200, 201], "psi_tru": 176, "xf": 176, "yf": 176, "one_hot": 176, "umu4wuwlkvg": 176, "_em_tutorial_video": 176, "b_i": 176, "pairwis": 176, "gamma_": 176, "xi_": 176, "sum_j": 176, "ji": 176, "a_j": 176, "b_j": 176, "b_": 176, "psi_i": 176, "gamma_i": 176, "compact": 176, "o_j": 176, "o_": 176, "lj": 176, "l1j": 176, "node": [176, 199], "log_a": 176, "log_ob": 176, "maxtmp": 176, "h4ggtg_9bae": 176, "_implement_the_m_step_video": 176, "swapax": 176, "_implement_m_step_exercis": 176, "6utsxxe3hg0": 176, "_running_and_plotting_em_video": 176, "\ud835\udf03": [176, 182], "8684143040628": 176, "481": [176, 178], "5065734432824": 176, "461": 176, "8610532934206": 176, "5662172692457": 176, "9130201971623": 176, "85767087913615": 176, "8475179733076": 176, "84438656802155": 176, "8431170392692": 176, "8425100301998": 176, "84218727724686": 176, "cost_mat": 176, "true_ind": 176, "est_ind": 176, "bertseka": [178, 183], "bellman": 178, "1966": 178, "3731": 178, "charnov": 178, "forag": 178, "129": 178, "136": 178, "doyl": 178, "1978": 178, "lqg": 178, "757": 178, "tac": 178, "1101812": 178, "kalman": 178, "1960": 178, "boletin": 178, "sociedad": 178, "matematica": 178, "mexicana": 178, "119": 178, "kappen": 178, "g\u00f3mez": 178, "opper": 178, "159": 178, "182": 178, "s10994": 178, "5278": 178, "todorov": 178, "11478": 178, "11483": 178, "0710743106": 178, "pmc2705278": 178, "castro": 178, "hadjiosif": 178, "hemphil": 178, "1061": 178, "cub": 178, "brandt": 178, "shadmehr": 178, "disord": 178, "huntington": 178, "6769": 178, "549": 178, "35000576": 178, "harvard": 178, "motorlab": 178, "reprint": 178, "nature00": 178, "sing": 178, "joiner": 178, "nanayakkara": 178, "brayanov": 178, "primit": 178, "575": 178, "589": 178, "wagner": 178, "10663": 178, "10673": 178, "5479": 178, "bautista": 178, "tinbergen": 178, "kacelnik": 178, "fly": 178, "1094": 178, "pmc14713": 178, "ralston": 178, "1958": 178, "international": 178, "zeitschrift": 178, "f\u00fcr": 178, "angewandt": 178, "physiologi": 178, "einschliesslich": 178, "arbeitsphysiologi": 178, "bf00698754": 178, "ahm": 178, "vigor": 178, "neuroeconom": 178, "zee": 178, "saccad": 178, "196": [178, 185], "475": 178, "s00221": 178, "1879": 178, "pmc2771693": 178, "yoon": 178, "geari": 178, "e10476": 178, "e10485": 178, "1812979115": 178, "pmc6217431": 178, "jaleel": 178, "2161": 178, "2172": 178, "00700": 178, "w3d3_daysummari": 179, "w3d3_intro": 180, "w3d3_outro": 181, "zhengwei": [182, 183], "shreya": [182, 183], "saxena": [182, 183], "melisa": 182, "maidana": 182, "capitan": 182, "pomdp": 182, "agent": [182, 187, 189, 190, 191, 192], "w3d3_t1": 182, "isclos": [182, 183], "plot_fish": 182, "fish_stat": 182, "cornflowerblu": 182, "54": [182, 192, 201], "rel_po": 182, "red_i": 182, "blue_i": 182, "royalblu": 182, "plot_act_loc": 182, "ax_loc": 182, "act_down": 182, "act_up": 182, "plot_belief": 182, "choose_polici": 182, "midnightblu": 182, "get_yticklabel": 182, "time_rang": 182, "mea": 182, "ax0": [182, 183], "ax_bel": 182, "belief_histogram": 182, "plot_value_threshold": 182, "threshold_arrai": 182, "value_arrai": 182, "yrang": 182, "star_loc": 182, "fig_": 182, "cost_sw": 182, "fist": 182, "init_t": 182, "rnd_tele": 182, "rnd_high_rwd": 182, "rnd_low_rwd": 182, "get_random": 182, "binomial_tel": 182, "getrandom": 182, "excerciseerror": 182, "assertionerror": [182, 183], "binaryhmm": 182, "fish_initi": 182, "loc_initi": 182, "fish_dynam": 182, "telegraph": 182, "p_stai": 182, "tele_oper": 182, "generate_process_lazi": 182, "rwd": 182, "p_low_rwd": 182, "p_high_rwd": 182, "p_rwd_vector": 182, "binaryhmm_belief": 182, "generate_process": 182, "low_rew_p": 182, "high_rew_p": 182, "rew_prob": 182, "belief_0": 182, "belief_upd": 182, "lazi": 182, "policy_threshold": 182, "policy_lazi": 182, "belief_past": 182, "rew_prob_matrix": 182, "belief_1": 182, "test_policy_threshold": 182, "well_don": 182, "test_value_funct": 182, "get_valu": 182, "value_funct": 182, "_gone_fishing_video": 182, "secretli": 182, "sw": 182, "q_": [182, 190], "price": 182, "prescrib": 182, "b_t": 182, "stay_prob": 182, "update_ex_1": 182, "swim": 182, "binaryhmm_test": 182, "forth": 182, "_examining_fish_dynamics_interactive_demo_and_discuss": 182, "_catch_some_fish_video": 182, "seren": 182, "high_rew_prob": 182, "low_rew_prob": 182, "radiobutton": [182, 183], "update_ex_2": 182, "agent_initi": 182, "_can_": 182, "hei": 182, "_examining_the_reward_function_interactive_demo_and_discuss": 182, "_where_are_the_fish_video": 182, "steepli": 182, "_examining_the_beliefs_interactive_demo_and_discuss": 182, "_how_should_you_act_video": 182, "_dynamics_threshold_based_policy_exercis": 182, "new_se": 182, "update_ex_4": 182, "unlucki": 182, "_dynamics_with_different_thresholds_interactive_demo_and_discuss": 182, "_evaluate_policy_video": 182, "a_t": [182, 183, 191], "paid": 182, "actions_int": 182, "_implementing_a_value_function_exercis": 182, "brute": 182, "get_optimal_threshold": 182, "large_time_horizon": 182, "run_polici": 182, "_run_the_policy_exercise_and_discuss": 182, "mdp": 182, "illumin": 182, "_from_discrete_to_continuous_control_video": 182, "_sensitivity_of_optimal_policy_bonus_video": 182, "high_rwd": 182, "low_rwd": 182, "rarer": 182, "coars": 182, "update_ex_bonu": 182, "convers": 182, "stringent": 182, "_zero_": 182, "promot": [182, 199], "conserv": 182, "_explore_task_parameters_bonus_interactive_demo_and_discuss": 182, "w3d3_t2": 183, "plot_vs_tim": 183, "slabel": 183, "plot_kf_state_vs_tim": 183, "latent_st": 183, "standard_normal_nois": 183, "standard_normal_noise_mea": 183, "exerciseerror": 183, "test_lds_class": 183, "lds_class": 183, "ldsy": 183, "ini_st": 183, "noise_var": 183, "dynamics_openloop": 183, "dynamics_closedloop": 183, "test_lqr_class": 183, "lqr_class": 183, "lqreg": 183, "calculate_j_st": 183, "calculate_j_control": 183, "_flying_through_space_video": 183, "corros": 183, "unintend": 183, "ba_t": 183, "ds_t": 183, "neq": [183, 199, 200], "excercis": 183, "polici": [183, 189, 190, 192], "static_nois": 183, "_implement_state_evolution_equations_exercis": 183, "fare": 183, "simulate_ld": 183, "s_no_control": 183, "s_open_loop": 183, "s_closed_loop": 183, "a_closed_loop": 183, "bl": 183, "_no_control_closed_lopp_open_loop_interactive_demo_and_discuss": 183, "optimum": 183, "ls_t": 183, "calculate_plot_ms": 183, "num_iter": 183, "num_candid": 183, "control_gain_arrai": 183, "mse_arrai": 183, "ambiti": 183, "051": 183, "simulate_l": 183, "s_closed_loop_choic": 183, "l_theori": 183, "s_closed_loop_theoret": 183, "overshoot": 183, "_closed_loop_exploration_interactive_demo_and_discuss": 183, "_lqr_video": 183, "fuel": 183, "certainli": 183, "riccati": 183, "dimitri": 183, "belmont": 183, "control_gain_lqr": 183, "p_t_1": 183, "j_state": 183, "j_control": 183, "_implement_the_cost_function_exercis": 183, "simulate_rho": 183, "s_lqr": 183, "a_lqr": 183, "_lqr_to_the_origin_interactive_demo_and_discuss": 183, "calculate_plot_cost": 183, "rho_arrai": 183, "_tracking_a_moving_goal_video": 183, "bounc": 183, "g_t": 183, "lqr_track": 183, "dynamics_track": 183, "intial": 183, "a_bar": 183, "react": 183, "goal_func": 183, "simulate_track": 183, "lqr_time": 183, "s_lqr_time": 183, "a_lqr_tim": 183, "a_bar_lqr_tim": 183, "lqr_control_to_desired_time_varying_goal_interactive_demo_and_discuss": 183, "_lqg_video": 183, "radar": 183, "proc_nois": 183, "meas_nois": 183, "get_estim": 183, "observation_matrix": 183, "innov": 183, "ntrial": 183, "get_control_gain_infinit": 183, "control_policy_lqg": 183, "control_gain": 183, "estimated_st": 183, "current_act": [183, 199], "simulate_kf_no_control": 183, "ini_state_mean": 183, "ini_state_cov": 183, "_lqg_control_interactive_demo_and_discuss": 183, "arround": 183, "simulate_kf_with_control": 183, "_lqc_controller_varying_gains_interactive_demo": 183, "simulate_kf_with_lqg": 183, "_lqc_controller_varying_weight_interactive_demo": 183, "lqg_slider": 183, "_process_noise_measurements_noise_interactive_demo": 183, "transit_matrix_slid": 183, "n_op": 183, "process_noise_var": 183, "measurement_noise_var": 183, "mse_array_n_mea": 183, "mse_array_n_proc": 183, "jcontrol_array_n_mea": 183, "jcontrol_array_n_proc": 183, "meas_noise_arrai": 183, "proc_noise_arrai": 183, "proc": 183, "mse_array_proc": 183, "jcontrol_array_proc": 183, "control_gain_lqg": 183, "filtered_state_means_impl": 183, "filtered_state_covariances_impl": 183, "action_cost": 183, "state_cost": 183, "mse_array_mea": 183, "jcontrol_array_mea": 183, "mse_array_proc_mean": 183, "mse_array_proc_std": 183, "mse_array_meas_mean": 183, "mse_array_meas_std": 183, "jcontrol_array_proc_mean": 183, "jcontrol_array_proc_std": 183, "jcontrol_array_meas_mean": 183, "jcontrol_array_meas_std": 183, "quantif": 183, "_noise_effects_on_the_lqg_discuss": 183, "sutton": 185, "barto": 185, "schultz": 185, "montagu": 185, "5306": 185, "1593": 185, "1599": 185, "utexa": 185, "dana": 185, "daw": 185, "dorsolater": 185, "striatal": 185, "1704": 185, "1711": 185, "nn1560": 185, "185": 185, "kurth": 185, "kumaran": 185, "tirumala": 185, "soyer": 185, "leibo": 185, "868": 185, "0147": 185, "295964": 185, "mattar": [185, 189, 190, 191, 192], "replai": 185, "1609": 185, "1617": 185, "0232": 185, "pmc6203620": 185, "dabnei": 185, "uchida": 185, "starkweath": 185, "hassabi": 185, "muno": 185, "dopamin": [185, 189], "577": 185, "7792": 185, "671": 185, "675": 185, "1924": 185, "pmc7476215": 185, "mnih": 185, "kavukcuoglu": 185, "rusu": 185, "veness": 185, "bellemar": 185, "518": 185, "7540": 185, "529": 185, "533": 185, "nature14236": 185, "huang": 185, "maddison": 185, "guez": 185, "sifr": 185, "driessch": 185, "game": 185, "tree": 185, "7587": 185, "484": 185, "489": 185, "nature16961": 185, "w3d4_daysummari": 186, "exploit": [187, 190, 191], "dilemma": [187, 190], "w3d4_intro": 187, "w3d4_outro": 188, "marcelo": [189, 190, 191, 192], "sargent": [189, 190, 191, 192], "sowmya": [189, 190, 191, 192], "parthiban": [189, 190, 191, 192], "feryal": [189, 190, 191, 192], "behbahani": [189, 190, 191, 192], "jane": [189, 190, 191, 192], "ezekiel": [189, 190, 191, 192], "mehul": [189, 190, 191, 192], "rastogi": [189, 190, 191, 192], "roberto": [189, 190, 191, 192], "guidotti": [189, 190, 191, 192], "arush": [189, 190, 191, 192], "tagad": [189, 190, 191, 192], "kelson": [189, 190, 191, 192], "shill": [189, 190, 191, 192], "scrivo": [189, 190, 191, 192], "uncondit": 189, "conting": 189, "rpe": 189, "tap": 189, "w3d4_t1": 189, "plot_value_funct": 189, "plot_tde_trac": 189, "tde": 189, "indx": 189, "fixedloc": 189, "learning_summary_plot": 189, "ex1": 189, "reward_guesser_title_hint": 189, "mildli": 189, "obfusc": 189, "spoil": 189, "classicalcondit": 189, "reward_magnitud": 189, "reward_tim": 189, "n_action": [189, 191, 192], "cs_time": 189, "reward_st": 189, "reward_prob": 189, "set_reward": 189, "_create_state_dictionari": 189, "get_outcom": [189, 191, 192], "current_st": 189, "next_stat": [189, 191, 192], "episod": [189, 190, 191, 192], "is_delai": 189, "t_in_delai": 189, "multirewardcc": 189, "deliv": 189, "probabilisticcc": 189, "p_reward": 189, "iti": 189, "rumelhart": 189, "pdplab": 189, "pdphandbook": 189, "handbookch10": 189, "limits_": 189, "sum_a": 189, "proxi": [189, 196], "delta_": [189, 198], "discrep": 189, "tl": 189, "td_learner": 189, "env": [189, 191, 192], "_td_learning_exercis": 189, "saliv": 189, "smell": 189, "tasti": 189, "pavlov": 189, "ring": 189, "inconsist": 189, "plot_tde_by_tri": 189, "basefmt": 189, "linefmt": 189, "markerfmt": 189, "c1d": 189, "c0o": 189, "_us_to_cs_transfer_interactive_demo": 189, "plot_summary_alpha_gamma": 189, "980": 189, "\u03b3": 189, "v_param": 189, "tde_param": 189, "excess": 189, "nearli": 189, "greedi": [189, 191, 192], "_learning_rates_and_discount_factors_interactive_demo_and_discuss": 189, "learner": 189, "dispens": 189, "rng_state": 189, "get_stat": 189, "v_multi": 189, "tde_multi": 189, "reward_guesser_interact": 189, "inttext": 189, "env2": 189, "v_guess": 189, "yo": 189, "set_markers": 189, "set_markerfacecolor": 189, "rx": 189, "_examining_the_td_error_discuss": 189, "intermitt": 189, "set_stat": 189, "resynchron": 189, "v_stochast": 189, "tde_stochast": 189, "implaus": 189, "persist": 189, "_probabilistic_rewards_discuss": 189, "bewar": 189, "_removing_the_cs_bonus_discuss": 189, "w3d4_t2": 190, "plot_choic": 190, "choice_fn": 190, "rng_seed": 190, "plot_multi_armed_bandit_result": 190, "qs": 190, "plot_parameter_perform": 190, "trial_reward": 190, "trial_optim": 190, "_multiarmed_bandits_video": 190, "colloqui": 190, "lever": 190, "rig": 190, "monei": 190, "payout": 190, "intention": 190, "r_t": [190, 191], "fatal": 190, "flaw": 190, "trap": 190, "bet": 190, "stumbl": 190, "epsilon_greedi": [190, 191, 192], "be_greedi": [190, 192], "_implement_epsilon_greedy_exercis": 190, "amongst": 190, "\u03b5": 190, "explore_epilson_valu": 190, "_changing_epsilon_interactive_demo_and_discuss": 190, "q_t": 190, "update_action_valu": 190, "_updating_action_values_exercis": 190, "multi_armed_bandit": 190, "n_arm": 190, "all_reward": 190, "optimal_act": 190, "alright": 190, "lock": 190, "explore_bandit_paramet": 190, "worst": 190, "_changing_epsilon_and_alpha_interactive_demo": 190, "bandit": [191, 192], "w3d4_t3": 191, "plot_state_action_valu": [191, 192], "n_state": [191, 192], "plot_quiver_max_act": [191, 192], "cheese_world": [191, 192], "dim_x": [191, 192], "dim_i": [191, 192], "which_max": [191, 192], "minor": [191, 192], "plot_heatmap_max_v": [191, 192], "value_max": [191, 192], "afmhot": [191, 192], "windy_cliff_grid": [191, 192], "plot_reward": [191, 192], "n_episod": [191, 192], "average_rang": [191, 192], "smoothed_reward": [191, 192], "plot_perform": [191, 192], "reward_sum": [191, 192], "_mdps_and_q_learning_video": 191, "overcom": 191, "cliff": [191, 192], "4x10": 191, "td": 191, "watkin": 191, "max_": [191, 192], "discount": [191, 192], "learn_environ": [191, 192], "lifecycl": 191, "cliffworld": 191, "probabilti": [191, 192], "border": [191, 192], "cliff_world": 191, "init_st": [191, 192], "get_all_outcom": [191, 192], "learning_rul": 191, "max_step": [191, 192], "q_learn": [191, 192], "max_next_q": 191, "td_error": 191, "value_qlearn": 191, "reward_sums_qlearn": 191, "_implement_q_learning_algorithm_exercis": 191, "notabl": 191, "steadili": 191, "policy_next_q": 191, "policy_act": 191, "value_sarsa": 191, "reward_sums_sarsa": 191, "traceback": [191, 201], "110": 191, "113": 191, "_implement_the_sarsa_algorithm_bonus_exercis": 191, "skittish": 191, "standpoint": 191, "skirt": 191, "wall": [191, 192], "rout": 191, "w3d4_t4": 192, "prev_valu": 192, "isnan": [192, 199, 200], "max_valu": 192, "model_updat": 192, "planner": 192, "shortcut_episod": 192, "episode_step": 192, "toggle_shortcut": 192, "quentinsworld": 192, "quentin": 192, "shortcut_st": 192, "71": 192, "73": 192, "74": 192, "89": 192, "46": 192, "67": 192, "82": 192, "_modelbased_rl_video": 192, "costli": 192, "fuller": 192, "assimil": 192, "10x10": 192, "trivial": 192, "tabular": 192, "forev": 192, "nontermin": 192, "dyna_q_model_upd": 192, "_dynaq_model_update_exercis": 192, "dyna_q_plan": 192, "nx2": 192, "_dynaq_planning_exercis": 192, "n_experi": 192, "planning_step": 192, "steps_per_episod": 192, "warm": 192, "upward": 192, "consolid": 192, "hernan": [194, 198], "robin": 194, "readabl": 194, "charit": 194, "dag": 194, "angrist": [194, 198], "pischk": [194, 198], "princeton": 194, "harmless": [194, 198], "imben": [194, 198], "aschengrau": 194, "seag": 194, "health": 194, "jone": 194, "bartlett": 194, "dominik": 194, "bernhard": 194, "cooper": 194, "herskovit": 194, "1992": 194, "induct": 194, "309": 194, "347": 194, "bf00994110": 194, "amari": 194, "arai": 194, "diekman": 194, "diesmann": 194, "kramer": 194, "041715": 194, "033733": 194, "126718": 194, "annrev2017fin": 194, "marinescu": 194, "lawlor": 194, "quasi": 194, "891": 194, "898": 194, "s41562": 194, "0466": 194, "econ": 194, "quasiexperiment": 194, "mooij": 194, "janz": 194, "zscheischler": 194, "sch\u00f6lkopf": 194, "1204": 194, "acm": 194, "5555": 194, "2946645": 194, "2946677": 194, "b\u00fchlmann": 194, "meinshausen": 194, "identif": 194, "royal": 194, "methodolog": 194, "947": 194, "1012": 194, "1111": 194, "rssb": 194, "12167": 194, "01332": 194, "scholkopf": 194, "judea": [194, 196], "765": 194, "804": 194, "3501714": 194, "3501755": 194, "1911": 194, "10500": 194, "shimizu": 194, "hoyer": 194, "hyv\u00e4rinen": 194, "kerminen": 194, "jordan": 194, "acycl": 194, "jmlr": 194, "v7": 194, "shimizu06a": 194, "spirt": 194, "glymour": 194, "schein": 194, "heckerman": 194, "causat": [194, 200, 201], "triantafil": 194, "tsamardino": 194, "2147": 194, "2205": 194, "v16": 194, "triantafillou15a": 194, "w3d5_daysummari": 195, "drug": [196, 198], "mislead": 196, "unmeasur": 196, "unavoid": 196, "w3d1": 196, "bedrock": 196, "heart": 196, "w3d5_intro": 196, "w3d5_outro": 197, "toni": [198, 199, 200, 201], "mike": [198, 199, 200, 201], "cohen": [198, 199, 200, 201], "yoni": [198, 199, 200, 201], "pproduct": 198, "w3d5_t1": 198, "see_neuron": [198, 199, 200, 201], "renorm": 198, "plot_connectivity_matrix": [198, 199, 200], "set_siz": [198, 199], "plot_connectivity_graph_matrix": 198, "plot_neural_act": [198, 201], "cax1": [198, 201], "plot_true_vs_estimated_connect": [198, 199], "estimated_connect": [198, 199, 200, 201], "true_connect": [198, 199], "selected_neuron": [198, 199, 201], "_defining_causality_video": 198, "rct": 198, "placebo": 198, "neuron_b": 198, "activity_of_a": 198, "diff_in_mean": 198, "9907195190159408": 198, "_randomized_controlled_trial_for_two_neurons_exercis": 198, "_simulated_neural_system_model_video": 198, "nonlinearli": 198, "i_n": 198, "create_connect": [198, 199, 200, 201], "nxn": [198, 199, 200, 201], "s_val": [198, 199, 200, 201], "s_val_test": [198, 201], "singular": [198, 201], "simulate_neuron": [198, 199, 200, 201], "timetep": [198, 199, 200, 201], "___t____t": 198, "1___": 198, "___1____0_____": 198, "_system_simulation_exercis": 198, "_perturbing_systems_video": 198, "frac1n": 198, "substack": 198, "interven": 198, "simulate_neurons_perturb": 198, "seriou": 198, "huh": 198, "x_perturb": 198, "boilerpl": 198, "cax0": 198, "_calculating_causality_video": 198, "start_index": 198, "end_index": 198, "count_bi": 198, "get_perturbed_connectivity_from_single_neuron": 198, "perturbed_x": 198, "neuron_perturb": 198, "all_neuron_output": 198, "this_neuron_output": 198, "one_idx": 198, "zero_idx": 198, "get_perturbed_connectivity_single_neuron": 198, "difference_in_mean": 198, "_perturbed_dynamics_to_recover_connectivity_exercis": 198, "9960188025389387": 198, "strictli": [198, 199], "get_perturbed_connectivity_all_neuron": 198, "2n": 198, "987593404378358": 198, "econometr": 198, "proportion": 198, "w3d5_t2": 199, "plot_estimation_quality_vs_n_neuron": 199, "number_of_neuron": 199, "corr_func": 199, "corr_data": [199, 200, 201], "get_sys_corr": [199, 200, 201], "corr_mean": [199, 200, 201], "corr_std": [199, 200, 201], "correlation_for_all_neuron": [199, 200, 201], "_correlation_vs_causation_video": 199, "compute_connectivity_from_single_neuron": 199, "next_act": 199, "this_output_act": 199, "_approximate_causation_with_correlation_exercis": 199, "5f": 199, "95967": 199, "_correlation_causation_for_small_systems_video": 199, "_correlation_causation_in_large_systems_video": 199, "plot_corr": 199, "_connectivity_estimation_as_a_function_of_number_of_neurons_interactive_demo": 199, "rightli": 199, "wonder": [199, 200, 201], "_connectivity_estimation_as_a_function_of_the_sparsity_a_interactive_demo": 199, "phrase": 199, "filler": 199, "mediat": 199, "_reflecting_on_causality_discuss": 199, "spearman": 199, "dichotom": 199, "concord": 199, "kappa": 199, "braini": 199, "coarse_x": 199, "get_coarse_corr": 199, "n_group": 199, "coarse_a": 199, "_compute_average_activity_bonus_exercis": 199, "neffect": 199, "controversi": 200, "w3d5_t3": 200, "multioutput": [200, 201], "multioutputregressor": [200, 201], "ratio_observ": 200, "_regression_approach_video": 200, "confound": [200, 201], "homework": 200, "grade": 200, "confond": 200, "collid": 200, "counterintuit": 200, "_fitting_a_glm_video": 200, "logit": [200, 201], "l_1": 200, "fit_intercept": [200, 201], "get_regression_estim": [200, 201], "865": 200, "703": 200, "_linear_regression_with_lasso_to_estimate_causal_connectivities_exercis": 200, "_omitted_variable_bias_video": 200, "sel_idx": [200, 201], "set_text": [200, 201], "046": [200, 201], "get_regression_estimate_full_connect": [200, 201], "get_regression_corr_full_connect": [200, 201], "reg": [200, 201], "n_job": [200, 201], "estimators_": [200, 201], "observed_ratio": [200, 201], "regression_arg": [200, 201], "betweem": [200, 201], "sel_x": [200, 201], "sel_a": [200, 201], "sel_v": [200, 201], "4000": 200, "reg_arg": [200, 201], "n_observ": [200, 201], "to_neuron": 200, "big_r": [200, 201], "125": 200, "nanmean": 200, "nanstd": 200, "_regression_performance_as_a_function_of_the_number_of_observed_neurons_interactive_demo": 200, "_summari": 200, "w3d5_t4": 201, "linearregress": 201, "compare_granger_connect": 201, "reject_nul": 201, "selecte_neuron": 201, "plot_performance_vs_eta": 201, "matri": 201, "print_corr": 201, "idx_dict": 201, "text_dict": 201, "tax": 201, "cigarett": 201, "statu": 201, "get_regression_corr": 201, "_instrumental_variables_video": 201, "wild": 201, "smoke": 201, "pregnant": 201, "wealth": 201, "tobacco": 201, "consumpt": 201, "z_": 201, "socioeconom": 201, "wealthier": 201, "birthweight": 201, "child": 201, "gram": 201, "3000": 201, "2t_": 201, "mother": 201, "babi": 201, "lighter": 201, "covar": 201, "483": 201, "740": 201, "unconfound": 201, "_stage_1_video": 201, "fit_first_stag": 201, "t_hat": 201, "stage1": 201, "t_c_corr": 201, "t_hat_c_corr": 201, "_compute_regression_stage_1_exercis": 201, "_stage_2_video": 201, "fit_second_stag": 201, "stage2": 201, "984": 201, "_compute_the_iv_estimate_exercis": 201, "ivs_in_simulated_neural_systems_video": 201, "wire": 201, "radio": 201, "simulate_neurons_iv": 201, "iv_on_this_timestep": 201, "_simulate_a_system_with_iv_exercis": 201, "get_iv_estimate_network": 201, "x_hati": 201, "corr_": 201, "_ivs_and_omitted_variable_bias_video": 201, "sel_z": 201, "iv_corr": 201, "big_v": 201, "reg_corr": 201, "compare_iv_estimate_to_regress": 201, "sel_reg_v": 201, "sel_iv_v": 201, "ncorrel": 201, "_estimating_connectivity_with_iv_vs_regression_interactive_demo": 201, "threat": 201, "discussion_questions_discuss": 201, "instrument_strength_effect": 201, "iv_v": 201, "to_remove_solut": 201, "_exploring_instrument_strength_bonus_exercis": 201, "h_a": 201, "b_1": 201, "statsmodel": 201, "tsa": 201, "stattool": 201, "grangercausalitytest": 201, "get_granger_caus": 201, "bonferroni": 201, "p_val": 201, "max_lag": 201, "target_neuron": 201, "ts_data": 201, "pval": 201, "lrtest": 201, "maxlag": 201, "_evaluate_granger_causality_bonus_exercis": 201, "019416331902158156": 201, "advic": 202, "isabel": 202, "brush": 202}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"prerequisit": [0, 86, 95, 106, 162, 170], "preparatori": 0, "materi": 0, "nma": 0, "comput": [0, 30, 71, 76, 77, 82, 89, 90, 97, 100, 101, 102, 111, 126, 139, 140, 147, 148, 150, 156, 157, 158, 164, 198, 199, 201], "neurosci": [0, 30, 76, 77, 93, 111, 134, 185], "prepar": [0, 30, 34, 35, 36], "yourself": 0, "cours": [0, 20, 30, 40], "program": 0, "math": [0, 64, 75, 76, 82, 164], "skill": 0, "overview": [1, 5, 21, 28, 32, 40, 64, 86, 95, 106, 113, 122, 130, 136, 145, 154, 162, 170, 172, 178, 180, 185, 187, 196, 202], "video": [1, 5, 21, 22, 23, 28, 30, 32, 33, 34, 35, 36, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 86, 87, 88, 89, 90, 95, 96, 97, 98, 99, 100, 101, 102, 106, 107, 108, 109, 113, 114, 115, 116, 117, 118, 122, 123, 124, 125, 126, 127, 130, 131, 132, 136, 137, 138, 139, 140, 141, 145, 146, 147, 148, 149, 150, 154, 155, 156, 157, 158, 162, 163, 164, 165, 166, 170, 171, 172, 173, 174, 175, 176, 180, 181, 182, 183, 187, 188, 189, 190, 191, 192, 196, 197, 198, 199, 200, 201, 202], "ted": 1, "talk": 1, "kai": [1, 16, 20, 21], "miller": 1, "watch": 1, "until": 1, "15": [1, 174], "45": 1, "guid": [2, 4, 12, 20, 26, 27, 29], "choos": [2, 4, 20, 27, 29, 34, 109, 190], "an": [2, 20, 64, 72, 77, 88, 115, 147, 150, 166, 172, 173, 183, 190, 201], "eeg": [2, 15, 60], "ecog": [2, 6], "lfp": [2, 59], "dataset": [2, 4, 8, 13, 16, 20, 21, 27, 28, 34, 35, 36, 88, 99, 120], "refer": [2, 20, 27, 76, 77], "face": [2, 13], "hous": 2, "fingerflex": 2, "joystick": 2, "track": [2, 150, 175, 183], "memori": [2, 13, 29, 158], "nback": 2, "direct": [2, 147], "see": [2, 27], "motor": [2, 13, 29], "imageri": 2, "explor": [2, 13, 88, 97, 98, 116, 147, 149, 156, 164, 165, 182, 183, 201], "ajile12": [2, 13], "project": [3, 11, 12, 13, 16, 22, 24, 25, 29, 30, 40, 46, 115, 116, 132], "behavior": [4, 5, 7, 13, 14, 56, 76], "caltech": [4, 5], "ibl": [4, 5], "laquitain": 4, "gardner": 4, "neuron": [4, 10, 17, 27, 54, 64, 66, 75, 88, 89, 90, 142, 143, 147, 148, 149, 150, 152, 156, 176, 198, 199, 200, 201], "2017": 4, "mous": [5, 13], "social": [5, 13], "bay": [5, 82, 164, 165, 166], "heurist": 5, "fmri": [9, 13, 16, 20, 21, 61], "2020": 11, "daili": [12, 40, 69, 80, 87, 96, 107, 114, 123, 131, 137, 146, 155, 163, 171, 181, 188, 197], "summari": [12, 22, 24, 25, 34, 35, 36, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 88, 89, 90, 94, 97, 98, 99, 100, 101, 102, 105, 108, 109, 112, 115, 116, 117, 118, 121, 124, 125, 126, 129, 132, 135, 138, 139, 140, 141, 144, 147, 148, 149, 150, 153, 156, 157, 161, 164, 165, 166, 169, 172, 173, 174, 179, 182, 183, 186, 189, 190, 191, 192, 195, 198, 199, 200, 201], "submiss": 12, "link": [12, 13, 30, 46, 76, 77, 185], "templat": [12, 13], "ta": [12, 30], "mentor": 12, "week": 12, "1": [12, 22, 25, 30, 34, 35, 36, 63, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 120, 123, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "get": [12, 30, 88], "start": [12, 77], "w1d2": 12, "w1d3": 12, "w1d5": 12, "w2": 12, "time": [12, 40, 64, 139, 143, 147, 148, 150, 157, 172, 174, 183], "w2d1": [12, 40], "half": [12, 40], "dai": [12, 40, 68, 74, 76, 77, 79, 85, 94, 105, 112, 121, 129, 135, 144, 153, 161, 169, 179, 186, 195], "w2d2": 12, "w2d5": [12, 40], "abstract": [12, 23, 25, 40], "write": [12, 23, 40], "bonu": [12, 34, 35, 70, 72, 75, 77, 82, 89, 90, 97, 98, 101, 102, 108, 109, 116, 117, 124, 125, 126, 127, 147, 148, 149, 150, 156, 158, 164, 166, 172, 175, 176, 182, 189, 191, 198, 199, 201], "w3": 12, "w3d5": [12, 40], "final": [12, 24, 25, 40], "present": 12, "schedul": [12, 40, 41], "logist": [12, 109], "content": 12, "question": [12, 22, 24, 25, 132, 175, 201], "flow": 13, "inform": [13, 90, 102, 165], "through": [13, 70, 174, 183, 198], "brain": [13, 58, 59, 60, 61, 62, 77, 82, 111, 120], "dure": [13, 176], "sensorimotor": 13, "task": [13, 20, 21, 124, 126, 182], "effect": [13, 76, 109, 115, 147, 148, 150, 158, 183], "stimulu": [13, 52, 166], "context": 13, "state": [13, 22, 132, 139, 156, 164, 165, 174, 182, 183, 185], "visual": [13, 34, 35, 75, 88, 117, 118, 124, 125, 126, 127, 150, 156], "represent": [13, 34, 52, 126], "cortex": 13, "map": [13, 202], "activ": [13, 34, 58, 72, 77, 88, 108, 124, 125, 126, 148, 156, 157, 158, 199], "retinotop": 13, "model": [13, 22, 23, 24, 25, 26, 29, 36, 40, 64, 70, 76, 77, 81, 83, 88, 89, 90, 91, 92, 93, 98, 100, 101, 102, 103, 108, 109, 120, 126, 127, 128, 134, 140, 141, 142, 143, 147, 149, 150, 152, 156, 157, 158, 160, 166, 168, 172, 173, 176, 192, 198, 200], "navig": 13, "afford": 13, "scene": 13, "select": [13, 23, 24, 25, 93, 101, 102, 109], "respons": [13, 30, 124, 147, 148, 166], "differ": [13, 36, 90, 100, 109, 117, 118, 147, 149, 157, 165, 182, 189], "region": 13, "depend": [13, 24, 70, 75, 143, 150, 175, 182], "decis": [13, 25, 159, 164, 165, 166, 168, 191], "make": [13, 66, 164, 168], "mice": 13, "perform": [13, 116, 117, 127, 200], "2afc": 13, "The": [13, 34, 64, 70, 76, 77, 89, 90, 109, 140, 147, 165, 172, 174, 175, 183], "work": [13, 29, 111, 158, 201], "capac": 13, "recurr": [13, 156], "neural": [13, 70, 71, 72, 75, 77, 109, 124, 125, 126, 127, 156, 160, 198, 201], "network": [13, 120, 124, 125, 126, 127, 148, 151, 152, 156, 158, 176, 193, 199], "attractor": 13, "doe": [13, 174, 182, 183], "reflect": [13, 88, 89, 90, 199], "percept": 13, "structur": [13, 30, 100], "probe": 13, "dynam": [13, 37, 72, 134, 138, 143, 149, 151, 156, 167, 172, 174, 175, 182, 183, 198], "human": [13, 16, 55], "estim": [13, 82, 97, 98, 99, 100, 165, 166, 174, 198, 199, 200, 201], "error": [13, 77, 97, 101, 127, 189], "bayesian": [13, 82, 159, 164, 165], "framework": 13, "function": [13, 22, 24, 34, 35, 36, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "rnn": [13, 29], "learn": [13, 38, 109, 119, 120, 125, 176, 184, 189, 190, 191, 192, 194], "connectom": 16, "stringer": [17, 27, 28], "steinmetz": [17, 27, 28, 88], "theori": [18, 19, 29, 82], "hcp": [20, 21], "fsl": 20, "retinotopi": [20, 21], "natur": 20, "imag": [20, 36, 62], "bonner": [20, 21], "algonaut": [20, 21], "cichi": [20, 21], "gallant": 21, "2021": 21, "fslcours": 21, "step": [22, 23, 26, 48, 75, 77, 132, 175, 176], "4": [22, 30, 34, 35, 36, 64, 66, 70, 71, 75, 76, 77, 81, 82, 88, 90, 91, 98, 100, 109, 115, 117, 118, 132, 138, 141, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 190, 192, 198, 199, 200, 201], "tutori": [22, 30, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 120, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "object": [22, 23, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "demo": [22, 66, 70, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 109, 115, 116, 117, 132, 138, 139, 140, 147, 149, 150, 156, 157, 158, 164, 165, 172, 173, 174, 175, 182, 183, 189, 190, 199, 200, 201], "introduct": [22, 30, 34, 35, 36, 70, 75, 76, 99, 124, 125, 132, 164, 165, 166, 173, 175, 176, 189, 202], "setup": [22, 24, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "plot": [22, 24, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "gener": [22, 25, 40, 72, 81, 82, 93, 103, 108, 115, 127, 132, 143, 147, 166, 176], "data": [22, 24, 88, 90, 101, 108, 109, 115, 116, 117, 124, 125, 126, 127, 132, 141, 160, 166, 175, 176], "find": [22, 82, 98, 115, 132, 139, 156, 158, 174], "phenomenon": [22, 24, 25, 132], "ask": [22, 132], "about": [22, 70, 75, 76, 109, 132, 201], "2": [22, 25, 30, 34, 35, 36, 64, 65, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 108, 109, 115, 116, 117, 118, 120, 123, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "exampl": [22, 24, 25, 70, 76, 82, 93, 132, 150, 158, 165, 201], "think": [22, 70, 71, 76, 77, 81, 82, 88, 89, 90, 91, 118, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 164, 189, 199, 201], "your": [22, 32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "own": [22, 132, 174], "understand": [22, 71, 72, 75, 77, 125, 126, 132, 141], "art": [22, 132, 185], "background": [22, 24, 25, 132], "3": [22, 25, 30, 34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 98, 99, 100, 109, 115, 117, 124, 125, 126, 127, 132, 138, 139, 140, 147, 148, 149, 150, 156, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "literatur": [22, 132], "review": [22, 120, 132, 175], "knowledg": [22, 86, 95, 106, 132], "determin": [22, 126, 132, 140], "basic": [22, 64, 82, 132], "ingredi": [22, 24, 25, 132], "formul": [22, 132, 139], "specif": [22, 30, 40, 132], "mathemat": [22, 116, 132, 157], "defin": [22, 64, 70, 72, 115, 132, 176, 198], "hypothes": [22, 24, 25, 132], "5": [22, 23, 30, 35, 64, 66, 70, 71, 75, 76, 77, 81, 82, 88, 90, 101, 109, 132, 164, 165, 166, 172, 173, 174, 175, 176, 182, 198, 201], "hypothesi": [22, 132], "next": [22, 132], "read": [22, 23, 76, 77, 84, 93, 104, 111, 120, 132, 134, 143, 152, 160, 168, 174, 178, 185, 194], "10": [23, 30, 64, 66, 164, 174], "toolkit": [23, 24, 25], "6": [23, 30, 36, 64, 66, 70, 75, 77, 82, 102, 164, 165, 166, 172, 173, 174, 182, 201], "plan": [23, 192], "draft": [23, 24, 25], "7": [23, 30, 64, 66, 70, 82, 164, 165, 166, 173, 174, 182], "implement": [23, 24, 25, 72, 102, 109, 116, 150, 156, 166, 174, 175, 176, 182, 183, 190, 191], "8": [23, 64, 66, 164, 165, 166, 174], "complet": [23, 24, 25], "9": [23, 30, 64, 66, 164, 165, 174], "test": [23, 24, 25, 101, 127, 172], "evalu": [23, 24, 25, 100, 109, 126, 127, 182, 201], "publish": 23, "11": [23, 30, 64, 66, 174], "paper": [23, 120, 194], "guidanc": 23, "suggest": [23, 84, 93, 104, 111, 120, 134, 143, 152, 160, 168, 178, 185, 194, 201], "train": [24, 25, 30, 34, 35, 36, 88, 101, 109, 127, 148, 176], "illus": [24, 25], "instal": [24, 32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "helper": [24, 34, 35, 36, 66, 72, 76, 77, 101, 102, 109, 116, 117, 124, 125, 126, 127, 141, 148, 149, 150, 157, 158, 164, 165, 166, 172, 174, 176, 182, 183, 189, 192, 199, 200, 201], "thought": [24, 25], "vestibular": 25, "signal": [25, 58, 59, 60, 61, 62, 89], "integr": [25, 64, 75, 76, 77, 89, 138, 147, 157], "ddm": [25, 172], "mechan": 25, "threshold": [25, 172, 182], "assembl": 25, "allen": [27, 28], "institut": [27, 28], "none": 27, "yet": 27, "thi": [27, 166], "databas": 29, "addit": 29, "resourc": [29, 30], "cn": 30, "welcom": 30, "who": 30, "ar": [30, 77, 141, 182], "we": [30, 36, 70, 75, 76, 109], "our": [30, 198, 201], "philosophi": 30, "meet": 30, "2023": 30, "leadership": 30, "us": [30, 44, 45, 47, 48, 64, 66, 70, 72, 75, 77, 109, 117, 118, 120, 124, 174, 183, 189, 198, 200, 201], "etc": 30, "teach": 30, "assess": 30, "help": [30, 49], "tech": 30, "stack": 30, "8a": 30, "8b": 30, "pedagogi": 30, "curriculum": [30, 202], "autoencod": [31, 34, 35, 36], "intro": [32, 34, 51, 64, 70, 71, 77, 81, 86, 95, 106, 113, 116, 117, 118, 120, 122, 130, 136, 145, 154, 162, 166, 170, 178, 180, 187, 196], "import": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "feedback": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "gadget": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "slide": [32, 33, 86, 87, 95, 96, 106, 107, 113, 114, 122, 123, 130, 131, 136, 137, 145, 146, 154, 155, 162, 163, 170, 171, 180, 181, 186, 187, 188, 196, 197], "submit": [32, 33, 34, 35, 36, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 85, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 166, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 186, 187, 188, 189, 190, 191, 192, 195, 196, 197, 198, 199, 200, 201], "outro": [33, 69, 80, 87, 93, 96, 107, 111, 114, 120, 123, 131, 134, 137, 146, 155, 163, 166, 171, 178, 181, 188, 197], "intern": [34, 77], "figur": [34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "set": [34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 132, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "section": [34, 35, 36, 64, 66, 70, 71, 72, 75, 76, 77, 81, 82, 88, 89, 90, 91, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 165, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "0": [34, 35, 36, 70, 75, 76, 116, 117, 118, 124, 132, 149, 164, 165, 172, 173, 175, 176], "mnist": [34, 35, 36, 117, 118], "download": [34, 35, 36, 90], "sampl": [34, 64, 81, 109, 115, 116, 138, 175, 199], "latent": [34, 35, 36, 175], "space": [34, 35, 36, 70, 71, 183], "pca": [34, 111, 116, 117, 118], "code": [34, 35, 36, 64, 66, 70, 71, 72, 75, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "exercis": [34, 35, 36, 64, 66, 70, 71, 72, 75, 77, 81, 82, 88, 89, 90, 97, 98, 99, 100, 101, 102, 108, 109, 115, 116, 117, 118, 124, 125, 126, 127, 138, 139, 140, 141, 147, 148, 149, 150, 156, 157, 158, 164, 166, 172, 173, 174, 175, 176, 182, 183, 189, 190, 191, 192, 198, 199, 200, 201], "2d": [34, 35, 64, 75, 118, 125, 165], "qualit": [34, 126], "analysi": [34, 111, 116, 152, 156, 157, 158, 160], "ann": [34, 36], "design": [34, 100, 108, 183], "32d": 34, "loss": [34, 124, 127, 165], "express": [34, 124], "power": 34, "wrap": [34, 35, 36, 37, 38, 39], "up": [34, 35, 36, 37, 38, 39, 88, 109, 126, 183], "failur": [34, 199], "mode": 34, "relu": 34, "unit": [34, 127], "weight": [34, 117, 125, 127, 150, 183], "initi": [34, 72, 76, 138, 156, 157, 176], "nmf": 34, "extens": [35, 147], "architectur": 35, "dependeci": 35, "deeper": [35, 127], "build": [35, 126], "spheric": 35, "3d": 35, "deep": [35, 119, 120, 124, 125, 126], "surfac": 35, "s_2": 35, "thick": 35, "applic": [36, 75, 118, 150], "pre": [36, 150], "nois": [36, 98, 117, 147, 148, 183], "reconstruct": [36, 117], "befor": 36, "fine": 36, "tune": [36, 126, 127], "noisi": [36, 147, 156], "global": 36, "shift": 36, "occlus": 36, "after": 36, "rotat": 36, "what": [36, 70, 75, 77, 88, 109, 125, 143, 148, 164], "would": 36, "digit": 36, "look": [36, 72], "like": 36, "had": 36, "never": 36, "seen": 36, "remov": [36, 189], "most": 36, "domin": 36, "class": [36, 66, 189], "same": 36, "system": [37, 71, 72, 77, 111, 133, 134, 138, 156, 158, 175, 183, 198, 199, 200, 201], "podcast": [37, 38, 39, 76, 77], "panel": [37, 38, 39, 40], "discuss": [37, 38, 39, 77, 91, 126, 164, 172, 173, 174, 175, 201], "machin": [38, 194], "stochast": [39, 81, 124, 140], "process": [39, 139, 140, 141, 147, 176, 183, 191], "coursework": [40, 46], "practic": [40, 128], "propos": 40, "profession": 40, "develop": [40, 93], "share": 42, "calendar": 42, "timezon": 43, "widget": 43, "discord": 44, "jupyterbook": 45, "quick": 46, "polici": [46, 182, 191], "attend": 46, "googl": 47, "colab": 47, "advic": 47, "kaggl": 48, "technic": [49, 168], "neuro": [50, 201], "seri": 50, "neurotransmitt": 53, "conscious": 54, "psychophys": 55, "readout": 56, "live": 57, "lab": 57, "spike": [58, 64, 66, 76, 88, 89, 90, 108, 143, 147, 148, 150, 152, 176], "meg": 60, "calcium": 62, "python": [63, 64, 65, 75, 147], "workshop": [63, 65], "lif": [64, 66, 76, 77, 89, 147, 149, 150], "part": [64, 66, 77, 175], "i": [64, 147, 149, 156, 157, 158], "comment": 64, "nano": [64, 66], "recap": [64, 66], "string": 64, "paramet": [64, 76, 81, 82, 109, 140, 141, 147, 156, 158, 165, 176, 182], "oper": [64, 70, 75], "simul": [64, 140, 147, 149, 150, 156, 157, 172, 173, 174, 176, 198, 199, 201], "input": [64, 75, 76, 89, 147, 148, 149, 150, 156, 166, 183], "current": [64, 147], "print": 64, "format": [64, 109], "pretti": 64, "number": [64, 117, 127, 199, 200], "For": 64, "loop": [64, 183], "discret": [64, 72, 81, 139, 182], "membran": [64, 76, 149], "potenti": [64, 75, 76, 149], "random": [64, 66, 81, 140, 198], "synapt": [64, 143, 149, 150], "ad": [64, 66, 76, 77, 127], "list": [64, 76, 77], "ensembl": [64, 148], "statist": [64, 78, 82, 160, 164, 194], "store": 64, "mean": [64, 88, 97, 140, 148, 149], "standard": [64, 148, 165], "deviat": [64, 148], "numpi": 64, "rewrit": [64, 66], "12": [64, 66, 174], "enumer": 64, "index": [64, 66], "aggreg": 64, "13": [64, 174], "arrai": [64, 166], "14": [64, 174], "ii": 66, "histogram": [66, 90], "dictionari": 66, "introduc": [66, 183], "boolean": 66, "binari": [66, 126, 152, 164, 166, 173], "raster": [66, 88], "refractori": 66, "period": 66, "investig": [66, 127, 148], "refactori": 66, "interact": [66, 70, 72, 75, 76, 77, 81, 82, 88, 89, 90, 97, 98, 109, 115, 116, 117, 138, 139, 140, 147, 149, 150, 156, 157, 158, 164, 165, 172, 173, 174, 175, 182, 183, 189, 190, 199, 200, 201], "last": 66, "concept": [66, 202], "linear": [67, 70, 71, 76, 89, 93, 97, 98, 100, 103, 108, 111, 127, 133, 134, 138, 156, 175, 183, 200], "algebra": [67, 70], "survei": [69, 80, 87, 96, 107, 114, 123, 131, 137, 146, 155, 163, 171, 181, 188, 197], "vector": [70, 115, 157], "why": [70, 75, 76, 89, 90, 109, 125], "do": [70, 75, 76, 89, 109, 148], "care": [70, 75, 76], "definit": [70, 175], "properti": [70, 116], "normal": [70, 166], "combin": [70, 140], "span": 70, "independ": 70, "determ": 70, "basi": [70, 115, 116], "out": [70, 157], "dot": 70, "product": [70, 75, 82], "lgn": 70, "fire": [70, 72, 76, 77, 89, 147, 150, 152], "geometri": 70, "polynomi": [70, 100], "proof": [70, 101], "equival": 70, "matric": 71, "solv": [71, 97, 183, 190], "equat": [71, 76, 77, 124, 138, 157, 183], "transform": [71, 150], "creat": [71, 81, 108, 127], "rank": 71, "null": 71, "eigenvalu": [71, 72, 138, 156, 158], "eigenvector": [71, 72, 116, 138], "eigenstuff": [71, 72], "identifi": 71, "from": [71, 81, 90, 115, 124, 125, 134, 157, 174, 175, 182, 190, 198], "matrix": [71, 100, 108, 116, 117, 126, 158, 166, 198], "multipl": [71, 75, 100], "corner": 71, "circuit": 72, "A": [72, 75, 77, 82, 126, 127, 138, 165, 194, 199, 201], "rate": [72, 76, 147, 149, 150, 152, 156, 189], "along": 72, "chang": [72, 75, 76, 77, 115, 150, 158, 173, 190, 192], "both": 72, "complex": [72, 125, 165, 199], "calculu": [73, 75], "differenti": [75, 76, 77, 138], "geometr": [75, 115], "interpret": [75, 76, 127, 138], "analyt": [75, 82], "numer": [75, 77, 156, 157], "rule": [75, 164, 166, 172], "deriv": [75, 77, 97], "postsynapt": [75, 150], "alpha": [75, 190], "chain": [75, 82], "sympi": 75, "sine": 75, "transfer": [75, 148, 189], "gain": [75, 183], "calcul": [75, 90, 116, 117, 156, 164, 166, 198], "variabl": [75, 200, 201], "partial": [75, 158, 183, 200], "demonstr": 75, "riemann": 75, "sum": 75, "vs": [75, 101, 124, 139, 149, 156, 172, 176, 183, 191, 199, 201], "size": [75, 109, 199], "charg": 75, "excitatori": [75, 149, 150, 156, 157], "filter": [75, 125, 168, 174, 175, 183], "popul": [76, 77, 156, 157], "exact": 76, "solut": [76, 77, 82, 126, 138], "condit": [76, 82, 138, 175], "leaki": [76, 77, 147], "without": 76, "v": 76, "v_": 76, "reset": 76, "impact": 76, "one": 76, "thing": 76, "matter": 76, "neuromatch": [76, 77], "bibliographi": [76, 77], "supplement": [76, 77], "popular": [76, 77], "method": [77, 93, 118], "euler": [77, 138], "slope": 77, "line": 77, "approxim": [77, 199], "singl": [77, 88, 156], "take": [77, 174], "more": [77, 109, 164, 165], "simpl": 77, "wilson": [77, 157, 158], "cowan": [77, 157, 158], "phase": [77, 152, 157, 158], "plane": [77, 152, 157, 158], "nullclin": [77, 157, 158], "connect": [77, 126, 127, 150, 198, 199, 200, 201], "oscil": [77, 158], "small": [77, 199, 201], "everyth": 77, "4th": 77, "order": [77, 100, 141], "rung": 77, "kutta": 77, "toward": 77, "rather": 77, "than": [77, 109], "end": 77, "Not": 77, "all": 77, "alik": 77, "stuart": 77, "landau": 77, "probabl": [81, 82, 90, 139, 164, 165, 166, 172], "distribut": [81, 82, 88, 90, 98, 115, 139, 150, 164, 165, 166, 175, 182], "world": [81, 173, 192], "uniform": 81, "walk": [81, 140], "vari": [81, 109, 138, 139, 148, 183, 189], "binomi": 81, "poisson": [81, 108, 176], "continu": [81, 139, 165, 182, 183], "gaussian": [81, 82, 98, 108, 147, 148, 165, 166, 173, 175, 183], "1a": [81, 140, 148, 150], "infer": [82, 165, 173, 178], "b": 82, "joint": [82, 175], "c": [82, 109], "d": 82, "margin": [82, 164, 165, 166, 175], "markov": [82, 139, 168, 173, 191], "likelihood": [82, 98, 164, 166], "maximum": [82, 98], "search": [82, 174], "best": 82, "optim": [82, 90, 93, 97, 108, 124, 177, 182, 183], "conjug": 82, "prior": [82, 165, 166], "posterior": [82, 164, 165, 166], "computation": 82, "net": 82, "causal": [82, 166, 193, 198, 199, 200, 201], "type": [83, 90, 147], "further": [84, 93, 104, 111, 120, 126, 134, 143, 152, 160, 168, 178, 183, 185, 194], "retriev": [88, 108, 109, 124, 125, 126, 127, 175], "warm": 88, "spike_tim": 88, "warmer": 88, "count": [88, 108], "total": 88, "compar": [88, 100, 101, 120, 174, 199], "median": 88, "subset": [88, 201], "inter": 88, "interv": [88, 99, 139], "isi": [88, 90, 147], "form": 88, "fit": [88, 92, 93, 100, 108, 109, 141, 166, 175, 200], "hand": 88, "how": [89, 143, 148, 174, 182, 183, 192, 201], "dv_m": 89, "IF": 89, "inhibitori": [89, 149, 156, 157], "inhibit": [89, 152, 158], "notat": [89, 90, 97, 98, 99, 100, 108, 109, 115, 116, 117], "entropi": 90, "mass": 90, "pmf": 90, "foundat": [90, 178], "tip": 93, "On": [93, 191], "regress": [93, 97, 98, 100, 108, 109, 200, 201], "llh": 93, "maxim": [93, 175, 176], "mse": [93, 97, 100], "minim": 93, "research": 93, "squar": [97, 100, 201], "least": [97, 100, 201], "mle": 98, "probabilist": [98, 189], "confid": [99, 172], "bootstrap": 99, "resampl": 99, "replac": 99, "ordinari": 100, "qualiti": 100, "bia": [101, 200, 201], "varianc": [101, 117, 140], "trade": 101, "off": [101, 191], "tradeoff": [101, 172, 183], "decomposit": 101, "cross": [102, 109], "valid": [102, 109], "akaik": 102, "s": [102, 125, 126, 174], "criterion": 102, "aic": 102, "glm": [108, 200], "encod": [108, 120, 126, 127, 166], "load": [108, 109, 124, 125, 126, 127, 175], "retin": 108, "ganglion": 108, "cell": [108, 125, 166], "predict": [108, 173, 189], "challeng": 108, "nonlinear": [108, 111, 118, 124], "scipi": 108, "classifi": 109, "regular": [109, 127], "sigmoid": 109, "scikit": 109, "decod": [109, 124, 127], "accuraci": [109, 172, 174], "featur": 109, "lead": 109, "overfit": 109, "can": 109, "l_2": 109, "l_1": 109, "kei": 109, "between": [109, 139, 148, 156, 183], "sparsiti": [109, 199], "penalti": 109, "full": 109, "detail": 109, "dimension": [110, 111, 117, 118, 126, 138], "reduct": [110, 111, 117, 118, 126], "princip": [111, 116], "compon": [111, 116, 117], "other": 111, "interfac": 111, "shown": 111, "view": 115, "correl": [115, 116, 126, 148, 150, 164, 165, 199], "multivari": 115, "draw": 115, "new": [115, 127], "orthonorm": 115, "base": [115, 149, 152, 182, 192], "onto": [115, 116], "plai": [115, 174], "covari": [116, 164, 165], "coeffici": 116, "scree": 117, "explain": 117, "pc": 117, "examin": [117, 182, 189], "denois": 117, "add": [117, 127], "t": [118, 139], "sne": 118, "appli": 118, "run": [118, 166, 176, 182], "perplex": 118, "pytorch": [120, 124, 125, 126], "recommend": 120, "feed": 124, "forward": [124, 138, 173, 176], "split": 124, "gradient": 124, "descent": 124, "depth": 124, "width": 124, "sgd": 124, "gd": 124, "convolut": [125, 126, 127], "output": [125, 148, 183], "shape": 125, "layer": [125, 126, 127], "cnn": [125, 126], "norm": [126, 160], "orient": [126, 202], "discrimin": 126, "quantit": 126, "comparison": 126, "dissimilar": 126, "rdm": 126, "similar": [126, 199], "curv": [126, 127, 156, 157], "reduc": [126, 147], "fulli": [126, 127], "max": 126, "pool": 126, "classif": 126, "problem": [126, 127, 182], "z": 126, "score": 126, "explan": 126, "dive": 127, "devic": 127, "gpu": 127, "cpu": 127, "execut": 127, "set_devic": 127, "peer": 127, "insid": 127, "improv": 127, "critic": 127, "delv": 127, "frame": 132, "lectur": 134, "One": 138, "oscillatori": 138, "determinist": [138, 140], "two": [138, 156, 198, 201], "dimens": 138, "multi": [138, 190], "trajectori": [138, 156, 157, 172], "3a": [138, 147], "3b": [138, 147], "stream": 138, "telegraph": 139, "switch": 139, "transit": [139, 156], "valu": [139, 147, 156, 157, 158, 182, 189, 190], "perspect": 139, "propag": 139, "equilibrium": 139, "stabl": [139, 156], "e": [140, 149, 156, 157, 158, 176], "coli": 140, "1b": [140, 148, 150], "influenc": [140, 183], "choic": 140, "ornstein": [140, 147], "uhlenbeck": [140, 147], "ou": [140, 141, 147], "drift": [140, 172], "diffus": [140, 172], "observ": [140, 183, 200, 201], "balanc": [140, 149, 152], "empir": 140, "autoregress": 141, "residu": 141, "higher": 141, "monkei": 141, "typewrit": 141, "biolog": 142, "text": 143, "book": 143, "hodgkin": 143, "huxlei": 143, "But": 143, "point": [143, 156, 158], "extend": [143, 158], "simplifi": 143, "synaps": [143, 149, 150], "short": [143, 149, 158], "term": [143, 149], "plastic": [143, 149, 150], "dc": 147, "amplitud": 147, "white": [147, 148], "gwn": [147, 148], "analyz": [147, 150, 157, 172, 182], "irregular": 147, "f": [147, 156, 157], "sig_gwn": 147, "cv_": 147, "synchroni": 148, "origin": [148, 183], "synchron": 148, "implic": 148, "measur": [148, 149, 173, 174, 183], "affect": [148, 164], "rational": 148, "behind": 148, "mu": 148, "sigma": 148, "transmiss": 149, "static": 149, "conduct": [149, 150], "free": 149, "depress": 149, "std": 149, "facilit": 149, "stf": 149, "stp": 149, "stdp": 150, "delta": 150, "w": 150, "keep": 150, "p": 150, "dp": 150, "show": 150, "evolut": [150, 183], "2a": 150, "strength": [150, 201], "2b": 150, "increas": 150, "presynapt": 150, "receiv": 150, "amplif": 152, "stabil": [152, 156, 158], "supralinear": 152, "scheme": [156, 157], "finit": 156, "fix": [156, 158, 172], "extern": 156, "relationship": 156, "unstabl": 156, "via": 156, "drive": 156, "descript": 157, "wc": 157, "field": 157, "r_i": 157, "r_e": [157, 158], "displaystyl": [157, 158], "big": 157, "frac": [157, 158], "dr_e": 157, "dt": 157, "dr_i": 157, "limit": 158, "cycl": 158, "jacobian": 158, "wee": 158, "posit": [158, 166], "isn": 158, "g_e": 158, "non": [158, 201], "puls": 158, "induc": 158, "persist": 158, "hidden": [164, 165, 167, 168, 172, 173], "gone": [164, 182], "fishin": 164, "decid": 164, "where": [164, 182], "fish": [164, 182], "util": [164, 165], "being": 164, "either": 164, "side": 164, "guess": 164, "locat": [164, 165], "belief": [164, 165, 182], "formula": 164, "astrocat": [165, 174], "multipli": 165, "mixtur": [165, 166], "complic": 165, "cat": 165, "cost": [165, 183], "theorem": 165, "variou": 165, "auditori": 166, "true": [166, 174, 176], "hypothet": 166, "x": 166, "hat": 166, "stimuli": 166, "expect": [166, 175, 176], "some": [166, 182], "generate_data": 166, "log": 166, "kalman": [168, 174, 175, 183], "aspect": 168, "sequenti": 172, "ratio": 172, "sprt": 172, "under": 172, "stop": 172, "speed": 172, "versu": 172, "revisit": 172, "hmm": [173, 176], "futur": 173, "forget": 173, "quantifi": 174, "movement": 174, "collar": 174, "action": [174, 183, 190], "long": 174, "ld": [175, 183], "adjust": 175, "ey": 175, "gaze": 175, "pykalman": 175, "handl": 175, "blink": 175, "smooth": 175, "em": [175, 176], "algorithm": [175, 176, 191], "m": [175, 176], "case": 176, "studi": 176, "frozen": 176, "sequenc": 176, "backward": 176, "learnt": 176, "progress": 176, "control": [177, 178, 182, 183, 198], "catch": 182, "reward": [182, 189, 190], "should": 182, "you": 182, "act": [182, 190, 191], "follow": 182, "sensit": 182, "open": 183, "close": 183, "fly": 183, "quadrat": 183, "regul": 183, "lqr": 183, "constraint": 183, "goal": 183, "move": 183, "desir": 183, "lqg": 183, "conjunct": 183, "effort": 183, "reinforc": [184, 192], "tempor": 189, "td": 189, "guarante": 189, "cs": 189, "discount": 189, "factor": 189, "magnitud": 189, "match": 189, "arm": 190, "bandit": 190, "epsilon": 190, "greedi": 190, "updat": [190, 192], "q": [191, 192], "mdp": 191, "sarsa": 191, "rl": 192, "dyna": 192, "much": 192, "when": 192, "econometr": 194, "epidemiolog": 194, "broad": 194, "rang": 194, "relev": 194, "intervent": 198, "trial": 198, "recov": [198, 200], "perturb": 198, "causat": 199, "try": 199, "larg": [199, 201], "metric": 199, "low": 199, "resolut": 199, "coars": 199, "averag": 199, "across": 199, "group": 199, "result": 199, "truth": 199, "simultan": 200, "approach": 200, "plu": 200, "lasso": 200, "omit": [200, 201], "instrument": 201, "iv": 201, "high": 201, "level": 201, "stage": 201, "granger": 201}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx": 56}})